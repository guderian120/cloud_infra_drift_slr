{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Processing: Drop Files with Missing Columns\n",
    "\n",
    "This notebook processes all CSV files in the Arxiv folder and:\n",
    "1. Identifies CSVs with missing columns\n",
    "2. Saves the data from those CSVs to a 'dropped.csv' file with information about missing columns\n",
    "3. Removes the CSVs with missing columns from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18: Files Successfully loaded \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the directory path\n",
    "csv_dir = Path(r'c:\\Users\\user\\Downloads\\New_SLR\\Query_Results')\n",
    "csv_files = []\n",
    "for root, directory, file in os.walk(csv_dir):\n",
    "        for path in directory:\n",
    "            for file in os.listdir(os.path.join(root, path)):\n",
    "                root_dir = os.path.join(root, path)\n",
    "                csv_files.append(os.path.join(root_dir, file))\n",
    "        \n",
    "print(\n",
    "    f\"{len(csv_files)}: Files Successfully loaded \\n\"\n",
    ")       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected columns: {'DOI', 'Author Names', 'Abstract', 'Publication Title', 'Publication Year', 'PDF Link', 'Paper Link', 'Publication Type', 'Paper Title'}\n"
     ]
    }
   ],
   "source": [
    "# Define the expected columns (based on the standard structure)\n",
    "expected_columns = {\n",
    "    'Paper Title',\n",
    "    'Paper Link',\n",
    "    'Publication Year',\n",
    "    'Publication Type',\n",
    "    'Publication Title',\n",
    "    'Author Names',\n",
    "    'DOI',\n",
    "    'PDF Link',\n",
    "    'Abstract'\n",
    "}\n",
    "\n",
    "print(f\"Expected columns: {expected_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ arxiv_query_1.csv has all expected columns\n",
      "✓ arxiv_query_2.csv has all expected columns\n",
      "✓ arxiv_query_3.csv has all expected columns\n",
      "✓ arxiv_query_4.csv has all expected columns\n",
      "✓ arxiv_query_5.csv has all expected columns\n",
      "✓ arxiv_query_6.csv has all expected columns\n",
      "✓ google_scholar_query_1.csv has all expected columns\n",
      "✓ google_scholar_query_2.csv has all expected columns\n",
      "✓ google_scholar_query_3.csv has all expected columns\n",
      "✓ google_scholar_query_4.csv has all expected columns\n",
      "✓ google_scholar_query_5.csv has all expected columns\n",
      "✓ google_scholar_query_6.csv has all expected columns\n",
      "✓ scispace_query_1.csv has all expected columns\n",
      "✓ scispace_query_2.csv has all expected columns\n",
      "✓ scispace_query_3.csv has all expected columns\n",
      "✓ scispace_query_4.csv has all expected columns\n",
      "✓ scispace_query_5.csv has all expected columns\n",
      "✓ scispace_query_6.csv has all expected columns\n"
     ]
    }
   ],
   "source": [
    "# Lists to store information about files with missing columns\n",
    "dropped_data = []\n",
    "files_to_drop = []\n",
    "\n",
    "# Check each CSV file for missing columns\n",
    "for csv_file in csv_files:\n",
    "    \n",
    "    csv_file_name = csv_file.split(\"\\\\\")[-1]\n",
    "                            \n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Get the actual columns\n",
    "        actual_columns = set(df.columns)\n",
    "        \n",
    "        # Find missing columns\n",
    "        missing_columns = expected_columns - actual_columns\n",
    "        \n",
    "        if missing_columns:\n",
    "            print(f\"\\n{csv_file_name} is missing columns: {missing_columns}\")\n",
    "            \n",
    "            # Add missing column(s) as a new column in the dataframe\n",
    "            df['Missing_Columns'] = ', '.join(sorted(missing_columns))\n",
    "            df['Source_File'] = csv_file_name\n",
    "            \n",
    "            # Add to dropped data\n",
    "            dropped_data.append(df)\n",
    "            files_to_drop.append(csv_file)\n",
    "        else:\n",
    "            print(f\"✓ {csv_file_name} has all expected columns\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {csv_file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No files with missing columns found. No 'dropped.csv' created.\n"
     ]
    }
   ],
   "source": [
    "# Create the dropped.csv file if there are any files with missing columns\n",
    "if dropped_data:\n",
    "    # Combine all dropped data\n",
    "    dropped_df = pd.concat(dropped_data, ignore_index=True)\n",
    "    \n",
    "    # Save to dropped.csv\n",
    "    output_file = arxiv_dir / 'dropped.csv'\n",
    "    dropped_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Created 'dropped.csv' with {len(dropped_df)} rows from {len(files_to_drop)} files\")\n",
    "    print(f\"Output file: {output_file}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\nSummary of dropped files:\")\n",
    "    for file in files_to_drop:\n",
    "        print(f\"  - {file.name}\")\n",
    "else:\n",
    "    print(\"\\nNo files with missing columns found. No 'dropped.csv' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Delete the files with missing columns\n",
    "# Uncomment the code below to actually delete the files\n",
    "\n",
    "# if files_to_drop:\n",
    "#     print(f\"\\nDeleting {len(files_to_drop)} files with missing columns...\")\n",
    "#     for file in files_to_drop:\n",
    "#         try:\n",
    "#             file.unlink()\n",
    "#             print(f\"  Deleted: {file.name}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"  Error deleting {file.name}: {e}\")\n",
    "#     print(\"\\nDeletion complete!\")\n",
    "# else:\n",
    "#     print(\"\\nNo files to delete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display preview of dropped.csv if it exists\n",
    "dropped_csv_path = arxiv_dir / 'dropped.csv'\n",
    "if dropped_csv_path.exists():\n",
    "    print(\"\\nPreview of dropped.csv:\")\n",
    "    preview_df = pd.read_csv(dropped_csv_path)\n",
    "    print(f\"\\nShape: {preview_df.shape}\")\n",
    "    print(f\"\\nColumns: {list(preview_df.columns)}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    display(preview_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
