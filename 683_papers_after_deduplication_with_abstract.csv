"Paper Title","Paper Link","Publication Year","Publication Type","Publication Title","Author Names","DOI","PDF Link","Open Access","Abstract"
"Infrastructure as Code (IaC): Insights on Various Platforms","https://scispace.com/papers/infrastructure-as-code-iac-insights-on-various-platforms-2eonqds3","2023","Journal Article","Advances in intelligent systems and computing","","10.1007/978-981-19-5443-6_33","","No","In the present-day tech-stack, cloud computing is evolving as a successful and one of the popular fields of technology where the new businesses are achieving success by deploying their functionalities, products, data, and services on cloud instead of on-premises system and that also without depending on any physical component. Infrastructure as code (IaC) is a set of methodologies which uses code to set up the install packages, virtual machines and networks, and configure environments. A successful IaC implementation and adoption by developers requires a broad set of skills and knowledge. It is DevelopmentOperations’ tactic of provisioning an application’s infrastructure and managing it through binary readable configuration files, instead of any hardware configuration."
"Integrating Emerging Technologies with Infrastructure as Code in Distributed Environments","https://scispace.com/papers/integrating-emerging-technologies-with-infrastructure-as-1zdu44xpb0","2024","Journal Article","","Syed imran Abbas
Ankit Garg","10.1109/icaaic60222.2024.10575600","","No","Manual provisioning of infrastructure limited flexibility, scalability, and stability in distributed environments. The adoption of Infrastructure as Code (IaC) principles has dramatically enhanced deployment agility, reducing infrastructure change implementation to mere minutes. Automation facilitated dynamic scaling, optimizing resource utilization and cost efficiency. By standardizing configurations as code, IaC improved consistency and reliability, mitigating the risks associated with configuration drift and security vulnerabilities. This shift significantly reduced operational overhead, allowing IT teams to concentrate on strategic initiatives. Uniform and auditable configurations strengthened security and compliance, ensuring adherence to regulatory standards. The integration of IaC with emerging technologies has revolutionized organizational operations, enabling enterprises to navigate complex digital landscapes with increased agility and resilience. Through automation and standardization, organizations are now better positioned for sustained success and competitiveness in the evolving digital era."
"Enterprise SaaS Workloads on New-Generation Infrastructure-as-Code (iac) on Multi-Cloud Platforms","https://scispace.com/papers/enterprise-saas-workloads-on-new-generation-infrastructure-1qohenqhdndz","","","","Sandesh Achar","10.18034/gdeb.v10i2.652","","No","Cloud Computing has become the primary model used by DevOps practitioners and researchers to provision infrastructure in minimal time. But recently, the traditional method of using a single cloud provider has fallen out of favor due to several limitations regarding performance, compliance rules, geographical reach, and vendor lock-in. To address these issues, industry and academia are implementing multiple clouds (i.e., multi-cloud). However, managing the infrastructure provisioning of enterprise SaaS applications faces several challenges, such as configuration drift and the heterogeneity of cloud providers. This has seen Infrastructure-as-Code (IaC) technologies being used to automate the deployment of SaaS applications. IaC facilitates the rapid deployment of new versions of application infrastructures without degrading quality or stability. Therefore, this work presents a vision of uniformly managing the infrastructure provisioning of enterprise SaaS applications that utilize multiple cloud providers. Hence, we introduce an initial design for the IaC-based Multi-Cloud Deployment pattern and discuss how it addresses the relative challenges."
"Effectively managing configuration drift","https://scispace.com/papers/effectively-managing-configuration-drift-2jto19wui8","2011","Patent","","Shon K. Shah
Prasanna Sridhar
James P. Finnigan
Srivatsan Parthasarathy
Alan H. Goodman","","","No","Configuration drift refers to changes made over time that cause a computer or service to deviate from a desired configuration. Configuration drift of a group of machines can be managed by defining configuration intent. Intent is defined by defining a configuration baseline comprised of a collection of related configuration rules. Configuration rules include settings, and targets which can be any managed entity that enables reporting of non-compliance at a more granular level. A configuration baseline can be completed by reading configuration rules from one or more well-configured computers. Configuration drift is assessed by comparing actual values to the configuration baseline values and is reported at a managed entity level instead of at a machine level. Remediation, returning the computer to a state of compliance with the configuration baseline, can be performed on demand. Remediations performed over time are retained and applied to a new instance of the service to eliminate configuration drift on the new instance."
"On Unifying the Compliance Management of Applications Based on IaC Automation","https://scispace.com/papers/on-unifying-the-compliance-management-of-applications-based-yq43btlh","2022","Journal Article","","Ghareeb Falazi
Uwe Breitenbücher
Frank Leymann
Miles Stötzner
Evangelos Ntentos
Uwe Zdun
Martin Becker
Elena Heldwein","10.1109/ICSA-C54293.2022.00050","","No","Infrastructure-as-Code (IaC) technologies are used to automate the deployment of cloud applications. They promote the usage of code to define and configure the IT infrastructure of cloud applications allowing them to benefit from conventional software development practices, which facilitates the rapid deployment of new versions of application infrastructures without sacrificing quality or stability. On the other hand, enterprise applications need to conform to compliance regarding external regulations and internal policies. Many of these compliance rules affect the application architecture on which IaC code operates. However, managing the architectural compliance of IaC-based application deployments faces a number of challenges, such as configuration drift and the heterogeneity of IaC technologies. Therefore, in this work, we present a vision on how to uniformly manage the compliance of the infrastructure of applications that utilize heterogeneous IaC technologies for deployment automation. To this end, we introduce an initial design for the IaC-based Architectural Compliance Management Framework and discuss how it addresses the corresponding challenges."
"Challenges Towards Modeling and Generating Infrastructure-as-Code","https://scispace.com/papers/challenges-towards-modeling-and-generating-infrastructure-as-24iepbs1","2023","Proceedings Article","International Conference on Performance Engineering","Galia Novakova Nedeltcheva","10.1145/3578245.3584937","","Yes","The infrastructure-as-code (IaC) is an approach for automating the deployment, maintenance, and monitoring of environments for online services and applications that developers usually do manually. The benefit is not only reducing the time and effort but also the operational costs. This paper aims at describing our experience in applying IaC in cloud-native applications, mainly discussing the key challenges towards modeling and generating IaC faced in the ongoing project Programming Trustworthy Infrastructure-As-Code in a Secure Framework (PIACERE). The concluding insights could spur the wider adoption of IaC by software developers."
"Implementing Infrastructure as Code (IaC) for Scalable DevOps Automation in Hybrid Cloud","https://scispace.com/papers/implementing-infrastructure-as-code-iac-for-scalable-devops-5nzf32htp115","2024","Journal Article","Journal of Sustainable Solutions.","Venkat Marella","10.36676/j.sust.sol.v1.i4.46","https://jss.thewriters.in/index.php/jss/article/download/46/39","No","The devOps approach known as Infrastructure as Code (IaC) automates all of the infrastructure's requirements to improve deployment speed, security, scalability, and automatic backup and restoration. Writing code that explains the infrastructure—which allows resources to be generated, destroyed, scaled, replaced, and relocated with ease—is the focus of Infrastructure as a Code (IaC). Installing an operating system on it, setting up servers on instance, adjusting how the software in the instances communicates with one other, and much more are all part of the scripting environment process. In order to achieve an effective infrastructure across all sectors while maintaining security via the usage of public and private clouds, this paper examines a number of tools and technology sets. By automating infrastructure deployment and procedures, continually enhancing the integration and delivery process, and monitoring application performance indicators, DevOps dismantles communication silos and enhances teamwork and productivity. In DevOps, automation is essential, and ""Infrastructure as code (IaC)"" is a critical component of automation. The management of infrastructure in cloud and physical datacenter systems will also be covered in this article, along with the impact of agile, DevOps, and IaC on infrastructure management. e. In order to achieve an effective infrastructure across all sectors while maintaining security via the usage of public and private clouds, this paper examines a number of tools and technology sets. Our results indicate that adopting IaC has many advantages, but there may also be some difficulties in putting IaC into practice. Additionally, the research recognizes the contribution of DevOps, cloud systems, and agile to the deployment of Infrastructure as a code."
"Empowering DevOps with Infrastructure as Code :Trends, Tools and Techniques","https://scispace.com/papers/empowering-devops-with-infrastructure-as-code-trends-tools-1dpc33eeo9","2024","Journal Article","Indian Scientific Journal Of Research In Engineering And Management","Sarita Ranjan","10.55041/ijsrem35407","https://scispace.com/pdf/empowering-devops-with-infrastructure-as-code-trends-tools-1dpc33eeo9.pdf","No","DevOps has arisen as a pillar of modern software engineering, emphasising the integration of development and operations to ensure effective product delivery. Infrastructure as Code (IaC) is an important DevOps technique that involves defining and managing infrastructure requirements using code, enabling for automated provisioning and maintenance. This technique enhances traceability, reuse, and consistency across development and production environments. The introduction of microservices architectures has increased project teams’ infras- tructure responsibilities, making IaC essential for delivering reliable and efficient deployments. IaC enables developers to describe infrastructure in code, simplifying the deployment process. In both large and small businesses, IaC is essen- tial for supporting efficient DevOps processes.The most recent breakthroughs, tools, and techniques in IaC demonstrate a revolutionary impact on software development and deployment workflows. As more businesses adopt cloud-native designs and containerisation technologies, the requirement for automated infrastructure provisioning grows, leading in the growth of IaC tools and methodologies. Organisations that combine IaC with continuous integration and delivery (CI/CD) pipelines can re- duce time-to-market and improve operational efficiency. IaC not only automates infrastructure management, but it also includes software engineering principles like version control and testing into infrastructure provisioning, which improves consistency and reliability. This democratisation of infrastructure management encourages increased collaboration across cross-functional teams, hence improving accountability and innovation. Implementing IaC is therefore crucial for achieving agility, scalability, and resilience in the digital age. Index Terms—Iac, DevOps, CI/CD, Automation, Cloud-native, Infrastructure Provisioning ,Terraform, Ansible, AWS CloudFor- mation"
"Pipeline Infrastructure Required to Meet the Requirements on AI","https://scispace.com/papers/pipeline-infrastructure-required-to-meet-the-requirements-on-2lumkhzw","2023","Journal Article","IEEE Software","Markus Borg","10.1109/MS.2022.3211687","","No","The theme of this issue is infrastructure as code (IaC). This concept typically refers to the application of software engineering practices in managing deployment infrastructure. Moving from physical hardware to virtual machines using configuration files that are way more flexible—and they can be version controlled and distributed. As such, IaC paves the way for automation and DevOps. This column touches upon similar topics: pipeline infrastructure to meet regulatory requirements on trustworthy AI solutions."
"Demystifying infrastructure automation: Evolving from scripts to self-healing systems","https://scispace.com/papers/demystifying-infrastructure-automation-evolving-from-scripts-1bdyyexosazn","2025","Journal Article","World Journal Of Advanced Research and Reviews","Mahipal Reddy Yalla","10.30574/wjarr.2025.26.2.1987","","No","Infrastructure automation has undergone a revolutionary transformation from rudimentary scripting tools to sophisticated AI-driven platforms, fundamentally reshaping enterprise IT operations and competitive dynamics. This evolution began with basic automation scripts in the 1990s, which offered limited coverage and required extensive maintenance, before progressing through several distinct technological epochs. The emergence of configuration management platforms between 2005-2012 introduced the transformative ""infrastructure as code"" paradigm, enabling version-controlled deployments and reducing configuration drift by over 80%. Cloud orchestration and containerization subsequently accelerated this progression, with enterprises achieving deployment time reductions exceeding 94% and dramatic improvements in operational efficiency. The integration of artificial intelligence represents the latest evolutionary stage, with AIOps platforms detecting anomalies before conventional tools and autonomously resolving routine incidents with exceptional accuracy. Beyond technical benefits, these advancements deliver substantial business value, including accelerated time-to-market, dramatically reduced operational costs, enhanced resilience, improved scalability, and optimized talent utilization. Organizations leveraging advanced automation demonstrate significantly higher profit margins, market share growth, and innovation throughput compared to traditional counterparts. As infrastructure environments continue to increase in complexity and scale, AI-driven automation has become not merely a technological advancement but a strategic business imperative essential for maintaining competitive advantages in rapidly evolving digital markets."
"Infrastructure as Code (IaC) in Cloud Migration: Enhancing Automation, Security and Scalability in AWS","https://scispace.com/papers/infrastructure-as-code-iac-in-cloud-migration-enhancing-rmpazk5bxp0t","2025","Journal Article","World Journal Of Advanced Research and Reviews","S. Challa","10.30574/wjarr.2025.26.2.1989","","No","This article examines the strategic implementation of Infrastructure as Code (IaC) methodologies in enterprise AWS cloud migrations, demonstrating how organizations can enhance automation, security, and scalability throughout their infrastructure lifecycle. Through analysis of implementation patterns across diverse industry sectors, the article identifies critical success factors for effective IaC adoption, including standardization through Git-based repositories, embedding security controls directly in templates, integration with CI/CD pipelines, and implementation of resilient scaling and disaster recovery mechanisms. The article combines qualitative assessment of organizational practices with quantitative metrics analysis to provide a comprehensive evaluation of IaC benefits, challenges, and emerging trends. The article reveals that organizations implementing mature IaC approaches achieve substantial improvements in deployment efficiency, configuration consistency, security posture, and operational costs while establishing foundations for future automation capabilities. The article further explores emerging technologies including AI-assisted template generation, automated drift detection, policy-as-code frameworks, and predictive scaling algorithms that represent the evolving frontier of infrastructure automation. These insights provide technology leaders with actionable guidance for implementing IaC as a strategic capability that aligns infrastructure management with broader digital transformation objectives while maintaining the governance and compliance requirements essential in enterprise environments."
"Infrastructure as code for dynamic deployments","https://scispace.com/papers/infrastructure-as-code-for-dynamic-deployments-1dkms5jq","2022","Proceedings Article","Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering","Daniel Sokolowski","10.1145/3540250.3558912","https://scispace.com/pdf/infrastructure-as-code-for-dynamic-deployments-1dkms5jq.pdf","Yes","Modern DevOps organizations require a high degree of automation to achieve software stability at frequent changes. Further, there is a need for flexible, timely reconfiguration of the infrastructure, e.g., to use pay-per-use infrastructure efficiently based on application load. Infrastructure as Code (IaC) is the DevOps tool to automate infrastructure. However, modern static IaC solutions only support infrastructures that are deployed and do not change afterward. To implement infrastructures that change dynamically over time, static IaC programs have to be (updated and) re-run, e.g., in a CI/CD pipeline, or configure an external orchestrator that implements the dynamic behavior, e.g., an autoscaler or Kubernetes operator. Both do not capture the dynamic behavior in the IaC program and prevent analyzing and testing the infrastructure configuration jointly with its dynamic behavior. To fill this gap, we envision dynamic IaC, which augments static IaC with the ability to define dynamic behavior within the IaC program. In contrast to static IaC programs, dynamic IaC programs run continuously. They re-evaluate program parts that depend on external signals when these change and automatically adjust the infrastructure accordingly. We implement DIaC as the first dynamic IaC solution and demonstrate it in two realistic use cases of broader relevance. With dynamic IaC, ensuring the program’s correctness is even harder than for static IaC because programs may define many target configurations in contrast to only a few. However, for this reason, it is also more critical. To solve this issue, we propose automated, specialized property-based testing for IaC programs and implement it in ProTI."
"PipeConf: An Integrated Architecture for the Automated Configuration of Network Assets","https://scispace.com/papers/pipeconf-an-integrated-architecture-for-the-automated-1oqi6b3h","2022","Journal Article","IEEE Transactions on Network and Service Management","Aecio Pires
Fernando B. Matos
Aldri Santos
Diego Pessoa
Paulo Ditarso Maciel","10.1109/TNSM.2022.3195382","","No","The manual management of network assets is susceptible to configuration errors, lack of standardization, a large amount of repetitive work, and little or no traceability of changes over time. The Infrastructure as Code (IaC) approach makes it possible to automate the process of configuring resources such as operating systems, network services, containers, and applications, by treating them as software and allowing standardization and configuration rollback. This paper proposes an integrated architecture based on different software tools that use the IaC approach to automate the configuration of network assets, considering different models and manufacturers. A quantitative analysis shows the architecture’s efficiency in response time and scalability. The architecture has achieved a proportional gain of 83% in the average response time to manage 128 assets, with no significant increase in processing and memory usage."
"Resolving configuration drift for computing resource stacks","https://scispace.com/papers/resolving-configuration-drift-for-computing-resource-stacks-33ouczq8r0","2020","Patent","","Hussain Amjad
Kumar Anil
Lohan Ryan John
Chakravarthy Diwakar
Lins Julio Cesar Dos Santos
Nakkeeran Prabhu Anand","","","No","This disclosure describes techniques for resolving discrepancies that occur to interrelated computing resources from computing resource drift. Users may describe computing resources in an infrastructure template. However, computing resource drift occurs when “out-of-band” modifications are made to the computing resources and are not reflected in the infrastructure template. To resolve discrepancies between the infrastructure template and the out-of-band modifications to the computing resources, a notification may be output to a user account associated with the computing resources detailing the differences. An updated infrastructure template may be received that resolves the differences, such as by including configuration settings that reflect a current state of the computing resources. The computing resources may then execute a workflow using the updated template, such that the workflow is executed on all of the computing resources in a current state."
"Adoption, Support, and Challenges of Infrastructure-as-Code: Insights from Industry","https://scispace.com/papers/adoption-support-and-challenges-of-infrastructure-as-code-596hu955ap","2019","Proceedings Article","International Conference on Software Maintenance","Michele Guerriero
Martin Garriga
Damian A. Tamburri
Fabio Palomba","10.1109/ICSME.2019.00092","","No","Infrastructure-as-code (IaC) is the DevOps tactic of managing and provisioning infrastructure through machine-readable definition files, rather than physical hardware configuration or interactive configuration tools. From a maintenance and evolution perspective, the topic has picked the interest of practitioners and academics alike, given the relative scarcity of supporting patterns, best practices, tools, and software engineering techniques. Using the data coming from 44 semistructured interviews to senior developers of as many companies, in this paper we shed light on the state of the practice in the adoption of IaC and the key software engineering challenges in the field. Particularly, we investigate (i) how practitioners adopt and develop IaC, (ii) which support is currently available, i.e., the typically used tools and their advantages/disadvantages, and (iii) what are the practitioner's needs when dealing with IaC development, maintenance, and evolution. Our findings clearly highlight the need for more research in the field: the support provided by currently available tools is still limited, and developers feel the need of novel techniques for testing and maintaining IaC code."
"Автоматизація міграції програмного забезпечення у хмарну архітектуру із використанням інструменту інфраструктури як код Terraform у середовищі AWS","https://scispace.com/papers/avtomatizatsiia-migratsiyi-programnogo-zabezpechennia-u-4rjrc04t7fnn","2024","Journal Article","Komp'ûterno-ìntegrovanì tehnologìï: osvìta, nauka, virobnictvo","S. Behlitsov","10.36910/6775-2524-0560-2024-56-12","","No","У цій статті розглядається комплексний підхід до автоматизації надання інфраструктури за допомогою Terraform і AWS. Основною метою цього дослідження було оптимізувати розгортання та керування хмарними ресурсами за допомогою практик інфраструктури як коду (IaC). Стаття починається з пояснення фундаментальних принципів інфраструктури як коду, підкреслюючи її переваги з точки зору послідовності, повторюваності та співпраці. Центральне місце в цій методології займає Terraform, інструмент із відкритим кодом, розроблений для декларативного керування конфігурацією. Здатність Terraform визначати компоненти інфраструктури за допомогою простих, зрозумілих для людини файлів конфігурації забезпечує потужний механізм для надання та керування хмарними ресурсами в різних провайдерів. Ключовим моментом реалізації є використання AWS як хмарного провайдера. AWS пропонує широкий спектр послуг, від обчислювальних екземплярів (EC2) до керованих баз даних (RDS) і безсерверних обчислень (Lambda). У статті розглядаються конкретні випадки використання, коли Terraform використовується для автоматизації надання ресурсів AWS, таких як екземпляри EC2 для масштабованих веб-додатків, бакети S3 для зберігання об’єктів і конфігурації VPC для ізоляції мережі. Важливим аспектом, який обговорюється в статті, є керування станом Terraform, який відстежує поточний стан розгорнутих ресурсів і полегшує співпрацю між членами команди. Стратегії обробки файлів стану, включно з конфігураціями віддаленої серверної частини за допомогою Amazon S3 для блокування, вивчаються, щоб забезпечити узгодженість і уникнути конфліктів під час одночасного розгортання. Крім того, стаття стосується модулів Terraform, які інкапсулюють багаторазові конфігурації для різних компонентів інфраструктури, сприяючи багаторазовому використанню коду та зручності обслуговування. Завдяки модульній конфігурації команди можуть стандартизувати найкращі практики та застосовувати політики в різних середовищах, від розробки до виробництва. Інтеграція Terraform з конвеєрами CI/CD автоматизує тестування та розгортання змін інфраструктури, сприяючи гнучкості та зменшуючи ручне втручання. Ця автоматизація не тільки прискорює доставку оновлень інфраструктури, але й підвищує загальну надійність системи за допомогою автоматизованого тестування та механізмів відкату."
"PipeConf: Uma Arquitetura Integrada Para Configuração Automatizada De Ativos De Rede Heterogêneos","https://scispace.com/papers/pipeconf-uma-arquitetura-integrada-para-configuracao-fkngdej7qdfi","","","","Aécio S. Pires
Paulo D. Maciel Jr.
Diego Pessoa
Fernando Matos
Aldri Santos","10.5753/wgrs.2021.17189","","No","O gerenciamento manual de ativos de rede está suscetível a erros de configuração, falta de padronização, grande quantidade de trabalho repetitivo e pouca ou nenhuma rastreabilidade de alterações ao longo do tempo. A abordagem Infrastructure as Code (IaC) permite automatizar o processo de configuração de recursos como sistemas operacionais, serviços de rede, contêineres e aplicações, tratando-os como software e possibilitando a padronização e reversão da configuração. Este artigo propõe uma arquitetura integrada a partir de ferramentas de softwares diferentes e que usam a abordagem IaC, a fim de automatizar a configuração de ativos de rede, considerando diferentes modelos e fabricantes. Uma avaliação quantitativa mostra a eficiência da arquitetura em tempo de resposta e escalabilidade. A arquitetura obteve um ganho proporcional de 83% no tempo médio de resposta para gerenciar 128 ativos, sem aumento significativo no uso de processamento e memória."
"Infrastructure as Code (IaC) and Its Role in Achieving DevOps Goals","https://scispace.com/papers/infrastructure-as-code-iac-and-its-role-in-achieving-devops-392vpj7543","2023","Journal Article","International journal of science and research","Dinesh Reddy Chittibala","10.21275/sr24304170702","","No","In the evolving landscape of software development, DevOps has emerged as a pivotal philosophy, blending software development (Dev) with information technology operations (Ops) to shorten the development lifecycle and provide continuous delivery with high software quality.Central to this paradigm is the concept of Infrastructure as Code (IaC), a practice that programmatically manages and provisions infrastructure through code rather than through manual processes. This paper delves into the integral role of IaC in actualizing DevOps objectives, highlighting how it catalyzes automation, ensures consistency and standardization, facilitates rapid deployment, and enhances collaboration. Through a comprehensive analysis, we explore how IaC not only automates and streamlines operations but also embeds compliance and security into the development process, aligning closely with the DevOps ethos of swift, reliable, and frequent deployments. Additionally, the paper addresses the challenges inherent in implementingIaC within a DevOps framework and proposes best practices to navigate these complexities effectively.The future of software development and IT operations is envisaged as a continuum where IaC and DevOps co -evolve, paving the way for more agile, efficient, and secure IT infrastructure management."
"Systematic Analysis of Infrastructure as Code Technologies","https://scispace.com/papers/systematic-analysis-of-infrastructure-as-code-technologies-3agbjvr6u3","2023","Journal Article","Gazi university journal of science part a:engineering and innovation","Erdal Özdoğan
Onur Ceran
Mutlu Tahsin Üstündağ","10.54287/gujsa.1373305","","No","“Infrastructure as Code” technologies are the network automation concept used in configuring network devices, allocating network resources, and deploying developed applications. By using machine-readable codes, various tasks that previously required time and effort can now be done dynamically with infrastructure as code tools. Although Infrastructure as Code is a technology that brings many advantages and is still at the beginning of its popularity, there are not enough resource in the literature. In this study, the key concepts of Infrastructure as Code technologies are discussed and infrastructure as code tools are systematically examined. The four most used Infrastructure as Code tools were examined in terms of management, language, data representation, code approach, stateful and stateless, architectural perspectives. Also, they were compared over these key concepts."
"GLITCH: Automated Polyglot Security Smell Detection in Infrastructure as Code","https://scispace.com/papers/glitch-automated-polyglot-security-smell-detection-in-3j01x3ij","2022","Proceedings Article","International Conference on Automated Software Engineering","Nuno Saavedra
João F. Ferreira","10.1145/3551349.3556945","","Yes","Infrastructure as Code (IaC) is the process of managing IT infrastructure via programmable configuration files (also called IaC scripts). Like other software artifacts, IaC scripts may contain security smells, which are coding patterns that can result in security weaknesses. Automated analysis tools to detect security smells in IaC scripts exist, but they focus on specific technologies such as Puppet, Ansible, or Chef. This means that when the detection of a new smell is implemented in one of the tools, it is not immediately available for the technologies supported by the other tools — the only option is to duplicate the effort. This paper presents an approach that enables consistent security smell detection across different IaC technologies. We conduct a large-scale empirical study that analyzes security smells on three large datasets containing 196,755 IaC scripts and 12,281,251 LOC. We show that all categories of security smells are identified across all datasets and we identify some smells that might affect many IaC projects. To conduct this study, we developed GLITCH, a new technology-agnostic framework that enables automated polyglot smell detection by transforming IaC scripts into an intermediate representation, on which different security smell detectors can be defined. GLITCH currently supports the detection of nine different security smells in scripts written in Ansible, Chef, or Puppet. We compare GLITCH with state-of-the-art security smell detectors. The results obtained not only show that GLITCH can reduce the effort of writing security smell analyses for multiple IaC technologies, but also that it has higher precision and recall than the current state-of-the-art tools."
"Analyzing Infrastructure as Code to Prevent Intra-update Sniping Vulnerabilities","https://scispace.com/papers/analyzing-infrastructure-as-code-to-prevent-intra-update-1ctwzprvru","2021","Book Chapter","Tools and Algorithms for Construction and Analysis of Systems","Julien Lepiller
Ruzica Piskac
Martin Schäf
Mark Santolucito","10.1007/978-3-030-72013-1_6","https://scispace.com/pdf/analyzing-infrastructure-as-code-to-prevent-intra-update-1ctwzprvru.pdf","Yes","Infrastructure as Code is a new approach to computing infrastructure management that allows users to leverage tools such as version control, automatic deployments, and program analysis for infrastructure configurations. This approach allows for faster and more homogeneous configuration of a complete infrastructure. Infrastructure as Code languages, such as CloudFormation or TerraForm, use a declarative model so that users only need to describe the desired state of the infrastructure. However, in practice, these languages are not processed atomically. During an upgrade, the infrastructure goes through a series of intermediate states. We identify a security vulnerability that occurs during an upgrade even when the initial and final states of the infrastructure are secure, and we show that those vulnerability are possible in Amazon’s AWS and Google Cloud. We call such attacks intra-update sniping vulnerabilities. In order to mitigate this shortcoming, we present a technique that detects such vulnerabilities and pinpoints the root causes of insecure deployment migrations. We implement this technique in a tool, Hayha, that uses dataflow graph analysis. We evaluate our tool on a set of open-source CloudFormation templates and find that it is scalable and could be used as part of a deployment workflow."
"Preliminary Investigation into a Security Approach for Infrastructure as Code","https://scispace.com/papers/preliminary-investigation-into-a-security-approach-for-2yqmb86ugq","2023","Book Chapter","","Ammar Zeini
Ruth Lennon
Patrick A. Lennon","10.1007/978-981-99-3091-3_63","","No","IaC is relatively a novel technology, with the result that many security frameworks don’t have a clear strategy for risk management or threat modelling for infrastructure when implementing IaC techniques. In DevOps, infrastructure is initialized, prepared, managed, and configured with a left-shift on quality. The DevOps methodology increases the integrity and stability of the deployment. IaC works best with DevOps practices for code quality, scalability, security, and reliability. Infrastructure as Code (IaC) promotes managing knowledge and experience through reusable scripts of infrastructure code, instead of the traditional method of manual labour technique, which is typically slow and time-consuming. This research determines some security risks that should considered during the IaC development process. It further defines the main security practices that should be added into Infrastructure as Code life cycle to fill the gap in the SDLC for IaC. An initial proposal to secure pipelines for IaC is presented."
"What Do Infrastructure-as-Code Practitioners Discuss: An Empirical Study on Stack Overflow","https://scispace.com/papers/what-do-infrastructure-as-code-practitioners-discuss-an-2zpxw4yhyx","2023","Journal Article","","Mahi Begoug
Narjess Bessghaier
Ali Ouni
Eman Abdullah AlOmar
Mohamed Wiem Mkaouer","10.1109/esem56168.2023.10304847","","No","Background. Infrastructure-as-Code (IaC) is an emerging practice to manage cloud infrastructure resources for software systems. Modern software development has evolved to embrace IaC as a best practice for consistently provisioning and managing infrastructure using various tools such as Terraform and Ansible. However, recent studies highlighted that developers still encounter various challenges with IaC tools. Aims. We aim in this paper to understand the different challenges that developers encounter with IaC and analyze the trend of seeking assistance on Q&A platforms in the context of IaC. To this end, we conduct a large-scale empirical study investigating developers' discussions in Stack Overflow. Method. We first collect IaC-relevant tags on Stack Overflow, constituting a dataset that comprises 52,692 questions and 64,078 answers. Then, we group questions into specific topics using the Latent Dirichlet Allocation (LDA) method, which we optimize using a Genetic Algorithm (GA) for parameter's fine-tuning. Finally, to gain better insights, we analyze the identified topics based on different criteria such as popularity and difficulty. Results. Our findings reveal an average yearly increase of 150% in terms of IaC-related questions and 135% in terms of users between 2011 and 2022. Furthermore, we observe that IaC questions revolve around seven main topics: server configuration, policy configuration, networking, deployment pipelines, variable management, templating, and file management. Notably, we found that server configuration and file management are the most popular topics, i.e., the most discussed among IaC developers, while the deployment pipelines and templating topics are the most difficult. Conclusions. Our results shed light on IaC challenges that are often encountered by developers on popular Q&A platforms. These findings reveal important implications for practitioners seeking better support for IaC tools in real-world settings and for researchers to better understand the IaC community needs and further investigate IaC in different aspects."
"Infrastructure as code: A paradigm shifts in cloud resource management and deployment automation","https://scispace.com/papers/infrastructure-as-code-a-paradigm-shifts-in-cloud-resource-j89640w0s6lx","2025","Journal Article","World Journal of Advanced Engineering Technology and Sciences","Ajay Varma Indukuri","10.30574/wjaets.2025.15.1.0478","","No","This article examines the emergence of Infrastructure as Code (IaC) as a transformative approach to cloud resource management, analyzing its impact on organizational agility and operational consistency. Through a systematic review of contemporary implementation strategies and tooling frameworks, the article explores how IaC principles have fundamentally altered traditional cloud deployment paradigms by enabling programmatic control of infrastructure. The article investigates the symbiotic relationship between IaC methodologies and DevOps practices, highlighting how this convergence facilitates enhanced collaboration between development and operations teams while simultaneously addressing scalability challenges inherent in manual provisioning processes. Drawing upon case studies from diverse industry sectors, the article evaluates both the technical and organizational dimensions of successful IaC adoption, providing insights into implementation patterns, common pitfalls, and emerging best practices. The article suggests that organizations embracing IaC as part of a broader automation strategy experience significant improvements in deployment reliability, security posture, and operational efficiency, while simultaneously reducing the cognitive overhead associated with infrastructure management in complex multi-cloud environments."
"Cloud Infrastructure Self Service Delivery System using Infrastructure as Code","https://scispace.com/papers/cloud-infrastructure-self-service-delivery-system-using-1x78pd1s","2022","Proceedings Article","","Ankita Dalvi","10.1109/ICCCIS56430.2022.10037603","","No","To succeed in cloud adoption and thrive in multi-cloud environments, most organizations develop centralized platform teams. The primary function of these centralized platform teams popularly known as Cloud Center of Excellence (CCoE) teams is to industrialize application delivery. The platform teams which are made up of individuals who provision, run and manage shared infrastructure in cloud environments across teams, act on the requests generated by developers. This activity is time-consuming and prone to manual errors. This paper defines a system that enables developers to access platform capabilities on-demand using templates via a self-service mechanism. Application delivery in cloud environments may evolve into proven repeated patterns useful for standardizing how people function and what tools they consume and which process they follow. These standardized steps can be converted into a template made with infrastructure as Code. Using this system, the developers can launch their required resources using templates without intervention from platform teams while adhering to internal compliance of the organization. These templates built using Infrastructure as Code (IaC) by the platform teams make it easy to create new resources in the cloud and release new capabilities more quickly; ensuring that desired configurations are set by Infrastructure, Network, Security, and Operations Engineers."
"Analysis of Software Tools for Automation of Configuration and Management Functions in It Infrastructures","https://scispace.com/papers/analysis-of-software-tools-for-automation-of-configuration-3bl3db9ijqcu","2024","Journal Article","Вісник Національного університету ""Львівська політехніка""","Mykola Orlov
Yurii Dmytriv","10.23939/sisn2024.15.370","","No","The work by the authors, using a systematic approach, analyzes a group of software tools that are functionally oriented towards the automated implementation of configuration and management processes in IT infrastructures. The research profile focuses on a methodology known in the professional environment as “Infrastructure as Code” (IaC) and is one of the foundational methodologies implemented in a systemic combination within the DevOps methodology. This methodology is actively used in processes of dynamic formation, deployment, and maintenance of corporate IT infrastructures in many modern successful high-tech companies to achieve the best business performance, efficiency, guaranteed success, and security. The article discusses two basic approaches to building software tools that implement the IaC methodology, namely the declarative and imperative approaches. The main emphasis is placed on the formation of a set of advantages and disadvantages inherent in software tools such as Terraform, ARM, Ansible, and CloudFormation. The focus of researchers on these four software tools is explained by their leading positions in a fairly extensive lineup of possible alternative software products that allow for a comprehensive implementation of the IaC methodology in the context of full and functional systemic deployment of the DevOps methodology in specific implementations of corporate IT infrastructures. The authors' generalized conclusion of original scientific research is that there is currently no single clearly distinguished universal software tool among others that fully satisfies the entire spectrum of requirements and needs. Potential users in this context are communities of DevOps professionals and clients – owners and managers of modern dynamic high- tech and successful companies, firms, and businesses that rely on modern information systems and technologies."
"Change management and rollback strategies using IaC in CI/CD Pipelines","https://scispace.com/papers/change-management-and-rollback-strategies-using-iac-in-ci-cd-67z5xpq9lohc","2021","Journal Article","International Journal of Science and Research Archive","Yogeswara Reddy Avuthu","10.30574/ijsra.2021.2.1.0037","","No","Infrastructure as Code (IaC) has emerged as a cornerstone of modern cloud and DevOps practices, enabling the management and provisioning of infrastructure through code-based configurations. The integration of IaC with Continuous Integration and Continuous Deployment (CI/CD) pipelines provides organizations with a comprehensive framework for automating the provisioning, configuration, and management of cloud resources. Despite these advantages, the automation of infrastructure introduces complexities, particularly in the realm of change management and efficient rollback mechanisms. This paper explores in-depth strategies for managing changes and implementing reliable rollback techniques using IaC within CI/CD pipelines. We discuss manual rollbacks, automated rollbacks, blue-green deployments, and canary deployments, detailing the trade-offs, benefits, and best practices for each approach. The paper also presents real-world case studies to demonstrate the practical implementation of these strategies, alongside graphs depicting the increasing adoption of IaC from 2013 to 2018 and the frequency of various rollback strategies based on a 2018 survey. Our findings emphasize the critical role of automated and strategic rollback mechanisms in maintaining system stability, minimizing downtime, and ensuring continuous performance of cloud-native applications. This research provides actionable insights and recommendations for practitioners seeking to optimize their IaC and CI/CD processes, ultimately contributing to more secure, resilient, and high-performing cloud operations."
"The do’s and don’ts of infrastructure code: A systematic gray literature review","https://scispace.com/papers/the-do-s-and-don-ts-of-infrastructure-code-a-systematic-gray-3vwxxwdt9p","2021","Journal Article","Information & Software Technology","Indika Kumara
Martin Garriga
Angel Urbano Romeu
Dario Di Nucci
Fabio Palomba
Damian A. Tamburri
Willem-Jan van den Heuvel","10.1016/J.INFSOF.2021.106593","","Yes","Context: Infrastructure-as-code (IaC) is the DevOps tactic of managing and provisioning software infrastructures through machine-readable definition files, rather than manual hardware configuration or interactive configuration tools. Objective: From a maintenance and evolution perspective, the topic has picked the interest of practitioners and academics alike, given the relative scarcity of supporting patterns and practices in the academic literature. At the same time, a considerable amount of gray literature exists on IaC. Thus we aim to characterize IaC and compile a catalog of best and bad practices for widely used IaC languages, all using gray literature materials. Method: In this paper, we systematically analyze the industrial gray literature on IaC, such as blog posts, tutorials, white papers using qualitative analysis techniques. Results: We proposed a definition for IaC and distilled a broad catalog summarized in a taxonomy consisting of 10 and 4 primary categories for best practices and bad practices, respectively, both language-agnostic and language-specific ones, for three IaC languages, namely Ansible, Puppet, and Chef. The practices reflect implementation issues, design issues, and the violation of/adherence to the essential principles of IaC. Conclusion: Our findings reveal critical insights concerning the top languages as well as the best practices adopted by practitioners to address (some of) those challenges. We evidence that the field of development and maintenance IaC is in its infancy and deserves further attention."
"GLITCH: an Intermediate-Representation-Based Security Analysis for Infrastructure as Code Scripts","https://scispace.com/papers/glitch-an-intermediate-representation-based-security-24z9ba10","","Journal Article","arXiv.org","Nuno Saavedra
João F. Ferreira","10.48550/arXiv.2205.14371","","No","Infrastructure as Code (IaC) is the process of managing IT infrastructure via programmable configuration files (also called IaC scripts). Like other software artifacts, IaC scripts may contain security smells, which are coding patterns that can result in security weaknesses. Automated analysis tools to detect security smells in IaC scripts exist, but they focus on specific technologies such as Puppet, Ansible, or Chef. This means that when the detection of a new smell is implemented in one of the tools, it is not immediately available for the technologies supported by the other tools—the only option is to duplicate the effort. This paper presents GLITCH, a new technology-agnostic framework that enables automated polyglot smell detection by transforming IaC scripts into an intermediate representation, on which different security smell detectors can be defined. GLITCH currently supports the detection of nine different security smells in scripts written in Puppet, Ansible, or Chef. We compare GLITCH with state-of-the-art security smell detectors. The results obtained not only show that GLITCH can reduce the effort of writing security smell analyses for multiple IaC technologies, but also that it has higher precision and recall than the current state-of-the-art tools."
"Luke Hoban on Infrastructure as Code","https://scispace.com/papers/luke-hoban-on-infrastructure-as-code-23f8fiye","2022","Journal Article","IEEE Software","Jeff Doolittle","10.1109/ms.2021.3131919","","No","Jeff Doolittle: What is infrastructure as code (IaC)?"
"Managing configuration drift","https://scispace.com/papers/managing-configuration-drift-3u3sfu1kaj","2016","Patent","","Dongye Pan
Kishan Thomas","","","No","A system is disclosed for managing configuration drift of computing resource instances, including instructions to (1) receive a definition of a plurality of functional roles to be played by resource instances within a multi-resource computing system; (2) select, for each of the roles, a designated exemplar from the group of resource instances playing that role; (3) capture characteristics of that designated exemplar and assign the captured characteristics to a functional role template; and (4) during operation, measure configuration drift by comparing resource instances for each functional role to the functional role template associated with that role, such measuring being independent of any comparing to resource instances in the functional role."
"Immutable Infrastructure Calls for Immutable Architecture","https://scispace.com/papers/immutable-infrastructure-calls-for-immutable-architecture-jlipsguc1h","2019","Proceedings Article","Hawaii International Conference on System Sciences","Anders Mikkelsen
Tor-Morten Grønli
Rick Kazman","10.24251/HICSS.2019.846","https://scispace.com/pdf/immutable-infrastructure-calls-for-immutable-architecture-jlipsguc1h.pdf","Yes","With the advent of cloud computing and the concept of immutable infrastructure, the scaling and deployment of applications has become significantly easier. This increases the possibility of “configuration drift” as an operations team manages this cluster of machines, both virtual and actual. In this paper we propose a revised view on configuration and architecture. We propose that software deployed on a public or private cloud should, to the furthest possible extent, be immutable and source controlled. This reduces configuration drift and ensures no configuration problems in production as a result of updates or changes. We will show an example of a software project deployed on Amazon Web Services with an immutable Jenkins setup which manages updating the whole cluster and is self-regenerating. We will also discuss how this lends itself naturally to interoperability between clouds, because of the infrastructure-agnostic nature of this approach."
"Infrastructure as Code: Revolutionizing Cloud Management with Automation Orchestration","https://scispace.com/papers/infrastructure-as-code-revolutionizing-cloud-management-with-1nq024a4r5il","2025","Journal Article","International Scientific Journal of Engineering and Management","Santosh Pashikanti","10.55041/isjem01092","","No","This white paper presents a detailed analysis of Infrastructure as Code (IaC) principles and practices, focusing on how they revolutionize cloud management through automation orchestration. As enterprises migrate more services to the cloud, the need for consistent, efficient, and scalable deployment practices becomes increasingly important. IaC addresses these needs by automating the provisioning, configuration, and management of infrastructure using machine-readable definitions rather than manual processes. This paper provides an in-depth examination of IaC’s technical architecture, methodologies, implementation strategies, challenges, and solutions. It also includes case studies that illustrate how organizations can leverage IaC to streamline cloud operations, reduce risk, and accelerate innovation. Keywords: Infrastructure as Code, Cloud Management, Automation Orchestration, Configuration Management, DevOps, Continuous Integration/Continuous Deployment (CI/CD)"
"Quality Assurance for Infrastructure Orchestrators: Emerging Results from Ansible","https://scispace.com/papers/quality-assurance-for-infrastructure-orchestrators-emerging-1z9wuk3s","2023","Journal Article","","Fan Wu
Akond Rahman","10.1109/ICSA-C57050.2023.00073","","No","Infrastructure as code (IaC) is the practice of automatically managing computing infrastructure at scale. Despite yielding multiple benefits for organizations, the practice of IaC is susceptible to quality concerns, which can lead to large-scale consequences. While researchers have studied quality concerns in IaC manifests, quality aspects of infrastructure orchestrators, i.e., tools that implement the practice of IaC, remain an under-explored area. A systematic investigation of defects in infrastructure orchestrators can help foster further research in the domain of IaC. From our empirical study with 22,445 commits mined from the Ansible infrastructure orchestrator we observe (i) a defect density of 17.9 per KLOC, (ii) 12 categories of Ansible components for which defects appear, and (iii) the ‘Module’ component to include more defects than the other 11 components. Based on our empirical study, we provide recommendations for researchers to conduct future research to enhance the quality of infrastructure orchestrators."
"The ‘as code’ activities: development anti-patterns for infrastructure as code","https://scispace.com/papers/the-as-code-activities-development-anti-patterns-for-1fsx9ik8r4","2020","Journal Article","Empirical Software Engineering","Akond Rahman
Effat Farhana
Laurie Williams","10.1007/S10664-020-09841-8","","Yes","The ‘as code’ suffix in infrastructure as code (IaC) refers to applying software engineering activities, such as version control, to maintain IaC scripts. Without the application of these activities, defects that can have serious consequences may be introduced in IaC scripts. A systematic investigation of the development anti-patterns for IaC scripts can guide practitioners in identifying activities to avoid defects in IaC scripts. Development anti-patterns are recurring development activities that relate with defective IaC scripts. The goal of this paper is to help practitioners improve the quality of infrastructure as code (IaC) scripts by identifying development activities that relate with defective IaC scripts. We identify development anti-patterns by adopting a mixed-methods approach, where we apply quantitative analysis with 2,138 open source IaC scripts and conduct a survey with 51 practitioners. We observe five development activities to be related with defective IaC scripts from our quantitative analysis. We identify five development anti-patterns namely, ‘boss is not around’, ‘many cooks spoil’, ‘minors are spoiler’, ‘silos’, and ‘unfocused contribution’. Our identified development anti-patterns suggest the importance of ‘as code’ activities in IaC because these activities are related to quality of IaC scripts."
"Infrastructure-as-Code for Data-Intensive Architectures: A Model-Driven Development Approach","https://scispace.com/papers/infrastructure-as-code-for-data-intensive-architectures-a-4szlpdii9v","2018","Proceedings Article","","Matej Artac
Tadej Borovsak
Elisabetta Di Nitto
Michele Guerriero
Diego Perez-Palacin
Damian A. Tamburri","10.1109/ICSA.2018.00025","","No","As part of the DevOps tactics, Infrastructure-as-Code (IaC) provides the ability to create, configure, and manage complex infrastructures by means of executable code. Writing IaC, however, is not an easy task, since it requires blending different infrastructure programming languages and abstractions, each specialized on a particular aspect of infrastructure creation, configuration, and management. Moreover, the more the architectures become large and complex (e.g. Data-Intensive or Microservice-based architectures), the more dire the need of IaC becomes. The goal of this paper is to exploit Model-Driven Engineering (MDE) to create language-agnostic models that are then automatically transformed into IaC. We focus on the domain of Data-Intensive Applications as these typically exploit complex infrastructures which demand sophisticated and fine-grained configuration and re-configuration — we show that, through our approach, called DICER, it is possible to create complex IaC with significant amounts of time savings, both in IaC design as well as deployment and re-deployment times."
"A Survey of using Large Language Models for Generating Infrastructure as Code","https://scispace.com/papers/a-survey-of-using-large-language-models-for-generating-5fwbdmuowg","2024","Journal Article","arXiv.org","Kalahasti Ganesh Srivatsa
Sabyasachi Mukhopadhyay
Ganesh Katrapati
Manish Shrivastava","10.48550/arxiv.2404.00227","https://scispace.com/pdf/a-survey-of-using-large-language-models-for-generating-5fwbdmuowg.pdf","No","Infrastructure as Code (IaC) is a revolutionary approach which has gained significant prominence in the Industry. IaC manages and provisions IT infrastructure using machine-readable code by enabling automation, consistency across the environments, reproducibility, version control, error reduction and enhancement in scalability. However, IaC orchestration is often a painstaking effort which requires specialised skills as well as a lot of manual effort. Automation of IaC is a necessity in the present conditions of the Industry and in this survey, we study the feasibility of applying Large Language Models (LLM) to address this problem. LLMs are large neural network-based models which have demonstrated significant language processing abilities and shown to be capable of following a range of instructions within a broad scope. Recently, they have also been adapted for code understanding and generation tasks successfully, which makes them a promising choice for the automatic generation of IaC configurations. In this survey, we delve into the details of IaC, usage of IaC in different platforms, their challenges, LLMs in terms of code-generation aspects and the importance of LLMs in IaC along with our own experiments. Finally, we conclude by presenting the challenges in this area and highlighting the scope for future research."
"Streamlining Infrastructure as Code in Azure DevOps: Automation Strategies for Scalability","https://scispace.com/papers/streamlining-infrastructure-as-code-in-azure-devops-51lhk50hr9q7","2022","Journal Article","International journal of science and research","Satheesh Reddy Gopireddy","10.21275/sr22810111317","","No",": In today's fast-paced digital landscape, the ability to efficiently manage and scale infrastructure is a critical factor for organizational success. Infrastructure as Code (IaC) has emerged as a foundational practice in DevOps, enabling teams to automate the provisioning and management of cloud resources with consistency and reliability. This paper explores how Azure DevOps can be leveraged to streamline IaC practices, with a focus on automation strategies that enhance scalability. By examining the principles of IaC, the benefits of automation, and the challenges of scaling, this research provides actionable insights and best practices for organizations looking to optimize their cloud infrastructure."
"Automation Tools for DevOps: Leveraging Ansible, Terraform, and Beyond","https://scispace.com/papers/automation-tools-for-devops-leveraging-ansible-terraform-and-5o38xj5igpd0","2025","Journal Article","International Scientific Journal of Engineering and Management","Surbhi Kanthed","10.55041/isjem01286","","No","DevOps has rapidly become a cornerstone for modern software development, providing faster release cycles and improved collaboration between development and operations teams. Central to DevOps practices is automation, which addresses the complexity of provisioning and configuring diverse computing environments. This white paper explores state-of-the-art automation tools, with a focus on Ansible for configuration management and Terraform for infrastructure as code (IaC). An extensive review of recent scholarly articles, conference papers, and real-world case studies reveals the unique strengths and limitations of these tools, including Ansible’s agentless architecture and Terraform’s robust declarative approach. In examining multi-cloud and hybrid deployments, the paper identifies best practices in modular code design, version control, automated testing, and policy-as-code for security and compliance. Empirical case studies demonstrate the performance, scalability, and maintainability benefits organizations gain from integrating Ansible and Terraform, while also highlighting challenges related to skill gaps, complex orchestration, and state management. Finally, the paper discusses emerging trends, including AI-driven infrastructure provisioning, serverless computing at the edge, and unified frameworks that incorporate multiple automation tools. By synthesizing these findings, this paper contributes a comprehensive roadmap for adopting and optimizing DevOps automation. It underscores how strategic integration of Ansible, Terraform, and complementary solutions not only reduces operational overhead but also enhances reliability, security, and agility. The outcomes empower practitioners and researchers to address current limitations, seize emerging opportunities, and drive further innovation in the rapidly evolving landscape of DevOps automation. Keywords: DevOps, Automation, Ansible, Terraform, Infrastructure as Code (IaC), Configuration Management, Orchestration, CI/CD, Policy-as-Code, Multi-Cloud, Hybrid Cloud, Security, Compliance, State Management, AI-Driven Automation, Serverless, Observability, GitOps, Modular Design, Monitoring, Scalability."
"PIACERE: Programming trustworthy Infrastructure As Code in a Secure Framework","https://scispace.com/papers/piacere-programming-trustworthy-infrastructure-as-code-in-a-414zdsvdvd","2021","","","Juncal Alonso
Christophe Joubert
Leire Orue-Echevarria
Matteo Pradella
Daniel Vladušič","","","Yes","Infrastructure-as-Code (IaC), enables the automation of several deployment, configuration and management tasks. IaC has a lot of potential in cloud computing as it results in a significant saving of time when an application needs to be redeployed on a different set of resources, even running on different infrastructures. Unfortunately, IaC still suffers from some important issues, such as the large variety of competing tools or the strong orientation toward the cloud, leaving aside e.g. the edge. Also, trustworthiness and security aspects of are often left for the end of the cycle, where errors and vulnerabilities are often too late or too expensive to correct. We present here the PIACERE project, which provides tools, methods and techniques for the Infrastructure-as-Code approach. The project will make the creation of IaC more accessible to designers, developers and operators, increasing the quality, security, trustworthiness and evolvability of infrastructural code while ensuring its business continuity by providing self-healing mechanisms anticipation of failures and violations."
"Mastering Infrastructure as Code: Leveraging AWS Cloud Formation to Automate, Scale, and Secure Your Software Deployments","https://scispace.com/papers/mastering-infrastructure-as-code-leveraging-aws-cloud-4unqrrasft0b","2021","Journal Article","Indian Scientific Journal Of Research In Engineering And Management","Sai Krishna Chirumamilla","10.55041/ijsrem10434","","No","Infrastructure as Code, also named Infrastructure-Aware Software, is one of the roots of modern software deployment tactics in clouds noted by providing high efficiency, measurability and modularity. This paper focuses on AWS Cloud Formation, the transformative and efficient IaC tool that simplifies, scales, and secures software instantiation. As more organizations adopt cloud environments, they experience challenges that arise from cloud infrastructure management. AWS Cloud Formation helps overcome these challenges by presenting a single, declarative, resource-provisioning model. In this paper, you learn the value of AWS Cloud Formation, such as its capacity to create and manage resources, including EC2 instances, VPCs, and load balancers for you. The paper also discusses further recommendations for considerations of AWS Cloud Formation templates in scaling and deploying applications, meeting the requirements of multi-Region applications, as well as the utilization of IAM policies and metadata for encryption into the application. Additionally, we explain use cases of Cloud Formation in different sectors and its use in conjunction with DevOps tools and CI/CD pipelines and the automation tools AWS Code Pipeline and AWS Code Build. In addition to this, we provide a literature review of the development of IaC and a comparison of IaC from different cloud computing platforms, as well as a comparison of how Cloud Formation differs from Terraform and other related tools. Furthermore, we provide best practices in general for Azure ARM and especially refine an already existing guide for AWS cloud formation for an enterprise environment, complemented with real examples. In the results and discussion section, we provide the extent to which Cloud Formation has helped minimize human error, made operations more efficient, and increased security in the cloud environment. Finally, we present a conclusion containing recommendations and possible prospects for the development of Cloud Formation in the context of a rapidly changing base of cloud services. Keywords: Infrastructure as Code (IaC), AWS Cloud Formation, DevOps, Multi-region Deployments, Resource Provisioning."
"Infrastructure as Code: Historical Insights and Future Directions","https://scispace.com/papers/infrastructure-as-code-historical-insights-and-future-1eme1ohpvr2q","2023","Journal Article","International journal of science and research","Vijay Kartik Sikha
Dayakar Siramgari
Satyaveda Somepalli","10.21275/sr24820064820","","No",": Infrastructure as Code (IaC) revolutionizes IT infrastructure management by automating provisioning and configuration through machine-readable definition files, replacing manual processes. This paper explores the evolution of IaC, highlighting its impact on efficiency, scalability, and security. Key IaC tools like Terraform, AWS CloudFormation, and Azure Resource Manager have transformed infrastructure management by enabling versioned, repeatable, and automated deployments. The integration of AI promises further advancements, including AI-assisted IaC, predictive scaling, and anomaly detection. Additionally, data centers play a crucial role in supporting AI workloads with high-performance computing resources, scalable storage, and efficient networking. As AI becomes more prevalent, energy-efficient data centers will be essential for sustainable AI infrastructure management. Case studies from Netflix, Spotify, and Expedia illustrate successful IaC implementation. The paper concludes by discussing future trends and AI-driven integration in IaC, emphasizing the importance of robust infrastructure for AI workloads."
"Bugs in Infrastructure as Code","https://scispace.com/papers/bugs-in-infrastructure-as-code-2i4rym29m6","2018","Posted Content","arXiv: Software Engineering","Akond Rahman
Sarah Elder
Faysal Hossain Shezan
Vanessa Frost
Jonathan Stallings
Laurie Williams","","https://arxiv.org/pdf/1809.07937.pdf","Yes","Infrastructure as code (IaC) scripts are used to automate the maintenance and configuration of software development and deployment infrastructure. IaC scripts can be complex in nature, containing hundreds of lines of code, leading to defects that can be difficult to debug, and lead to wide-scale system discrepancies such as service outages at scale. Use of IaC scripts is getting increasingly popular, yet the nature of defects that occur in these scripts have not been systematically categorized. A systematic categorization of defects can inform practitioners about process improvement opportunities to mitigate defects in IaC scripts. The goal of this paper is to help software practitioners improve their development process of infrastructure as code (IaC) scripts by categorizing the defect categories in IaC scripts based upon a qualitative analysis of commit messages and issue report descriptions. We mine open source version control systems collected from four organizations namely, Mirantis, Mozilla, Openstack, and Wikimedia Commons to conduct our research study. We use 1021, 3074, 7808, and 972 commits that map to 165, 580, 1383, and 296 IaC scripts, respectively, collected from Mirantis, Mozilla, Openstack, and Wikimedia Commons. With 89 raters we apply the defect type attribute of the orthogonal defect classification (ODC) methodology to categorize the defects. We also review prior literature that have used ODC to categorize defects, and compare the defect category distribution of IaC scripts with 26 non-IaC software systems. Respectively, for Mirantis, Mozilla, Openstack, and Wikimedia Commons, we observe (i) 49.3%, 36.5%, 57.6%, and 62.7% of the IaC defects to contain syntax and configuration-related defects; (ii) syntax and configuration-related defects are more prevalent amongst IaC scripts compared to that of previously-studied non-IaC software."
"On the Effectiveness of Tools to Support Infrastructure as Code: Model-Driven Versus Code-Centric","https://scispace.com/papers/on-the-effectiveness-of-tools-to-support-infrastructure-as-39et69r222","2020","Journal Article","IEEE Access","Julio Sandobalin
Emilio Insfran
Silvia Abrahão","10.1109/ACCESS.2020.2966597","https://scispace.com/pdf/on-the-effectiveness-of-tools-to-support-infrastructure-as-39et69r222.pdf","Yes","Infrastructure as Code (IaC) is an approach for infrastructure automation that is based on software development practices. The IaC approach supports code-centric tools that use scripts to specify the creation, updating and execution of cloud infrastructure resources. Since each cloud provider offers a different type of infrastructure, the definition of an infrastructure resource (e.g., a virtual machine) implies writing several lines of code that greatly depend on the target cloud provider. Model-driven tools, meanwhile, abstract the complexity of using IaC scripts through the high-level modeling of the cloud infrastructure. In a previous work, we presented an infrastructure modeling approach and tool (Argon) for cloud provisioning that leverages model-driven engineering and supports the IaC approach. The objective of the present work is to compare a model-driven tool (Argon) with a well-known code-centric tool (Ansible) in order to provide empirical evidence of their effectiveness when defining the cloud infrastructure, and the participants' perceptions when using these tools. We, therefore, conducted a family of three experiments involving 67 Computer Science students in order to compare Argon with Ansible as regards their effectiveness, efficiency, perceived ease of use, perceived usefulness, and intention to use. We used the AB/BA crossover design to configure the individual experiments and the linear mixed model to statistically analyze the data collected and subsequently obtain empirical findings. The results of the individual experiments and meta-analysis indicate that Argon is more effective as regards supporting the IaC approach in terms of defining the cloud infrastructure. The participants also perceived that Argon is easier to use and more useful for specifying the infrastructure resources. Our findings suggest that Argon accelerates the provisioning process by modeling the cloud infrastructure and automating the generation of scripts for different DevOps tools when compared to Ansible, which is a code-centric tool that is greatly used in practice."
"The Implementation of Infrastructure as Code Template for Low-cost Cloud Infrastructure Operations","https://scispace.com/papers/the-implementation-of-infrastructure-as-code-template-for-632edykmmjdm","2024","Journal Article","East African journal of information technology","M. Santhosh Samuel
Okello Jimmy Obira
Sansa Keneth","10.37284/eajit.7.1.2538","","No","Cloud computing has emerged as a cornerstone of modern business operations, offering unmatched scalability, flexibility, and efficiency. However, migrating IT infrastructure to the cloud presents significant challenges, particularly for organizations with limited budgets, dependency on costly proprietary cloud tools, complex migration procedures, and a lack of technical expertise. These obstacles are especially evident in regions like Africa, where the adoption of cloud solutions remains restricted due to financial and technical barriers. This research tackles these challenges by developing and implementing an Infrastructure as Code (IaC) template tailored for cost-effective cloud infrastructure management, using Microsoft Azure as a case study. The project developed and tested a reusable IaC template using tools like Terraform, Visual Studio Code, and Azure CLI. It optimized costs with a monitoring bash script that was executed on one of the Linux-based virtual machines that was created on the Azure portal during the implementation of IaC and ensured reliability via extensive validation thereby reducing the deployment time and costs by approximately 90% as compared to standard Azure configurations. The proposed solution harnesses open-source tools and industry best practices to streamline cloud resource deployment and management, reducing the reliance on expensive inbuilt services and lowering the technical barriers to cloud adoption. By automating the infrastructure provisioning process, the IaC template enables companies to efficiently manage their cloud environments, optimize costs by approximately 30% on infrastructure management, incur 0% costs on resource monitoring and maintain flexibility. The initiative is focused on empowering businesses in resource-constrained environments to take full advantage of cloud computing capabilities without incurring prohibitive expenses. It addresses key issues such as budget constraints, technical complexities, and inefficient management practices, providing a pathway for wider cloud adoption in economically developing regions. The research contributes valuable insights into how organizations can achieve low-cost, scalable, and efficient cloud infrastructure operations. The findings have the potential to significantly impact cloud technology adoption across various industries, enabling companies, particularly in developing regions, to leverage cloud solutions to enhance their competitiveness and operational efficiency"
"A Pilot Study of Testing Infrastructure as Code for Cloud Systems","https://scispace.com/papers/a-pilot-study-of-testing-infrastructure-as-code-for-cloud-3xkvnk4c48","2023","Proceedings Article","","Nabhan Suwanachote
Soratouch Pornmaneerattanatri
Yutaro Kashiwa
Kohei Ichikawa
Pattara Leelaprute
Arnon Rungsawang
Bundit Manaskasemsak
Hajimu Iida","10.1109/apsec60848.2023.00075","","No","Infrastructure as Code (IaC) has become the de-facto standard method for managing cloud resources. Just like general source code (e.g., Java, etc.), infrastructure code also has numerous bugs so it needs to be tested. While several testing frameworks for IaC for cloud systems have been developed in practice, researchers have paid little attention to their testing. This study presents an empirical investigation of the use of tests for IaC for cloud systems. Our empirical results show that (i) 55.2% of the repositories using Terratest have at least one server infrastructure test; (ii) developers often maintain server infrastructure tests (1.7%-11.3% commits out of all the commits); (iii) many repositories have tests for system functionality (28%), deployment (20%), and configuration (17%)."
"State Reconciliation Defects in Infrastructure as Code","https://scispace.com/papers/state-reconciliation-defects-in-infrastructure-as-code-2wjrj4drla","2024","Journal Article","","Md Mahadi Hassan
John Salvador
Shubhra Kanti Karmaker
Akond Rahman","10.1145/3660790","","No","In infrastructure as code (IaC), state reconciliation is the process of querying and comparing the infrastructure state prior to changing the infrastructure. As state reconciliation is pivotal to manage IaC-based computing infrastructure at scale, defects related to state reconciliation can create large-scale consequences. A categorization of state reconciliation defects, i.e., defects related to state reconciliation, can aid in understanding the nature of state reconciliation defects. We conduct an empirical study with 5,110 state reconciliation defects where we apply qualitative analysis to categorize state reconciliation defects. From the identified defect categories, we derive heuristics to design prompts for a large language model (LLM), which in turn are used for validation of state reconciliation. From our empirical study, we identify 8 categories of state reconciliation defects, amongst which 3 have not been reported for previously-studied software systems. The most frequently occurring defect category is inventory, i.e., the category of defects that occur when managing infrastructure inventory. Using an LLM with heuristics-based paragraph style prompts, we identify 9 previously unknown state reconciliation defects of which 7 have been accepted as valid defects, and 4 have already been fixed. Based on our findings, we conclude the paper by providing a set of recommendations for researchers and practitioners."
"When Your Infrastructure Is a Buggy Program: Understanding Faults in Infrastructure as Code Ecosystems","https://scispace.com/papers/when-your-infrastructure-is-a-buggy-program-understanding-2dchxhfdiak6","2024","Journal Article","Proceedings of the ACM on programming languages","Georgios-Petros Drosos
Thodoris Sotiropoulos
Georgios Alexopoulos
Dimitris Mitropoulos
Zhendong Su","10.1145/3689799","","No","Modern applications have become increasingly complex and their manual installation and configuration is no longer practical. Instead, IT organizations heavily rely on Infrastructure as Code (IaC) technologies, to automate the provisioning, configuration, and maintenance of computing infrastructures and systems. IaC systems typically offer declarative, domain-specific languages (DSLs) that allow system administrators and developers to write high-level programs that specify the desired state of their infrastructure in a reliable, predictable, and documented fashion. Just like traditional programs, IaC software is not immune to faults, with issues ranging from deployment failures to critical misconfigurations that often impact production systems used by millions of end users. Surprisingly, despite its crucial role in global infrastructure management, the tooling and techniques for ensuring IaC reliability still have room for improvement. In this work, we conduct a comprehensive analysis of 360 bugs identified in IaC software within prominent IaC ecosystems including Ansible, Puppet, and Chef. Our work is the first in-depth exploration of bug characteristics in these widely-used IaC environments. Through our analysis we aim to understand: (1) how these bugs manifest, (2) their underlying root causes, (3) their reproduction requirements in terms of system state (e.g., operating system versions) or input characteristics, and (4) how these bugs are fixed. Based on our findings, we evaluate the state-of-the-art techniques for IaC reliability, identify their limitations, and provide a set of recommendations for future research. We believe that our study helps researchers to (1) better understand the complexity and peculiarities of IaC software, and (2) develop advanced tooling for more reliable and robust system configurations."
"DOML: A New Modelling Approach to Infrastructure-as-Code","https://scispace.com/papers/doml-a-new-modelling-approach-to-infrastructure-as-code-15oil744","2023","Book Chapter","Lecture Notes in Computer Science","Michele Chiari
Bin Xiang
Galia Novakova Nedeltcheva
Elisabetta Di Nitto
Lorenzo Blasi","10.1007/978-3-031-34560-9_18","","Yes","Abstract One of the main DevOps practices is the automation of resource provisioning and deployment of complex software. This automation is enabled by the explicit definition of Infrastructure-as-Code (IaC), i.e., a set of scripts, often written in different modelling languages, which defines the infrastructure and applications to be deployed. We introduce the DevOps Modelling Language (DOML), a new Cloud modelling language for infrastructure deployments. DOML is a modelling approach that can be mapped into multiple IaC languages, addressing infrastructure provisioning, application deployment and configuration at once. The idea behind DOML is to use a single modelling paradigm which can help to reduce the need of deep technical expertise in using different specialised IaC languages. We present the DOML’s principles and discuss the related work on IaC languages. We demonstrate the DOML advantages for the end-user in comparison with state-of-the-art IaC languages such as Ansible, Terraform, and Cloudify, and show its effectiveness through an example."
"A systematic mapping study of infrastructure as code research","https://scispace.com/papers/a-systematic-mapping-study-of-infrastructure-as-code-3mm0kc4tro","2019","Journal Article","Information & Software Technology","Akond Rahman
Rezvan Mahdavi-Hezaveh
Laurie Williams","10.1016/J.INFSOF.2018.12.004","https://arxiv.org/pdf/1807.04872.pdf","Yes","Context: Infrastructure as code (IaC) is the practice to automatically configure system dependencies and to provision local and remote instances Practitioners consider IaC as a fundamental pillar to implement DevOps practices, which helps them to rapidly deliver software and services to end-users Information technology (IT) organizations, such as GitHub, Mozilla, Facebook, Google and Netflix have adopted IaC A systematic mapping study on existing IaC research can help researchers to identify potential research areas related to IaC, for example defects and security flaws that may occur in IaC scripts Objective: The objective of this paper is to help researchers identify research areas related to infrastructure as code (IaC) by conducting a systematic mapping study of IaC-related research Method: We conduct our research study by searching five scholar databases We collect a set of 31,498 publications by using seven search strings By systematically applying inclusion and exclusion criteria, which includes removing duplicates and removing non-English and non peer-reviewed publications, we identify 32 publications related to IaC We identify topics addressed in these publications by applying qualitative analysis Results: We identify four topics studied in IaC-related publications: (i) framework/tool for infrastructure as code; (ii) adoption of infrastructure as code; (iii) empirical study related to infrastructure as code; and (iv) testing in infrastructure as code According to our analysis, 500% of the studied 32 publications propose a framework or tool to implement the practice of IaC or extend the functionality of an existing IaC tool Conclusion: Our findings suggest that framework or tools is a well-studied topic in IaC research As defects and security flaws can have serious consequences for the deployment and development environments in DevOps, we observe the need for research studies that will study defects and security flaws for IaC"
"Co-evolution of infrastructure and source code: an empirical study","https://scispace.com/papers/co-evolution-of-infrastructure-and-source-code-an-empirical-ob1dqmqz4y","2015","Proceedings Article","Mining Software Repositories","Yujuan Jiang
Bram Adams","10.5555/2820518.2820527","","Yes","Infrastructure-as-code automates the process of configuring and setting up the environment (e.g., servers, VMs and databases) in which a software system will be tested and/or deployed, through textual specification files in a language like Puppet or Chef. Since the environment is instantiated automatically by the infrastructure languages' tools, no manual intervention is necessary apart from maintaining the infrastructure specification files. The amount of work involved with such maintenance, as well as the size and complexity of infrastructure specification files, have not yet been studied empirically. Through an empirical study of the version control system of 265 Open Stack projects, we find that infrastructure files are large and churn frequently, which could indicate a potential of introducing bugs. Furthermore, we found that the infrastructure code files are coupled tightly with the other files in a project, especially test files, which implies that testers often need to change infrastructure specifications when making changes to the test framework and tests."
"Automating Multi-Cloud Infrastructure: Leveraging Terraform and IaC for Scalable, Secure, and Efficient Cloud Management","https://scispace.com/papers/automating-multi-cloud-infrastructure-leveraging-terraform-82m50gseyjiy","2025","Journal Article","International journal of scientific research in computer science, engineering and information technology","P. Ravindran","10.32628/cseit25112704","","No","Cloud computing transformation has revolutionized digital infrastructure management, particularly in multi-cloud environments. The substantial growth in cloud adoption, especially in Infrastructure as a Service, reflects increasing confidence in cloud-based solutions across industries. Implementing Infrastructure as Code principles, robust security frameworks, and automated compliance mechanisms enables organizations to achieve enhanced operational efficiency and reduced deployment times. The effectiveness of cloud-native technologies and automated infrastructure management becomes evident through comprehensive case studies spanning financial institutions and technology startups. The integration of sophisticated deployment models, particularly in the banking and financial services sector, demonstrates the maturity of cloud solutions in handling sensitive operations. The emergence of Terraform as a leading Infrastructure as Code tool, supported by its provider-agnostic architecture and effective state management capabilities, further validates the evolution of infrastructure automation practices."
"Policy-Driven Infrastructure Automation for Microservices: A Unified Framework Combining Infrastructure as Code and Policy as Code in Cloud-Native Environments","https://scispace.com/papers/policy-driven-infrastructure-automation-for-microservices-a-qb2g39pzueog","2022","Journal Article","Ibn Al-Haitham","Nagateja Alugunuri","10.71097/ijsat.v13.i3.5966","","No","With the cloud-native applications era, microservices architecture is now the de facto standard because it is scalable, flexible, and modular. However, it's extremely challenging to orchestrate the underlying infrastructure for such a distributed system, such as complexity, consistency, and governance at scale. To address these, automation through Infrastructure as Code (IaC) has emerged as a front-runner, allowing for declarative provisioning of infrastructure, while Policy as Code (PaC) enforces security, compliance, and operational policy governance through codified policies. This study tries to provide a holistic model that combines IaC and PaC to automate infrastructure provisioning and policy enforcement in a consistent way throughout the deployment pipeline. Through the use of solutions like Terraform for infrastructure and Open Policy Agent (OPA) to enforce policy, the model is proposed to enhance the speed of deployment, reduce human error, and achieve policy compliance."
"Static Analysis of Infrastructure as Code: a Survey","https://scispace.com/papers/static-analysis-of-infrastructure-as-code-a-survey-1j1agdew","2022","Journal Article","","Michele Chiari
Michele De Pascalis
Matteo Pradella","10.1109/ICSA-C54293.2022.00049","","No","The increasing use of Infrastructure as Code (IaC) in DevOps leads to benefits in speed and reliability of deployment operation, but extends to infrastructure challenges typical of software systems. IaC scripts can contain defects that result in security and reliability issues in the deployed infrastructure: techniques for detecting and preventing them are needed. We analyze and survey the current state of research in this respect by conducting a literature review on static analysis techniques for IaC. We describe analysis techniques, defect categories and platforms targeted by tools in the literature."
"Categorizing Defects in Infrastructure as Code.","https://scispace.com/papers/categorizing-defects-in-infrastructure-as-code-37kg19atca","2018","Posted Content","arXiv: Software Engineering","Akond Rahman
Sarah Elder
Faysal Hossain Shezan
Vanessa Frost
Jonathan Stallings
Laurie Williams","","","Yes","Infrastructure as code (IaC) scripts are used to automate the maintenance and configuration of software development and deployment infrastructure. IaC scripts can be complex in nature, containing hundreds of lines of code, leading to defects that can be difficult to debug, and lead to wide-scale system discrepancies such as service outages at scale. Use of IaC scripts is getting increasingly popular, yet the nature of defects that occur in these scripts have not been systematically categorized. A systematic categorization of defects can inform practitioners about process improvement opportunities to mitigate defects in IaC scripts. The goal of this paper is to help software practitioners improve their development process of infrastructure as code (IaC) scripts by categorizing the defect categories in IaC scripts based upon a qualitative analysis of commit messages and issue report descriptions. We mine open source version control systems collected from four organizations namely, Mirantis, Mozilla, Openstack, and Wikimedia Commons to conduct our research study. We use 1021, 3074, 7808, and 972 commits that map to 165, 580, 1383, and 296 IaC scripts, respectively, collected from Mirantis, Mozilla, Openstack, and Wikimedia Commons. With 89 raters we apply the defect type attribute of the orthogonal defect classification (ODC) methodology to categorize the defects. We also review prior literature that have used ODC to categorize defects, and compare the defect category distribution of IaC scripts with 26 non-IaC software systems. Respectively, for Mirantis, Mozilla, Openstack, and Wikimedia Commons, we observe (i) 49.3%, 36.5%, 57.6%, and 62.7% of the IaC defects to contain syntax and configuration-related defects; (ii) syntax and configuration-related defects are more prevalent amongst IaC scripts compared to that of previously-studied non-IaC software."
"DevOps: introducing infrastructure-as-code","https://scispace.com/papers/devops-introducing-infrastructure-as-code-2fn7h8erf3","2017","Proceedings Article","International Conference on Software Engineering","Matej Artac
Tadej Borovssak
Elisabetta Di Nitto
Michele Guerriero
Damian A. Tamburri","10.1109/ICSE-C.2017.162","","No","DevOps entails a series of software engineering tactics aimed at shortening the actionable operation of software design changes One of these tactics is to harness infrastructure-as-code, that is, writing a blueprint that contains deployment specifications ready for orchestration in the cloud This abstract briefly discusses all necessary elements and abstractions in writing and maintaining that blueprint, revolving around a key standard for its expression, namely, the OASIS ""Topology and Orchestration Specification for Cloud Applications"" (TOSCA) industrial standard adopted by as many as 60+ big industrial players worldwide"
"The PIPr Dataset of Public Infrastructure as Code Programs","https://scispace.com/papers/the-pipr-dataset-of-public-infrastructure-as-code-programs-1cj1lu92r4","2024","Journal Article","","Daniel Sokolowski
David Spielmann
Guido Salvaneschi","10.1145/3643991.3644888","","No","With Programming Languages Infrastructure as Code (PL-IaC), developers implement IaC programs in popular imperative programming languages like Python and Typescript. Such programs generate the declarative target state of the deployment, i.e., they describe what to set up, not how to set it up. Despite the popularity of PL-IaC, which has grown more than ten times from 2020 to 2023, we know little about how developers apply it and how IaC programs differ from other software. Such knowledge is essential to effectively use existing software engineering techniques and develop new ones for PL-IaC. To shed light on PL-IaC in practice, we present PIPr, the first systematic PL-IaC dataset. PIPr is based on 37 712 public IaC programs on GitHub from August 2022 and includes initial analyses, assessing the programming languages, testing techniques, and licenses of the IaC programs. Beyond the metadata and analysis results of all IaC programs, PIPr contains the code of all 15 504 IaC programs whose licenses permit redistribution. PIPr sets the ground for future in-depth investigations on PL-IaC in practice.CCS CONCEPTS•Software and its engineering Architecture description languages; Software configuration→ management and version control systems; Cloud computing."
"Within-Project Defect Prediction of Infrastructure-as-Code Using Product and Process Metrics","https://scispace.com/papers/within-project-defect-prediction-of-infrastructure-as-code-39tn896gzc","2021","Journal Article","IEEE Transactions on Software Engineering","Stefano Dalla Palma
Dario Di Nucci
Fabio Palomba
Damian A. Tamburri","10.1109/TSE.2021.3051492","https://scispace.com/pdf/within-project-defect-prediction-of-infrastructure-as-code-39tn896gzc.pdf","Yes","Infrastructure-as-code (IaC) is the DevOps practice enabling management and provisioning of infrastructure through the definition of machine-readable files, hereinafter referred to as IaC scripts. Similarly to other source code artefacts, these files may contain defects that can preclude their correct functioning. In this paper, we aim at assessing the role of product and process metrics when predicting defective IaC scripts. We propose a fully integrated machine-learning framework for IaC Defect Prediction, that allows for repository crawling, metrics collection, model building, and evaluation. To evaluate it, we analyzed 104 projects and employed five machine-learning classifiers to compare their performance in flagging suspicious defective IaC scripts. The key results of the study report Random Forest as the best-performing model, with a median AUC-PR of 0.93 and MCC of 0.80. Furthermore, at least for the collected projects, product metrics identify defective IaC scripts more accurately than process metrics. Our findings put a baseline for investigating IaC Defect Prediction and the relationship between the product and process metrics, and IaC scripts' quality."
"TerraMetrics: An Open Source Tool for Infrastructure-as-Code (IaC) Quality Metrics in Terraform","https://scispace.com/papers/terrametrics-an-open-source-tool-for-infrastructure-as-code-6o23qvcnqu","2024","Journal Article","","Mahi Begoug
Moataz Chouchen
Ali Ouni","10.1145/3643916.3644439","","No","Infrastructure-as-Code (IaC) constitutes a pivotal DevOps methodology, leading edge of software deployment onto cloud platforms. IaC relies on source code files rather than manual configuration to manage the infrastructure of a software system. Terraform, an IaC tool and its declarative configuration language named HCL, has recently garnered considerable attention among IaC practitioners. Like other software artefacts, Terraform files could be affected by misconfigurations, faults, and smells. Therefore, DevOps practitioners might benefit from a quality assurance tool to help them perform quality assurance activities on Terrafrom artefacts. This paper introduces TerraMetrics, an open-source tool designed to characterize the quality of Terraform artefacts by providing a catalogue of 40 quality metrics. TerraMetrics leverages the Terraform Abstract Syntax Tree (AST) to extract the metric list, offering a potentially enduring solution compared to conventional regular expressions. This tool comprises three main components: (i) a parser transforming HCL code into an AST, (ii) visitors that traverse the AST nodes to extract the metrics, and (iii) collectors for storing the collected metrics in JSON format. The TerraMetrics tool is publicly available as an Open Source tool, with a demo video, at: https://github.com/stilab-ets/terametrics."
"Gang of eight: a defect taxonomy for infrastructure as code scripts","https://scispace.com/papers/gang-of-eight-a-defect-taxonomy-for-infrastructure-as-code-23hvo3uk7l","2020","Proceedings Article","International Conference on Software Engineering","Akond Rahman
Effat Farhana
Chris Parnin
Laurie Williams","10.1145/3377811.3380409","","No","Defects in infrastructure as code (IaC) scripts can have serious consequences, for example, creating large-scale system outages. A taxonomy of IaC defects can be useful for understanding the nature of defects, and identifying activities needed to fix and prevent defects in IaC scripts. The goal of this paper is to help practitioners improve the quality of infrastructure as code (IaC) scripts by developing a defect taxonomy for IaC scripts through qualitative analysis. We develop a taxonomy of IaC defects by applying qualitative analysis on 1,448 defect-related commits collected from open source software (OSS) repositories of the Openstack organization. We conduct a survey with 66 practitioners to assess if they agree with the identified defect categories included in our taxonomy. We quantify the frequency of identified defect categories by analyzing 80,425 commits collected from 291 OSS repositories spanning across 2005 to 2019. Our defect taxonomy for IaC consists of eight categories, including a category specific to IaC called idempotency (i.e., defects that lead to incorrect system provisioning when the same IaC script is executed multiple times). We observe the surveyed 66 practitioners to agree most with idempotency. The most frequent defect category is configuration data i.e., providing erroneous configuration data in IaC scripts. Our taxonomy and the quantified frequency of the defect categories may help in advancing the science of IaC script quality."
"Automation in Cloud Infrastructure Management: Enhancing Efficiency and Reliability","https://scispace.com/papers/automation-in-cloud-infrastructure-management-enhancing-3u4k0nujd5","2024","Journal Article","Indian Scientific Journal Of Research In Engineering And Management","Varshitha Bysani","10.55041/ijsrem35750","","No","This paper explores the role of automation in cloud infrastructure management, focusing on its impact on efficiency and reliability. Key use cases, including Infrastructure as Code (IaC) with Terraform, Continuous Integration/ Continuous De- ployment (CI/CD), and real-time monitoring with the ELK stack are examined. The paper discusses how automation reduces manual effort, promotes consistency, and enhances scalability in cloud environments. It highlights the benefits of automated alerting and its role in improving security and system stability. By embracing automation, organizations can streamline cloud infrastructure management, ensuring a robust and adaptable framework that supports business continuity and agility. Index Terms—Cloud Infrastructure Management, Automation, Infrastructure as Code (IaC), Terraform, ELK Stack (Elastic- search, Logstash, Kibana), Automated Alerting"
"Automating Infrastructure Deployment in DevOps: Evaluating Tools and Strategies for Scalability","https://scispace.com/papers/automating-infrastructure-deployment-in-devops-evaluating-te6bpg2u5doh","2020","Journal Article","International Journal of Leading Research Publication.","Vidyasagar Vangala -","10.70528/ijlrp.v1.i1.1716","","No","The modern software development timeframe necessitates infrastructure deployment automation because it facilitates DevOps success. This book explores Infrastructure as Code (IaC) as an important tool for structure management because it prevents human mistakes in addition to allowing agile repeatable deployment. The article presents a detailed comparison of four major automation tools like Terraform and AWS CloudFormation and Ansible and Pulumi by discussing their specific features along with their applicable use cases and how to blend them. The discussion includes developed strategies that outline infrastructure automation across diverse environments which combine microservices elements with hybrid cloud infrastructures. The article enriches readers' understanding with practical examples and simple diagrams and side-by-side comparisons showing tried-and-tested techniques of better infrastructure management in DevOps environments."
"Strategies for managing hybrid cloud architectures with IaC: A practical framework","https://scispace.com/papers/strategies-for-managing-hybrid-cloud-architectures-with-iac-3s310yy2aemo","2025","Journal Article","International Journal of Science and Research Archive","Sridhar Nelloru","10.30574/ijsra.2025.14.1.0053","","No","This article presents a comprehensive framework for managing hybrid cloud architectures through Infrastructure as Code (IaC), addressing the complex challenges organizations face when maintaining infrastructure across on-premises and cloud environments. The article examines key components of successful IaC implementation, including template modularization, policy-as-code integration, and state management strategies, while providing practical insights into operational frameworks and implementation approaches. Through an in-depth case study of Salesforce's IaC implementation, the paper demonstrates how organizations can effectively navigate the transition to automated infrastructure management while maintaining security, compliance, and operational efficiency. The article highlights critical success factors such as standardized module development, automated compliance checking, and comprehensive testing frameworks, while also addressing common pitfalls and their solutions. Additionally, the article explores emerging trends and future considerations in hybrid cloud management, offering valuable insights for organizations seeking to optimize their infrastructure operations through IaC practices. The article findings provide a structured approach to implementing and maintaining IaC in hybrid environments, enabling organizations to achieve greater operational efficiency, reduced deployment times, and improved infrastructure consistency."
"Streamlining Multi-Cloud Infrastructure Orchestration: Leveraging Terraform as a Battle-Tested Solution","https://scispace.com/papers/streamlining-multi-cloud-infrastructure-orchestration-1l5j76vxtf","2024","Proceedings Article","","Aniruddha Ghosh
Sudhanshu Srivastava
P. Supraja","10.1109/icc-robins60238.2024.10533995","","No","Cloud computing provides the agility required to dynamically adjust applications in response to changing demands. Despite the proliferation of cloud service providers, the issue of vendor lock-in continues to pose significant challenges. Recent service disruptions have underscored the perils of exclusive reliance on a single provider. Existing cloud orchestration tools, while designed to mitigate these issues by facilitating deployments across multiple cloud providers, are often bound to provider-specific models. This necessitates users' familiarity with the unique offerings of each provider and may limit adaptability in the face of errors. To address these challenges, a custom wrapper is proposed that operates on top of Terraform, a leading Infrastructure-as-Code (IaC) tool. This wrapper enables diverse cloud deployments through a customized configuration file, simplifying the process of auditing, configuring, and securing various deployments. Practical experiments confirm the seamless deployment of infrastructure across various cloud providers, notably AWS and Azure. Specifically, the successful deployment of a Linux VM on both platforms showcases the adaptability of the approach to diverse cloud environments. The solution also maintains an easy learning curve, ensuring accessibility and industry-friendliness for users managing infrastructure across different cloud providers."
"Automated Infrastructure as Code Program Testing","https://scispace.com/papers/automated-infrastructure-as-code-program-testing-29gxo0g091","2024","Journal Article","IEEE Transactions on Software Engineering","Daniel Sokolowski
David Spielmann
Guido Salvaneschi","10.1109/tse.2024.3393070","","No","Infrastructure as Code (IaC) enables efficient deployment and operation, which are crucial to releasing software quickly. As setups can be complex, developers implement IaC programs in general-purpose programming languages like TypeScript and Python, using PL-IaC solutions like Pulumi and AWS CDK. The reliability of such IaC programs is even more relevant than in traditional software because a bug in IaC impacts the whole system. Yet, even though testing is a standard development practice, it is rarely used for IaC programs. For instance, in August 2022, less than 1% of the public Pulumi IaC programs on GitHub implemented tests. Available IaC program testing techniques severely limit the development velocity or require much development effort. <p xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">To solve these issues, we propose Automated Configuration Testing (ACT), a methodology to test IaC programs in many configurations quickly and with low effort. ACT automatically mocks all resource definitions in the IaC program and uses generator and oracle plugins for test generation and validation. We implement ACT in <b>ProTI</b>, a testing tool for Pulumi TypeScript with a type-based generator and oracle, and support for application specifications. Our evaluation with 6 081 programs from GitHub and artificial benchmarks shows that <b>ProTI</b> can directly be applied to existing IaC programs, quickly finds bugs where current techniques are infeasible, and enables reusing existing generators and oracles thanks to its pluggable architecture."
"Provider-Agnostic Infrastructure As Code: A Modular Framework For Secure Multi-Tenant Cloud Automation","https://scispace.com/papers/provider-agnostic-infrastructure-as-code-a-modular-framework-epkpvwnrvx5w","2025","Journal Article","Journal of international crisis and risk communication research","Manoj Kumar Reddy Kalakoti","10.63278/jicrcr.vi.3257","https://scispace.com/pdf/provider-agnostic-infrastructure-as-code-a-modular-framework-epkpvwnrvx5w.pdf","No","Modern enterprises face significant challenges in managing infrastructure across multiple cloud providers while maintaining security and operational efficiency. This work presents a modular automation framework addressing these challenges through provider-agnostic abstraction patterns implemented using Infrastructure as Code principles. The framework introduces reusable modules for core infrastructure components including networking, identity management, compute, and monitoring systems. A key innovation lies in the abstraction layer enabling unified provisioning across AWS, Azure, and Google Cloud Platform. Security requirements are addressed through integrated Role-Based Access Control, automated secret management, and policy-as-code enforcement. The framework leverages GitOps pipelines for continuous deployment with approval gates and automated rollback capabilities. Evaluation in multi-tenant enterprise environments demonstrates improved deployment consistency, reduced provisioning complexity, and enhanced developer productivity. This work advances Infrastructure as Code by integrating multi-tenancy, security-by-design principles, and provider-agnostic abstractions within a cohesive architecture, significantly reducing operational complexity in multi-cloud deployments."
"Towards Reliable Infrastructure as Code","https://scispace.com/papers/towards-reliable-infrastructure-as-code-2dh0z2me","2023","Journal Article","","Daniel Sokolowski
Guido Salvaneschi","10.1109/ICSA-C57050.2023.00072","","No","Modern Infrastructure as Code (IaC) programs are increasingly complex and much closer to traditional software than to simple configuration scripts. Their reliability is crucial because their failure prevents the deployment of applications, and incorrect behavior can introduce malfunction and severe security issues. Yet, software engineering tools to develop reliable programs, such as testing and verification, are barely used in IaC. In fact, we observed that developers mainly rely on integration testing, a slow and expensive practice that can increase confidence in end-to-end functionality but is infeasible to systematically test IaC programs in various configurations—which is required to ensure robustness. On the other hand, fast testing techniques, such as unit testing, are cumbersome with IaC programs because, today, they require significant coding overhead while only providing limited confidence.To solve this issue, we envision the automated testing tool ProTI, reducing the manual overhead and boosting confidence in the test results. ProTI embraces modern unit testing techniques to test IaC programs in many different configurations. Out of the box, ProTI is a fuzzer for Pulumi TypeScript IaC programs, randomly testing the program in many different configurations for termination, configuration correctness, and existing policy compliance. Then developers can add specifications to their program to guide random-based value generation, test additional properties, and add further mocking, making ProTI a property-based testing tool. Lastly, we aim at automatically verifying IaC-specific properties, e.g., access paths between resources."
"Assessing Architecture Conformance to Coupling-Related Infrastructure-as-Code Best Practices: Metrics and Case Studies","https://scispace.com/papers/assessing-architecture-conformance-to-coupling-related-347fgt4n","2022","Book Chapter","European Conference on Software Architecture","Evangelos Ntentos
Uwe Zdun
Jacopo Soldani
Antonio Brogi","10.1007/978-3-031-16697-6_7","https://zenodo.org/record/6801247/files/paper.pdf","Yes","Infrastructure as Code (IaC) is an IT practice that facilitates the management of the underlying infrastructure as software. It enables developers or operations teams to automatically manage, monitor, and provision resources rather than organize them manually. In many industries, this practice is widespread and has already been fully adopted. However, few studies provide techniques for evaluating architectural conformance in IaC deployments and, in particular, aspects such as loose coupling. This paper focuses on coupling-related patterns and practices such as deployment strategies and the structuring of IaC elements. Many best practices are documented in gray literature sources, such as practitioner books, blogs, and public repositories. Still, there are no approaches yet to automatically check conformance with such best practices. We propose an approach based on generic, technology-independent metrics tied to typical architectural design decisions for IaC-based practices in microservice deployments to support architecting in the context of continuous delivery practices. We present three case studies based on open-source microservice architectures to validate our approach."
"Anti-Patterns in Infrastructure as Code","https://scispace.com/papers/anti-patterns-in-infrastructure-as-code-1t3ad4o23b","2018","Proceedings Article","International Conference on Software Testing, Verification, and Validation","Akond Rahman","10.1109/ICST.2018.00057","https://scispace.com/pdf/anti-patterns-in-infrastructure-as-code-1t3ad4o23b.pdf","Yes","In DevOps, infrastructure as code (IaC) scripts are used by practitioners to create and manage an automated deployment pipeline that enables IT organizations to release their software changes rapidly at scale. Low quality IaC scripts can have serious consequences, potentially leading to wide-spread system outages and service discrepancies. The goal of this research is to help practitioners increase the quality of infrastructure as code (IaC) scripts by identifying anti-patterns in IaC scripts and development of IaC scripts. Using open source repositories, we conduct three initial studies to (i) quantify the frequency and categorize the defects in IaC scripts; and (ii) identify operations that characterize defective IaC scripts. Based on our empirical analysis we observe (i) the dominant defect defect categories to be related to syntax and configuration assignments, and (ii) three operations that characterize defective IaC scripts. The above-mentioned findings motivate us to identify anti-patterns in IaC scripts and IaC development. To this end, we propose three studies that identify (i) process anti-patterns; and (ii) security-related anti-patterns in IaC."
"Infrastructure as Code","https://scispace.com/papers/infrastructure-as-code-2yslo2fk","2023","Journal Article","IEEE Software","Giovanni Quattrocchi
Damian A. Tamburri","10.1109/ms.2022.3212034","","Yes","This special issue shows how the realm of infrastructure code has evolved to a status which—analyzed from a scientific perspective—can be considered mature, and rich in practices which can be seen as off-the-shelf approaches to continuous software engineering."
"Infrastructure as Code: Managing Servers in the Cloud","https://scispace.com/papers/infrastructure-as-code-managing-servers-in-the-cloud-40fvw4w5hp","2016","Book","","Kief Morris","","","Yes","Virtualization, cloud, containers, server automation, and software-defined networking are meant to simplify IT operations. But many organizations adopting these technologies have found that it only leads to a faster-growing sprawl of unmanageable systems. This is where infrastructure as code can help. With this practical guide, author Kief Morris of Thought Works shows you how to effectively use principles, practices, and patterns pioneered through the DevOps movement to manage cloud age infrastructure. Ideal for system administrators, infrastructure engineers, team leads, and architects, this book demonstrates various tools, techniques, and patterns you can use to implement infrastructure as code. In three parts, youll learn about the platforms and tooling involved in creating and configuring infrastructure elements, patterns for using these tools, and practices for making infrastructure as code work in your environment. Examine the pitfalls that organizations fall into when adopting the new generation of infrastructure technologies Understand the capabilities and service models of dynamic infrastructure platforms Learn about tools that provide, provision, and configure core infrastructure resources Explore services and tools for managing a dynamic infrastructureLearn specific patterns and practices for provisioning servers, building server templates, and updating running servers"
"Interpreting Infrastructure Automation for Cloud Service: A Focus on Identity and Access Management","https://scispace.com/papers/interpreting-infrastructure-automation-for-cloud-service-a-1cfytedlavji","2024","Journal Article","International Journal For Multidisciplinary Research","Kiran Kumar Suram","10.36948/ijfmr.2024.v06i06.34088","","No","This comprehensive article examines the transformative role of infrastructure automation within cloud services, focusing on automated controls and Identity and Access Management (IAM) systems. The article investigates how Infrastructure as Code (IaC) and automated security frameworks are reshaping traditional approaches to IT infrastructure deployment and management in modern business environments. Through detailed analysis of current implementation practices, security frameworks, and organizational transformation patterns, this article demonstrates the significant impact of automated infrastructure management on operational efficiency and security posture. The research reveals that organizations implementing automated IAM controls experience substantial reductions in security incidents, improved resource utilization, and enhanced operational efficiency. Key findings highlight the effectiveness of dynamic permission management, continuous authentication mechanisms, and automated security controls in maintaining robust security frameworks while enabling scalable operations. The article also explores the business implications of infrastructure automation, addressing both challenges and opportunities in implementation. The findings suggest that organizations adopting comprehensive automation frameworks achieve significant advantages in security, efficiency, and resource optimization. This article contributes to the growing body of knowledge on infrastructure automation and provides practical insights for organizations seeking to enhance their cloud security posture through automated solutions."
"Assessing Architecture Conformance to Security-Related Practices in Infrastructure as Code Based Deployments","https://scispace.com/papers/assessing-architecture-conformance-to-security-related-3d9qcesv","2022","Proceedings Article","IEEE International Conference on Services Computing","Evangelos Ntentos
Uwe Zdun
Ghareeb Falazi
Uwe Breitenbücher
Frank Leymann","10.1109/SCC55611.2022.00029","","No","Infrastructure as Code (IaC) enables developers and operations teams to automatically deploy and manage an IT infrastructure via software. Among other uses, IaC is widely used in the context of continuously released deployments such as those of microservice and other cloud-based systems. Although IaC-based deployments have been utilized by many companies, there are no approaches on checking their conformance to architectural aspects yet. In this paper, we focus on security-related practices including observability, access control, and traffic control in IaC-based deployments. While best practices for this topic have been documented in some gray literature sources such as practitioners’ blogs and public repositories, approaches enabling automated checking of conformance to such best practices do not yet exist. We propose a model-based approach based on generic, technology-independent metrics, tied to typical architectural design decisions on IaC-based deployments. With this approach, we can measure conformance to security-related practices. We demonstrate and assess the validity and appropriateness of these metrics in assessing a system’s conformance to practices through regression analysis."
"An Approach to Identifying Error Patterns for Infrastructure as Code","https://scispace.com/papers/an-approach-to-identifying-error-patterns-for-infrastructure-ef9uahf9ue","2018","Proceedings Article","International Symposium on Software Reliability Engineering","Wei Chen
Guoquan Wu
Jun Wei","10.1109/ISSREW.2018.00-19","","No","Infrastructure as Code (IaC), which specifies system configurations in an imperative or declarative way, automates environment set up, system deployment and configuration. Despite wide adoption, developing and maintaining high-quality IaC artifacts is still challenging. This paper proposes an approach to handling the fine-grained and frequently occurring IaC code errors. The approach extracts code changes from historical commits and clusters them into groups, by constructing a feature model of code changes and employing an unsupervised machine learning algorithm. It identifies error patterns from the clusters and proposes a set of inspection rules to check the potential IaC code errors. In practice, we take Puppet code artifacts as subject objects and perform a comprehensive study on 14 popular Puppet artifacts. In our experiment, we get 41 cross-artifact error patterns, covering 42% crawled code changes. Based on these patterns, 30 rules are proposed, covering 60% identified error patterns, to proactively check IaC artifacts. The approach would be helpful in improving code quality of IaC artifacts."
"Testing practices for infrastructure as code","https://scispace.com/papers/testing-practices-for-infrastructure-as-code-44zn79831f","2020","Proceedings Article","","Mohammed Mehedi Hasan
Farzana Ahamed Bhuiyan
Akond Rahman","10.1145/3416504.3424334","","No","Infrastructure as code (IaC) helps practitioners to rapidly deploy software services to end-users. Despite reported benefits, IaC scripts are susceptible to defects. Defects in IaC scripts can cause serious consequences, for example, creating large-scale outages similar to the Amazon Web Services (AWS) incident in 2017. The prevalence of defects in IaC scripts necessitates practitioners to implement IaC testing and be aware of IaC testing practices. A synthesis of IaC testing practices can enable practitioners in early mitigation of IaC defects and also help researchers to identify potential research avenues. The goal of this paper is to help practitioners improve the quality of infrastructure as code (IaC) scripts by identifying a set of testing practices for IaC scripts. We apply open coding on 50 Internet artifacts, such as blog posts to derive IaC testing practices. We identify six testing practices that include behavior-focused test coverage, the practice of measuring coverage of IaC test cases in terms of expected behavior. We conclude our paper by discussing how practitioners and researchers can leverage our derived list of testing practices for IaC."
"PIACERE project: description and prototype for optimizing infrastructure as code deployment configurations","https://scispace.com/papers/piacere-project-description-and-prototype-for-optimizing-3d7juox3","2022","Proceedings Article","Proceedings of the Genetic and Evolutionary Computation Conference Companion","Eneko Osaba
Josu Díaz-de-Arcaya
Leire Orúe Echevarría Arrieta
Juncal Alonso
Jesus L. Lobo
Gorka Benguria
Iñaki Etxaniz","10.1145/3520304.3533938","","No","PIACERE is an European project supported by the Union's Horizon 2020 research and innovation programme, whose objective is to enhance the productivity of DevOps teams in the operation of Infrastructure as Code (IaC) by offering an integrated DevSec-Ops framework. Thus, DevOps practitioners can develop IaC as if they were programming a common software application. In order to achieve this challenging task, one of the core technologies considered within PIACERE will be the design and development of optimization metaheuristics, in a module coined as IaC Optimizer Platform (IOP). The main objective of the IOP is to provide DevSecOps teams with the most appropriate deployment configurations that best fit a set of defined constraints. The goal of this technical paper is to describe the preliminary approach followed in PIACERE for carrying out this optimization, and how the IOP fits into the whole PIACERE ecosystem. Additionally, results obtained in a preliminary experimentation are detailed in this study."
"Automation in Cloud-Based DevOps: A Guide to CI/CD Pipelines and Infrastructure as Code (IaC) with Terraform and Jenkins","https://scispace.com/papers/automation-in-cloud-based-devops-a-guide-to-ci-cd-pipelines-4r9yvv45w1qc","2024","Journal Article","World Journal of Advanced Engineering Technology and Sciences","Taiwo Joseph Akinbolaji
Godwin Nzeako
David Akokodaripon
Akorede Victor Aderoju","10.30574/wjaets.2024.13.2.0542","","No","This study offers a comprehensive analysis of automation in cloud-based DevOps, focusing on the role of Continuous Integration/Continuous Delivery (CI/CD) pipelines and Infrastructure as Code (IaC) in streamlining software development processes. Employing tools like Jenkins and Terraform, the research aims to demonstrate how automation can significantly enhance operational efficiency, scalability, and security in cloud deployments. Through a detailed examination of CI/CD components and their integration with IaC, this paper identifies key findings, including the reduction of manual errors, improved deployment consistency across environments, and enhanced security through DevSecOps practices. The study further explores challenges such as configuration complexity and compliance, proposing best practices like proactive monitoring, encrypted secrets management, and version control to mitigate these issues. Conclusively, the research recommends the adoption of AI-driven analytics and robust security frameworks to optimize cloud-based CI/CD automation. This work not only highlights current methodologies but also anticipates future trends, providing a strategic roadmap for organizations aiming to leverage DevOps automation effectively."
"Terraformization: Revolutionizing Enterprise IT Strategy","https://scispace.com/papers/terraformization-revolutionizing-enterprise-it-strategy-cv714mshvh5n","2025","Journal Article","Global Journal of Engineering and Technology Advances","Dharmendra Ahuja","10.30574/gjeta.2025.23.1.0120","","No","This article presents a comprehensive analysis of Terraformization—the enterprise-wide adoption of Terraform as the primary Infrastructure as Code (IaC) solution—and its transformative impact on modern IT strategy. Through rigorous examination of industry research and implementation data across multiple sectors, the article quantifies the substantial benefits organizations achieve through declarative infrastructure management. Key findings demonstrate how Terraformization delivers measurable improvements: 78% reduction in security misconfigurations, 91% decrease in credential-related incidents, 83% fewer change management audit findings, and 67% lower disaster recovery costs with 90% faster recovery times. The analysis traces the evolution from manual paradigms to sophisticated code-based approaches and examines how leading organizations leverage Terraform to drive innovation across multi-cloud environments. Beyond technical implementation, the article explores organizational patterns that maximize success—including platform engineering models, self-service provisioning frameworks, and emerging trends like GitOps and AI-enhanced infrastructure management. By establishing infrastructure as a first-class software artifact governed by the same development practices and quality standards as application code, Terraformization enables enterprises to achieve unprecedented levels of operational efficiency, security integration, cost optimization, and delivery speed while positioning them to adapt to evolving cloud strategies."
"On the Prevalence, Co-occurrence, and Impact of Infrastructure-as-Code Smells","https://scispace.com/papers/on-the-prevalence-co-occurrence-and-impact-of-infrastructure-1rf9zp74hg","2024","Journal Article","","Narjes Bessghaier
Mahi Begoug
Chemseddine Mebarki
Ali Ouni
Mohammed Sayagh
Mohamed Wiem Mkaouer","10.1109/saner60148.2024.00009","","No","In modern software systems, Infrastructure-as-Code (IaC) tools play a pivotal role in automating the management of various infrastructure resources such as networks, databases, and services. This automation is done through code-based specification files, commonly known as IaC files. Similarly to other code files, IaC files can suffer from violations of established implementation and design standards, i.e., IaC smells. Although prior research has studied various aspects of traditional smells in non-IaC artifacts, there is little knowledge of how IaC smells are prevalent, co-occurring, and impacting the change and defect proneness of IaC code. To fill this gap, we conduct an empirical study encompassing 82 Puppet-based open-source projects. Our investigation focused on 12 types of IaC smells in both implementation and design levels. Our findings reveal that IaC smells do not manifest uniformly, as IaC smells that are particularly associated with modularity issues, exhibit high prevalence rates across projects. Additionally, we found that 74% of IaC files are smelly and over 52% of the smelly IaC files have at least two co-occurring IaC smells. Furthermore, our findings highlight that, on average, smelly IaC files are modified nearly 3.8 times, in terms of number of commits, more frequently than non-smelly IaC files. Furthermore, smelly IaC files are found to be 3.1 times more prone to larger code changes, in terms of code churn, than non-smelly IaC files. Additionally, we found that smelly IaC files are 3.3 times more prone to the introduction of defects that are likely to persist in 1.65 more commits before being fixed than non-smelly IaC files. These findings advocate developers to be more aware of IaC smells in their projects and consider their correction."
"Embracing IaC Through the DevSecOps Philosophy: Concepts, Challenges, and a Reference Framework","https://scispace.com/papers/embracing-iac-through-the-devsecops-philosophy-concepts-3s4k96zu","2023","Journal Article","IEEE Software","Juncal Alonso
Radoslaw Piliszek
Matic Cankar","10.1109/MS.2022.3212194","https://ieeexplore.ieee.org/ielx7/52/5204063/09915031.pdf","No","We introduce the challenges of DevSecOps philosophy and its applicability to the development and operation of trustworthy infrastructure-as-code, and we combine the solutions into a single framework covering all crucial steps. Finally, we discuss how the proposed framework addresses the challenges and introduce an initial design for it."
"SoK: Static Configuration Analysis in Infrastructure as Code Scripts","https://scispace.com/papers/sok-static-configuration-analysis-in-infrastructure-as-code-1r7w1ccwcl","2023","Journal Article","","Pandu Ranga Reddy Konala
Vimal Kumar
David Bainbridge","10.1109/csr57506.2023.10224925","","No","This SoK paper presents findings from a survey conducted on the current state of tools and techniques used in the static configuration analysis of Infrastructure as Code (IaC). Our findings highlight the increasing importance of ensuring the quality of IaC scripts through techniques such as detecting code and security smells. Our findings reveal that regular expressions are widely used, but this may not be a long-term or fully automated solution for detecting smells. Additionally, our study found that the majority of the tools and techniques are developed for infrastructure provisioning, rather than configuration management and image building. This raises concerns because configuring software is a high-risk task, with malicious actors constantly targeting software systems. Therefore, it is crucial for researchers to develop efficient and advanced techniques for detecting defects in configuration management and image building. The aim of this paper is to provide a detailed overview of the current state of research in this field, and to identify areas for future development."
"Developing a New DevOps Modelling Language to Support the Creation of Infrastructure as Code","https://scispace.com/papers/developing-a-new-devops-modelling-language-to-support-the-vh7bf9rz","2022","Book Chapter","","Michele Chiari
Elisabetta Di Nitto
Adrián Noguero Mucientes
Bin Xiang","10.1007/978-3-031-23298-5_8","https://zenodo.org/record/6697369/files/ESOCCProjectTrack.pdf","Yes","The deployment of cloud applications and the correct management of their lifecycle is a colossal task. Infrastructure as Code (IaC) tools make this task easier; however, they require the user to have a deep knowledge of both the IaC language and the characteristics of various cloud services providers. The PIACERE project has developed a DevOps Modelling Language (DOML), aiming at describing cloud applications that are agnostic of the specificities of the different providers and IaC tools used for provisioning, deployment and configuration. DOML provides several modeling perspectives in a multi-layer approach. An application can be described in three layers: application layer, abstract and concrete infrastructure layer. It allows developers to describe how cloud applications are structured in an abstract manner, mapping the different software components to the concrete infrastructure elements, enabling the usage of different concretizations to match one particular deployment. This paper provides an overview of the DOML language: its layers and extension mechanisms, as well as an example to showcase its modeling capabilities."
"Characteristics of defective infrastructure as code scripts in DevOps","https://scispace.com/papers/characteristics-of-defective-infrastructure-as-code-scripts-1t6le9ryi0","2018","Proceedings Article","International Conference on Software Engineering","Akond Rahman","10.1145/3183440.3183452","","No","Defects in infrastructure as code (IaC) scripts can have serious consequences for organizations who adopt DevOps. By identifying which characteristics of IaC scripts correlate with defects, we can identify anti-patterns, and help software practitioners make informed decisions on better development and maintenance of IaC scripts, and increase quality of IaC scripts. The goal of this paper is to help practitioners increase the quality of IaC scripts by identifying characteristics of IaC scripts and IaC development process that correlate with defects, and violate security and privacy objectives. We focus on characteristics of IaC scripts and IaC development that (i) correlate with IaC defects, and (ii) violate security and privacy-related objectives namely, confidentiality, availability, and integrity. For our initial studies, we mined open source version control systems from three organizations: Mozilla, Openstack, and Wikimedia, to identify the defect-related characteristics and conduct our case studies. From our empirical analysis, we identify (i) 14 IaC code and four churn characteristics that correlate with defects; and (ii) 12 process characteristics such as, frequency of changes, and ownership of IaC scripts that correlate with defects. We propose the following studies: (i) identify structural characteristics that correlate with defects; (ii) with respect to prediction performance, compare which characteristics of IaC scripts are more correlated with defects; and (iii) identify characteristics that violate security and privacy objectives."
"Scaling devops with infrastructure as code in multi- cloud environments","https://scispace.com/papers/scaling-devops-with-infrastructure-as-code-in-multi-cloud-hfm39kn56g5m","2022","Journal Article","Turkish Journal of Computer and Mathematics Education","V. Gunnam
N. Kilaru
Sai Krishna Manohar Cheemakurthi","10.61841/turcomat.v13i2.14764","","No","In the dynamic environment of contemporary cloud technologies, combining DevOps with such technologies as IaC is critical. This report looks at DevOps in multi-cloud setup, focusing on IaC as part of the DevOps' Pillars.' Catering for extensive DevOps adoption across different clouds, the discussion in this paper reveals the value of large-scale DevOps through reports based on simulated real-life scenarios and situations. The main findings reveal that IaC positively improves operationality, reliability and agility in the cycle process. But at the same time, it brings additional issues connected to the problem of cloud compatibility, safety, and the issue of cloud management. Thus, this report outlines recurrent problems and provides realistic recommendations to tackle such difficulties and maintain trustworthy and efficient DevOps when using multiple clouds. Through the enablement of IaC, organizations shall experience enhanced efficiency in day-to-day operations and float consolidation of development and operations teams, which, in the long run, create competitiveness in the cloud computing discourse."
"Automated Disaster Recovery Infrastructure for HIPAA-Regulated Healthcare Systems: A Cloud-Native Implementation Using Infrastructure as Code","https://scispace.com/papers/automated-disaster-recovery-infrastructure-for-hipaa-pewr4iyy2qsn","2025","Journal Article","International journal of computational and experimental science and engineering","Manoj Kumar Reddy Kalakoti","10.22399/ijcesen.3928","","No","Background: Healthcare institutions require robust disaster recovery infrastructure to ensure continuous access to vital patient data and clinical applications. Traditional manual recovery procedures are error-prone and cannot meet stringent regulatory timeframes for restoring critical healthcare services.Methods: This study implemented an automated disaster recovery system for a web-based healthcare platform using Infrastructure as Code principles. The implementation employed Terraform and AWS CloudFormation to codify infrastructure designs across multiple AWS regions, incorporating automated provisioning of VPCs, RDS clusters, EKS environments, and IAM settings. Data synchronization leveraged RDS cross-region replication, S3 bucket policies, and CloudEndure, while a CI/CD pipeline built with Jenkins and GitLab enabled automatic environment provisioning and compliance reporting.Results: The solution demonstrated significant improvements in recovery metrics, with recovery time objectives reduced by a factor of 10-50x compared to manual methods. Data loss windows decreased from hours to seconds or minutes (60-120x improvement). Testing frequency increased 4-12x while staff hours per test decreased by 10-40x. AI-enhanced observability reduced mean-time-to-identify by approximately 70% in test scenarios.Conclusions: Through platform automation and infrastructure as code concepts, this implementation offers a replicable framework for healthcare institutions seeking to improve disaster recovery capabilities while maintaining HIPAA compliance. The codification of infrastructure provides a foundation for future AI-driven autonomous recovery systems."
"Lessons from Research to Practice on Writing Better Quality Puppet Scripts","https://scispace.com/papers/lessons-from-research-to-practice-on-writing-better-quality-1jvvqcqy","2022","Proceedings Article","2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)","Akond Rahman
Tushar Sharma","10.1109/saner53432.2022.00019","","No","Infrastructure as Code (IaC) scripts, such as Puppet scripts, provide practitioners the opportunity to provision computing infrastructure automatically at scale. Poorly written IaC scripts impact various facets of quality (such as security and maintainability) and, in turn, may lead to serious consequences. Many of the ill-effects can be avoided or rectified easily by following recommendations derived from research and best practices gleaned from experience. While researchers have investigated methods to improve quality aspects of Puppet scripts, such research needs to be summarized and synthesized for industry practitioners. In this article, we summarize recent research in the IaC domain by discussing key quality issues, specifically security and maintainability smells, that may arise in an IaC script. We also mine open-source repositories from three organizations (Mozilla, Openstack, and Wikimedia) and report our observations on the identified smells. Furthermore, we also synthesize recommendations from the literature for software practitioners that could improve the quality of IaC scripts. Software development teams dealing with large computing infrastructure can get benefited from the actionable recommended practices. In addition, researchers in the domain may use this study to find opportunities to improve the state-of-the-art."
"Automating Infrastructure Management: Benefits and Challenges of Ansible and Terraform Implementation Across Sectors","https://scispace.com/papers/automating-infrastructure-management-benefits-and-challenges-4h93llhf1f4g","2024","Journal Article","International journal of scientific research in computer science, engineering and information technology","Avinash Pathak","10.32628/cseit241051032","","No","This article examines the implementation and impact of Infrastructure as Code (IaC) practices using Ansible and Terraform across various industries. Through a mixed-methods approach combining case studies, surveys, and quantitative analysis, we investigate how these tools enable more efficient, scalable, and repeatable infrastructure deployments. Our findings reveal significant benefits, including reduced operational costs (average 30% reduction), improved resource utilization (up to 40% increase), and enhanced disaster recovery capabilities (50% faster recovery times). However, challenges such as skills gaps, security concerns, and legacy system integration persist. The article provides insights into industry-specific applications, highlighting how finance, healthcare, and telecommunications sectors leverage these tools to meet unique demands. We present best practices for successful implementation, emphasizing continuous monitoring, data governance, and cross-functional collaboration. This article contributes to the growing body of literature on IaC and offers practical recommendations for organizations seeking to optimize their infrastructure management strategies in an increasingly digital landscape."
"Policy-Driven Infrastructure Validation for Network Modernization","https://scispace.com/papers/policy-driven-infrastructure-validation-for-network-1t51pmgjj3l6","2025","Journal Article","International journal of computational and experimental science and engineering","Prasanth Kosaraju","10.22399/ijcesen.3808","","No","Network infrastructure refresh projects traditionally focus on hardware replacement while neglecting the critical aspect of configuration standardization and policy enforcement, resulting in configuration inconsistencies and operational challenges that persist despite successful hardware upgrades. This article introduces NetConForm, a policy-based infrastructure standardization and validation framework designed specifically for large-scale network refresh initiatives that addresses the fundamental gap between hardware modernization and configuration standardization. The framework implements a comprehensive three-tier architecture consisting of a Policy Definition Layer that employs declarative baseline systems, a Validation Engine leveraging Python-based automation libraries for multi-vendor device interaction, and a Compliance Reporting System that maintains version-controlled repositories of configuration states. Through empirical evaluation across multiple enterprise network refresh projects, NetConForm demonstrates significant improvements in operational efficiency, compliance outcomes, and network reliability by transforming refresh projects from simple replacement exercises into opportunities for comprehensive infrastructure optimization. The framework's automated approach to configuration management, drawing from principles established in Infrastructure as Code and modern security configuration management practices, enables organizations to achieve systematic policy enforcement, proactive compliance validation, and continuous monitoring that aligns technical standards with business objectives and regulatory requirements."
"Architecting Multi-Cloud Immutable Infrastructure Workflows: Beyond Traditional CI/CD","https://scispace.com/papers/architecting-multi-cloud-immutable-infrastructure-workflows-50g60gs72law","2025","Journal Article","International journal of scientific research in computer science, engineering and information technology","Sridhar Nelloru","10.32628/cseit25111221","","No","This article explores the advanced realm of multi-cloud immutable infrastructure workflows, presenting a comprehensive analysis of their implementation, benefits, and future directions. It delves into the foundational principles of immutable infrastructure and their application in multi-cloud environments, highlighting the integration with Infrastructure as Code and policy-as-code frameworks. The discussion extends to advanced patterns and workflows, including strategies for unifying disparate cloud APIs, leveraging orchestration tools, and standardizing security measures across heterogeneous environments. The article examines how these approaches enhance both stability and agility in software deployment, covering dynamic scaling policies, automated rollback mechanisms, and strategies for maintaining consistency. It also addresses the operational benefits and challenges associated with these workflows, providing insights into faster service deployment, reduced operational overhead, and proactive governance management. Looking ahead, the article forecasts the impact of emerging technologies such as artificial intelligence and machine learning on multi-cloud orchestration and infrastructure management. By offering a holistic view of current practices and future trends, this article serves as a valuable resource for organizations seeking to optimize their cloud infrastructure strategies and stay ahead in the rapidly evolving landscape of software deployment and management."
"Enhancing Efficiency Through Infrastructure Automation: An In-Depth Analysis of Infrastructure as Code (IaC) Tools","https://scispace.com/papers/enhancing-efficiency-through-infrastructure-automation-an-in-1dvqut8mtx","2023","Proceedings Article","","Milandeep Kour Bali
Ranjan Walia","10.1109/icccis60361.2023.10425162","","No","Due to the increasing demand for efficient management and provisioning of infrastructure resources, Infrastructure as Code (IaC) tools have become indispensable in modern IT environments. Ensuring the scalability of these tools is crucial for accommodating organizations changing requirements and maintaining their effectiveness. Our investigation delves into the visualization of IaC tool scalability and reliability, illustrated by a line chart. On the x-axis, each tool is depicted, with scalability ratings or metrics plotted on the y-axis. IaC tools can be easily compared and evaluated for scalability with the aid of this chart. It provides valuable insight for organizations looking to make informed decisions about selecting the most appropriate tool based on their specific infrastructure needs and growth potential. The chart summarizes and compares key scalability features, making it easier to identify the best tool for meeting performance expectations."
"A Conformance Checking-based Approach for Drift Detection in Business Processes","https://scispace.com/papers/a-conformance-checking-based-approach-for-drift-detection-in-3wwgxig1qh","2021","Journal Article","IEEE Transactions on Services Computing","Víctor Gallego-Fontenla
Juan C. Vidal
Manuel Lama","10.1109/TSC.2021.3120031","https://arxiv.org/pdf/1907.04276.pdf","No","Real life business processes change over time, in both planned and unexpected ways. The detection of these changes is crucial for organizations to ensure that the expected and the real behavior are as similar as possible. These changes over time are called concept drift and its detection is a big challenge in process mining since the inherent complexity of the data makes difficult distinguishing between a change and an anomalous execution. In this paper, we present C2D2 (Conformance Checking-based Drift Detection), a new approach to detect sudden control-flow changes in the process models from event traces. C2D2 combines discovery techniques with conformance checking methods to perform an offline detection. Our approach has been validated with a synthetic benchmarking dataset formed by 68 logs, showing an improvement in the accuracy while maintaining a minimum delay in the drift detection."
"Rule based continuous drift and consistency management for complex systems","https://scispace.com/papers/rule-based-continuous-drift-and-consistency-management-for-54g8u9gcmy","2015","Patent","","Raja Chatterjee
Ashishkumar Gor","","","No","Techniques are for rule-based continuous drift and consistency management for target systems. In one embodiment, a set of rules is stored in volatile or non-volatile store. The set of rules may include one or more drift rules and/or one or more consistency rules. A rule may be applied to one or more associated targets to detect drift or inconsistency. A drift rule identifies a set of one or more attributes and a source and may be applied by comparing a first configuration of the set of one or more attributes on an associated target with a second configuration of the set of one or more attributes on the source. A consistency rule may be applied to a composite target by comparing member targets that are grouped by target type. Notification data may be output if target drift or inconsistency is detected to alert a user."
"Drift detection and notification","https://scispace.com/papers/drift-detection-and-notification-2d4wlj1kbl","2012","Patent","","Haroon Ahmed
James D. Laflen","","","No","A drift condition, or change, in a data structure can be detected and communicated to one or more subscribers. Data structure can be monitored by periodic configurable polling of a data source or on demand polling. Upon detection of a change in the in the data structure, subscribers can be notified of the change and optionally other information such as the identity of the object that changed and nature of the change."
"Advanced computer system drift detection","https://scispace.com/papers/advanced-computer-system-drift-detection-51kfw41488","2019","Patent","","Lahav Omri Moshe
Johnson Raoul Christopher
Tolpin David","","","No","Computer system drift can occur when a computer system or a cluster of computer systems deviates from ideal and/or desired behavior. In a server farm, for example, many different machines may be identically configured to work in conjunction with each other to provide an electronic service (serving web pages, processing electronic payment transactions, etc.). Over time, however, one or more of these systems may drift from previous behavior. Early drift detection can be important, especially in large enterprises, to avoiding costly downtime. Changes in a computer's configuration files, network connections, and/or executable processes can indicate ongoing drift, but collecting this information at scale can be difficult. By using certain hashing and min-Hash techniques, however, drift detection can be streamlined and accomplished for large scale operations. Velocity of drift may also be tracked using a decay function."
"A Conflict-based Drift Detection and Adaptation Approach for Multisensor Information Fusion","https://scispace.com/papers/a-conflict-based-drift-detection-and-adaptation-approach-for-jycdjqld9e","2018","Proceedings Article","Emerging Technologies and Factory Automation","Christoph-Alexander Holst
Volker Lohweg","10.1109/ETFA.2018.8502571","","No","Multisensor systems are susceptible to sensor ageing effects as well as to environmental changes. Due to these effects, the distribution of sensor measurements may change over time, which is referred to as sensor drift. A multisensor system which adapts to drift by self-monitoring is more durable, requires less manual maintenance, and provides information of higher quality. This contribution proposes an approach for detecting and adapting to sensor drift. The proposed detection algorithm determines the reliability of a sensor based on fuzzy pattern classifiers and a consistency measure. By this means, the inherent redundancy in multisensor systems is exploited to detect drift. Detected drift leads then to a retraining of the classifier on batched data guided by information fusion. The retraining incorporates the estimated magnitude of the drift. The proposed algorithms are evaluated in comparison with state-of-the-art methods in the scope of a publicly available dataset. It is shown that the drift detection algorithm yields results similar to the benchmark algorithm but is less computationally complex. Relearning with the drift-adapted approach results in more robust classifiers with regard to potential future drift."
"Gradual Drift Detection in Process Models Using Conformance Metrics","https://scispace.com/papers/gradual-drift-detection-in-process-models-using-conformance-e9wtufqat3fb","2025","Journal Article","ACM Transactions on Knowledge Discovery From Data","Víctor Gallego-Fontenla
Pedro Gamallo-Fernandez
Juan C. Vidal
Manuel Lama","10.1145/3716169","","No","Changes, planned or unexpected, are common during the execution of real-life processes. Detecting these changes is a must for optimizing the performance of organizations running such processes. Most of the algorithms present in the state-of-the-art focus on the detection of sudden changes, leaving aside other types of changes. In this paper, we will focus on the automatic detection of gradual drifts, a special type of change, in which the cases of two models overlap during a period of time. The proposed algorithm relies on conformance checking metrics to carry out the automatic detection of the changes, performing also a fully automatic classification of these changes into sudden or gradual. The approach has been validated with a synthetic dataset consisting of 120 logs with different distributions of changes, getting better results in terms of detection and classification accuracy, delay and change region overlapping than the main state-of-the-art algorithms."
"Detecting sudden and gradual drifts in business processes from execution traces","https://scispace.com/papers/detecting-sudden-and-gradual-drifts-in-business-processes-3t0dobaohx","2020","Journal Article","arXiv: Artificial Intelligence","Abderrahmane Maaradji
Marlon Dumas
Marcello La Rosa
Alireza Ostovar","10.1109/TKDE.2017.2720601","http://export.arxiv.org/pdf/2005.04016","Yes","Business processes are prone to unexpected changes, as process workers may suddenly or gradually start executing a process differently in order to adjust to changes in workload, season, or other external factors. Early detection of business process changes enables managers to identify and act upon changes that may otherwise affect process performance. Business process drift detection refers to a family of methods to detect changes in a business process by analyzing event logs extracted from the systems that support the execution of the process. Existing methods for business process drift detection are based on an explorative analysis of a potentially large feature space and in some cases they require users to manually identify specific features that characterize the drift. Depending on the explored feature space, these methods miss various types of changes. Moreover, they are either designed to detect sudden drifts or gradual drifts but not both. This paper proposes an automated and statistically grounded method for detecting sudden and gradual business process drifts under a unified framework. An empirical evaluation shows that the method detects typical change patterns with significantly higher accuracy and lower detection delay than existing methods, while accurately distinguishing between sudden and gradual drifts."
"Out-of-Distribution Detection and Data Drift Monitoring using Statistical Process Control","https://scispace.com/papers/out-of-distribution-detection-and-data-drift-monitoring-1wljaj13es","2024","Journal Article","arXiv.org","Ghada Zamzmi
Kesavan Venkatesh
Brandon Nelson
Smriti Prathapan
Paul H. Yi
Berkman Sahiner
Jana G. Delfino","10.48550/arxiv.2402.08088","","No","Background: Machine learning (ML) methods often fail with data that deviates from their training distribution. This is a significant concern for ML-enabled devices in clinical settings, where data drift may cause unexpected performance that jeopardizes patient safety. Method: We propose a ML-enabled Statistical Process Control (SPC) framework for out-of-distribution (OOD) detection and drift monitoring. SPC is advantageous as it visually and statistically highlights deviations from the expected distribution. To demonstrate the utility of the proposed framework for monitoring data drift in radiological images, we investigated different design choices, including methods for extracting feature representations, drift quantification, and SPC parameter selection. Results: We demonstrate the effectiveness of our framework for two tasks: 1) differentiating axial vs. non-axial computed tomography (CT) images and 2) separating chest x-ray (CXR) from other modalities. For both tasks, we achieved high accuracy in detecting OOD inputs, with 0.913 in CT and 0.995 in CXR, and sensitivity of 0.980 in CT and 0.984 in CXR. Our framework was also adept at monitoring data streams and identifying the time a drift occurred. In a simulation with 100 daily CXR cases, we detected a drift in OOD input percentage from 0-1% to 3-5% within two days, maintaining a low false-positive rate. Through additional experimental results, we demonstrate the framework's data-agnostic nature and independence from the underlying model's structure. Conclusion: We propose a framework for OOD detection and drift monitoring that is agnostic to data, modality, and model. The framework is customizable and can be adapted for specific applications."
"DriftInsight: Detecting Anomalous Behaviors in Large-Scale Cloud Platform","https://scispace.com/papers/driftinsight-detecting-anomalous-behaviors-in-large-scale-20kwf82z8u","2017","Proceedings Article","International Conference on Cloud Computing","Fan Jing Meng
Xiao Zhang
Pengfei Chen
Jing Min Xu","10.1109/CLOUD.2017.37","","No","Detecting anomalous behaviors of cloud platforms is one of critical tasks for cloud providers. Every anomalous behavior potentially causes incidents, especially some unaware and/or unknown issues, which severely harm their SLA (Service Level Agreement). Existing solutions generally monitor cloud platform at different layers and then detect anomalies based on rules or learning algorithms on monitoring metrics. However, complexity of nowadays cloud platforms, high dynamics of cloud workloads and thousands of various types of metrics make anomalous behavior detection more challenging to be applied in production, especially in large scale cloud production environments. In this paper, we present a practical cloud anomalous behavior detection system called DriftInsight. It firstly analyzes multi-denominational metrics of each component and identifies a set of representative steady components based on the convergences of their states. Then it generates a state model and a state transit model for each steady cloud component. Finally, it detects behavior anomalies of these steady components in near real-time and meanwhile evolve behavior models on the fly. The evaluation results of this approach in a commercial large-scale PaaS (Platform-as-a-Service) cloud are demonstrated its capability and efficiency."
"Rendez-Vous Based Drift Diagnosis Algorithm for Sensor Networks Toward In Situ Calibration","https://scispace.com/papers/rendez-vous-based-drift-diagnosis-algorithm-for-sensor-11qy3ezm","2023","Journal Article","IEEE Transactions on Automation Science and Engineering","Florentin Delaine
Bérengère Lebental
Hervé Rivano","10.1109/TASE.2022.3182289","","No","In recent years, low-cost sensors have raised strong interest for environmental monitoring applications. These instruments often suffer from degraded data quality. Notably, they are prone to drift. It can be mitigated with costly periodic calibrations. To reduce this cost, in situ calibration strategies have emerged, enabling the recalibration of instruments while leaving them in the field. However, they rarely identify which instruments actually need a calibration because of drift, so that in situ calibration may instead degrade performances. Therefore, a novel drift detection algorithm is presented in this work, exploiting the concept of rendez-vous between measuring instruments. Its originality lies mainly in the comparisons of values determining the state of the instruments, for which the quality of the measurement results is taken into account. It defines the concept of compatibility between measurement results. A case study is developed, showing an accuracy of 88% for correct detection of drifting instruments. The results of the diagnosis algorithm are then combined with calibration approaches. Results show a significant improvement of the measurement results. Notably, an increase of 15% of the coefficient of determination of the linear regression between their true values and the measured values is observed with the correction and the error on the slope and on the intercept respectively is reduced by 50% and 60% at least. Note to Practitioners—In this paper, we investigate the problem of drift detection in sensor networks. This work was motivated by the fact that faulty nodes are rarely detected in existing in situ calibration algorithm prior to the correction of the instruments. Moreover, existing fault diagnosis algorithms for sensor networks do not specifically target drift and are often applicable to either (dense) static or mobile sensor networks but not both. We propose an algorithm designed for the detection of drift faults regardless of the type of sensor network and of the measurand. Specific attention is paid to the metrological quality of the measurement results used to carry out the diagnosis. The output of the algorithm provides information that can be exploited for the recalibration of faulty instruments. In future work, we will aim at providing tools and recommendations for the adjusment of the parameters of the diagnosis algorithm but also more elaborated approaches based on the results of our diagnosis algorithm to calibrate faulty nodes."
"Drift Detection and Handling","https://scispace.com/papers/drift-detection-and-handling-18n3kx91u8","2024","Book Chapter","Machine Learning: Foundations, Methodologies, and Applications","Thomas Bartz‐Beielstein
Lukas Hans","10.1007/978-981-99-7007-0_3","","No","Structural changes (“drift”) in the data cause problems for many algorithms. Based on the drift definitions given in Chap. 1 , methods for drift detection and handling are discussed. For the algorithms presented in Chap. 2 , it is clarified to what extent concept drift is reacted to. In turn, the extent to which catastrophic forgetting is an issue is described in Sect. 4.3 . Section 3.1 describes three architectures for implementing drift detection algorithms. Basic properties of window-based approaches are presented in Sect. 3.2. Section 3.4 presents commonly used drift detection techniques. Section 3.4 describes how the drift detection techniques introduced in Sect. 3.3 are used in Online Machine Learning (OML) algorithms and summarizes the tree-based OML techniques implemented in the River package. Section 3.5 introduces scaling methods for handling drift."
"Data drift detection and mitigation: A comprehensive MLOps approach for real-time systems","https://scispace.com/papers/data-drift-detection-and-mitigation-a-comprehensive-mlops-5qvvm1zkpipk","2024","Journal Article","International Journal of Science and Research Archive","Naveen Kodakandla","10.30574/ijsra.2024.12.1.0724","","No","About Real time continuously updating machine learning systems it is important to note that model consistency and resilience is highly desirable. Nonetheless, data shift, or changes in the statistical properties of data over time, represent a great threat when it comes to maintaining the best possible model accuracy. In this article, the author considers the phenomenon of data drift in detail, and the methods of its prevention within the framework of MLOps. What this work aims to achieve The study explores different forms of data drift and their consequences, especially on real-time systems, the tools and methods used in monitoring the drift and methods used in containing the same. Therein, we propose an end-to-end MLOps solution for handling the drift and using automated drift detection, retraining techniques and adaptive models for continuous learning. Finally, detailed experimental evaluations in numerous domains including healthcare, finance, and IoT confirm the effectiveness of the proposed approach. Moreover, the article focuses on the new trends, The social or moral issues associated with the drift management and how advanced more advanced artificial intelligence tools become instrumental in the future of drift management. That is why, with a proper MLOps approach in place, an organization would be ready and able to address data drift as a problem, thereby maintaining sustainable, efficient real-time systems."
"Context-Aware Drift Detection","https://scispace.com/papers/context-aware-drift-detection-2qe136yn","2022","Proceedings Article","International Conference on Machine Learning","Oliver J. Cobb
Arnaud Van Looveren","10.48550/arXiv.2203.08644","","No","When monitoring machine learning systems, two-sample tests of homogeneity form the foundation upon which existing approaches to drift detection build. They are used to test for evidence that the distribution underlying recent deployment data differs from that underlying the historical reference data. Often, however, various factors such as time-induced correlation mean that batches of recent deployment data are not expected to form an i.i.d. sample from the historical data distribution. Instead we may wish to test for differences in the distributions conditional on context that is permitted to change. To facilitate this we borrow machin-ery from the causal inference domain to develop a more general drift detection framework built upon a foundation of two-sample tests for conditional distributional treatment effects. We recommend a particular instantiation of the framework based on maximum conditional mean discrepancies. We then provide an empirical study demonstrating its effectiveness for various drift detection problems of practical interest, such as detecting drift in the distributions underlying subpopulations of data in a manner that is insensitive to their respective prevalences. The study additionally demonstrates applicability to ImageNet-scale vision problems. and night) covered by the training data. We often do not wish for this partial coverage to cause drift detections, but instead to detect other changes not explained by the change/narrowing of context. A nighttime deployment batch should be permitted to contain only wolves and owls, but a daytime deployment batch should not contain any owls."
"Drifter: Efficient Online Feature Monitoring for Improved Data Integrity in Large-Scale Recommendation Systems","https://scispace.com/papers/drifter-efficient-online-feature-monitoring-for-improved-160rx2sv7w","2023","Journal Article","arXiv.org","Blaz Skrlj
Nir Ki-Tov
Lee Edelist
Natalia Silberstein
Hila Weisman-Zohar
B. Mramor
Davorin Kopič
Naama Ziporin","10.48550/arxiv.2309.08617","https://scispace.com/pdf/drifter-efficient-online-feature-monitoring-for-improved-160rx2sv7w.pdf","No","Real-world production systems often grapple with maintaining data quality in large-scale, dynamic streams. We introduce Drifter, an efficient and lightweight system for online feature monitoring and verification in recommendation use cases. Drifter addresses limitations of existing methods by delivering agile, responsive, and adaptable data quality monitoring, enabling real-time root cause analysis, drift detection and insights into problematic production events. Integrating state-of-the-art online feature ranking for sparse data and anomaly detection ideas, Drifter is highly scalable and resource-efficient, requiring only two threads and less than a gigabyte of RAM per production deployments that handle millions of instances per minute. Evaluation on real-world data sets demonstrates Drifter's effectiveness in alerting and mitigating data quality issues, substantially improving reliability and performance of real-time live recommender systems."
"UDDT: An Unsupervised Drift Detection Method for Industrial Time Series Data","https://scispace.com/papers/uddt-an-unsupervised-drift-detection-method-for-industrial-3b3eola7x6","2023","Proceedings Article","","Deepti Maduskar
Divyasheel Sharma
Chandrika Kr
Reuben Borrison
Gianluca Manca
Marcel Dix","10.1109/oncon60463.2023.10431133","","No","Industrial ML models are primarily data-driven. Therefore, one of the main focus for monitoring the model should be towards identifying the drifts in the data that might affect the performance of the model. The traditional drift detecting methods are usually based on some assumptions related to the underlying data such as no inter-dependence. However industrial sensor data typically consists of time series data, which is collected at regular intervals. Therefore, detecting drift in dependent data where the current readings depend on the previously registered readings demands a different approach. Existing solutions require either the ground truth, a fixed size, or the underlying model details. We propose an Unsupervised Drift Detection method for industrial Time series data or UDDT, a generic approach with no such pre-requisites. In our approach, we can check whether two series belong to the same model. Apart from detecting the drift in the two series, it can also provide the rationale behind the observed drift, i.e., whether the drift is due to a difference in stationarity, correlation structures, or noise distributions. We evaluate the UDDT on two datasets to demonstrate its correctness and the trust regions under various circumstances. We also establish its applicability for the real industrial setting."
"Concept Drift Monitoring and Diagnostics of Supervised Learning Models via Score Vectors","https://scispace.com/papers/concept-drift-monitoring-and-diagnostics-of-supervised-x20t8xah","2022","Journal Article","Technometrics","Dianne C. Mitchell","10.1080/00401706.2022.2124310","http://arxiv.org/pdf/2012.06916","Yes","Supervised learning models are one of the most fundamental classes of models. Viewing supervised learning from a probabilistic perspective, the set of training data to which the model is fitted is usually assumed to follow a stationary distribution. However, this stationarity assumption is often violated in a phenomenon called concept drift, which refers to changes over time in the predictive relationship between covariates X and a response variable Y and can render trained models suboptimal or obsolete. We develop a comprehensive and computationally efficient framework for detecting, monitoring, and diagnosing concept drift. Specifically, we monitor the Fisher score vector, defined as the gradient of the log-likelihood for the fitted model, using a form of multivariate exponentially weighted moving average, which monitors for general changes in the mean of a random vector. In spite of the substantial performance advantages that we demonstrate over popular error-based methods, a score-based approach has not been previously considered for concept drift monitoring. Advantages of the proposed score-based framework include applicability to broad classes of parametric models, more powerful detection of changes as shown in theory and experiments, and inherent diagnostic capabilities for helping to identify the nature of the changes."
"Predictive drift detection and correction","https://scispace.com/papers/predictive-drift-detection-and-correction-6a6btt6vqb","2017","Patent","","Maughan Jason
James T. Lovell
Richard W. Wellman
Kelly D. Phillipps","","","No","Apparatuses, systems, methods, and computer program products are disclosed for drift detection and correction for predictive analytics. A prediction module (202) applies a model to workload data to produce one or more predictive results. Workload data may include one or more records. A model may include one or more learned functions (702, 704, 706) based on training data. A drift detection module (204) detects a drift phenomenon relating to one or more predictive results. A predict-time fix module (206) may modify at least one predictive result in response to a drift phenomenon."
"Improving Drift Detection by Monitoring Shapley Loss Values","https://scispace.com/papers/improving-drift-detection-by-monitoring-shapley-loss-values-3cc1eywe","2022","Book Chapter","Lecture Notes in Computer Science","Bastien Zimmermann
Mathieu Boussard","10.1007/978-3-031-09282-4_38","","No","Along the deployment of Machine Learning models rises an inherent need for monitoring, where model performances should be tracked as well as potential drifts. In a live environment, with evolving data, the risk is for the model to become ill-adapted for the given situation. The failure to detect drift while leading to a performance deterioration could also cause side effects due to model over-trust. Informing the user of any anomaly upon detection is the key to enabling any action. We propose Shap-ADWIN, a novel approach improving the performance of state-of-the-art drift detectors such as ADWIN by leveraging the information brought by Shapley Loss Values. While common practice is to monitor the evolution of the loss of models at most for every predicted instance, the proposed solution monitors each individual instance and features the Shapley Loss value. Whenever the loss is attributed more toward a given feature the information becomes more contrasted, which enables a better detection. Indeed the signal-to-noise ratio is higher on that feature and allows the detector to leverage that information. The opposite case being equal Shapley values that are just the Loss under-scaled for every feature. Moreover, noise over the output would be equally distributed along with each Shapley Loss value of every feature providing lower information to noise ratio and allows a more reliable detection. We provide: a restricted proof, experiments and source code. Results were obtained using synthetically generated data presenting diverse types of drift, showing the performance of Shap-ADWIN over ADWIN."
"Data Drift Monitoring for Log Anomaly Detection Pipelines","https://scispace.com/papers/data-drift-monitoring-for-log-anomaly-detection-pipelines-5dv7weqbbp","","Journal Article","arXiv.org","Dipak Wani
Samuel Ackerman
Eitan Farchi
Sarasi Lalithsena","10.48550/arxiv.2310.14893","","No","Logs enable the monitoring of infrastructure status and the performance of associated applications. Logs are also invaluable for diagnosing the root causes of any problems that may arise. Log Anomaly Detection (LAD) pipelines automate the detection of anomalies in logs, providing assistance to site reliability engineers (SREs) in system diagnosis. Log patterns change over time, necessitating updates to the LAD model defining the `normal' log activity profile. In this paper, we introduce a Bayes Factor-based drift detection method that identifies when intervention, retraining, and updating of the LAD model are required with human involvement. We illustrate our method using sequences of log activity, both from unaltered data, and simulated activity with controlled levels of anomaly contamination, based on real collected log data."
"Comprehensive Process Drift Detection with Visual Analytics","https://scispace.com/papers/comprehensive-process-drift-detection-with-visual-analytics-3wfjao3tb1","2019","","","Anton Yeshchenko
Claudio Di Ciccio
Jan Mendling
Artem Polyvyanyy","","https://scispace.com/https://minerva-access.unimelb.edu.au/bitstream/handle/11343/258888/057 - ER 2019 - Comprehensive Process Drift Detection with Visual Analytics - POSTPRINT.pdf","Yes","Recent research has introduced ideas from concept drift into process mining to enable the analysis of changes in business processes over time. This stream of research, however, has not yet addressed the challenges of drift categorization, drilling-down, and quantification. In this paper, we propose a novel technique for managing process drifts, called Visual Drift Detection (VDD), which fulfills these requirements. The technique starts by clustering declarative process constraints discovered from recorded logs of executed business processes based on their similarity and then applies change point detection on the identified clusters to detect drifts. VDD complements these features with detailed visualizations and explanations of drifts. Our evaluation, both on synthetic and real-world logs, demonstrates all the aforementioned capabilities of the technique."
"Towards non-parametric drift detection via Dynamic Adapting Window Independence Drift Detection (DAWIDD)","https://scispace.com/papers/towards-non-parametric-drift-detection-via-dynamic-adapting-3b373cqg4m","2020","Proceedings Article","International Conference on Machine Learning","Fabian Hinder
André Artelt
Citec Barbara Hammer","","https://scispace.com/pdf/towards-non-parametric-drift-detection-via-dynamic-adapting-3b373cqg4m.pdf","Yes","The notion of concept drift refers to the phenomenon that the distribution, which is underlying the observed data, changes over time; as a consequence machine learning models may become inaccurate and need adjustment. Many online learning schemes include drift detection to actively detect and react to observed changes. Yet, reliable drift detection constitutes a challenging problem in particular in the context of high dimensional data, varying drift characteristics, and the absence of a parametric model such as a classification scheme which reflects the drift. In this paper we present a novel concept drift detection method, Dynamic Adapting Window Independence Drift Detection (DAWIDD), which aims for non-parametric drift detection of diverse drift characteristics. For this purpose, we establish a mathematical equivalence of the presence of drift to the dependency of specific random variables in an according drift process. This allows us to rely on independence tests rather than parametric models or the classification loss, resulting in a fairly robust scheme to universally detect different types of drift, as it is also confirmed in experiments."
"RDDM: Reactive drift detection method","https://scispace.com/papers/rddm-reactive-drift-detection-method-3dqroh5i0c","2017","Journal Article","Expert Systems With Applications","Roberto Souto Maior de Barros
Danilo Rafael de Lima Cabral
Paulo Mauricio Gonçalves
Silas Garrido Teixeira de Carvalho Santos","10.1016/J.ESWA.2017.08.023","","No","Concept drift detectors are online learning software that mostly attempt to estimate the drift positions in data streams in order to modify the base classifier after these changes and improve accuracy. This is very important in applications such as the detection of anomalies in TCP/IP traffic and/or frauds in financial transactions. Drift Detection Method (DDM) is a simple, efficient, well-known method whose performance is often impaired when the concepts are very long. This article proposes the Reactive Drift Detection Method (RDDM) , which is based on DDM and, among other modifications, discards older instances of very long concepts aiming to detect drifts earlier, improving the final accuracy. Experiments run in MOA, using abrupt and gradual concept drift versions of different dataset generators and sizes (48 artificial datasets in total), as well as three real-world datasets, suggest RDDM beats the accuracy results of DDM, ECDD, and STEPD in most scenarios."
"An unsupervised methodology for online drift detection in multivariate industrial datasets","https://scispace.com/papers/an-unsupervised-methodology-for-online-drift-detection-in-38g4f5iew1","2020","Proceedings Article","International Conference on Data Mining","Sarah Klein
Mathias Verbeke","10.1109/ICDMW51313.2020.00061","","No","Slight deviations in the evolution of measured parameters of industrial machinery or processes can signal performance degradations and upcoming failures. Therefore, the timely and accurate detection of these drifts is important, yet complicated by the fact that industrial datasets are often multivariate in nature, inherently dynamic and often noisy. In this paper, a robust drift detection approach is proposed that extends a semi-parametric log-likelihood detector with adaptive windowing, allowing to dynamically adapt to the newly incoming data over time. It is shown that the approach is more accurate and can strongly reduce the computation time when compared to non-adaptive approaches, while achieving a similar detection delay. When evaluated on an industrial data set, the methodology can compete with offline drift detection methods."
"Comparison of Off-the-Shelf Methods and a Hotelling Multidimensional Approximation for Data Drift Detection","https://scispace.com/papers/comparison-of-off-the-shelf-methods-and-a-hotelling-16dr56lqik1k","2024","Journal Article","Machine learning and knowledge extraction","J. Ramón Navarro-Cerdán
Vicent Ortiz Castelló
David Millán Escrivá","10.3390/make7010002","","No","Data drift can significantly impact the outcome of a model. Early detection of data drift is crucial for ensuring user confidence in predictions. It allows the user to check if a particular model needs retraining using updated data to adapt to the evolving process dynamics. This study compares five different statistical tests, namely four unidimensional and a new multidimensional test (MSPC), to identify data drift in both mean and deviation. While some are designed to detect drift in mean only, like our multidimensional proposal, others respond to changes in both mean and deviation. However, our Hotelling multidimensional method can be trained once and then applied in a single stage to any data stream with several attributes, and it can identify the most relevant variables causing a data drift with one execution, thus avoiding the need for a single univariate test for each attribute. Moreover, our method yields the relative importance of each attribute for drift and allows users to increase or decrease the relative weight of each variable regarding drift detection. It also may be capable of detecting drift due to changes in multivariate interactions. This behavior is especially suitable for real-world scenarios, such as industry, finance, or healthcare environments."
"Evaluation of Drift Detection Algorithms in the Condition Monitoring Domain","https://scispace.com/papers/evaluation-of-drift-detection-algorithms-in-the-condition-232ienhikgy6","","Journal Article","IEEE Transactions on Industrial Informatics","Alireza Estaji
Maximilian Götzinger
Benedikt Tutzer
Stefan Kollmann
Thilo Sauter
Axel Jantsch","10.1109/tii.2024.3452208","","No","In condition monitoring, early detection of process signal drifts indicating, e.g., equipment degradation is crucial. exponentially weighted moving average (EWMA), cumulative sum (CUSUM), and discrete average block (DAB)-based drift detectors are statistical and commonly used methods. Each has benefits and limitations, suited to different data types. However, EWMA and CUSUM are fixed mean drift detectors, limiting their applicability and adaptability. This article explores adding dynamic behavior to drift detection methods. We use a wide range of synthetic data based on a real-world manufacturing process. The investigated parameter space includes standard deviation, drift rates, and outliers. Besides, each algorithm has some tuning parameters that define its behavior. Two metrics validate experiments against labeled data. Based on our observations, EWMA performs better for drift detection on average, but CUSUM is superior in detecting very small drifts. Furthermore, we derive guidelines for the choice and application of drift detection in practice."
"Concept Drift Detection Delay Index","https://scispace.com/papers/concept-drift-detection-delay-index-29zrzdad","2023","Journal Article","IEEE Transactions on Knowledge and Data Engineering","Anjin Liu
Jie Lu
Yiliao Song
Junyu Xuan
Guang-Lin Zhang","10.1109/TKDE.2022.3153349","","No","Data streams may encounter data distribution changes, which can significantly impair the accuracy of models. Concept drift detection tracks data distribution changes and signals when to update models. Many drift detection methods apply thresholds to distinguish between drift or non-drift streams and to claim their method outperforms others with non-aligned drift thresholds. We consider that selecting a proper drift threshold could be more important than developing a new drift detection algorithm, and different drift detection algorithms may end up with very similar performance with aligned drift thresholds. To better understand this process, we propose a novel threshold selection algorithm to align the drift thresholds of a set of algorithms so that they are all at the same sensitivity level. Based on comprehensive experiment evaluations, we observed that several state-of-the-art drift detection algorithms could achieve similar results by aligning their thresholds, providing a novel insight to explain how drift detection algorithms contribute to data stream learning. We noticed that a higher detection sensitivity improves accuracy for data streams with frequent distribution change. The evaluation results are showing that drift thresholds should not be fixed during stream learning. Rather, they should adjust dynamically based on the prevailing conditions of the data stream."
"Unveiling dynamics changes: Singular spectrum analysis-based method for detecting concept drift in industrial data streams","https://scispace.com/papers/unveiling-dynamics-changes-singular-spectrum-analysis-based-47frj0hp60","2024","Journal Article","Knowledge Based Systems","Yuyan Zhang
Zhe Liu
Chunjie Yang
Xiaoke Huang
Siwei Lou
Hanwen Zhang
Duojin Yan","10.1016/j.knosys.2024.111640","","No","Industrial data streams frequently experience concept drifts. Current drift detection methods, focusing on prediction performance or data distribution, often neglect temporal dependencies and require prior distribution assumptions. These limitations have catalyzed the development of dynamic theory-based approaches that identify drifts by discerning variations in data dynamics. However, the majority of these exhibit high complexity in dynamics characterization and still underperform in industrial drift detection. To overcome these challenges, we propose a singular spectrum analysis-based drift detection method for industry data streams, comprising three modules: common dynamics extraction, noise-robust drift detection, and threshold adaptation. Our approach uses singular spectrum analysis (SSA) as the dynamics representation method instead of traditional high-dimensional phase space embedding and Fourier transform. SSA allows for the efficient description of principal dynamics by intelligently mixing the Fourier basis functions according to given data. The first two modules are specifically engineered to address the common dynamics and stochastic noise inherent in industrial data streams through a well-designed online common dynamics extraction algorithm and a noise-robust detection index respectively. Threshold adaptation module provides a more reasonable way of updating the drift threshold based on the extreme value theory, ensuring global consistency for parameter estimation of extreme value distribution. Our proposed method was tested on simulated examples and a real-world sintering process, exhibiting enhanced drift detection performance."
"Tackling data and model drift in AI: Strategies for maintaining accuracy during ML model inference","https://scispace.com/papers/tackling-data-and-model-drift-in-ai-strategies-for-4hpuyvpizq23","2023","Journal Article","International Journal of Science and Research Archive","Surya Gangadhar Patchipala","10.30574/ijsra.2023.10.2.0855","","No","In machine learning (ML) and artificial intelligence (AI), model accuracy over time is very important, particularly in dynamic environments where data and relationships change. Data and model drift pose challenging issues that this paper seeks to explore: shifts in input data distributions or underlying model structures that continuously degrade predictive performance. It analyzes different drift types in-depth, including covariate, prior probability, concept drift for dasta, parameters, hyperparameter, and algorithmic model drift. Key causes, ranging from environmental changes to evolving data sources and overfitting, contribute to decreased model reliability. The article also discusses practical strategies for detecting and mitigating Drift, such as regular monitoring, statistical tests, and performance tracking, alongside solutions like automated recalibration, ensemble methods, and online learning models to enhance adaptability. Furthermore, the importance of feedback loops and computerized systems in handling Drift is emphasized, with real-world case studies illustrating drift impacts in financial and healthcare applications. Finally, future AI system drift management will be highlighted from emerging directions such as AI-based drift prediction, transfer learning, and robust model design."
"Detecting drift from event streams of unpredictable business processes","https://scispace.com/papers/detecting-drift-from-event-streams-of-unpredictable-business-1ofdon1e3o","2016","Book Chapter","International Conference on Conceptual Modeling","Alireza Ostovar
Abderrahmane Maaradji
Marcello La Rosa
Arthur H. M. ter Hofstede
Arthur H. M. ter Hofstede
Boudewijn F. van Dongen","10.1007/978-3-319-46397-1_26","","No","Existing business process drift detection methods do not work with event streams. As such, they are designed to detect inter-trace drifts only, i.e. drifts that occur between complete process executions (traces), as recorded in event logs. However, process drift may also occur during the execution of a process, and may impact ongoing executions. Existing methods either do not detect such intra-trace drifts, or detect them with a long delay. Moreover, they do not perform well with unpredictable processes, i.e. processes whose logs exhibit a high number of distinct executions to the total number of executions. We address these two issues by proposing a fully automated and scalable method for online detection of process drift from event streams. We perform statistical tests over distributions of behavioral relations between events, as observed in two adjacent windows of adaptive size, sliding along with the stream. An extensive evaluation on synthetic and real-life logs shows that our method is fast and accurate in the detection of typical change patterns, and performs significantly better than the state of the art."
"Detecting Drift in Deep Learning: A Methodology Primer","https://scispace.com/papers/detecting-drift-in-deep-learning-a-methodology-primer-b2skd1o1","2022","Journal Article","IT Professional","","10.1109/mitp.2022.3191318","","No","Supervised machine learning models are trained on historical data to learn a static mapping between their input and output variables. However, when they are deployed on continuously streamed data, whose nature is likely to change over time (data or concept drift), model performance may suddenly and substantially degrade, forcing practitioners to continuously update the models to reflect the new data distribution. Few methods, however, are available to reliably detect data drift on heterogeneous data types (structured and unstructured), possibly without requiring labeled data at inference time. In this article, we review existing methods for dataset drift detection, discuss their applicability to deep neural networks, and experiment on a practical case study related to semistructured document analysis."
"Characterizing drift from event streams of business processes","https://scispace.com/papers/characterizing-drift-from-event-streams-of-business-2ufopi3w0j","2017","Book Chapter","Conference on Advanced Information Systems Engineering","Alireza Ostovar
Abderrahmane Maaradji
Marcello La Rosa
Arthur H. M. ter Hofstede","10.1007/978-3-319-59536-8_14","https://scispace.com/pdf/characterizing-drift-from-event-streams-of-business-2ufopi3w0j.pdf","Yes","Early detection of business process drifts from event logs enables analysts to identify changes that may negatively affect process performance. However, detecting a process drift without characterizing its nature is not enough to support analysts in understanding and rectifying process performance issues. We propose a method to characterize process drifts from event streams, in terms of the behavioral relations that are modified by the drift. The method builds upon a technique for online drift detection, and relies on a statistical test to select the behavioral relations extracted from the stream that have the highest explanatory power. The selected relations are then mapped to typical change patterns to explain the detected drifts. An extensive evaluation on synthetic and real-life logs shows that our method is fast and accurate in characterizing process drifts, and performs significantly better than alternative techniques."
"Augur","https://scispace.com/papers/augur-2wqai734","2022","Proceedings Article","","Grace A. Lewis
Sebastian Echeverria
Lena Pons
Jeffrey Chrabaszcz","10.1145/3526073.3527590","","Yes","The inference quality of deployed machine learning (ML) models degrades over time due to differences between training and production data, typically referred to as drift. While large organizations rely on periodic training to evade drift, the reality is that not all organizations have the data and the resources required to do so. We propose a process for drift behavior analysis at model development time that determines the set of metrics and thresholds to monitor for runtime drift detection. Better understanding of how models will react to drift before they are deployed, combined with a mechanism for how to detect this drift in production, is an important aspect of Responsible AI. The toolset and experiments reported in this paper provide an initial demonstration of (1) drift behavior analysis as a part of the model development process, (2) metrics and thresholds that need to be monitored for drift detection in production, and (3) libraries for drift detection that can be embedded in production monitoring infrastructures."
"Transformation drift detection and remediation","https://scispace.com/papers/transformation-drift-detection-and-remediation-19zyh2cf92","2019","Patent","","Shah Rupal Jatinkumar","","","No","In various example embodiments, a system, computer-readable medium and method to detect and dynamically correct a transformation drift in a data pipeline, the method comprising detecting a change in a transformation performed by an upstream subsystem of the data pipeline on a data field of an output dataset of the upstream subsystem; classifying the data field as an impacted data field; identifying, based on the topology information, a downstream subsystem of the data pipeline downstream of the upstream subsystem; identifying an input dataset of the downstream subsystem including the impacted data field; and performing a corrective transformation on the impacted data field of the input dataset of the downstream subsystem"
"Handling Concept Drift in Data Streams by Using Drift Detection Methods","https://scispace.com/papers/handling-concept-drift-in-data-streams-by-using-drift-auk5h7a93y","2019","Book Chapter","","Malini M. Patil","10.1007/978-981-13-1274-8_12","","No","The growth and development of the information and communication technology of the present era resulted in huge amount data generation It is found that the rate of data distribution is very high The data which is generated with varying distributions is referred to as data stream Few examples to quote, data generated with regard to applications related to mobile networks, sensor networks, network traffic monitoring and network traffic management, etc It is found that, the data generation process often change with respect to data distribution for any kind of concept, ie application which is referred to as concept drift Handling concept drift is a challenging task It is impossible to develop a model as it will be inconsistent in nature because of continuous change The present work emphasises on handling the concept drifts, using different drift detection methods using Massive Online Analysis Framework The important feature of the present study is varying size of a data stream (50,000–250,000) Totally the Concept Drift is handled using 11 drift detection methods using 2 stream generators abrupt and gradual under this frame work respectively"
"Detecting and Identifying Data Drifts in Process Event Streams Based on Process Histories","https://scispace.com/papers/detecting-and-identifying-data-drifts-in-process-event-1ygu69xqvg","2019","Book Chapter","Conference on Advanced Information Systems Engineering","Florian Stertz
Stefanie Rinderle-Ma","10.1007/978-3-030-21297-1_21","","No","Volatile environments force companies to adapt their processes, leading to so called concept drifts during run-time. Concept drifts do not only affect the control flow, but also process data. An example are manufacturing processes where a multitude of machining parameters are necessary to drive the production and might be subject to change due to e.g., machine errors. Detecting such data drifts immediately can help to trigger exception handling in time and to avoid gradual deterioration of the process execution quality. This paper provides online algorithms for concept drift detection in process data employing the concept of process histories. The feasibility of the algorithms is shown based on a prototypical implementation and the analysis of a real-world data set from the manufacturing domain."
"Detecting drifts in data streams using Kullback-Leibler (KL) divergence measure for data engineering applications","https://scispace.com/papers/detecting-drifts-in-data-streams-using-kullback-leibler-kl-wm9uk7yhe1","2024","Journal Article","Journal of Data, Information and Management","Job Kurian
Mohamed Allali","10.1007/s42488-024-00119-y","https://scispace.com/pdf/detecting-drifts-in-data-streams-using-kullback-leibler-kl-wm9uk7yhe1.pdf","No","Abstract The exponential growth of data coupled with the widespread application of artificial intelligence(AI) presents organizations with challenges in upholding data accuracy, especially within data engineering functions. While the Extraction, Transformation, and Loading process addresses error-free data ingestion, validating the content within data streams remains a challenge. Prompt detection and remediation of data issues are crucial, especially in automated analytical environments driven by AI. To address these issues, this study focuses on detecting drifts in data distributions and divergence within data fields processed from different sample populations. Using a hypothetical banking scenario, we illustrate the impact of data drift on automated decision-making processes. We propose a scalable method leveraging the Kullback-Leibler (KL) divergence measure, specifically the Population Stability Index (PSI), to detect and quantify data drift. Through comprehensive simulations, we demonstrate the effectiveness of PSI in identifying and mitigating data drift issues. This study contributes to enhancing data engineering functions in organizations by offering a scalable solution for early drift detection in data ingestion pipelines. We discuss related research works, identify gaps, and present the methodology and experiment results, underscoring the importance of robust data governance practices in mitigating risks associated with data drift and improving data observability."
"Detecting and addressing model drift: Automated monitoring and real-time retraining in ML pipelines","https://scispace.com/papers/detecting-and-addressing-model-drift-automated-monitoring-pagw13st56ub","2019","Journal Article","World Journal Of Advanced Research and Reviews","Mohan Raja Pulicharla","10.30574/wjarr.2019.3.2.0189","","No","As machine learning (ML) models transition from development to deployment, their performance can degrade over time due to changes in underlying data distributions, a phenomenon known as model drift. If left unaddressed, model drift can lead to inaccurate predictions, biased outcomes, and poor business decisions. To mitigate this risk, automated model monitoring and real-time retraining are essential in modern ML pipelines. Model drift can manifest in several forms, including concept drift, where the relationship between features and labels changes; covariate shift, where the distribution of input features evolves; and label drift, where the frequency of class labels varies over time. Detecting and addressing model drift is crucial for maintaining model accuracy and reliability, particularly in high-stakes applications such as financial fraud detection, healthcare diagnostics, and predictive maintenance. This paper explores various methodologies for detecting model drift, including statistical techniques, drift detection algorithms, and real-time anomaly detection frameworks. We discuss key performance monitoring tools such as Prometheus, Grafana, AWS SageMaker Model Monitor, and Evidently AI that facilitate proactive drift identification. Additionally, we highlight strategies for implementing automated model retraining pipelines using MLOps frameworks like Kubeflow, Apache Airflow, and MLflow, ensuring seamless integration with production environments. A significant focus is placed on real-time retraining approaches, where model updates are triggered dynamically based on performance metrics, drift thresholds, and adaptive learning mechanisms. We analyze trade-offs between scheduled vs. event-driven retraining, discuss CI/CD workflows for ML models, and present case studies that showcase the impact of drift management in real-world applications. Finally, we address challenges associated with automated drift mitigation, including computational cost, ethical considerations, and data latency issues. Future research directions explore the role of federated learning, large-scale reinforcement learning, and AI-augmented drift detection techniques to enhance robustness in continuously evolving ML systems. Through a comprehensive study of model drift detection and mitigation strategies, this paper aims to provide actionable insights for data scientists, MLOps engineers, and AI practitioners to build resilient, self-healing ML pipelines that sustain performance in dynamic data environments."
"A multi-components approach to monitoring process structure and customer behaviour concept drift","https://scispace.com/papers/a-multi-components-approach-to-monitoring-process-structure-nyh2q3n3","2022","Journal Article","Expert Systems With Applications","Lingkai Yang
Sally McClean
Mark Donnelly
Kevin Burke
Kashaf Naseer Khan","10.1016/j.eswa.2022.118533","","No","Concept drifts within business processes are viewed as variations in the business circumstances, such as structural and behavioural changes in the control-flow, which necessitate process refinement and model updating. Existing approaches, such as relation-based precedence rules, tuned to detect drifts in the process structure are often not well suited to detecting changes in customer behaviour. This paper proposes a concept drift detector employing multi-components originating from Discrete-time Markov chains to detect, localize and reason about concept drifts in both process structure and customer behaviour of the control-flow. The approach was compared with three commonly used methods using 52 artificial event logs representing various types of drift (sudden and gradual, structural and behavioural). Experimental results demonstrated desirable performance with average F1 scores of 0.871 and 0.893 under structural and behavioural drifts, respectively. The approach was also employed in a real-life hospital billing dataset. The main contribution of this paper is a concept drift detector that is able to detect and explain root causes of control-flow changes whether such variations occurred suddenly or gradually. • A method for detecting sudden and gradual drifts in process event data. • The method can detect structural and behavioural process drifts. • A sliding window framework associated with the proposed drift detector. • The method can detect, localize and rationalize process drifts."
"Open-Source Drift Detection Tools in Action: Insights from Two Use Cases","https://scispace.com/papers/open-source-drift-detection-tools-in-action-insights-from-2eomdc8p27","2024","Preprint","","Renate Müller
Mohamed Abdelaal
Davor Stjelja","10.48550/arxiv.2404.18673","https://scispace.com/pdf/open-source-drift-detection-tools-in-action-insights-from-2eomdc8p27.pdf","No","Data drifts pose a critical challenge in the lifecycle of machine learning (ML) models, affecting their performance and reliability. In response to this challenge, we present a microbenchmark study, called D3Bench, which evaluates the efficacy of open-source drift detection tools. D3Bench examines the capabilities of Evidently AI, NannyML, and Alibi-Detect, leveraging real-world data from two smart building use cases.We prioritize assessing the functional suitability of these tools to identify and analyze data drifts. Furthermore, we consider a comprehensive set of non-functional criteria, such as the integrability with ML pipelines, the adaptability to diverse data types, user-friendliness, computational efficiency, and resource demands. Our findings reveal that Evidently AI stands out for its general data drift detection, whereas NannyML excels at pinpointing the precise timing of shifts and evaluating their consequent effects on predictive accuracy."
"Federated Learning Drift Detection: An Empirical Study on the Impact of Concept and Data Drift","https://scispace.com/papers/federated-learning-drift-detection-an-empirical-study-on-the-363ui0unj5se","2024","Journal Article","","Leyla Rahimli
Feras M. Awaysheh
Sawsan Al Zubi
Sadi Alawadi","10.1109/flta63145.2024.10839814","","No","Federated Learning (FL) has emerged as a transformative paradigm in machine learning, enabling decentralized model training while preserving data privacy across multiple clients. FL addresses critical privacy concerns but introduces challenges related to model drift. Model drift is a phenomenon where the model degrades over time due to changes in the underlying data distribution or the relationships between input features and target variables. This paper proposes a novel drift detection and management methodology within federated environments. Our experimental analysis demonstrates the effectiveness of the proposed drift detection framework. The study systematically evaluates the impact of drift on model performance metrics, including accuracy, F1 score, Cohen's kappa, and ROC. The findings indicate that even minimal drift in a subset of clients can significantly degrade the global model's performance, underscoring the importance of robust drift detection. The proposed solution enhances the reliability and accuracy of federated models and addresses the scalability and privacy-preserving requirements inherent in FL environments."
"Drift detection using stream volatility","https://scispace.com/papers/drift-detection-using-stream-volatility-2bbeexqgfz","2015","Book Chapter","European conference on Machine Learning","David Tse Jung Huang
Yun Sing Koh
Gillian Dobbie
Albert Bifet","10.1007/978-3-319-23528-8_26","","No","Current methods in data streams that detect concept drifts in the underlying distribution of data look at the distribution difference using statistical measures based on mean and variance. Existing methods are unable to proactively approximate the probability of a concept drift occurring and predict future drift points. We extend the current drift detection design by proposing the use of historical drift trends to estimate the probability of expecting a drift at different points across the stream, which we term the expected drift probability. We offer empirical evidence that applying our expected drift probability with the state-of-the-art drift detector, ADWIN, we can improve the detection performance of ADWIN by significantly reducing the false positive rate. To the best of our knowledge, this is the first work that investigates this idea. We also show that our overall concept can be easily incorporated back onto incremental classifiers such as VFDT and demonstrate that the performance of the classifier is further improved."
"Adaptation for Automated Drift Detection in Electromechanical Machine Monitoring.","https://scispace.com/papers/adaptation-for-automated-drift-detection-in-1wdr7xw8","2022","Journal Article","IEEE transactions on neural networks and learning systems","Daisy Hikari Green
Aaron W. Langham
Rebecca A. Agustin
Devin W. Quinn
S. Lee","10.1109/TNNLS.2022.3184011","","No","Practical machine learning applications for streaming data can involve concept drift (the change in statistical properties of data over time), one-shot or few-shot learning (starting with only one or a few examples for each class), a scarcity of representative training data, and extreme verification latency (only the initial dataset has ground-truth labels). This work presents a framework for organizing signal processing and machine learning techniques to provide adaptive classification and drift detection. Nonintrusive load monitoring (NILM) serves as an ideal case study, as modern sensing solutions provide a wellspring of electromechanical data sources. There is a lack of training datasets that generalize across different load and fault scenarios. Accordingly, training must be accomplished with a limited set of data when deploying a NILM to a new power system. Also, loads can exhibit concept drift over time either due to faults or normal variation. NILM field data is used as an illustrative case study to demonstrate the proposed framework for adaptation and drift tracking."
"AutoDrift: A Forecast-Aware Concept Drift Detection and Retraining Pipeline in MLOps with CMAPSS","https://scispace.com/papers/autodrift-a-forecast-aware-concept-drift-detection-and-64cw1f2w4t55","2025","Journal Article","","Raj Kumar Myakala
Praveen Kumar Nagata
Sampath Lavudya
Sanjeev Kumar Pedhapally
Vinithya Reddy Podduturi","10.1109/bigdataservice65758.2025.00019","","No","Concept drift poses a critical challenge to deploying reliable machine learning models in real-world production environments, particularly in time series forecasting and predictive maintenance systems. We present AutoDrift, a modular, forecast-aware framework to detect concept drift and trigger the automated retraining of models within modern MLOps pipelines. This approach integrates Facebook Prophet for time series prediction, statistical drift detection techniques such as the Kolmogorov-Smirnov test, and Apache Airflow to orchestrate retraining and deployment tasks in response to detected drift. Using the widely bench marked NASA CMAPSS dataset, we simulate real-world engine degradation and sensor drift conditions to evaluate AutoDrift's effectiveness in predictive maintenance scenarios. The results demonstrate that AutoDrift maintains high forecasting accuracy (91 % precision) while reducing retraining latency by 37 % compared to static retraining schedules. The framework supports model versioning via MLflow and is cloud-agnostic, enabling seamless deployment across Kubernetes, AWS, and on-premises environments. AutoDrift offers a practical solution to one of the most pressing MLOps challenges such as maintaining the adaptability of deployed models to changing data distributions, by unifying drift detection, retraining logic, and orchestration in a single, extensible pipeline. The system is designed to be interpretable, scalable, and easy to integrate into existing machine learning operations, making it suitable for industrial applications in aviation, IoT, and large-scale telemetry monitoring."
"Quantifying input data drift in medical machine learning models by detecting change-points in time-series data","https://scispace.com/papers/quantifying-input-data-drift-in-medical-machine-learning-rrhtevfya4","2024","Journal Article","","Smriti Prathapan
Ravi K. Samala
Nathan Hadjiyski
Pierre-François D'Haese
Fabien Maldonado
Phuong Nguyen
Yelena Yesha
Berkman Sahiner","10.1117/12.3008771","","No","Devices enabled by artificial intelligence (AI) and machine learning (ML) are being introduced for clinical use at an accelerating pace. In a dynamic clinical environment, these devices may encounter conditions different from those they were developed for. The statistical data mismatch between training/initial testing and production is often referred to as data drift. Detecting and quantifying data drift is significant for ensuring that AI model performs as expected in clinical environments. A drift detector signals when a corrective action is needed if the performance changes. In this study, we investigate how a change in the performance of an AI model due to data drift can be detected and quantified using a cumulative sum (CUSUM) control chart. To study the properties of CUSUM, we first simulate different scenarios that change the performance of an AI model. We simulate a sudden change in the mean of the performance metric at a change-point (change day) in time. The task is to quickly detect the change while providing few false-alarms before the change-point, which may be caused by the statistical variation of the performance metric over time. Subsequently, we simulate data drift by denoising the Emory Breast Imaging Dataset (EMBED) after a pre-defined change-point. We detect the change-point by studying the pre- and post-change specificity of a mammographic CAD algorithm. Our results indicate that with the appropriate choice of parameters, CUSUM is able to quickly detect relatively small drifts with a small number of false-positive alarms."
"Electron beam drift detection device and method for detecting electron beam drift","https://scispace.com/papers/electron-beam-drift-detection-device-and-method-for-2z9405ocka","2011","Patent","","Jia-Yush Yen
Yung-Yaw Chen
Yi-Hung Kuo
Cheng-Ju Wu","","","No","An electron beam drift detection device and a method for detecting electron beam drift are provided in which the method includes placing a predetermined characteristic identification pattern on a surface of a workpiece; emitting an electron beam, and focusing and deflecting the electron beam such that the focused and deflected electron beam scans the surface of the workpiece and the characteristic identification pattern; detecting backscattered electrons and secondary electrons; and detection signals; and receives the receiving detection signals and performs performing an image process on the detection signals to obtain an electronic image of the characteristic identification pattern, and measuring a drift degree by comparing the electronic image with the predetermined shape of the characteristic identification pattern."
"Navigating Process Drift: The Power of CUSUM in Monitoring Air Quality Processes and Maintenance Operations","https://scispace.com/papers/navigating-process-drift-the-power-of-cusum-in-monitoring-44o3l0wxh278","2024","Journal Article","Arabian journal for science and engineering","Muhammad Riaz
Huda Alshammari
Nasir Abbas
Tahir Mahmood","10.1007/s13369-024-09453-0","","No","Abstract Nowadays, manufacturers face intense pressure to maintain a high standard of quality. Due to the damage to machine components, manufacturing processes degrade over time, resulting in substandard products. Generally, statistical process control tools such as control charts aid in identifying patterns and trends indicative of process changes. This investigation delves into the effectiveness of cumulative sum control charts using the sample mean and median as plotting statistics. Run-length measurements assess performance after the charts experience linear and quadratic drifts in non-normal setups under zero- and steady-state conditions. The findings reveal that Cumulative Sum (CUSUM) charts outperform zero-state monitoring compared to steady-state monitoring. Notably, the CUSUM chart for the mean is suitable for normal and Gamma distributions, exhibiting a greater ability for drift detection under biased and unbiased Average Run Lengths. This study offers valuable insights into enhancing manufacturing quality through effectively implementing and comparing Shewhart, Exponentially Weighted Moving Average, and CUSUM charts. By evaluating their performance under various conditions and comparing them with other control chart methods, this research provides valuable guidance for industries seeking to improve process monitoring and product quality. It is essential to acknowledge that the findings are based on specific experimental conditions and may not fully capture the complexity of real-world manufacturing environments. For practical purposes, the suggested charts are also applied to real-world case studies, including air quality (focusing on five metal oxide chemistry sensors: carbon monoxide concentration, non-metonic hydrocarbons, benzene, total nitrogen oxides, and nitrogen dioxide) and maintenance data (including air temperature, rotating speed, and equipment failure)."
"PCA-based drift and shift quantification framework for multidimensional data","https://scispace.com/papers/pca-based-drift-and-shift-quantification-framework-for-r95gw04d3p","2020","Journal Article","Knowledge and Information Systems","Igor Goldenberg
Geoffrey I. Webb","10.1007/S10115-020-01438-3","","No","Concept drift is a serious problem confronting machine learning systems in a dynamic and ever-changing world. In order to manage concept drift it may be useful to first quantify it by measuring the distance between distributions that generate data before and after a drift. There is a paucity of methods to do so in the case of multidimensional numeric data. This paper provides an in-depth analysis of the PCA-based change detection approach, identifies shortcomings of existing methods and shows how this approach can be used to measure a drift, not merely detect it."
"Regional Concept Drift Detection and Density Synchronized Drift Adaptation","https://scispace.com/papers/regional-concept-drift-detection-and-density-synchronized-2kksxf835c","2017","Proceedings Article","International Joint Conference on Artificial Intelligence","Anjin Liu
Yiliao Song
Guangquan Zhang
Jie Lu","10.24963/IJCAI.2017/317","https://scispace.com/pdf/regional-concept-drift-detection-and-density-synchronized-2kksxf835c.pdf","Yes","In data stream mining, the emergence of new patterns or a pattern ceasing to exist is called concept drift. Concept drift makes the learning process complicated because of the inconsistency between existing data and upcoming data. Since concept drift was first proposed, numerous articles have been published to address this issue in terms of distribution analysis. However, most distributionbased drift detection methods assume that a drift happens at an exact time point, and the data arrived before that time point is considered not important. Thus, if a drift only occurs in a small region of the entire feature space, the other non-drifted regions may also be suspended, thereby reducing the learning efficiency of models. To retrieve nondrifted information from suspended historical data, we propose a local drift degree (LDD) measurement that can continuously monitor regional density changes. Instead of suspending all historical data after a drift, we synchronize the regional density discrepancies according to LDD. Experimental evaluations on three benchmark data sets show that our concept drift adaptation algorithm improves accuracy compared to other methods."
"GLRT based fault detection in sensor drift monitoring system","https://scispace.com/papers/glrt-based-fault-detection-in-sensor-drift-monitoring-system-1gzacwz2ez","2009","Book Chapter","International Conference on Intelligent Computing","In-Yong Seo
Ho-Cheol Shin
Moon-Ghu Park
Seong-Jun Kim","10.1007/978-3-642-04020-7_64","","No","In a nuclear power plant (NPP), periodic sensor calibrations are required to assure sensors are operating correctly. However, only a few faulty sensors are found to be calibrated. For the safe operation of an NPP and the reduction of unnecessary calibration, on-line calibration monitoring is needed. This paper presents an on-line sensor drift monitoring technique, based on a Generalized Likelihood Ratio Test (GLRT), for detecting and estimating mean shifts in sensor signal. Also, principal component-based Auto-Associative support vector regression (AASVR) is proposed for the sensor signal validation of the NPP. Response surface methodology (RSM) is employed to efficiently determine the optimal values of SVR hyperparameters. The proposed model was confirmed with actual plant data of Kori NPP Unit 3. The results show that the accuracy of the model and the fault detection performance of the GLRT are very competitive."
"Concept drift detection for distributed multi-model machine learning systems","https://scispace.com/papers/concept-drift-detection-for-distributed-multi-model-machine-8lbr4r09","2022","Proceedings Article","Annual International Computer Software and Applications Conference","Beverly Abadines Quon
Jean-Luc Gaudiot","10.1109/COMPSAC54236.2022.00168","","No","Many works focus on optimizing machine learning models during their training phase, but fail to account how these models adapt into their model-serving phase once they are deployed into real world applications. In this phase models must process through streams of data that can evolve over time and distort the relationship between incoming data, causing concept drift. This paper proposes leveraging the advantages of emerging features stores in order to improve concept drift detection on unlabeled, dynamic data streams across multiple models. Firstly, we introduce Drift Detection on Distributed Datasets (QuaD), which combines classical drift detectors to make use of labeled and unlabeled data, and create local context (i.e. per live model) and global context (i.e. across multiple models). Secondly, we propose using feature store entities, SHAP values, and Collaborative Filtering (CF) to augment unlabeled data across multiple models. To the best of our knowledge, QuaD is the first work that examines the collective behavior of concept drift across multiple models and discerns associations between models that may share a susceptibility in a dynamic setting. QuaD uses a combination of performance-based and data distribution-based drift detectors and CF to capture varying types of concept drifts for labeled and unlabeled data streams and is modeled around the data abstraction provided by emerging feature stores."
"Maintaining and Monitoring AIOps Models Against Concept Drift","https://scispace.com/papers/maintaining-and-monitoring-aiops-models-against-concept-844jfgah","2023","Journal Article","","Lorena Poenaru-Olaru
Luis Cruz
Jan S. Rellermeyer
Arie Theodorus van Deursen","10.1109/CAIN58948.2023.00024","","No","AIOps solutions enable faster discovery of failures in operational large-scale systems through machine learning models trained on operation data. These models become outdated during the occurrence of concept drift, a term used to describe shifts in data distributions. In operation data concept drift is inevitable and it impacts the performance of AIOps solutions over time. Therefore, concept drift should be closely monitored and immediate maintenance to prevent erroneous predictions is required. In this work, we propose an automated maintenance pipeline for AIOps models that monitors the occurrence of concept drift and chooses the most appropriate model retraining technique according to the drift type."
"Unsupervised Concept Drift Detection for Time Series on Riemannian Manifolds","https://scispace.com/papers/unsupervised-concept-drift-detection-for-time-series-on-448bryi721","2023","Journal Article","Journal of The Franklin Institute-engineering and Applied Mathematics","Shusen Wang
Luo Chao
Shao Rui","10.1016/j.jfranklin.2023.09.050","","No","Concept drifts generally refer to the changing of statistical characteristics of non-stationary series over time, which considerably affect the analysis of time series including prediction, anomaly detection and classification, etc. However, since the external noise interference and internal uncertainty of time series, it is still an open problem to detect the occurrence of concept drifts timely and effectively in real applications. In this article, based on Riemannian manifolds and statistical process control, we propose a novel online algorithm for the concept drift detection of time series. Using the online segmentations with multiple sliding windows, phase space reconstruction of time series is implemented, based on which multi-scale features of series data are calculated. By means of information geometry theory, the obtained features are projected into Riemannian manifolds for the evading of noise interference and structural redundancy in the time series. Finally, with statistical process control, the detection of concept drifts is implemented. The experimental results reveal the promising detection performances verified by both artificial data sets and real-life data sets."
"A Generalized Likelihood Ratio Control Chart for Monitoring the Process Mean Subject to Linear Drifts","https://scispace.com/papers/a-generalized-likelihood-ratio-control-chart-for-monitoring-2157rcj44g","2013","Journal Article","Quality and Reliability Engineering International","Liaosa Xu
Sai Wang
Marion R. Reynolds","10.1002/QRE.1404","","No","This article considers the problem of monitoring a normally distributed process variable when a special cause may produce a time-varying linear drift in the mean. The design and application of a generalized likelihood ratio (GLR) control chart for drift detection are evaluated. The GLR drift chart does not require specification of any tuning parameters by the practitioner and has the advantage that, at the time of the signal, estimates of both the change point and the drift size are immediately available. An equation to accurately approximate the control limit is provided. The performance of the GLR drift chart is compared with that of other control charts such as a standard cumulative sum chart and a cumulative score chart designed for drift detection. We also compare the GLR chart designed for drift detection with the GLR chart designed for sustained shift detection because both of them require only a control limit to be specified. In terms of the expected time for detection and in terms of the bias and mean squared error of the change-point estimators, the GLR drift chart has better performance for a wide range of drift rates relative to the GLR shift chart when the out-of-control process is truly a linear drift. Copyright © 2012 John Wiley & Sons, Ltd."
"Detection of anomalies and Data Drift in a time-series dismissal prediction system","https://scispace.com/papers/detection-of-anomalies-and-data-drift-in-a-time-series-kuhha32dw8xs","2024","Journal Article","Iraqi journal for computer science and mathematics","Nataliya Boyko
Roman Kovalchuk","10.52866/ijcsm.2024.05.03.012","","No","The purpose of the study is to develop a system that automatically processes data based on existingand newly entered data, especially with the aim of ensuring high data quality by detecting and eliminatinganomalies. The quantile filtering method, Chebyshev’s inequality, Kolmogorov-Smirnov two-sample test, andothers should be noted among the methods used. In the course of the research, the theoretical aspects of themethods, various principles of detecting anomalies for different types of data were considered and analysed.Different principles and approaches applied to anomaly detection in different contexts were explored. The resultsof the analysis and the selection of optimal methods for detecting anomalies in various types of data are importantfor the effective functioning of the automatic data processing system. This will make it possible to achieveaccuracy and reliability in the detection of anomalies and ensure high quality of data used in the machine learningsystem."
"Predictive Handling of Asynchronous Concept Drifts in Distributed Environments","https://scispace.com/papers/predictive-handling-of-asynchronous-concept-drifts-in-4r9iz85zwa","2013","Journal Article","IEEE Transactions on Knowledge and Data Engineering","Hock Hee Ang
Vivekanand Gopalkrishnan
Indre Zliobaite
Mykola Pechenizkiy
Steven C. H. Hoi","10.1109/TKDE.2012.172","https://scispace.com/pdf/predictive-handling-of-asynchronous-concept-drifts-in-4r9iz85zwa.pdf","Yes","In a distributed computing environment, peers collaboratively learn to classify concepts of interest from each other. When external changes happen and their concepts drift, the peers should adapt to avoid increase in misclassification errors. The problem of adaptation becomes more difficult when the changes are asynchronous, i.e., when peers experience drifts at different times. We address this problem by developing an ensemble approach, PINE, that combines reactive adaptation via drift detection, and proactive handling of upcoming changes via early warning and adaptation across the peers. With empirical study on simulated and real-world data sets, we show that PINE handles asynchronous concept drifts better and faster than current state-of-the-art approaches, which have been designed to work in less challenging environments. In addition, PINE is parameter insensitive and incurs less communication cost while achieving better accuracy."
"Gaussian Mixture Approach to Detect Drift","https://scispace.com/papers/gaussian-mixture-approach-to-detect-drift-3ajnqqu99g","2006","","","Mamidi Sree Kalyan Chakravorty","","https://scispace.com/pdf/gaussian-mixture-approach-to-detect-drift-3ajnqqu99g.pdf","Yes","Historically it has been difficult to measure the deviation in the notion of a concept. Several schemes have been proposed to attack this challenging problem [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]. The central notion of all these efforts is to detect the change point where the data mining model deviates significantly with respect to the data characteristics that it was trained or built on. The process of detecting such change points is often termed as concept drift. Current state of algorithms assume attribute independence, view the problem as a supervised learning problem and also need tagged data. The proposed algorithm does not make any assumption among attribute independence and uses the covariance summary to detect concept drift in an unsupervised setting. The algorithm proposed in this thesis monitors the underlying characteristics of the input data, maintains data summaries of the various snapshots in time and utilizes effective distance metrics to determine when concept drifts. The technique was evaluated against synthetic and real data sets."
"Monitoring Concept Drift in Continuous Federated Learning Platforms","https://scispace.com/papers/monitoring-concept-drift-in-continuous-federated-learning-1aag14blxs","","Journal Article","","Christoph Düsing
Philipp Cimiano","10.1007/978-3-031-58553-1_7","","No","Continuous federated learning (CFL), a recently emerging learning paradigm that facilitates collaborative, yet privacy-preserving machine learning (ML), bears the potential to shape the future of distributed ML. In spite of its great potential, it is - similar to continuous ML - prone to suffer from concept drift (a change in data properties over time). In turn, CFL can greatly benefit from employing drift detection to react adequately to emerging drifts. Although various such approaches exist, respective research lacks application of drift detection to CFL with dynamic client participation as well as detailed analysis of the advantages of different drift detection approaches such as error-based or data-based drift detection. To this end, we apply these drift detection approaches to a CFL platform that allows new clients to join even after the training has started and measure the negative impact of concept drift on model performance. Moreover, we uncover distinct differences between the error- and data-based drift detection. In particular, we find the former ones to be more suitable to detect the point in time where the joint models stops benefiting from concept drift whereas the latter allows for a more precise detection of the first occurrence of concept drift."
"Individuals control schemes for monitoring the mean and variance of processes subject to drifts","https://scispace.com/papers/individuals-control-schemes-for-monitoring-the-mean-and-1mn6oh48u3","2001","Journal Article","Stochastic Analysis and Applications","Marion R. Reynolds
Zachary G. Stoumbos","10.1081/SAP-120000226","https://rmgsc.cr.usgs.gov/outgoing/threshold_articles/Reynolds_Stoumbos2001.pdf","No","This paper investigates control chart schemes for detecting drifts in the process mean μ and/or process standard deviation σ when individual observations are sampled. Drifts may be due to causes such as gradual deterioration of equipment, catalyst aging, waste accumulation, or human causes, such as operator fatigue or close supervision. The standard Shewhart X chart and moving range (MR) chart are evaluated, as well as several types of exponentially weighted moving average (EWMA) charts and combinations of charts involving these EWMA charts. We show that the combinations of the EWMA charts detect slow-rate and moderate-rate drifts much faster than the combined X and MR charts. We also show that varying the sampling interval adaptively as a function of the process data results in notable reductions in the detection delay of drifts in μ and/or σ."
"Concept Drift Detection Through Resampling","https://scispace.com/papers/concept-drift-detection-through-resampling-o0menodjfs","2014","Proceedings Article","International Conference on Machine Learning","Maayan Harel
Shie Mannor
Ran El-Yaniv
Koby Crammer","","https://scispace.com/pdf/concept-drift-detection-through-resampling-o0menodjfs.pdf","Yes","Detecting changes in data-streams is an important part of enhancing learning quality in dynamic environments. We devise a procedure for detecting concept drifts in data-streams that relies on analyzing the empirical loss of learning algorithms. Our method is based on obtaining statistics from the loss distribution by reusing the data multiple times via resampling. We present theoretical guarantees for the proposed procedure based on the stability of the underlying learning algorithms. Experimental results show that the method has high recall and precision, and performs well in the presence of noise."
"A Robust Drift Detection Algorithm with High Accuracy and Low False Positives Rate","https://scispace.com/papers/a-robust-drift-detection-algorithm-with-high-accuracy-and-3c7zfl5t","","","","Laurent Simon
Akka Zemmari","","","No","The number of decision-making processes that rely on machine learning models to operate has been increasing in recent years. Safety of those systems is compromised when models deviate from their expected behavior. One root cause is a shift in the underlying data distribution, known as concept drift. A direct consequence of concept drift is a rapid drop in model’s predictive power. Accurate detection of drift is essential as false alarms lead to unnecessary down time and undermine confidence in the drift detection model. This paper introduces Real-Drift Detector (RDD), a drift detector that is not triggered by virtual drift. RDD does not need use class labels during the inference phase to operate. Our detector outperformed the state of the art in an extensive benchmark on a large panel of well-known datasets used in drift detection."
"Pre-event Abrupt Drift Detection","https://scispace.com/papers/pre-event-abrupt-drift-detection-4het9ai495","2015","","","Tatiana Escovedo
Adriano Koshiyama
Marley M. B. R. Vellasco
Rubens N. Melo","","","Yes","ldistribution - a concept drift. However, detecting changes after its occurrence can be in some situations harmful for the process under supervision. This paper proposes a pre-event approach for abrupt drift detection, called by A2D2. Briefly, this method is composed of three steps: (i) label the patterns from the test set, using an unsupervised method; (ii) compute some statistics from the train and test set, conditioned on the given class labels; and (iii) compare the train and test statistics using a multivariate hypothesis test. Also, it has been proposed a procedure for creating datasets with abrupt drift. This procedure was used in the sensivity analysis of A2D2, in order to understand the influence degree of each parameter on its final performance."
"Alignment Monitoring","https://scispace.com/papers/alignment-monitoring-92465syo7c1j","2025","Journal Article","arXiv.org","Thomas A. Henzinger
Konstantin Kueffner
Vasu Singh
I. Sun","10.48550/arxiv.2508.00021","https://scispace.com/pdf/alignment-monitoring-92465syo7c1j.pdf","No","Formal verification provides assurances that a probabilistic system satisfies its specification--conditioned on the system model being aligned with reality. We propose alignment monitoring to watch that this assumption is justified. We consider a probabilistic model well aligned if it accurately predicts the behaviour of an uncertain system in advance. An alignment score measures this by quantifying the similarity between the model's predicted and the system's (unknown) actual distributions. An alignment monitor observes the system at runtime; at each point in time it uses the current state and the model to predict the next state. After the next state is observed, the monitor updates the verdict, which is a high-probability interval estimate for the true alignment score. We utilize tools from sequential forecasting to construct our alignment monitors. Besides a monitor for measuring the expected alignment score, we introduce a differential alignment monitor, designed for comparing two models, and a weighted alignment monitor, which permits task-specific alignment monitoring. We evaluate our monitors experimentally on the PRISM benchmark suite. They are fast, memory-efficient, and detect misalignment early."
"Condition detection and reporting in complex systems","https://scispace.com/papers/condition-detection-and-reporting-in-complex-systems-4mdv0u5mzo","2011","Patent","","Philip White","","","No","Maintaining consistency and freshness of information about an operational system, assuring consistent actions by system actors, assuring that system elements use only a single global status of the system for any particular status time, assuring that each pair of elements acts only upon consistent status values, assuring that system elements operate only with status values measured sufficiently recently to be reliable. Information collectors respond to status values. Information containers respond to information collectors, maintaining status values and metadata indicating whether those status values are reliable, or are consistent with respect to known correct values. Information conditions respond to information collectors or information containers, maintaining logical consistency with a unified global status. System actors respond to information containers or information conditions, acting logically consistent with that global status. System actors might include those which notify monitors or operators, and those which modify the system to detect and correct operation gone awry."
"Adaptive Data Quality Scoring Operations Framework using Drift-Aware
  Mechanism for Industrial Applications","https://scispace.com/papers/adaptive-data-quality-scoring-operations-framework-using-609pocfekyil","2024","Journal Article","","Firas Bayram
Bestoun S. Ahmed
Erik I. Hallin","10.48550/arxiv.2408.06724","https://scispace.com/pdf/adaptive-data-quality-scoring-operations-framework-using-609pocfekyil.pdf","No","Within data-driven artificial intelligence (AI) systems for industrial applications, ensuring the reliability of the incoming data streams is an integral part of trustworthy decision-making. An approach to assess data validity is data quality scoring, which assigns a score to each data point or stream based on various quality dimensions. However, certain dimensions exhibit dynamic qualities, which require adaptation on the basis of the system's current conditions. Existing methods often overlook this aspect, making them inefficient in dynamic production environments. In this paper, we introduce the Adaptive Data Quality Scoring Operations Framework, a novel framework developed to address the challenges posed by dynamic quality dimensions in industrial data streams. The framework introduces an innovative approach by integrating a dynamic change detector mechanism that actively monitors and adapts to changes in data quality, ensuring the relevance of quality scores. We evaluate the proposed framework performance in a real-world industrial use case. The experimental results reveal high predictive performance and efficient processing time, highlighting its effectiveness in practical quality-driven AI applications."
"Algebra of Data Reconciliation","https://scispace.com/papers/algebra-of-data-reconciliation-2d45g336","2022","Journal Article","Studia Scientiarum Mathematicarum Hungarica","Oliver Clifford Pedersen","10.1556/012.2022.01529","https://scispace.com/pdf/algebra-of-data-reconciliation-2d45g336.pdf","Yes","With distributed computing and mobile applications becoming ever more prevalent, synchronizing diverging replicas of the same data is a common problem. Reconciliation – bringing two replicas of the same data structure as close as possible without overriding local changes – is investigated in an algebraic model. Our approach is to consider two sequences of simple commands that describe the changes in the replicas compared to the original structure, and then determine the maximal subsequences of each that can be propagated to the other. The proposed command set is shown to be functionally complete, and an update detection algorithm is presented which produces a command sequence transforming the original data structure into the replica while traversing both simultaneously. Syntactical characterization is provided in terms of a rewriting system for semantically equivalent command sequences. Algebraic properties of sequence pairs that are applicable to the same data structure are investigated. Based on these results the reconciliation problem is shown to have a unique maximal solution. In addition, syntactical properties of the maximal solution allow for an efficient algorithm that produces it."
"Detecting gradual trends: Integrating EWMA control charts with artificial intelligence algorithms (LSTM)","https://scispace.com/papers/detecting-gradual-trends-integrating-ewma-control-charts-nco3dk0ujhdo","2025","Journal Article","Sustainable Engineering and Innovation","Husam M. Sabri
Hasanain Jalil Neamah Alsaedi
Salwan M. Alwan","10.37868/sei.v7i2.id614","https://scispace.com/pdf/detecting-gradual-trends-integrating-ewma-control-charts-nco3dk0ujhdo.pdf","No","Control charts are widely used in statistical process control (SPC) to detect small, gradual shifts in process behavior, although effective at mitigating noise, such as the exponentially weighted moving average (EWMA). Traditional EWMAs, however, face significant challenges and limited adaptability in complex and dynamic environments. In this paper, we propose an improved hybrid approach that integrates EWMAs with artificial intelligence algorithms, such as anomaly detection models, deep learning networks, and unsupervised learning, to enhance the early detection of non-random variations and subtle process trends. Simulations and real-world datasets were used to validate the effectiveness of the integrated model in identifying slow-developing faults."
"DriftWatch: A Tool that Automatically Detects Data Drift and Extracts Representative Examples Affected by Drift","https://scispace.com/papers/driftwatch-a-tool-that-automatically-detects-data-drift-and-6heq74v1bt","","Proceedings Article","","Myeongjun Jang
Antonios Georgiadis
Yiyun Zhao
Fran Silavong","10.18653/v1/2024.naacl-industry.28","","No","Data drift, which denotes a misalignment be-tween the distribution of reference (i.e., training) and production data, constitutes a significant challenge for AI applications, as it under-mines the generalisation capacity of machine learning (ML) models. Therefore, it is imperative to proactively identify data drift before users meet with performance degradation. Moreover, to ensure the successful execution of AI services, endeavours should be directed not only toward detecting the occurrence of drift but also toward effectively addressing this challenge. In this work, we introduce a tool designed to detect data drift in text data. In addition, we propose an unsupervised sampling technique for extracting representative examples from drifted instances. This approach be-stows a practical advantage by significantly reducing expenses associated with annotating the labels for drifted instances, an essential pre-requisite for retraining the model to sustain its performance on production data."
"An integrated change point detection and online monitoring approach for the ratio of two variables using clustering-based control charts","https://scispace.com/papers/an-integrated-change-point-detection-and-online-monitoring-2ce1521ztvdj","2025","Journal Article","Journal of Applied Statistics","Adel Ahmadi Nadi
Ali Yeganeh
Sandile Charles Shongwe
Alireza Shadman","10.1080/02664763.2025.2455625","","No","Online monitoring of the ratio of two random characteristics rather than monitoring their individual behaviors has many applications. For this aim, there are various control charts, known as RZ charts in the literature, e.g. Shewhart, memory-type and adaptive monitoring schemes, have been designed to detect the ratio's abnormal patterns as soon as possible. Most of the existing RZ charts rely on two assumptions about the process: (i) both individual characteristics are normally distributed, and (ii) the direction (upward or downward) of the RZ's deviation from its in-control (IC) state to an out-of-control (OC) condition is known. However, these assumptions can be violated in many practical situations. In recent years, applying the machine learning (ML) models in the Statistical Process Monitoring (SPM) area has provided several contributions compared to traditional statistical methods. However, ML-based control charts have not yet been discussed in the RZ monitoring literature. To this end, this study introduces a novel clustering-based control chart for monitoring RZ in Phase II. This method avoids making any assumptions about the direction of RZ's deviation and does not need to assume a specific distribution for the two random characteristics. Furthermore, it can estimate the Change Point (CP) in the process."
"Strongly consistent global states detection using relative clock errors","https://scispace.com/papers/strongly-consistent-global-states-detection-using-relative-3we8ulewp1","2003","Proceedings Article","International Symposium on Parallel and Distributed Computing","Janusz Borkowski","10.1109/ISPDC.2003.1267642","http://ieeexplore.ieee.org/iel5/8946/28341/01267642.pdf","No","Observation of global states is of a great importance in the area of distributed systems monitoring. Global states constructed with the use of real time timestamps involve small communication and computational cost and therefore are suitable for monitoring large systems. Properties of Strongly Consistent Global States (SCGS) make them especially useful for on-line monitoring and direct application control. SCGS detection depends heavily on clock synchronization quality. This quality can be improved easily (or it is very good already) locally, within a subset of processes. A SCGS detection algorithm exploiting local fine synchronization is presented. It detects more states than a usual algorithm allowing for more strict control over a monitored application."
"Using the expected detection delay to assess the performance of different multivariate statistical process monitoring methods for multiplicative and drift faults.","https://scispace.com/papers/using-the-expected-detection-delay-to-assess-the-performance-1n6nipg6ct","2017","Journal Article","Isa Transactions","Kai Zhang
Yuri A.W. Shardt
Zhiwen Chen
Kaixiang Peng","10.1016/J.ISATRA.2016.11.007","","No","Using the expected detection delay (EDD) index to measure the performance of multivariate statistical process monitoring (MSPM) methods for constant additive faults have been recently developed. This paper, based on a statistical investigation of the T2- and Q-test statistics, extends the EDD index to the multiplicative and drift fault cases. As well, it is used to assess the performance of common MSPM methods that adopt these two test statistics. Based on how to use the measurement space, these methods can be divided into two groups, those which consider the complete measurement space, for example, principal component analysis-based methods, and those which only consider some subspace that reflects changes in key performance indicators, such as partial least squares-based methods. Furthermore, a generic form for them to use T2- and Q-test statistics are given. With the extended EDD index, the performance of these methods to detect drift and multiplicative faults is assessed using both numerical simulations and the Tennessee Eastman process."
"Retroscope: Retrospective Monitoring of Distributed Systems","https://scispace.com/papers/retroscope-retrospective-monitoring-of-distributed-systems-3c70kyafqk","2019","Journal Article","IEEE Transactions on Parallel and Distributed Systems","Aleksey Charapko
Ailidani Ailijiang
Murat Demirbas
Sandeep S. Kulkarni","10.1109/TPDS.2019.2911944","","No","Retroscope is a comprehensive lightweight distributed monitoring tool that enables users to query and reconstruct past consistent global states of the system. Retroscope achieves this by augmenting the system with Hybrid Logical Clocks (HLC) and by streaming HLC-stamped event logs for storage and processing; these HLC timestamps are then used for constructing global (or nonlocal) snapshots upon request. Retroscope provides a rich querying language (RQL) to facilitate searching for global predicates across past consistent states. The search is performed by advancing through global states in small incremental steps, greatly reducing the amount of computation needed to construct consistent states. The Retroscope search algorithm is embarrassingly-parallel and can employ many worker processes (each processing up to 150,000 consistent snapshots per second) to handle a single query. We evaluate Retroscope's monitoring capabilities in two case studies: Chord and Apache ZooKeeper."
"A data-driven monitoring scheme for multivariate multimodal data","https://scispace.com/papers/a-data-driven-monitoring-scheme-for-multivariate-multimodal-3p7p1r5jl0","2024","Journal Article","","Zhiqiong Wang
Renping Gong
Lisha Song
Shuguang He
Yuan Gao","10.1016/j.cie.2024.110186","","No","Multivariate multimodal data, obtained from complex processes with multiple correlated quality characteristics and multiple operating modes, are commonly used in many applications. Online monitoring of multivariate multimodal data has been receiving increasing attention because timely detection of process problems is important. However, existing statistical process monitoring methods are often inadequate for addressing the challenges of multivariate multimodal data monitoring. For example, they may require the process data to be unimodal or identically distributed or may assume the information regarding the multimodal processes to be known a priori. Therefore, a data-driven monitoring scheme is proposed in this paper. First, the Dirichlet process Gaussian mixture model is adopted, which can depend entirely on data characteristics and automatically cluster the data without any prior knowledge. On this basis, an exponentially weighted moving average scheme is then constructed by incorporating the negative log-likelihood statistic. Using thorough simulations and a real example, we analyse and compare the performance of the model estimation and online monitoring for detecting various out-of-control scenarios. Extensive results show that our proposed monitoring scheme is sensitive to not only model parameter shifts but also model order changes. Moreover, the proposed scheme generally performs better and more robustly than existing methods."
"Online Nonparametric Monitoring for Asynchronous Processes with Serial Correlation","https://scispace.com/papers/online-nonparametric-monitoring-for-asynchronous-processes-37mew90loz","2024","Journal Article","IISE transactions","Zi-Dong Zheng
Honghan Ye
Kaibo Liu","10.1080/24725854.2024.2302355","","No","Existing multivariate statistical process control methods commonly require all data streams have the same sampling interval. In practice, this assumption may not be valid, as different sensors can have different sampling intervals. In this article, we first propose a generic nonparametric monitoring scheme to online monitor the asynchronous data streams without considering serial correlation. Then the proposed scheme is extended such that it can handle serially correlated data streams. Specifically, we construct a nonparametric local statistic for each data stream, which is sensitive to mean shifts. To eliminate the influence of different sampling intervals, our innovative idea is to transform the local statistics into time-related statistics according to the sampling intervals. A global monitoring scheme is then constructed based on the sum of top-r time-related statistics. To extend the proposed method for serially correlated data streams, we further propose a novel estimation method for the pairwise covariance functions and the data streams can be decorrelated accordingly. Numerical simulations and a case study are conducted, showing the effectiveness of the proposed method in handling asynchronous data streams with serial correlation."
"Verify, And Then Trust: Data Inconsistency Detection in ZooKeeper","https://scispace.com/papers/verify-and-then-trust-data-inconsistency-detection-in-164qq7xe","2023","Proceedings Article","","Fang Lyu
Benjamin Reed","10.1145/3578358.3591328","","No","ZooKeeper masks crash failure of servers to provide a highly available, distributed coordination kernel; however, in production, not all failures are crash failures. Bugs in underlying software systems and hardware can corrupt the ZooKeeper replicas, leading to data loss. Since ZooKeeper is used as a 'source of truth' for mission-critical applications, it essential to detect data inconsistencies caused by arbitrary faults to safeguard reliability. Byzantine Fault Tolerance (BFT) promises to handle these problems. However, these protocols are expensive in important dimensions: development, deployment, complexity, and performance. ZooKeeper takes an alternative approach that focuses on detecting faulty behavior rather than tolerating it and thus providing improved reliability without paying the full expense of BFT protocols. This paper describes various techniques used for detecting data inconsistencies in ZooKeeper. We also analyzed the impact of using these techniques on the reliability and performance of the overall system. Our evaluation shows that a real-time digest-based fault detection technique can be employed in production to provide improved reliability with a minimal performance penalty and no additional operational cost. We hope that our analysis and evaluation can help guide the design of next-generation primary-backup systems aiming to provide high reliability."
"Detection & Management of Concept Drift","https://scispace.com/papers/detection-management-of-concept-drift-cdymr2dx22","2006","Proceedings Article","International Conference on Machine Learning and Cybernetics","L.-O. Mak
Paul Krause","10.1109/ICMLC.2006.258538","","No","The ability to correctly detect the location and derive the contextual information where a concept begins to drift is essential in the study of domains with changing context. This paper proposes a Top-down learning method with the incorporation of a learning accuracy mechanism to efficiently detect and manage context changes within a large dataset. With the utilisation of simple search operators to perform convergent search and JBNC with a graphical viewer to derive context information, the identified hidden context are shown with the location of the disjoint points, the contextual attributes that contribute to the concept drift, the graphical output of the true relationships between these attributes and the Boolean characterisation which is the context."
"Multi-window Drift Detection Method Based on Integrating Outlier Identification and Input/Output Space Information with Its Application","https://scispace.com/papers/multi-window-drift-detection-method-based-on-integrating-n30ia2m7eihb","","","","Chaofan Xu
Jian Tang
Zijian Sun
Heng Xia
Zhe Xu
Wen Xu","10.1109/cac53003.2021.9727302","","No","In soft sensing application of actual industrial process, it is necessary to accurately identify samples that represent the working condition drift. Therefore, a multiwindow concept drift detection method is proposed in this paper, which integrates outlier identification and input/output space information. Firstly, a principal component analysis (PCA) model and a decision tree (DT) model are built by using historical data. Then, in the first window, the process data are standardized on the basis of 3σ criterion to remove outliers. In the second window, the T2 and SPE of the new sample are calculated to determine whether it is a drift sample in the input space. In the third window, the prediction error of the new sample is calculated to determine whether it is a drift sample in the out space. Finally, we take the union of the concept drift samples detected in the input and output space to obtain the new updating sample set. At the same time, the PCA model and the decision tree model are updated after the number of the updating samples reach a pre-set threshold. The experimental results verify the effectiveness of the proposed algorithm in the actual industrial datasets."
"Online monitoring of high-dimensional asynchronous and heterogeneous data streams for shifts in location and scale","https://scispace.com/papers/online-monitoring-of-high-dimensional-asynchronous-and-35tmrt22","2023","Journal Article","International Journal of Production Research","Honghan Ye
Zi-Dong Zheng
Jing-Ru C. Cheng
Brock Hable
Kaibo Liu","10.1080/00207543.2023.2172474","","No","Recent advancement of sensor technology has made it possible to monitor high-dimensional data streams in various manufacturing systems for quality improvement. However, existing monitoring schemes commonly assume that all data streams have the same sampling interval. This assumption does not always hold in practice, which poses new and unique challenges for multivariate statistical process control. In this paper, we propose a generic nonparametric monitoring framework to online monitor high-dimensional asynchronous and heterogeneous data streams, where sampling intervals of data streams are different from each other, and measurements of each data stream follow arbitrary distributions. In particular, we first propose a quantile-based nonparametric framework to monitor each data stream locally for possible shifts in both location and scale. Then, for unsampled measurements due to different sampling intervals, a compensation strategy based on the Bayesian approach is introduced. Furthermore, we develop a global monitoring scheme using the sum of top-r local statistics, which can quickly detect a wide range of possible shifts in all directions. Simulations and case studies are conducted to evaluate the performance and demonstrate the superiority of the proposed method."
"Strongly consistent global state detection for on-line control of distributed applications","https://scispace.com/papers/strongly-consistent-global-state-detection-for-on-line-54kagqlxv0","2004","Proceedings Article","Parallel, Distributed and Network-Based Processing","J. Borkowski","10.1109/EMPDP.2004.1271437","","No","Global states can be used for distributed/parallel application monitoring and control. Strongly consistent global states (SCGS) are especially well suited for on-line controlling. Existing SCGS detecting algorithms work with process local states. They must wait for state terminations before complete states can be taken into account. Because of that the global states seen by a monitor always belong to the past. We present an algorithm, which works with unterminated local states. This approach lets the monitor detect SCGS sooner: currently lasting global states can be perceived promptly after they started. Application control based on SCGS detection should react quicker to arising situations when using the new algorithm. The quick reactions contribute to a better parallel/distributed application performance. Simulation tests confirm these suppositions. Our solution utilizes bounded maximal message transfer time. It is compared with another method, which employs frequent confirmation messages. While both methods can lead to similar application performance, our approach induces a few times lower both monitor load and network traffic."
"Consistency Maintenance in Distributed Analytical Stream Processing","https://scispace.com/papers/consistency-maintenance-in-distributed-analytical-stream-4fzk0tq3qr","2018","Book Chapter","Advances in Databases and Information Systems","Artem Trofimov
Artem Trofimov","10.1007/978-3-030-00063-9_38","","No","State-of-the-art industrial and research projects in the area of distributed stream processing mainly consider only a limited set of delivery-level consistency models, which do not guarantee consistency regarding business requirements. However, such guarantees are able to make stream analytics more reliable. In this paper we define a problem of designing mechanisms, which can detect and possibly fix semantic-based inconsistencies. The results which have been already obtained and a detailed plan of further research are discussed."
"AutoMon: Automatic Distributed Monitoring for Arbitrary Multivariate Functions","https://scispace.com/papers/automon-automatic-distributed-monitoring-for-arbitrary-2dv0afw7","2022","Proceedings Article","Proceedings of the 2022 International Conference on Management of Data","Hadar Sivan
Moshe Gabel
Assaf Schuster","10.1145/3514221.3517866","","No","Approaches for evaluating functions over distributed data streams are increasingly important as data sources become more geographically distributed. However, existing methodologies are limited to small classes of functions, requiring non-trivial effort and substantial mathematical sophistication to tailor them to new functions. In this work we present AutoMon, the first general solution to this problem. AutoMon enables automatic, communication-efficient distributed monitoring of arbitrary functions. Given source code that computes a function from centralized data, the AutoMon algorithm approximates the function over the aggregate of distributed data streams, without centralizing data updates. Our evaluation shows that AutoMon sends the same number or fewer messages as state-of-the-art techniques when monitoring specific functions for which a distributed, hand-crafted solution is known. AutoMon, however, is a lot more powerful. It automatically generates a communication-efficient distributed monitoring solution for arbitrary functions, e.g., monitoring deep neural networks inference tasks for which no non-trivial solution is known."
"A Distribution-Free CUSUM Scheme for Monitoring Location and Scale in High-Dimensional Processes","https://scispace.com/papers/a-distribution-free-cusum-scheme-for-monitoring-location-and-gdsyv4jc","2022","Proceedings Article","Chinese Control and Decision Conference","Anan Tang
Yongtu Wang
Ximing Wang","10.1109/CCDC55256.2022.10033593","","No","Cumulative Sum (CUSUM)-type schemes have been widely applied as a key tool in the field of Statistical Process Monitoring (SPM) considering its simplicity and efficiency. Whereas, in a high-dimensional environment, constructing a CUSUM scheme that is convenient to implement as well as effective is yet to be adequately addressed. In this paper, a distribution-free CUSUM scheme is developed for monitoring high-dimensional processes. The proposed scheme combines the advantage of the nonparametric statistics for jointly monitoring process location and scale with the better shift detection performance of a CUSUM scheme. The theoretical and numerical results demonstrate that the proposed scheme has satisfactory in-control properties for any distributions with any dimension when only a small reference dataset is available. Control limits in terms of median run length are tabulated for implementation of the proposed chart in practice, and extensive comparative studies have been conducted to verify the effectiveness of the proposed scheme in detecting shifts in process location or scale or both."
"Change detection in multivariate datastreams controlling false alarms","https://scispace.com/papers/change-detection-in-multivariate-datastreams-controlling-3zfgv2qkvj","2021","Book Chapter","European conference on Machine Learning","Luca Frittoli
Diego Carrera
Giacomo Boracchi","10.1007/978-3-030-86486-6_26","https://scispace.com/pdf/change-detection-in-multivariate-datastreams-controlling-3zfgv2qkvj.pdf","Yes","We introduce QuantTree Exponentially Weighted Moving Average (QT-EWMA), a novel change-detection algorithm for multivariate datastreams that can operate in a nonparametric and online manner. QT-EWMA can be configured to yield a target Average Run Length (ARL\(_0\)), thus controlling the expected time before a false alarm. Control over false alarms has many practical implications and is rarely guaranteed by online change-detection algorithms that can monitor multivariate datastreams whose distribution is unknown. Our experiments, performed on synthetic and real-world datasets, demonstrate that QT-EWMA controls the ARL\(_0\) and the false alarm rate better than state-of-the-art methods operating in similar conditions, achieving comparable detection delays."
"Inconsistency Detection in Distributed Model Driven Software Engineering Environments","https://scispace.com/papers/inconsistency-detection-in-distributed-model-driven-software-5g8mfn3vb4","2010","","","Alix Mougenot
Xavier Blanc
Marie-Pierre Gervais","","https://scispace.com/pdf/inconsistency-detection-in-distributed-model-driven-software-5g8mfn3vb4.pdf","Yes","Model driven development uses more and more complementary models. Indeed, large-scale industrial systems are currently developed by hundreds of developers working on hundreds of models by different distributed teams. In such a context, model inconsistency detection is gaining a lot of attention as the overlap between all these models, which are often maintained by different persons, are a common source of inconsistencies. This paper proposes a method to detect inconsistencies when models are scattered on different editing sites using partial replication. The method provides a way to check the consistency of a single view against the ones that are related to it regarding consistency. It relies on Praxis, an operation based representation of models, to determine what information needs to be collected for consistency checking and the DPraxis protocol to find where it can be."
"Detection of data drift and outliers affecting machine learning model   performance over time","https://scispace.com/papers/detection-of-data-drift-and-outliers-affecting-machine-l2jwgl7xdyro","","","","Samuel Ackerman
Eitan Farchi
Orna Raz
Marcel Zalmanovici
Parijat Dube","10.48550/arxiv.2012.09258","","No","A trained ML model is deployed on another `test' dataset where target feature values (labels) are unknown. Drift is distribution change between the training and deployment data, which is concerning if model performance changes. For a cat/dog image classifier, for instance, drift during deployment could be rabbit images (new class) or cat/dog images with changed characteristics (change in distribution). We wish to detect these changes but can't measure accuracy without deployment data labels. We instead detect drift indirectly by nonparametrically testing the distribution of model prediction confidence for changes. This generalizes our method and sidesteps domain-specific feature representation. We address important statistical issues, particularly Type-1 error control in sequential testing, using Change Point Models (CPMs; see Adams and Ross 2012). We also use nonparametric outlier methods to show the user suspicious observations for model diagnosis, since the before/after change confidence distributions overlap significantly. In experiments to demonstrate robustness, we train on a subset of MNIST digit classes, then insert drift (e.g., unseen digit class) in deployment data in various settings (gradual/sudden changes in the drift proportion). A novel loss function is introduced to compare the performance (detection delay, Type-1 and 2 errors) of a drift detector under different levels of drift class contamination."
"Precision, recall, and sensitivity of monitoring partially synchronous distributed programs","https://scispace.com/papers/precision-recall-and-sensitivity-of-monitoring-partially-446v76lah9","2021","Journal Article","Distributed Computing","Duong N. Nguyen
Sorrachai Yingchareonthawornchai
Vidhya Tekken Valapil
Sandeep S. Kulkarni
Murat Demirbas","10.1007/S00446-021-00402-W","","No","Distributed programs are often designed with implicit assumptions about the underlying system. We focus on assumptions related to clock synchronization. When a program written with clock synchronization assumptions is monitored to determine if it satisfies its requirements, the monitor should also account for these assumptions precisely. Otherwise, the monitor will either miss potential bugs (false negatives) or find bugs that are inconsistent with these assumptions (false positives). However, if assumptions made by the program are implicit or change over time and are not immediately available to the monitor, such false positives and/or negatives are unavoidable. This paper characterizes precision (probability that the violation identified by the monitor is valid) and recall (probability that the monitor identifies an actual violation) of the monitor based on the gap between clock synchronization assumptions made by the program/application and the clock synchronization assumptions made by the monitor. Our analysis is based on the development of an analytical model for precision, recall and sensitivity of monitors detecting conjunctive predicates. We validate the model via simulations and experiments on the Amazon Web Services platform."
"Decentralised Data Quality Control in Ground Truth Production for Autonomic Decisions","https://scispace.com/papers/decentralised-data-quality-control-in-ground-truth-z3gqd2ld","2022","Journal Article","IEEE Transactions on Parallel and Distributed Systems","","10.1109/tpds.2022.3142967","","No","Autonomic decision-making based on rules and metrics is inevitably on the rise in distributed software systems. Often, the metrics are acquired from system observations such as static checks and runtime traces. To avoid bias propagation and hence reduce wrong decisions in increasingly autonomous systems due to poor observation data quality, multiple independent observers can exchange their findings and produce a majority-accepted, complete and outlier-cleaned ground truth in the form of consensus-supported metrics. In this work, we motivate the growing importance of metrics for informed and autonomic decisions in clouds and other distributed systems, present reasons for diverging observations, and describe a federated approach to produce ground truth with data-centric consensus voting for more reliable decision making processes. We validate the system design with experiments in the area of cloud software artefact observations and highlight benefits for reproducible distributed system behaviour."
"A Solution for Fault-Tolerance Based on Adaptive Replication in MonALISA","https://scispace.com/papers/a-solution-for-fault-tolerance-based-on-adaptive-replication-4nokhg5u6y","2010","Proceedings Article","","Alexandru Costan
Mugurel Ionut Andreica
Valentin Cristea
Costin Grigoras","10.1109/3PGCIC.2010.63","","No","The domains of usage of large-scale distributed systems have been extending during the past years from scientific to commercial applications. Together with the extension of the application domains, new requirements have emerged for large-scale distributed systems. Among these, fault tolerance is needed by more and more modern distributed applications, not only by the critical ones. In this paper we present a solution aiming at fault tolerant monitoring of the distributed systems within the MonALISA framework. Our approach uses replication and guarantees that all processing replicas achieve state consistency, both in the absence of failures and after failure recovery. We achieve consistency in the former case by implementing a module that ensures that the order of monitoring tuples is the same at all the replicas. To achieve consistency after failure recovery, we rely on check pointing techniques. We address the optimization problem of the replication architecture by dynamically monitoring and estimating inter-replica link throughputs and real-time replica status. We demonstrate the strengths of our solution using the MonALISA monitoring application in a distributed environment. Our tests show that the proposed approach outperforms previous solutions in terms of latency and that it uses system resources efficiently by carefully updating replicas, while keeping overhead very low."
"IDEA: an infrastructure for detection-based adaptive consistency control in replicated services","https://scispace.com/papers/idea-an-infrastructure-for-detection-based-adaptive-4ahqriscyb","2007","Proceedings Article","High Performance Distributed Computing","Yijun Lu
Ying Lu
Hong Jiang","10.1145/1272366.1272401","https://scispace.com/pdf/idea-an-infrastructure-for-detection-based-adaptive-4ahqriscyb.pdf","No","In Internet-scale distributed and replicated services, poor consistency results in poor QoS or even monetary loss. Recent research focuses on enforcing a certain consistency level, instead of perfect consistency, to strike a balance between consistency guarantee and system's scalability. In this paper, we argue that it is equally, if not more, important to achieve adaptability. I.e., the system adjusts its consistency level on the fly to suit applications. ongoing need. This paper presents IDEA (an Infrastructure for DEtection-based Adaptive consistency control), a protocol that adaptively controls consistency in replicated services by detecting inconsistency among nodes in a timely manner via an inconsistency detection framework and resolving the detected inconsistencies efficiently when necessary. Through experimentation on Planet-Lab, IDEA is evaluated from two aspects: its adaptive interface and its performance of inconsistency resolution. Results show that IDEA achieves adaptability by adjusting the consistency level according to users. preference on-demand, and it achieves low inconsistency resolution delay and incurs minimal communication cost."
"Systems and methods for drift correction","https://scispace.com/papers/systems-and-methods-for-drift-correction-1tg0fsztmw","2017","Patent","","Christopher A. Peri","","","No","A method to correct for drift in an electronic device is described. The method comprises determining a first center pose of the electronic device; tracking, using a sensor in conjunction with computer vision operating on a processor, at least one key point within a scene when the first center pose is within a tolerance with respect to a reported center pose; determining a derived center poser based upon the first center pose and the at least one key point; disabling the sensor for a predetermined time; determining, after the predetermined time, whether a second center pose is within the tolerance with respect to the derived center pose; tracking, using the sensor, the at least one key point when the second center pose is within the tolerance with respect to the derived center pose; and adjusting the second center pose when there is a difference between the second center pose and the derived center pose."
"Automatic drift correction","https://scispace.com/papers/automatic-drift-correction-3t14uujdjy","1983","Patent","","Brian D. Tucker","","","No","Drift in the zero or datum reference point of a circuit (such as that forming part of a measuring device) is corrected by sensing the rate of change of the signal provided by the circuit and distinguishing between a rate of change characteristic of that due to a valid signal indicative of a measurement and a rate of change characteristic of that due to drift in the circuit. In one embodiment, a window comparator 18 senses the rate of change of the signal output from circuit 10 by periodically sampling in sample/ hold 16 and then comparing with the current value of the signal. A signal circulating path 20, 21, 22 holds a drift compensating value which is updated when comparator 18 senses a rate of change below a threshold value which is indicative of drift in circuit 10. The drift compensating value is added to the signal from circuit 10 in summing amplifier 15 thereby correcting the signal for drift."
"Video frame drift correction","https://scispace.com/papers/video-frame-drift-correction-2sp1gzodel","2020","Patent","","Mark Q. Shaw
Jan P. Allebach
Edward J. Delp","","","No","In example implementations, a method executed by a processor is provided. The method determines an amount of video information that is lost in a video frame due to compression. A drift correction is applied to the video frame to add back a percentage of the amount of video information that is lost. The video frame is encoded with the drift correction."
"Drift correction circuit","https://scispace.com/papers/drift-correction-circuit-59idswrkvn","1977","Patent","","Mori Masaaki","","","No","PURPOSE:To automatically correct drift of the base line and to perform the exact measurement without using a reference electro-magnetic wave flux by processing the output signal itself of a detector"
"A drift correction procedure.","https://scispace.com/papers/a-drift-correction-procedure-jsr8a2zya9","1998","Journal Article","Analytical Chemistry","Marc L. Salit
Gregory C. Turk","10.1021/AC980095B","https://scispace.com/pdf/a-drift-correction-procedure-jsr8a2zya9.pdf","No","A procedure is introduced that can mitigate the deleterious effect of low-frequency noiseoften termed drifton the precision of an analytical experiment. This procedure offers several performance benefits over traditional designs based on the periodic measurement of standards to diagnose and correct for variation in instrument response. Using repeated measurements of every sample as a drift diagnostic, as opposed to requiring the periodic measurement of any given sample or standard, the analyst can better budget the measurement time to be devoted to each sample, distributing it to optimize the uncertainty of the analytical result. The drift is diagnosed from the repeated measurements, a model of the instrument response drift is constructed, and the data are corrected to a “drift-free” condition. This drift-free condition allows data to be accumulated over long periods of time with little or no loss in precision due to drift. More than 10-fold precision enhancements of analytical atomic emission results hav..."
"SP Curve Drift Correction","https://scispace.com/papers/sp-curve-drift-correction-3xgy9wlb0y","2012","Patent","","Adrian Esteban Scillato","","","No","A method and apparatus for removing drift from a curve of raw data acquired from a wellbore that intersects a subterranean formation. The raw data curve is filtered to remove DC components, integrating the filtered curve generates a new baseline curve. Adding the new base line curve to the filtered curve yields a corrected curve that is used to extract drift from the raw data curve. The corrected curve is filtered and then subtracted from the raw data curve to produce a drift curve. A data curve, absent any drift, is generated by filtering the drift curve, and subtracting the filtered data curve from the raw data curve."
"Self-Healing RPA Systems: Machine Learning Approaches","https://scispace.com/papers/self-healing-rpa-systems-machine-learning-approaches-ctbb91c4cjmy","2025","Journal Article","International Journal of Basic and Applied Sciences","Kiran Babu Macha","10.14419/ka544y53","","No","Robotic process automation (RPA) is being adopted as the flagship technology for optimizing rule-based repetitive tasks in virtually all industries. On the other hand, conventional RPA may not be able to handle unforeseen errors due to changes in the software environment, data format, or user interface. A prospective solution to this challenge could be the integration of a self-healing feature powered by machine learning. Thus, focusing on ML-driven solutions for real-time failure detection and automated repair, this study undertakes a holistic review of current advancements toward self-healing RPA systems. Beyond semantic matching, predictive maintenance, and anomaly detection, this study also explores the avenues through which supervised, unsupervised, and reinforcement learning can bolster resilience in RPA. Significant recent advances toward satisfying dynamic execution conditions using natural language processing, deep learning, and explainable artificial intelligence are looked at with a view toward frameworks that leverage these techniques. Current constraints like data shortage, interpretability, and model drift are noted as the study outlines future directions for use and study to take this study towards guiding practitioners and researchers in developing robust, intelligent, and adaptive RPA systems that can autonomously manage operational disruptions."
"Cloud compliance drift automation and root cause analysis tool","https://scispace.com/papers/cloud-compliance-drift-automation-and-root-cause-analysis-1savvo5gn7","2020","Patent","","Blackburn Justin Christopher
Blackburn Jacob
Royal Lorie
Kelly Shawn","","","No","A method, enterprise information handling system (IHS), and a computer-readable storage medium provide for mitigating a noncompliant configuration of an IHS. A determination is made whether a triggering event has occurred that has a potential for degrading compliance of the enterprise IHS. In response to determining that the triggering event has occurred, a controller performs a configuration scan of the hardware and software of the enterprise IHS to obtain current configuration information. The controller determines changes in the current configuration information based on a comparison of the current configuration information with baseline configuration information that was obtained in response to a previous triggering event. A determination is made whether any changes determined in the current configuration information are non-compliant based on a comparison to compliance status information. The controller enables the enterprise IHS to perform a compliance remediation operation in response to determining that at least one change is non-compliant."
"Endpoint drift correction for automatic titrations","https://scispace.com/papers/endpoint-drift-correction-for-automatic-titrations-4kx5fisuz6","1978","Patent","","Lee B. Eppstein
James K. Kroeger
Kenneth A. Lindblom","","","No","An apparatus and method are described for automatically correcting drift in automatic titrations, such as coulometric titrations of water. An endpoint detector provides a signal indicative of the state of the titration mixture and the detector signal is monitored by two comparators, responsive to titration mixture states on opposite sides of the endpoint and connected to means for controlling forward and back titration. At the end of a titration, the titration time and amount of titrant are stored in memory elements, and circuitry including an array of gates monitors the comparator signals during two post titration time periods to determine both the direction and rate of drift, and to correct the titration results for the amount of drift detected."
"Self-Healing Cloud Databases: Automatically Resolving Outages for Non-Stop Business","https://scispace.com/papers/self-healing-cloud-databases-automatically-resolving-outages-ay0zw50ywnfl","2025","Journal Article","Journal of Information Systems Engineering and Management","Veeravenkata Maruthi Lakshmi Ganesh Nerella","10.52783/jisem.v10i4.12498","","No","In the modern digital era, cloud databases serve as the foundational layer for business-critical applications, demanding uninterrupted availability, dynamic scalability, and fault tolerance. The concept and architecture of self-healing cloud databases emphasize their role in minimizing downtime and ensuring business continuity. Traditional reactive fault recovery approaches are increasingly insufficient in handling today’s complex, distributed, and real-time cloud systems. Self-healing databases leverage automation, real-time monitoring, and artificial intelligence (AI) to proactively detect, diagnose, and autonomously recover from faults. The study details enabling technologies such as predictive analytics, observability frameworks, container orchestration (e.g., Kubernetes), and DevOps-SRE integrations that make automated remediation possible. Additionally, techniques like load balancing, elastic resource provisioning, and auto-scaling are examined to demonstrate resilience in dynamic workloads. such as anomaly classification complexity and cross-architecture generalization. Evaluation metrics including MTTR, MTTD, fault recovery rate, and uptime percentage are presented to quantify effectiveness. The paper concludes that the convergence of AI, cloud-native infrastructure, and proactive automation is essential for the next generation of resilient database systems capable of responding to operational anomalies autonomously, thus supporting continuous service availability for non-stop business operations."
"Container based framework for self-healing software system","https://scispace.com/papers/container-based-framework-for-self-healing-software-system-1q9ra0zvya","2004","Proceedings Article","International Workshop on Variable Structure Systems","Rajesh Kumar Ravi
V. Sathyanarayana","10.1109/FTDCS.2004.1316631","","No","Software ""self-healing"" is an approach to detect improper operations of software applications, transactions and business processes, and then to initiate corrective action without disrupting users. The software engineering literature contains many studies on software error detection and error correction. In this paper, we introduce a ""container based self-healing"" framework and provide an outline on how the framework can help in evolving a self-healing system for a complex distributed system."
"Sample drift correction device","https://scispace.com/papers/sample-drift-correction-device-e3iuynjgnl","1976","Patent","","Okumura Masahide
Katou Yasuo","","","No","PURPOSE:To automatically sense the drift of a sample in regard to the original irradiation position of the charged particle beam and to correct the position of the sample"
"Drift correction for scattering measurements","https://scispace.com/papers/drift-correction-for-scattering-measurements-347p75szt3","2006","Journal Article","Applied Physics Letters","Christelle Eyraud
Jean-Michel Geffrin
Amelie Litman
Pierre Sabouroux
Hugues Giovannini","10.1063/1.2404978","","No","The authors propose a method to correct for drift errors which occur when performing three-dimensional scattering field measurements. This method has the advantages of being fast, without loss of information and with no need of a priori information on the scatterer. It is based on the properties of limited spatial bandwidth of the scattered field."
"Automatic self-healing method based on IT operation and maintenance","https://scispace.com/papers/automatic-self-healing-method-based-on-it-operation-and-5e6u8sv9r2","2018","Patent","","Zhao Jing
Mei Yongjian
Lian Zhigang
Wu Wenqing
Deng Shufen","","","No","The invention discloses an automatic self-healing method based on IT operation and maintenance. The method specifically comprises the steps of S1, obtaining start time points and end time points of exception items when exceptions are monitored; S2, obtaining exception information at the start time points and the end time points; and S3, carrying out comparison on exception causes in a model base according to the exception information, calling corresponding self-healing models for processing if the comparison is successful, detailing the exceptions if the comparison is unsuccessful, carrying out the comparison on the exception causes in the model base, calling the corresponding self-healing models for processing if the comparison is successful, for the exception items of which causes cannotbe completely determined, providing possible exception causes according to comparison results of the exceptions, providing reference suggestions and notifying operation and maintenance personnel to carry out artificial processing. According to the method, the exceptions occurring in the system can be positioned and automatically processed in an operation process of a business system, the businessinterruption time is reduced, the manpower investment is reduced, the working efficiency is improved, and technical requirements for the operation and maintenance personnel are reduced."
"System and method for configuration drift detection and remediation","https://scispace.com/papers/system-and-method-for-configuration-drift-detection-and-126x2ghd7t","2020","Patent","","Shetty Sudhir Vittal
Ayolasomyajula Rakesh Kumar
Iyer Pushkala","","","No","Administration of IHSs (Information Handling Systems) within a data center results gradual drift of the configuration parameters of the individual IHSs such that the IHSs may no longer be in compliance with data center policies, such as policies in support of security and disaster recovery procedures. Embodiments provide techniques for distributed determination of drift within a network of managed IHSs, in which each managed IHS is provided with baselines for the configuration parameters utilized by each managed IHS. Using the provided baselines, each managed IHS identifies discrepancies between its current configuration and the applicable baselines. Based on discrepancies reported by the managed IHSs, a management console evaluates drift within the network of managed IHSs and determines when to trigger remediation procedures in order to correct the drift."
"Robust tracking method with drift correction","https://scispace.com/papers/robust-tracking-method-with-drift-correction-389f3g4tvk","2010","Proceedings Article","International Conference on Image Analysis and Signal Processing","Kun-peng Wang
Yang Gui
Xiao-hu Zhang
Qi-feng Yu","10.1109/IASP.2010.5476089","","No","A new method is proposed to address the problem of template drift, a common phenomenon in which the target gradually shifts away from the template in object tracking. This paper integrates drift monitoring and drift correction with template matching. During the tracking based on template matching, drift is corrected once it is detected. The robustness and practicality of the method have been proven by experimental results."
"Automated issue remediation for information technology infrastructure","https://scispace.com/papers/automated-issue-remediation-for-information-technology-vvupo9reph","2019","Patent","","David Mah
Macfiggen Scott
John Watson","","","No","Automated issue remediation for information technology infrastructure comprises invoking an application programming interface to obtain at least one issue object corresponding to an alert generated by a monitoring system; matching the issue object to at least one diagnosis plugin of a plurality of diagnosis plugins; obtaining a prescription object from the diagnosis plugin, the prescription object comprising a remedy; and invoking the remedy after verifying the remedy is authorized to proceed."
"A Framework for Self-Healing Enterprise Applications Using Observability and Generative Intelligence","https://scispace.com/papers/a-framework-for-self-healing-enterprise-applications-using-ztb6b7pnqp2l","2025","Journal Article","European journal of computer science and information technology","Goutham Yenuganti","10.37745/ejcsit.2013/vol13n42147155","","No","Enterprise applications operating in distributed cloud environments face significant reliability challenges that traditional monitoring systems cannot adequately address. This framework presents a novel solution combining structured observability with generative artificial intelligence to create autonomous self-healing capabilities. The proposed system integrates multi-layered architecture encompassing telemetry collection, intelligent processing, and controlled execution layers. Generative intelligence models serve as reasoning engines that interpret system anomalies and synthesize appropriate remediation strategies within carefully defined safety boundaries. The framework implements hierarchical anomaly detection methodologies that minimize false positives while maintaining sensitivity to genuine system issues. Automated remediation workflows incorporate risk assessment logic and human-in-the-loop approval processes for complex scenarios. Multiple safety mechanisms including circuit breakers, canary deployments, and automatic rollback triggers ensure system integrity during autonomous operations. The framework transforms enterprise application reliability from reactive incident response to proactive self-maintenance, significantly reducing mean time to recovery while minimizing operational burden on engineering teams."
"Method and system for providing automated self-healing virtual assets","https://scispace.com/papers/method-and-system-for-providing-automated-self-healing-1by4580f77","2015","Patent","","Luis Felipe Cabrera
M. Shannon Lietz","","","No","A method and system for performing self-monitoring and self-healing operations from a virtual asset include receiving a first operating policy from an asset management computing environment, according to one embodiment. The method and system includes receiving a library of repairs from the asset management computing environment, according to one embodiment. The method and system includes detecting events, with the virtual asset, at least partially based on operational characteristics of the virtual asset exceeding at least one of the thresholds, according to one embodiment. The method and system includes repairing the virtual asset, with the virtual asset, using the library of repairs to return the virtual asset to the pre-determined state of operation."
"Drift correction method","https://scispace.com/papers/drift-correction-method-j4r4szdwb5","1987","Patent","","Ono Shigeki","","","No","PURPOSE:To enable the lowering of the rate of influence of contamination of a flow cell on an analysis value, by a method wherein a reagent blank is measured at specified interval of frequency, and the resulting measured value is subtracted from the measured value of the subsequent experimental object for correction. CONSTITUTION:When a biochemical analysis is carried out by nephelometry, a reagent blank is measured at a time interval after the measurement of a specified number of specimens is made, so to speak, after a flow cell begins to contaminate. Then, the measured value of the reagent blank is subtracted from the measured value of the subsequent specimen reactant for correction. So, the correction of the measured value is accomplished before the contamination of the flow cell affects the analysis value to eliminate the effect of the contamination of the flow cell on the analysis value. Thus, a highly reliable analysis value can be obtained with a higher analysis accuracy."
"System and method for providing software build violation detection and self-healing","https://scispace.com/papers/system-and-method-for-providing-software-build-violation-4p9uq7nc4a","2015","Patent","","Kyasaram Vishwa Prasad
Anilkumar Gande
Srikanth Subrahmanya Nandula
Subhadarshi Mishra","","","No","Systems, methods, and other embodiments are disclosed that provide self-healing solutions to problems that occur during a software build. In one embodiment, build log data structures of build data, generated during execution of a software build of a software application, are automatically monitored. The build data is automatically analyzed to detect patterns that can result in build violations. Detected patterns are automatically matched to remediation solutions stored in a knowledge database. The remediation solutions are automatically applied to the software application."
"Drift correction in aes analysis","https://scispace.com/papers/drift-correction-in-aes-analysis-1xjnboqcz0","1993","Patent","","Miyatake Isao","","","No","PURPOSE:To micronize displacement quantity and to analyze a micro-region by calculating the displacement of a scanning surface by comparing the distributions of the quantity of secondary electrons on the scanning surface at the start time of analysis and at the time of each analysis and moving the scanning position of electron beam to the first region to perform drift correction. CONSTITUTION:The secondary electron image signal S1 of secondary electrons detected during AES (Auger electron spectroscopy) analysis is subjected to the image processing due to a calculator 2 fitted with an image processor and an observation surface is divided into small regions and the quantities of secondary electrons of the respective regions are converted to numerical data to be stored in an AES analyser 1. The numerical data at the start time of AES analysis are preliminarily stored in the analyser 1 and, when the analyser 1 becomes a state capable of taking in a secondary electron image, secondary electrons are immediately taken in the analyser 1 to be converted to numerical data which are, in turn, compared with the data at the start time of analysis to calculate displacements in X- and Y-directions and an electron beam X-Y position control signal S2 is sent to the analyser 1 to move the scanning position of electron beam to the position at the start time of analysis. At the point of time when the displacements are detected, the displacements are immediately corrected to make it possible to analyze the micro-regions without omission."
"Nudged broadcast orbit drift correction","https://scispace.com/papers/nudged-broadcast-orbit-drift-correction-hvhw8i60fm","2008","Patent","","Benjamin William Remondi","","","No","In method of correcting for drift in a Global Navigation Satellite System (GNSS) receiver, a broadcast orbit in use at the GNSS receiver is nudged based on a first message received from a GNSS base station. The nudging creates a first nudged broadcast orbit for a GNSS satellite, the first nudged broadcast orbit being more precise than the broadcast orbit. A second message is received from the GNSS base station. Information included in the second message is employed to determine a drift rate of the first nudged broadcast orbit relative to a more precise orbit in use at the GNSS base station. Based upon the second message, the broadcast orbit is nudged to create a second nudged broadcast orbit for the GNSS satellite. A component of the drift rate is corrected for, relative to the second nudged broadcast orbit."
"Generative AI for Cloud Infrastructure Decision-Making and SelfHealing Systems","https://scispace.com/papers/generative-ai-for-cloud-infrastructure-decision-making-and-ws6z4dv29trs","2024","Journal Article","Design of Single Chip Microcomputer Control System for Stepping Motor","Tirumala Ashish Kumar Manne","10.47363/jaicc/2024(3)456","","No","Cloud infrastructure has grown increasingly complex, demanding intelligent automation to ensure performance, reliability, and resilience. This paper explores the application of Generative Artificial Intelligence (Generative AI) to enhance decision-making and enable self-healing capabilities in cloud environments. Generative models such as large language models (LLMs), generative adversarial networks (GANs), and variational autoencoders (VAEs) are proving instrumental in addressing challenges related to dynamic resource provisioning, anomaly detection, root cause analysis, and automated remediation. I present a framework that leverages generative models to simulate failure scenarios, generate configuration policies, and synthesize runbooks for autonomous recovery. Integration with observability pipelines and cloud-native services enables closed-loop, real-time adaptation, reducing mean time to resolution (MTTR) and improving system uptime. Case studies demonstrate improved accuracy in fault prediction and faster recovery compared to traditional methods. I also discuss implementation challenges, including model drift, latency constraints, and data privacy. This study underscores the transformative potential of Generative AI in building resilient, adaptive, and scalable cloud infrastructures, while offering practical insights for architects, DevOps teams, and AI researchers aiming to advance autonomous cloud operations."
"Temporal drift correction","https://scispace.com/papers/temporal-drift-correction-2de7aaugxk","2001","Patent","","John Mantegna
Shuwu Wu","","","No","Temporal drift correction may be provided in a real-time audio communication system by measuring a size of a receiving data buffer and comparing that size to a predetermined nominal data buffer size. An amount of temporal drift is characterized as a number of samples per audio playback data block based on the measured data buffer size and the nominal data buffer size. A number of samples to be inserted or removed for each audio playback data block to correct the temporal drift may be determined, and the number of samples for each audio playback data block may be modified. For example, an instantaneous size of the receiving data buffer may be measured, and if measured multiple times, may be averaged over a time period. Heuristic resampling of the audio playback data block also may be performed. When heuristic resampling is performed, multiple consecutive samples of audio data in an audio buffer may be analyzed, consecutive samples with minimal variation in a parameter of their data may be identified, and the number of samples in the identified consecutive samples may be adjusted. A sample may be removed from or added to the identified consecutive samples."
"Drift correction for camera tracking","https://scispace.com/papers/drift-correction-for-camera-tracking-46x2gocn51","2016","Patent","","Samer S. Barakat
Mohamed Selim Ben Himane","","","No","Techniques are disclosed for drift correction for camera tracking. In some cases, the techniques include iterative optimization of the camera poses at selected keyframes captured along the camera trajectory to reduce pose errors. Such iterative optimization may include performing an alignment process using the point cloud of a given keyframe and a point cloud made from one or more overlapping keyframes, such as via an iterative closest point (ICP)-based expectation maximization. The keyframes may then be fused to reconstruct a more accurate model of the scene, discarding the existing model. The new model can then be used for tracking and meshing. In some instances, keyframes may be selected such that the overlap with other keyframes includes enough shape features to allow for alignment with the keyframe depth point cloud. In some cases, the techniques can be performed in a particular order giving precedence to keyframes having smaller pose errors."
"Double-sided rapid drift correction","https://scispace.com/papers/double-sided-rapid-drift-correction-314rpqzmji","2010","Patent","","Michael Mueller","","","No","A method and system for gas sensor drift correction is disclosed, appropriate for use in a system placed in an environment that with some regularity reaches a background gas concentration. A background gas concentration range is defined. When the gas sensor readings drop below the background gas concentration range for at least a defined short dwell time, an upwards calibration adjustment is effected. When the gas sensor readings stay above the background gas concentration range for a defined long dwell time (longer than the maximum expected interval between excursions to the background gas concentration), a downwards calibration adjustment is effected."
"Self-healing in the Scope of Software-Based Computer and Mobile Networks","https://scispace.com/papers/self-healing-in-the-scope-of-software-based-computer-and-40ia5uollx","2020","Book Chapter","International Conference on Cloud Computing and Services Science","Natal Vieira de Souza Neto
Daniel Ricardo Cunha Oliveira
Maurício Amaral Gonçalves
Flávio de Oliveira Silva
Pedro Frosi Rosa","10.1007/978-3-030-72369-9_14","","No","Self-healing is an autonomic computing fundamental well-disseminated in standalone computer systems. In distributed systems, e.g. computer networks or mobile networks, the introduction of self-healing capabilities poses some challenges, mainly when software-based networks, e.g. Software-Defined Networking (SDN) and Network Functions Virtualisation (NFV), are involved. Such networks impose new control and management layers, and the adoption of self-healing functions means that all layers must be considered. In this paper, we present the challenges of self-healing in the scope of SDN and NFV, by revising the self-healing concept in computer and mobile networks, and by presenting the thorough difference between a system that applies fault tolerance from one that applies self-healing functions. We also introduce a framework for solving these challenges, by describing four use cases of self-healing, considering control, management, and data layers. The use cases focus on maintaining the health of the network at run-time, considering control, management, and infrastructure layers. Our framework is a novel Operations, Administration, and Maintenance (OAM) tool, based on a self-management network architecture that was introduced in our previous works."
"Drift correction in integrators","https://scispace.com/papers/drift-correction-in-integrators-11ie664ods","1991","Patent","","Dudding John","","","No","A measurement output signal of an integrator is converted (ADC) to a digital signal and then processed in a microprocessor; and the output obtained when a measurement signal is present is compared with the output obtained due to drift errors alone as previously determined for that integrator whereby to produce a measurement output signal substantially free from drift errors."
"Correction for long-term instrumental drift","https://scispace.com/papers/correction-for-long-term-instrumental-drift-44kk4p7mo2","2002","Journal Article","X-Ray Spectrometry","Richard M. Rousseau","10.1002/XRS.582","","No","A method of correcting for instrumental drift must be associated with any calibration procedure in order to validate the stored calibration data (slopes and intercepts) over a long period of time. Indeed, it can usually be observed that the drift is negligible for a 24 h period, but over longer periods corrections to the measured intensities have to be made. These corrections are based on the measurement of special specimens known as drift monitors or simply monitors. Physically, the monitor can comprise one to several specimens, each containing one or several analytes of which the intensity of each analyte is slightly higher than the highest intensity in the analyte concentration range. The other two essential properties of a monitor are its stability over time and reproducibility of its intensity measurements. A drift correction must be applied to the measured intensities of every analyte using one, two or several monitors depending on the spread of the intensity ranges. Some drift correction methods are proposed and it is explained how to combine them with the calibration procedure in order to obtain precise analytical results over long periods of time from the same set of calibration data. Copyright © 2002 John Wiley & Sons, Ltd."
"Self-Healing Approach in the FastFix Project.","https://scispace.com/papers/self-healing-approach-in-the-fastfix-project-1ev7wclfwh","2011","","","Benoit Gaudin
Mike Hinchey","","","Yes","The EU FP7 FastFIX project tackles issues related to remote software maintenance. In order to achieve this, the project considers approaches relying on context elicitation, event correlation, fault-replication and self-healing. Self-healing helps systems return to a normal state after the occurrence of a fault or vulnerability exploitation has been detected. The problem is intuitively appealing as a way to automate the different maintenance type processes (corrective, adaptive and perfective) and forms an interesting area of research that has inspired many research initiatives. In this paper, we propose a framework for automating corrective maintenance and present its early stage development, based on software control principles. Our approach automates the engineering of self-healing systems as it does not require the system to be designed in a specific way. Instead it can be applied to legacy systems and automatically equips them with observation and control points. Moreover, the proposed approach relies on a sound control theory developed for Discrete Event Systems. Finally, this paper contributes to the field by introducing challenges for effective application of this approach to relevant industrial systems."
"Autonomous cloud engineering: The rise of self-healing AWS infrastructure using AI and event-driven automation","https://scispace.com/papers/autonomous-cloud-engineering-the-rise-of-self-healing-aws-8xkgdqiytjmr","2025","Journal Article","World Journal of Advanced Engineering Technology and Sciences","Sreeja Reddy Challa","10.30574/wjaets.2025.15.2.0810","","No","This article explores the emergence of autonomous cloud engineering as a paradigm shift in AWS infrastructure management, examining how the integration of artificial intelligence, event-driven automation, and self-healing workflows is transforming operational practices. The article investigates the evolution from reactive monitoring to proactive self-healing systems that can detect, diagnose, and remediate failures autonomously across multiple AWS accounts. The article analyzes key components of this architecture, including AI-driven anomaly detection through services like DevOps Guru and GuardDuty, automated remediation frameworks using Lambda and Step Functions, and event-driven governance through AWS Config and Security Hub. Through case studies of enterprise implementations, the article quantifies the substantial operational benefits: reductions in mean time to resolution, decreases in downtime, and shorter security vulnerability lifespans. We present a maturity model for implementation, an economic analysis demonstrating typical ROI within 9-14 months, and organizational considerations for successful adoption. Finally, the article examines future directions in autonomous cloud engineering, including applications of generative AI, the evolution of intelligent Infrastructure as Code, and the ethical considerations surrounding appropriate human oversight as autonomous capabilities continue to advance."
"FastFix: A Control Theoretic View of Self-Healing for Automatic Corrective Software Maintenance","https://scispace.com/papers/fastfix-a-control-theoretic-view-of-self-healing-for-jb79xxhmj0","2012","Journal Article","Scalable Computing: Practice and Experience","Benoit Gaudin
Mike Hinchey
Emil Vassev
Paddy Nixon
João Garcia
Walid Maalej","10.12694/SCPE.V13I1.763","https://scispace.com/pdf/fastfix-a-control-theoretic-view-of-self-healing-for-jb79xxhmj0.pdf","Yes","One of the main objectives of self-adaptive systems is to reduce maintenance costs through automatic adaptation. Self-healing is a self-adapting property that helps systems return to a normal state after a fault or vulnerability exploit has been detected. The problem is intuitively appealing as a way to automate the different type of maintenance processes (corrective, adaptive and perfective) and forms an interesting area of research that has inspired many initiatives. As a result, several surveys on self-healing have been published to describe the state of the art in this field. According to those surveys, the major trend towards finding a solution of the self-healing problem relies on redundancy that may concern both architecture and code resources. These approaches are therefore better suited to address adaptive and perfective maintenance. As part of the EU FP7 FastFix project, we focus on self-healing for corrective maintenance. We propose a framework for automating corrective maintenance that is based on software control principles. Our approach automates the engineering of self-healing systems as it does not require the system to be designed in a specific way. Instead it can be applied to legacy systems and automatically equip them with observation and control points. Moreover, the proposed approach relies on a sound control theory developed for Discrete Event Systems. Finally, this paper contributes to the field by introducing challenges to the effective application of this approach to relevant industrial systems. Some of these challenges are currently being tackled within FastFix."
"Self-Healing Cloud: Autonomous Resilience through Reinforcement Learning","https://scispace.com/papers/self-healing-cloud-autonomous-resilience-through-0wk55wfwlnd6","2025","Journal Article","European modern studies journal","Rakesh Kumar Gouri Neni","10.59573/emsj.9(5).2025.48","","No","This article presents an autonomous resilience framework for cloud computing environments that leverages reinforcement learning (RL) to enable self-healing capabilities. The framework embeds intelligent agents throughout the cloud stack to continuously monitor system health, detect anomalies, and automatically implement remediation actions without human intervention. Drawing inspiration from biological self-healing systems, the approach creates a distributed intelligence architecture that transforms cloud management from reactive to proactive operations. The system employs a comprehensive simulation environment for training RL agents, a carefully engineered multi-dimensional reward function, and a hierarchical decision-making framework. Extensive evaluation through both simulation and real-world testbed experiments demonstrates significant improvements in incident detection and recovery times, root cause identification accuracy, service availability during attacks, and overall operational efficiency. The framework exhibits emergent adaptive behaviors, including anticipatory actions that preemptively address potential failures before they impact service delivery, representing a paradigm shift in cloud infrastructure resilience."
"FastFIX: An approach to self-healing","https://scispace.com/papers/fastfix-an-approach-to-self-healing-3jbbju3oi2","2011","Proceedings Article","Federated Conference on Computer Science and Information Systems","Benoit Gaudin
Mike Hinchey","","https://ieeexplore.ieee.org/iel5/6068195/6078170/06078234.pdf","Yes","The EU FP7 FastFIX project tackles issues related to remote software maintenance. In order to achieve this, the project considers approaches relying on context elicitation, event correlation, fault-replication and self-healing. Self-healing helps systems return to a normal state after the occurrence of a fault or vulnerability exploitation has been detected. The problem is intuitively appealing as a way to automate the different maintenance type processes (corrective, adaptive and perfective) and forms an interesting area of research that has inspired many research initiatives. In this paper, we propose a framework for automating corrective maintenance and present its early stage development, based on software control principles. Our approach automates the engineering of self-healing systems as it does not require the system to be designed in a specific way. Instead it can be applied to legacy systems and automatically equips them with observation and control points. Moreover, the proposed approach relies on a sound control theory developed for Discrete Event Systems. Finally, this paper contributes to the field by introducing challenges for effective application of this approach to relevant industrial systems."
"Autonomic Computing: Applications of Self-Healing Systems","https://scispace.com/papers/autonomic-computing-applications-of-self-healing-systems-4n6dbrtywz","2011","Proceedings Article","","M. Mousa Al-Zawi
Dhiya Al-Jumeily
Abir Hussain
A. Taleb-Bendiab","10.1109/DESE.2011.22","","No","Self -- Management systems are the main objective of Autonomic Computing (AC), and it is needed to increase the running system's reliability, stability, and performance. This field needs to investigate some issues related to complex systems such as, self-awareness system, when and where an error state occurs, knowledge for system stabilization, analyze the problem, healing plan with different solutions for adaptation without the need for human intervention. This paper focuses on self-healing which is the most important component of Autonomic Computing. Self-healing is a technique that aims to detect, analyze, and repair existing faults within the system. All of these phases are accomplished in real-time system. In this approach, the system is capable of performing a reconfiguration action in order to recover from a permanent fault. Moreover, self-healing system should have the ability to modify its own behavior in response to changes within the environment. Recursive neural network has been proposed and used to solve the main challenges of self-healing, such as monitoring, interpretation, resolution, and adaptation."
"Self-healing systems - survey and synthesis","https://scispace.com/papers/self-healing-systems-survey-and-synthesis-58w33dazh8","2007","Journal Article","Decision Support Systems","Debanjan Ghosh
Raj Sharman
H. Raghav Rao
Shambhu Upadhyaya","10.1016/J.DSS.2006.06.011","","No","As modern software-based systems and applications gain in versatility and functionality, the ability to manage inconsistent resources and service disparate user requirements becomes increasingly imperative. Furthermore, as systems increase in complexity, rectification of system faults and recovery from malicious attacks become more difficult, labor-intensive, expensive, and error-prone. These factors have actuated research dealing with the concept of self-healing systems. Self-healing systems attempt to ''heal'' themselves in the sense of recovering from faults and regaining normative performance levels independently the concept derives from the manner in which a biological system heals a wound. Such systems employ models, whether external or internal, to monitor system behavior and use inputs obtaining therefore to adapt themselves to the run-time environment. Researchers have approached this concept from several different angles this paper surveys research in this field and proposes a strategy of synthesis and classification."
"Demystifying self-healing cloud architectures: Building resilient systems for modern applications","https://scispace.com/papers/demystifying-self-healing-cloud-architectures-building-n64sk47xcid2","2025","Journal Article","World Journal of Advanced Engineering Technology and Sciences","Praveen Kumar Thota","10.30574/wjaets.2025.15.1.0426","","No","This article presents a comprehensive overview of self-healing cloud architectures, examining their transformative impact on modern infrastructure design. It details how these intelligent systems automatically detect, diagnose, and recover from failures without manual intervention, significantly reducing downtime and operational costs across various industries. The article explores the foundational components of self-healing systems including health monitoring, automation frameworks, and AI-driven predictive capabilities. It further examines implementation strategies such as microservices architecture, circuit breakers, and observability practices that collectively enhance system resilience. Through real-world applications in e-commerce, financial services, and cloud-native environments, the article demonstrates how self-healing capabilities have become essential for maintaining service availability and business continuity in today's competitive digital landscape."
"Amplifier nonlinear offset drift correction","https://scispace.com/papers/amplifier-nonlinear-offset-drift-correction-1hau8sivk5","2020","Patent","","Wan Quan","","","No","An amplifier circuit comprises a differential input stage configured to receive a differential input signal, wherein the differential input stage is susceptible to an offset error that includes a linear offset error portion and a nonlinear offset error portion; and an offset error correction circuit coupled to the differential input stage and configured to apply a second order error correction signal to the differential input stage to reduce the nonlinear portion of the offset error."
"Predictive self-healing error remediation architecture","https://scispace.com/papers/predictive-self-healing-error-remediation-architecture-267kp0nu9j","2019","Patent","","Joshi Sarang Padmakar
Nanal Mihir","","","No","Systems and methods for remediating errors in distributed computing are provided. A system may include a remediation node. The remediation node may forecast receipt of a service request by a service authority. The service request may be configured to cause the service authority to modify a service assigned to an account. The service authority may be in communication with a plurality of source systems. The remediation node may acquire, from at least one of the source systems, a service parameter in which the service authority is configured to access to process the service request. The remediation node may determine an error condition corresponding to the service parameter. The remediation node may communicate, in response to determination of error condition, a remediation instruction to the at least one of the source systems, the remediation instruction configured to cause the at least one of the source systems to modify the service parameter."
"Case-based reasoning for autonomous service failure diagnosis and remediation in software systems","https://scispace.com/papers/case-based-reasoning-for-autonomous-service-failure-4dxao7lwc3","2006","Book Chapter","Lecture Notes in Computer Science","Stefania Montani
Cosimo Anglano","10.1007/11805816_36","https://scispace.com/pdf/case-based-reasoning-for-autonomous-service-failure-4dxao7lwc3.pdf","No","Self-healing, one of the four key properties characterizing Autonomic Systems, aims to enable large-scale software systems delivering complex services on a 24/7 basis to meet their goals without any human intervention. Achieving self-healing requires the elicitation and maintenance of domain knowledge in the form of 〈service failure diagnosis, remediation strategy〉 patterns, a task which can be overwhelming. Case-Based Reasoning (CBR) is a lazy learning paradigm that largely reduces this kind of knowledge acquisition bottleneck. Moreover, the application of CBR for failure diagnosis and remediation in software systems appears to be very suitable, as in this domain most errors are re-occurrences of known problems. In this paper, we describe a CBR approach for providing large-scale, distributed software systems with self-healing capabilities, and demonstrate the practical applicability of our methodology by means of some experimental results on a real world application."
"Proactive Self-healing System for Application Maintenance in Ubiquitous Computing Environment","https://scispace.com/papers/proactive-self-healing-system-for-application-maintenance-in-1bikrwodl3","2006","Journal Article","Lecture Notes in Computer Science","Jeongmin Park
Giliong Yoo
Chulho Jeong
Eunseok Lee","","","Yes","With evolving modem IT technology, one desirable characteristic of distributed of applications is self-healing, or the ability to reconfigure themselves on the fly to circumvent failure. Thus, the goal is to avoid catastrophic failure through prompt execution of remedial actions. This paper proposes a self-healing system that monitors, diagnoses and heals its own internal problems using self-awareness as contextual information. The proposed system consists of multi agents that analyze the log context, error events and resource status in order to perform self-diagnosis and self-healing. For rapid and efficient self-healing, for developing the proposed system, we use a 6-step process: monitoring, filtering, translation, diagnosis, decision and feedback. Our experiments conducted with a prototype system confirm the effectiveness of the proposed system."
"Enterprise level cybersecurity automatic remediation","https://scispace.com/papers/enterprise-level-cybersecurity-automatic-remediation-1049dbfwug","2019","Patent","","Digiambattista Ernesto
Bezdedeanu Andrei
Kail Michael D","","","No","Automatic detection and remediation of cybersecurity threats to an information technology installation is disclosed. An information technology installation receives at an orchestration system a requested update which may include a configuration change, a code change, a change to a binary, or other change to the installation. A mirror instance of the installation is instantiated on a cloud infrastructure where the requested updated is applied and scanned for cybersecurity threats. Where cybersecurity threats are detected, a remediation response is identified. The update and the remediation response may either be sent to an administrator for acceptance prior to deployment to production, or may be deployed automatically, with rollback information generated in the event the administrator desires to undo the deployment. Information as to whether an administrator accepts or rejects an update and/or a remediation are stored in a community database to assist others to evaluate the update and/or remediation for their use."
"Predictive dependency constraint directed self-healing for wireless sensor networks","https://scispace.com/papers/predictive-dependency-constraint-directed-self-healing-for-4ws4fnfxrc","2010","Proceedings Article","International Conference on Networked Sensing Systems","Jingyuan Li
Yafeng Wu
John A. Stankovic
Sang H. Son
Ziguo Zhong
Tian He
Bong Wan Kim
Seong-Soon Joo","10.1109/INSS.2010.5573547","https://scispace.com/pdf/predictive-dependency-constraint-directed-self-healing-for-4ws4fnfxrc.pdf","No","Wireless sensor networks are now being considered for mission critical applications, which are often largely unattended and need to operate reliably for years. However, due to the real world communication, sensing and failure realities, clock drift, and node faults, the system performance may degrade significantly over time. It is highly desirable that these natural deteriorations can be monitored continuously and can be corrected with self-healing when necessary. In this paper, we introduce a dependency constraint directed self-healing scheme for wireless sensor networks. We reveal that when self-healing services are being composed, certain dependency constraints, including invocation, parameter consistency, control and implicit assumption dependencies must be carefully identified and respected. We illustrate each of these dependency constraints through case studies in 3 different systems covering the typical functions of wireless sensor networks, including sensing, communication and tracking. Our research indicates that, following the dependency constraints in self-healing design is not only a must for the correctness of self-healing services, but is also a key to energy efficient self-healing."
"Remedial Actions for Self-Healing in Cyber-Physical Systems","https://scispace.com/papers/remedial-actions-for-self-healing-in-cyber-physical-systems-b4trjtj7h4h3","2025","Journal Article","","Obinna Johnphill
Ali Safaa Sadiq
Omprakash Kaiwartya
Mohammed Adam Taheird","10.21203/rs.3.rs-7030947/v1","https://scispace.com/pdf/remedial-actions-for-self-healing-in-cyber-physical-systems-b4trjtj7h4h3.pdf","No","<title>Abstract</title> Building upon our previous work on theLog Intelligence and Self-Healing System (LISH), whichutilised CountVectorizer and Multinomial Naive Bayes(MNB) for multi-platform anomaly detection, this pa-per advances the self-healing paradigm by operational-ising the autonomous execution of remedial actions fol-lowing anomaly classification. We introduce CROSS:Cross-platform Remediation and Observability Self-Healing System, a novel framework designed to auto-mate post-detection recovery tasks such as system up-dates, service restarts, device reboots, disk clean-up,and configuration enforcement across Android, Linux,macOS, and Windows environments. CROSS processespre-classified logs to detect elevated error and warninglevels per system and initiates platform-specific cor-rective actions through a unified handler mechanism.Upon breach, it triggers remediation routines tailoredto the target environment, ensuring contextual appro-priateness and minimal manual oversight. Prometheusmetrics are integrated to expose fine-grained teleme-try on detected anomalies and remedial actions, en-hancing observability and enabling external policy en-forcement or audit. Experimental validation across het-erogeneous cyber-physical system (CPS) environmentsdemonstrates significant improvements in recovery la-tency and fault tolerance. This research reinforces theimperative of automating the post-detection responsephase in security-focused self-healing systems. Futurework will address risk-aware remedial action selectionand integrate secure execution constraints to mitigate the threat surface introduced by autonomous system-level interventions."
"Policy-driven automatic network fault remediation","https://scispace.com/papers/policy-driven-automatic-network-fault-remediation-5e70djb0vz","2012","Patent","","Karl Andre McCabe
Brian White
Brian Joseph Callan
Robert Kennedy","","","No","A policy-driven automatic network remediation service is described, which resides on the network and is triggered when a network fault is detected. Once triggered, the service automatically connects to network devices in the topological locale of the detected fault and collects diagnostic information from the affected area, running diagnostics which are appropriate to the fault type. The service can validate a set of preconditions prior to taking remedial action. For example, the service can empirically validate that the network topology is actually as expected and that automatic remediation would be safe and would not compromise network availability or redundancy. Diagnostic information can be recorded in a trouble ticket to support post-event auditing. Once the preconditions have been validated, the service can automatically take corrective action based on the type of the fault, such as shutting down an interface on a particular network device."
"AI-Augmented Self-Healing Infrastructure: Combining Health Probes with Remediation Playbooks","https://scispace.com/papers/ai-augmented-self-healing-infrastructure-combining-health-mqhdw5brqkqg","2025","Journal Article","Journal of Information Systems Engineering and Management","Manoj Kumar Reddy Kalakoti","10.52783/jisem.v10i58s.12800","","No","Self-healing infrastructure has evolved as a foundational component in resilient, cloud-native systems. This paper introduces an advanced framework that enhances traditional health probe-driven remediation with artificial intelligence and machine learning. By integrating AI-powered anomaly detection, adaptive remediation strategies, and generative playbook synthesis, the proposed architecture transforms reactive fault response into a proactive, predictive, and autonomous paradigm. Utilizing native observability tools like Kubernetes, AWS CloudWatch, and Prometheus, combined with LLM-based pattern inference, we build a multi-tiered AI-driven monitoring system. Event-driven automation via AWS Lambda and EventBridge is extended with intelligent decision engines and reinforcement learning loops. Remediation workflows are executed through Ansible and AWS Systems Manager and enhanced by AI-generated playbooks tailored to novel incidents. Empirical validation shows dramatic reductions in MTTR, enhanced failure prevention rates, and lower operational overhead. This research redefines self-healing as an intelligent, continuously evolving capability vital for multi-cloud resilience. To our knowledge, this is the first framework to integrate LLMs and RL for playbook synthesis in self-healing cloud environments."
"Towards Autonomous Kubernetes: A Framework for AI-Driven Operations (AIOps)","https://scispace.com/papers/towards-autonomous-kubernetes-a-framework-for-ai-driven-6nj8odu6hfri","2025","Journal Article","","Kishan Raj Bellala","10.38124/ijisrt/25sep1016","","No","The increasing use of Kubernetes has brought substantial operational complexity because manual management of its numerous dynamic components (pods, nodes, networks) is slow, error-prone, and unsustainable at scale. This research investigates how AIOps (Artificial Intelligence for IT Operations) principles can move past native automation to establish fully autonomous Kubernetes management. The proposed framework uses machine learning to detect anomalies, identify causes, and predict scaling needs before executing automatic remediation steps. Our methodology demonstrates that AIOps can enhance system reliability and reduce operational Toil while optimizing resource efficiency through closed-loop observation-action cycles, leading to self-healing Kubernetes ecosystems that require minimal human intervention."
"Drift Detection and Correction Post-Tracking","https://scispace.com/papers/drift-detection-and-correction-post-tracking-2bb2zts435","2020","Proceedings Article","International Conference on Acoustics, Speech, and Signal Processing","Tarek Ghoniemy
Maria A. Amer","10.1109/ICASSP40776.2020.9054179","","No","Accurate object tracking is a challenging problem due to numerous factors, that may cause the tracker to drift away from the target object. Typically, the output of a tracker is a bounding box (BB); such BB may not well discriminate the object from its background and may not be centered correctly around the object. This paper proposes a method that first detects, at each frame, if a tracker tends to drift by analyzing saliency features of the output BB of a tracker, and then applies automatic seeded object segmentation on the BB to correct the drift once detected. Such segmentation is meant to relocate (recenter) the BB adaptive to the object segmented. As seeds, we propose to use SIFT and salient points conditioned they are non-background pixels. Different than related work, our approach thus models drift external to a base tracker by examining its output BB at each and corrects drift, as needed, by updating that BB adaptive to segmentation. We show the ability of the proposed method to significantly improve the tracking quality of base trackers. We also show that the proposed method outperforms by far segmentation-based trackers."
"Self‐Healing Membranes: Smart Materials for Water Remediation and Desalination","https://scispace.com/papers/self-healing-membranes-smart-materials-for-water-remediation-ingohmnti6ob","2025","Journal Article","Water Environment Research","Divya Bajpai Tripathy
Subhalaxmi Pradhan","10.1002/wer.70148","","No","ABSTRACT Self‐healing membranes have emerged as an innovative solution to address critical challenges in water remediation, including fouling, mechanical wear, and chemical degradation, all of which severely compromise the performance and longevity of conventional membranes. Traditional filtration membranes often require frequent maintenance and replacement due to the accumulation of contaminants, structural damage, or chemical erosion, which increase operational costs and environmental impacts. Self‐healing membranes, on the other hand, offer a unique advantage by automatically repairing micro‐cracks, mitigating fouling, and rejuvenating their filtration capacity. By integrating advanced materials such as graphene oxide (GO), nanofibers, and MXenes, these membranes demonstrate enhanced chemical stability, mechanical strength, and antifouling properties, making them particularly effective in applications such as oil–water separation, desalination, and the removal of heavy metals and organic pollutants. Additionally, their self‐cleaning capabilities and resistance to environmental stresses significantly reduce downtime and operational inefficiencies in large‐scale water treatment systems. The incorporation of smart functionalities, such as stimuli‐responsive healing triggered by temperature, pH changes, or light, further enhances their adaptability to varying environmental conditions, making self‐healing membranes a sustainable and cost‐effective solution for long‐term water remediation."
"Model-Driven Adaptive Self-healing for Autonomic Computing","https://scispace.com/papers/model-driven-adaptive-self-healing-for-autonomic-computing-4yk1mpns5t","2008","Book Chapter","Modelling Autonomic Communications Environments","Yan Liu
Jing Zhang
John Strassner","10.1007/978-3-540-87355-6_6","","No","Self-healing is a vital property that an autonomic system must possess in order to provide robust performance and survivability The promise of self-healing depends on other properties that the system should provide, which include self-monitoring and self-configuring Autonomic systems further require self-healing behavior to adapt to changes in user needs, business goals, and environmental conditions such that self-healing decisions are made dynamically and adaptively according to the system context In this paper, we propose a model-driven approach that leverages modeling techniques, reliability engineering methodologies, and aspect-oriented development to realize an adaptive self- healing paradigm for autonomic computing"
"Method and apparatus for drift management in clustered environments","https://scispace.com/papers/method-and-apparatus-for-drift-management-in-clustered-8f40zs2vk5","2020","Patent","","Satapathy Shibasis
Naik Harsha","","","No","Configuration drift from a baseline configuration is autonomously resolved. A baseboard management controller may inspect error and/or failure logs to determine system parameters at times of error/failure. The baseboard management controller may compare the system parameters to the baseline configuration. The baseboard management controller may have authority to autonomously change any of the system values to resolve a configuration drift from the baseline configuration."
"Active drift correction template tracking algorithm","https://scispace.com/papers/active-drift-correction-template-tracking-algorithm-3f0v865854","2012","Proceedings Article","International Conference on Image Processing","Baojie Fan
Yingkui Du
Yang Cong
Yandong Tang","10.1109/ICIP.2012.6466879","","No","This paper presents a novel active drift correction template tracking algorithm. Compared to Matthews' algorithm in [8], the proposed algorithm achieves synchronously object tracking and drift correction, and save half running time. For the template drift problem during long sequential object tracking, we introduce the active drift correction term into inverse compositional affine image alignment algorithm. This operation can avoid the template drift before it occurs, or reduce the drift after it happens. The total energy function consists of two terms: the tracking term and the active drift correction term. By minimizing the total energy function with the steepest descent algorithm, the proposed algorithm can decrease the accumulative tracking error, and prevent the drift during the tracking process effectively. Various object tracking experiments show that our method has super performance than the passive drift correction algorithm in [8]."
"Autonomous CI/CD Meshes: Self-healing deployment architectures with AI-ML Orchestration","https://scispace.com/papers/autonomous-ci-cd-meshes-self-healing-deployment-ciz46sn7icy3","2025","Journal Article","World Journal of Advanced Engineering Technology and Sciences","Venkata Krishna Koganti","10.30574/wjaets.2025.15.2.0777","","No","This article introduces a novel architecture for autonomous continuous integration and continuous deployment (CI/CD) systems capable of self-healing and self-optimization without human intervention. The article presents intelligent deployment meshes that integrate deep anomaly detection using LSTM networks with Bayesian change-point detection to identify deployment anomalies before they impact production environments. The proposed framework leverages causal CI/CD graphs to model complex interdependencies between microservices, enabling context-aware remediation strategies including automated rollbacks and intelligent canary analysis. The article's approach unifies machine learning metadata tracking (MLMD) with traditional software observability stacks, creating dual-aspect visibility that optimizes for both model-aware and application-aware pipeline configurations. The article demonstrates how semantic diffing engines can perform version-aware auto-validation, significantly reducing false positives in anomaly detection while improving remediation accuracy in multi-tenant environments. The resulting autonomous CI/CD architecture represents a paradigm shift from reactive to predictive deployment strategies, enabling organizations to maintain high availability while accelerating release velocity in complex microservice ecosystems."
"Self-management system based on self-healing mechanism","https://scispace.com/papers/self-management-system-based-on-self-healing-mechanism-mtn7mvj52u","2006","Book Chapter","Asia-Pacific Network Operations and Management Symposium","Jeongmin Park
Giljong Yoo
Chulho Jeong
Eunseok Lee","10.1007/11876601_38","https://scispace.com/pdf/self-management-system-based-on-self-healing-mechanism-mtn7mvj52u.pdf","No","Systems designed to be self-healing are able to heal themselves at runtime in response to changing environmental or operational circumstances. Thus, the goal is to avoid catastrophic failure through prompt execution of remedial actions. This paper proposes a self-healing mechanism that monitors, diagnoses and heals its own internal problems using self-awareness as contextual information. The self-management system that encapsulates the self-healing mechanism related to reliability improvement addresses: (1) Monitoring layer, (2) Diagnosis & Decision Layer, and (3) Adaptation Layer, in order to perform self-diagnosis and self-healing. To confirm the effectiveness of self-healing mechanism, practical experiments are conducted with a prototype system."
"Association-Analysis-Based Research on Self-Healing of Information System and its Application","https://scispace.com/papers/association-analysis-based-research-on-self-healing-of-1fcr9fmlx0","2014","Journal Article","Applied Mechanics and Materials","Li Yan
Liu Zhang Zhu
Li Xie
Zhi Feng Wang","10.4028/WWW.SCIENTIFIC.NET/AMM.678.94","","No","With the development of information technology, the architecture of information system is more and more complicated. The domestic and international related research is still blank on monitoring and early-warning analyze on the complex information systems’ various operating parameters, no matter self-healing. Through this research, an automatically repair platform is put forward. It can analyze early warning to get the real fault cause and solve the problem or give the solution. It can greatly reduced respond time."
"System and method for autonomus data center operation and healing","https://scispace.com/papers/system-and-method-for-autonomus-data-center-operation-and-4s2zh7qv6d","2019","Patent","","Magcale Arnold","","","No","Methods and systems for autonomous computing comprising processing historical data to analyze a past performance, collecting data from a plurality of connected devices over a network, synchronizing the collected data from the plurality of connected devices with the processed historical data. Based on the synchronized data, methods and systems disclosed include detecting an alert (error/fault) condition in one or more of the plurality of connected devices, based on the detected alert condition, triggering the delivery of the detected alert condition to an automated network operations center (NOC), and matching the determined alert condition to a historical alert condition by the network operations center. Based on the matching, methods and systems include determining a corrective action, and based on the determined corrective action, assigning a virtual self-healing module from a plurality of virtual self-healing modules. Finally, a trigger to performance of the determined corrective action by the assigned virtual self-healing module is initiated."
"Self-Learning Automated Remediation of Changes that Cause Performance Degradation of Applications","https://scispace.com/papers/self-learning-automated-remediation-of-changes-that-cause-36e7dmpmrr","2014","Patent","","Adar Margalit
Eran Dvir","","","No","Techniques are disclosed for automatic remediation of application performance degradations caused by configuration changes. In one embodiment, a learning module keeps track of application configuration changes and subsequent effects on the application's performance. The learning module creates new potential remediation rules based on correlations between such configuration changes and performance degradations or improvements. The learning module affirms such potential rules if the correlation between the configuration changes and degradations or improvements are repeatedly observed, and vice versa. When subsequent performance degradations are observed, a rule engine, which maintains a set of remediation rules, evaluates the rules to identify configuration changes relevant to the observed performance degradation and determines whether the probability that the configuration changes caused the degradation are greater than a threshold for invoking a remediation action, such as rolling back the configuration changes."
"Self-Healing Software Architectures in the Cloud: AI-Driven Detection and Recovery Mechanisms","https://scispace.com/papers/self-healing-software-architectures-in-the-cloud-ai-driven-ev9b7r2s0du5","2025","Journal Article","International journal of data science and machine learning.","Srinivasu Yalamati","10.55640/ijdsml-05-02-05","","No","The recent evolution of cloud computing demands that systems are able to self-diagnose and self-heal as well as constantly optimize without human intervention. This paper provides an in-depth review of the self-healing software architectures in cloud computing, focusing on AI-induced detection and recovery methods. The authors talk about how self-healing systems have changed from traditional ideas to modern AI-powered systems and categorize the main types of methods used for synchronization, tracking, and fixing problems in today's cloud services. Based on a systematic review of available literature, we investigate essential issues such as fault detection accuracy, recovery time optimization, and system reliability improvement. The study finds that although much has been achieved in self-healing, the existing approaches are not yet able to efficiently deal with complex fault situations and to reduce the level of service interruption. Our results suggest that the application of large language models updated using machine learning has the potential to deliver up to an 85% increase in the accuracy of fault prediction and a 60% reduction in system downtime as compared to state-of-the-art approaches. Finally, we talk about what future research should focus on, including the necessary understanding and development of new AI models, different system structures, and standard ways to measure how well self-healing cloud systems work."
"Automatic self-healing systems in a cross-product IT environment","https://scispace.com/papers/automatic-self-healing-systems-in-a-cross-product-it-3ysvju1i36","2004","Proceedings Article","International Conference on Autonomic Computing","G. Dudley
Neeraj Joshi
David M. Ogle
Balan Subramanian
Brad B. Topol","10.1109/ICAC.2004.1301393","","No","This paper presents the architecture and implementation of a prototype system developed to investigate fixing real-world problems with self-healing systems. Case studies performed to evaluate the efficacy of this approach are described along with the issues encountered and lessons learned."
"A Holistic Approach to Autonomic Self-Healing Distributed Computing System","https://scispace.com/papers/a-holistic-approach-to-autonomic-self-healing-distributed-3zqgkojybr","2013","Journal Article","International Journal of Computer Applications","Abhishek Bhavsar
Ameya More
Chinmay Kulkarni
Dheeraj Oswal
Jagannath Aghav","10.5120/13228-0657","https://scispace.com/pdf/a-holistic-approach-to-autonomic-self-healing-distributed-3zqgkojybr.pdf","Yes","Distributed Computing systems are prone to errors and faults and a major amount of time is wasted in maintaining the system and bringing it back to a stable state after a fault. Human resources in the distributed systems architecture currently handle this maintenance. Despite the emergence of ultra-reliable components, failure in distributed computing systems is still an unmitigated problem. As a result of this a lot of resources in the form of money and manpower and efforts in the form of man months are wasted. The proposed mechanism focuses efforts to make a distributed systems environment reliable and robust by proposing an autonomic, self-healing architecture. A holistic approach to the problem is adopted and an architecture that is general enough to be adopted by a wide range of existing systems is proposed. Some of the major challenges include selecting the appropriate actions for healing and reducing the overhead thus making healing lightweight and transparent, yet effective. The proposed system architecture makes use of data mining techniques to generate rules based on gathered system data from logs. The rules are used to make decisions of corrective action and hence carry out the self-healing mechanism."
"Electrical drift correction system","https://scispace.com/papers/electrical-drift-correction-system-52tyz7q2gw","1971","Patent","","Robert S. Prill","","","No","Analog to digital converter systems which include an integratorcomparator combination, utilizing operational amplifiers, often suffer from drift due to radiation and other causes. The drift can be effectively nulled out by means of a closed loop pulsed feedback circuit between the comparator and the integrator. The feedback circuit includes a capacitor which is charged or discharged in a pulsed manner to the required correction voltage during times other than actual measurement, such capacitor being coupled to that input of the operational amplifier integrator which is normally coupled to a point of reference potential, such as ground."
"Introducing responsibly self-healing into the incident management lifecycle","https://scispace.com/papers/introducing-responsibly-self-healing-into-the-incident-4pfzumqlbc","2023","Journal Article","","Alexandros Papanikolaou
Christos Ilioudis
Vasilios Katos","10.1145/3594806.3594837","","No","In this paper we propose an approach for adopting the self-healing paradigm in complex networking environments. We argue that a straightforward application of self-healing capabilities may have an adverse effect on incident response due to the ill-understanding of the state of the system under protection. We sketch how the use of the Cynefin framework leverages the understanding of complex systems at the appropriate level of detail. In particular, we show how the framework can help to understand how the environment operates and to identify ways to improve its resilience and ability to recover from failures."
"Self-healing Performance Anomalies in Web-based Applications","https://scispace.com/papers/self-healing-performance-anomalies-in-web-based-applications-2vtnbhhmg4","2013","Proceedings Article","Network Computing and Applications","Joao Paulo Magalhaes
Luis Silva","10.1109/NCA.2013.19","","No","In this paper, we describe the SHoWA framework and evaluate its ability to recover from performance anomalies in Web-based applications. SHoWA is meant to automatically detect and recover from performance anomalies, without calling for human intervention. It does not require manual changes to the application source code or previous knowledge about its implementation details. The application is monitored at runtime and the anomalies are detected and pinpointed by means of correlation analysis. A recovery procedure is performed every time an anomaly is detected. An experimental study was conducted to evaluate the recovery process included in the SHoWA framework. The experimental environment considers a benchmarking application, installed in a high-availability system. The results show that SHoWA is able to detect and recover from different anomaly scenarios, before any visible error, higher-latency or work-in-progress loss is observed. It proved to be efficient in terms of time of repair. The performance impact induced on the managed system was low: the response time penalty per request varied between 0 and 2.21 milliseconds, the throughput was affected in less than 1%."
"Self-Healing in Cyber–Physical Systems Using Machine Learning: A Critical Analysis of Theories and Tools","https://scispace.com/papers/self-healing-in-cyber-physical-systems-using-machine-1iglnkb1","2023","Journal Article","Future Internet","","10.3390/fi15070244","","No","The rapid advancement of networking, computing, sensing, and control systems has introduced a wide range of cyber threats, including those from new devices deployed during the development of scenarios. With recent advancements in automobiles, medical devices, smart industrial systems, and other technologies, system failures resulting from external attacks or internal process malfunctions are increasingly common. Restoring the system’s stable state requires autonomous intervention through the self-healing process to maintain service quality. This paper, therefore, aims to analyse state of the art and identify where self-healing using machine learning can be applied to cyber–physical systems to enhance security and prevent failures within the system. The paper describes three key components of self-healing functionality in computer systems: anomaly detection, fault alert, and fault auto-remediation. The significance of these components is that self-healing functionality cannot be practical without considering all three. Understanding the self-healing theories that form the guiding principles for implementing these functionalities with real-life implications is crucial. There are strong indications that self-healing functionality in the cyber–physical system is an emerging area of research that holds great promise for the future of computing technology. It has the potential to provide seamless self-organising and self-restoration functionality to cyber–physical systems, leading to increased security of systems and improved user experience. For instance, a functional self-healing system implemented on a power grid will react autonomously when a threat or fault occurs, without requiring human intervention to restore power to communities and preserve critical services after power outages or defects. This paper presents the existing vulnerabilities, threats, and challenges and critically analyses the current self-healing theories and methods that use machine learning for cyber–physical systems."
"On Self-healing Based on Collaborating End-Systems, Access, Edge and Core Network Components","https://scispace.com/papers/on-self-healing-based-on-collaborating-end-systems-access-4c9n200t8z","2010","Book Chapter","International Conference on Access Networks","Nikolay Tcholtchev
Ranganai Chaparadza","10.1007/978-3-642-20931-4_22","https://scispace.com/pdf/on-self-healing-based-on-collaborating-end-systems-access-4c9n200t8z.pdf","No","Autonomic Networking, realized through control loops, is an enabler for advanced self-manageability of network nodes and respectively the network as a whole. Self-healing is one of the desired autonomic features of a system/network that can be facilitated through autonomic behaviors realized by control loop structures. Autonomicity, implemented over existing protocol stacks as managed resources, requires an architectural framework that integrates the diverse aspects and levels of self-healing capabilities of individual protocols, systems and the network as a whole, such that they all should co-operate as required towards achieving reliable network services. This integration should include the traditional resilience capabilities intrinsically embedded within some protocols e.g. some telecommunication protocols, as well as diverse proactive and reactive schemes for incident prevention and resolution, which must be realized by autonomic entities implementing a control loops at a higher-level outside of protocols. In this paper, we present our considerations on how such an architectural framework, integrating the diverse resilience aspects inside an autonomic node, can facilitate collaborative self-healing across end systems, access networks, edge and core network components."
"Machine learning based instance remediation","https://scispace.com/papers/machine-learning-based-instance-remediation-4xqbiq8lht","2013","Patent","","Laban Mwangi Kimotho
Jean-Paul Bauer","","","No","Computer systems, such as network computing resources systems, are subject to hardware and software errors. To improve error handling and troubleshooting, information relating to errors is collected from a multitude of computer system and analyzed. As a result of this analysis, troubleshooting errors in computer systems is improved and errors are remediated automatically."
"AI-Driven Self-Healing Cloud Systems: Enhancing Reliability and Reducing Downtime through Event-Driven Automation","https://scispace.com/papers/ai-driven-self-healing-cloud-systems-enhancing-reliability-h0syspip9u97","2024","Journal Article","","Rajeev Arora
Anoop Kumar
Arpita Soni
Aniruddh Tiwari","10.20944/preprints202408.1860.v1","","No","Abstract. The goal of this study is to create and carry out a self-healing cloud system by combining an event-driven automation framework depending on the if-this-then-that principle for managing incidents and recovery. A recovery engine with Artificial Intelligence (AI)-based decision-making approaches is presented&amp;mdash;which chooses the best remedial actions from a pre-established catalogue in order to maximise system reliability and minimise downtime. The system is tested on an OpenStack-based video on demand service&amp;mdash;where multiple issues are replicated in order to assess the efficaciousness of various recovery actions and workflows. The decision-making module of the recovery engine examines data from these experiments to determine the most effective remedial actions, taking into account their impact on the quality of service and other factors. The recovery engine is only meant to need human input when it comes to parameterizing and optimising decision models at particular points in time. In order to show how these AI-driven decision-making techniques can enhance mean time to repair and overall service quality in cloud environments&amp;mdash;the study presents and assesses their results. This novel strategy represents a change towards cloud systems that are more sturdy autonomous, and able to effectively manage anomalies and recover from failure."
"Method and system for self-learning issues remediation","https://scispace.com/papers/method-and-system-for-self-learning-issues-remediation-4t4n6v6xwb","2009","Patent","","Christopher Collard
John Igoe","","","No","A system and method are disclosed for automatically performing remediation operations on a plurality of information handling system (IHS) resources. Survey information related to a user of IHS resources is collected and processed to generate survey information. IHS resources used by the user are determined and associated configuration and operational information is collected and processed to generate imported information. The survey information and the imported information are then processed to generate state analysis information, which is then compared to a plurality of health baseline information. The results of the comparison operations are used to determine individual IHS resources not conforming to predetermined health baseline parameters. If an individual IHS resource does not conform to the predetermined health baseline parameters, then a remediation operation is automatically performed on the individual IHS resource."
"SASH: Safe Autonomous Self-Healing","https://scispace.com/papers/sash-safe-autonomous-self-healing-137wjeqv","2023","Book Chapter","Lecture Notes in Computer Science","Gary L. White
Leonardo Lucio Custode
Owen O'Brien","10.1007/978-3-031-26507-5_12","","No","With the large scale and user demands on modern cloud systems there is a need for autonomous approaches to self-healing. When there is no operator in the loop for self-healing actions, it is crucial to ensure that the actions taken are safe and effective. In this paper we propose SASH: Safe Autonomous Self-Healing, which uses surrogate models to estimate the safety and effectiveness of self-healing actions. SASH uses system metrics, configuration parameters, domain information and available actions to decide on the best fault remediation action or combination of actions. The performance of the action(s) are then verified through a validation block that updates the knowledge base with how the actions performed for that fault. This data is then used to update the safety and effectiveness estimation algorithm. The results show the framework is able to successfully remediate faults with a low number of actions and with protection against unsafe actions."
"Advancing autonomous network optimization: A DevOps-based framework for self-healing telecommunications networks","https://scispace.com/papers/advancing-autonomous-network-optimization-a-devops-based-3bzcpk2gva30","2021","Journal Article","Open access research journal of multidisciplinary studies","Alan Collins
Oladimeji Hamza
Adeoluwa Eweje","10.53022/oarjms.2021.2.1.0042","","No","The evolving demands of modern telecommunications networks require continuous optimization to ensure reliability, performance, and scalability. This paper proposes an advanced framework for autonomous network optimization, utilizing a DevOps-driven approach to enable self-healing capabilities in telecommunications networks. The framework integrates automation, machine learning, and real-time anomaly detection to facilitate proactive network management, minimizing downtime and enhancing operational efficiency. In traditional telecom network management, the detection and resolution of network issues are often reactive, leading to delays and performance degradation. The proposed self-healing network system, based on DevOps principles, automates the entire process of anomaly detection, root cause analysis, and resolution. The framework employs machine learning algorithms to continuously monitor network traffic and performance metrics, enabling real-time identification of potential issues such as congestion, service degradation, or security breaches. Upon detecting anomalies, the system automatically triggers corrective actions, including rerouting traffic, optimizing resource allocation, or scaling network components, all without human intervention. The architecture integrates key DevOps elements, such as continuous integration/continuous deployment (CI/CD) pipelines, version control, and automated testing, to ensure rapid and reliable updates to the network infrastructure. This seamless integration of automation and machine learning enhances the system’s ability to adapt to evolving network conditions, providing a dynamic and self-optimizing network environment. The paper explores the benefits of this self-healing framework, including reduced operational costs, improved network uptime, and enhanced user experience. It also addresses the challenges associated with implementing such systems, including data quality, training models, and network complexity. Ultimately, this DevOps-based framework represents a significant step toward the future of autonomous, self-healing telecommunications networks, offering a foundation for the next generation of intelligent network management."
"Self-Healing in Knowledge-Driven Autonomous Networks: Context, Challenges, and Future Directions","https://scispace.com/papers/self-healing-in-knowledge-driven-autonomous-networks-context-5cksvfk8gf","2024","Journal Article","IEEE Network","Honglin Fang
Peng Yu
Cheng Tan
Junye Zhang
Defu Lin
Liyan Zhang
Yong Zeng
Wenjing Li
Luoming Meng","10.1109/mnet.2024.3416850","","No","With the advancement of communication and computer technology, network architectures have become increasingly complex, accompanied by the continual emergence of novel services. This increase in sophistication surpasses the abilities of manual maintenance and traditional network management solutions, thereby elevating the potential risk of network failures. This article provides a comprehensive review of significant network incidents that have occurred over the past decade and outlines the evolution of network self-healing. Building on these findings, we propose an effective knowledge-driven self-healing pattern (KSHP) suitable for a broad spectrum of network failure scenarios, designed to alleviate the challenges of automation and scalability in autonomous networks. In our case study, we implemented a self-healing agent following the KSHP schema to mitigate network service failures caused by link congestion. The experimental results validate the efficacy and practicality of KSHP in network fault scenarios. Furthermore, future directions are discussed and analyzed in detail. The insights presented in this article provide a basic pattern for the knowledge-driven self-healing framework, facilitating the achievement of Level 5 autonomous networks."
"Frequency drift correction in subscriber terminals","https://scispace.com/papers/frequency-drift-correction-in-subscriber-terminals-2hr4vwgcbw","1996","Patent","","Allan Evans
Horen Chen","","","No","A frequency control system and method for minimizing frequency drifts in subscriber terminals in a point-to-multipoint system is described enabling the use of low cost oscillators (5) in the subscriber terminals by measuring the frequency offset (9) of the subscriber terminal's receiver to estimate its oscillator frequency drift which is then used to correct the subscriber terminal's transmitter (12) frequency and also by feedback of a frequency correction from the base station to the subscriber."
"Self-Healing Infrastructure: Leveraging Reinforcement Learning for Autonomous Cloud Recovery and Enhanced Resilience","https://scispace.com/papers/self-healing-infrastructure-leveraging-reinforcement-gum9060pdc7k","2025","Journal Article","Journal of Information Systems Engineering and Management","Rohit Laheri","10.52783/jisem.v10i49s.9888","","No","Maintaining high availability and reliability in dynamic cloud environments demands proactive, automated solutions capable of handling failures at scale. This study introduces a novel multi-layer self-healing infrastructure framework that unites predictive analytics, reinforcement learning (RL), and rule-based automation into a cohesive, horizontally scalable system. Predictive analytics continuously ingests telemetry—CPU, memory, network metrics, and application logs—using time-series forecasting (ARIMA, LSTM) and unsupervised anomaly detection (Isolation Forest, k-Means) to flag potential faults with &gt;96% accuracy. An RL agent employing Proximal Policy Optimization (PPO) then dynamically selects recovery actions (e.g., container restart, horizontal scaling, resource reallocation) guided by a reward function that balances rapid Mean Time To Repair (MTTR) reduction with minimal resource overhead and service impact. Simultaneously, rule-based playbooks address frequent failure patterns, ensuring immediate remediation within 30 seconds for predictable incidents. Deployed as Infrastructure as Code (IaC) via Terraform and Helm on Kubernetes clusters across AWS and Azure, our framework was validated over 220 fault scenarios. Key performance indicators demonstrate an 85% MTTR reduction (from 90 to 13.5 minutes), recovery reliability exceeding 95%, fault tolerance above 91%, and system uptime surpassing 98%. Resource overhead during recovery remains under 10%. Compared to prior isolated methods—rule-based MTTR reduction of 60%, RL-only MTTR reduction of 50%, and anomaly detection without remediation—our integrated model delivers superior resilience and operational efficiency. This paper is organized as follows: Section 1 introduces the problem and contributions; Section 2 reviews related work; Section 3 details the methodology; Section 4 describes experimental setup; Section 5 presents results; Section 6 discusses implications and limitations; Section 7 outlines future research directions; and Section 8 concludes."
"Learning Recovery Strategies for Dynamic Self-healing in Reactive Systems","https://scispace.com/papers/learning-recovery-strategies-for-dynamic-self-healing-in-1ng3af1sjr","2024","Journal Article","","Mateo Sanabria
Ivana Dusparić
Nicolás Cardozo","10.1145/3643915.3644097","","No","Self-healing systems depend on following a set of predefined instructions to recover from a known failure state. Failure states are generally detected based on domain specific specialized metrics. Failure fixes are applied at predefined application hooks that are not sufficiently expressive to manage different failure types. Self-healing is usually applied in the context of distributed systems, where the detection of failures is constrained to communication problems, and resolution strategies often consist of replacing complete components. However, current complex systems may reach failure states at a fine granularity not anticipated by developers (for example, value range changes for data streaming in IoT systems), making them unsuitable for existing self-healing techniques. To counter these problems, in this paper we propose a new self-healing framework that learns recovery strategies for healing fine-grained system behavior at run time. Our proposal targets complex reactive systems, defining monitors as predicates specifying satisfiability conditions of system properties. Such monitors are functionally expressive and can be defined at run time to detect failure states at any execution point. Once failure states are detected, we use a Reinforcement Learning-based technique to learn a recovery strategy based on users' corrective sequences. Finally, to execute the learned strategies, we extract them as Context-oriented Programming variations that activate dynamically whenever the failure state is detected, overwriting the base system behavior with the recovery strategy for that state. We validate the feasibility and effectiveness of our framework through a prototypical reactive application for tracking mouse movements, and the DeltaIoT exemplar for self-healing systems. Our results demonstrate that with just the definition of monitors, the system is effective in detecting and recovering from failures between 55% -- 92% of the cases in the first application, and at par with the predefined strategies in the second application."
"Event-Driven Self-Healing Infrastructure: A Conceptual Framework for Intelligent Automation in Site Reliability Engineering","https://scispace.com/papers/event-driven-self-healing-infrastructure-a-conceptual-puujcpqj5vwd","2025","Journal Article","Journal of Information Systems Engineering and Management","Sunil Agarwal","10.52783/jisem.v10i57s.12320","","No","Since organizations have adopted microservice and cloud-native architectures, resilience and autonomous operations have become more and more popular. In this paper, the focus is an event-driven self-healing infrastructure concept at the Site Reliability Engineering (SRE). The framework allows proactive detective of incidents and their resolution without the involvement of humans by following up on the real-time observability pipelines, serverless automation, and AI-driven decision engines. It has been evaluated that the mean time to repair and recovery accuracy have significantly dropped as well as the operational cost. Complexity of integration and requirement to oversight in edge cases are other challenges studied in the paper, which provides a practical road map to achieving intelligent and self-managing systems that improve reliability of services provided."
"Drift management of images","https://scispace.com/papers/drift-management-of-images-3t7vd6njv6","2015","Patent","","Balasubrahmanyam Kuchibhotla
Bharat Paliwal
Hariprasanna Srinivasan
Kamaldeep Khanuja
Shachi Sanklecha
Ramalakshmi Vaidhiyanathan","","","No","Techniques are described for managing drift within a standardized environment. According to one embodiment, an end state definition is stored that identifies a standard set of source components for a plurality of targets. A drift manager determines that at least one target of the plurality of targets has drifted from the standard set of source components identified by the end state definition. After determining that the at least one target of the plurality of targets has drifted from the standard set of source components identified by the end state definition, the drift manager reconciles the at least one target with the end state definition."
"Root Cause Analysis and Proactive Problem Prediction for Self-Healing","https://scispace.com/papers/root-cause-analysis-and-proactive-problem-prediction-for-3ff9k8moss","2007","Proceedings Article","International Conference on Convergence Information Technology","Shunshan Piao
Jeongmin Park
Eunseok Lee","10.1109/ICCIT.2007.340","","No","As the rapid evolvement of distributed computing system, the requirements imposed on problem determination techniques are increased to help system control and manage in high levels of automated ways, which represents the capability of self-healing. Many artificial intelligent approaches are widely used in the fields of fault managements. In this paper, we propose an approach to fault management for self-healing system through learning and analyzing real-time information, to provide both root cause analysis and proactive problem prediction. Using Bayesian network algorithm, we describe a complex system as a compact model that presents probabilistic dependency relationships between various factors in such a domain. We also provide an improved process that deals with collected parameters in advance, which enhances learning efficiency and reduces learning time. For estimating the efficiency and accuracy, an experimental demonstration based on system performance measurements is implemented and evaluated via diverse comparisons, which shows the availability is optimistic."
"Decawave UWB Clock Drift Correction and Power Self-Calibration","https://scispace.com/papers/decawave-uwb-clock-drift-correction-and-power-self-4v2fwcdg9w","2019","Journal Article","Sensors","Juri Sidorenko
Volker Schatz
Norbert Scherer-Negenborn
Michael Arens
Urs Hugentobler","10.3390/S19132942","","Yes","The position accuracy based on Decawave Ultra-Wideband (UWB) is affected mainly by three factors: hardware delays, clock drift, and signal power. This article discusses the last two factors. The general approach to clock drift correction uses the phase-locked loop (PLL) integrator, which we show is subject to signal power variations, and therefore, is less suitable for clock drift correction. The general approach to the estimation of signal power correction curves requires additional measurement equipment. This article presents a new method for obtaining the curve without additional hardware and clock drift correction without the PLL integrator. Both correction methods were fused together to improve two-way ranging (TWR)."
"Real-time correction method for spectral drift of PET detector and correction system for spectral drift","https://scispace.com/papers/real-time-correction-method-for-spectral-drift-of-pet-1v4osbhau6","2018","Patent","","Tian Libo
Sun Dehui","","","No","The invention discloses a real-time correction method for spectral drift of a PET detector and a correction system for spectral drift. The method comprises the following steps: according to the energyspectrum diagram of the PET detector, judging that whether the PET detector has spectral drift or not, if spectral drift occurs, judging that whether the PET detector is positioned inside an externalradiation field or outside the external radiation field; if the PET detector is positioned in the external radiation field, by adopting the temperature value of the environment where the PET detectoris located currently, inquiring the mapping relation of temperature/spectral drift correction, and acquiring compensation gain needed by spectral drift correction; and based on the compensation gain,compensating a compensating circuit corresponding to the PET detector, wherein the mapping relation of temperature/spectral drift correction is the mapping relation of the temperature value and the compensation gain of the temperature value. With the method provided by the invention, the round-the-clock correction for the spectral drift of the PET detector can be realized, the correction speed ishigh, and the correction effect is good."
"A survey of self-healing systems frameworks","https://scispace.com/papers/a-survey-of-self-healing-systems-frameworks-16k78jxwkn","2015","Journal Article","Software - Practice and Experience","Chris L. Schneider
Adam Barker
Simon Dobson","10.1002/SPE.2250","https://scispace.com/pdf/a-survey-of-self-healing-systems-frameworks-16k78jxwkn.pdf","Yes","SUMMARY Rising complexity within multi-tier computing architectures remains an open problem As complexity increases, so do the costs associated with operating and maintaining systems within these environments One approach for addressing these problems is to build self-healing systems (ie frameworks) that can autonomously detect and recover from faulty states Self-healing systems often combine machine learning techniques with closed control loops to reduce the number of situations requiring human intervention This is particularly useful in situations where human involvement is both costly to develop, and a source of potential faults Therefore, a survey of self-healing frameworks and methodologies in multi-tier architectures is provided to the reader Uniquely, this study combines an overview of the state of the art with a comparative analysis of the computing environment, degree of behavioural autonomy, and organisational requirements of these approaches Highlighting these aspects provides for an understanding of the different situational benefits of these self-healing systems We conclude with a discussion of potential and current research directions within this field Copyright © 2014 John Wiley & Sons, Ltd"
"Multiple linear regression based parameter influencer model of a Self-healing network","https://scispace.com/papers/multiple-linear-regression-based-parameter-influencer-model-2anwwc3i1d","2011","Proceedings Article","International Workshop on Security","HP Raghunandan
Smita Bedekar","10.1109/IWSCN.2011.6827716","","No","Autonomic features can be built into systems by including Self-* properties. Amongst the various Self-* properties the Self-healing feature is important because it ensures increased uptime and no or less downtime by healing the system and/or its components. System adminstrators desperately need help as complexity of networks and their management systems continue to grow unabatedly. In this paper, we describe how a multiple linear regression based parameter-influencer model can be used to build in Self-healing features in a network. We describe a scenario in a system where each parameter in the system is affected distinctly by many influencers. Statistical techniques are used to identify extent of dependency of parameters on more than one influencer. Empirical data and smaller ranges of values of data from case studies encouraged us to assume a linear relation as a starting point. After identifying the relationship amongst them the appropriate influencers are modified so as to affect the values of parameters. They are thus brought away from their threshold values and near their median values and in turn stability is brought into the system. Our model is programmed as a daemon on the network and a case study is described where historical data is used to tune the network parameters more accurately."
"Drift correction in periodic crosscorrelation schemes","https://scispace.com/papers/drift-correction-in-periodic-crosscorrelation-schemes-3x1n0mhnqw","1968","Journal Article","Electronics Letters","R.F. Brown","10.1049/EL:19680374","","No","In the evaluation of a periodic crosscorrelation for a time-invariant system, a simple-to-instrument method is described for eliminating error terms due to polynomial drift disturbances. The method is based on the periodic input perturbation signal being of inverse repeat form, and leads to the result that polynomial drift up to the rth degree may be eliminated by crosscorrelating over r + 2 half periods with appropriate constant weights associated with each half period."
"Autonomous Self-Adaptation in the Cloud: ML-Heal’s Framework for Proactive Fault Detection and Recovery","https://scispace.com/papers/autonomous-self-adaptation-in-the-cloud-ml-heals-framework-k3hmrqevrela","2025","Journal Article","International Journal of Advanced Computer Science and Applications","Qais Al-Na’amneh
Mahmoud Aljawarneh
Rahaf Hazaymih
Ayoub Alsarhan
Khalid Hamad Alnafisah
Nayef H. Alshammari
Sami Aziz Alshammari","10.14569/ijacsa.2025.0160892","","No","—Cloud computing environments increasingly host applications constructed from orchestrated service compositions, which deliver enhanced functionality through distributed work-flows. This paradigm, however, introduces vulnerabilities where component failures can cascade, disrupting entire applications. Conventional fault tolerance often falls short in these dynamic settings. This paper introduces ML-Heal, an autonomous self-healing framework architected to bolster the resilience of such service compositions. ML-Heal leverages machine learning for proactive failure detection, precise diagnosis, and intelligent recovery strategy selection. The framework integrates real-time monitoring data, applies ML-based anomaly detection and classification to identify faults, and plans corrective actions via a learned policy or predictive models. Implemented using Python with scikit-learn models and a custom orchestration layer, its efficacy is demonstrated through simulated fault injection scenarios. Illustrative system architecture and evaluation results show that this ML-driven methodology significantly curtails recovery time and augments availability when confronted with faults, showcasing AI’s potential in creating more robust, self-adaptive cloud service compositions with minimal human oversight."
"Self-Healing of Operational Workflow Incidents on Distributed Computing Infrastructures","https://scispace.com/papers/self-healing-of-operational-workflow-incidents-on-3acq6cipue","2012","Proceedings Article","Cluster Computing and the Grid","Rafael Ferreira da Silva
Tristan Glatard
Frédéric Desprez","10.1109/CCGRID.2012.24","https://scispace.com/pdf/self-healing-of-operational-workflow-incidents-on-3acq6cipue.pdf","Yes","Distributed computing infrastructures are commonly used through scientific gateways, but operating these gateways requires important human intervention to handle operational incidents. This paper presents a self-healing process that quantifies incident degrees of workflow activities from metrics measuring long-tail effect, application efficiency, data transfer issues, and site-specific problems. These metrics are simple enough to be computed online and they make little assumptions on the application or resource characteristics. Incidents are classified in levels and associated to sets of healing actions that are selected based on association rules modeling correlations between incident levels. The healing process is parametrized on real application traces acquired in production on the European Grid Infrastructure. Implementation and experimental results obtained in the Virtual Imaging Platform show that the proposed method speeds up execution up to a factor of 4 and properly detects unrecoverable errors."
"Scalable GitOps Models for Multi-Cloud Infrastructure as Code Deployment","https://scispace.com/papers/scalable-gitops-models-for-multi-cloud-infrastructure-as-mqyy0svwe2i4","2022","Journal Article","International journal of computing and engineering","Sri Ramya Deevi","10.47941/ijce.3190","","No","As enterprises embrace multi-cloud strategies to enhance agility, reduce vendor lock-in, and meet regulatory requirements, the need for scalable and reliable infrastructure management becomes critical. GitOps a paradigm that leverages Git as the single source of truth for declarative infrastructure offers a transformative approach to manage Infrastructure as Code (IaC) across heterogeneous cloud environments. This paper explores scalable GitOps models tailored for multi-cloud deployments, highlighting key architectural patterns, toolchains, and workflows that enable secure, auditable, and automated infrastructure operations. The study analyzes the strengths and limitations of leading GitOps tools such as ArgoCD and Flux in coordinating cross-cloud configurations and reconcile loops. The study also examines strategies for repository structuring, modularization of IaC, policy-as-code integration, and dynamic secrets management to support enterprise-scale deployments. The study propose a reference architecture that addresses the challenges of scalability, compliance, and resilience in multi-cloud GitOps workflows. My findings demonstrate that, when correctly implemented, GitOps can serve as a powerful operational model for achieving continuous delivery and governance in complex cloud-native ecosystems."
"Terraform: Streamlining Infrastructure Deployment and Management Through Infrastructure as Code","https://scispace.com/papers/terraform-streamlining-infrastructure-deployment-and-5d585yxp3k","2023","Proceedings Article","","Abbas Mehdi
Ranjan Walia","10.1109/icccis60361.2023.10425616","","No","Terraform first appeared in the decade of the 2017 Infrastructure management tools have the potential to revolutionize how we manage IT infrastructure. However, many organizations today report no significant improvements, and some report that using these tools only makes things more complicated. The question of when a person will be able to deploy the infrastructure utilizing the on-go click service arisesas the cloud gives us the click-on-go interface for deploying infrastructure. Using Terraform to deploy the infrastructure with code in a single step is the straightforward answer to the issue. Terraform allows you to write code for numerous resources that will be deployed on your AWS account. Terraform supports a wide range of providers in addition to AWS, including Azure, Digital Ocean, Grafana, etc. Terraform has significantly reduced the time and effort required for deployment, as well as the amount of human interaction required to do it and the associated errors. Before, we had trouble setting up many resources across several cloud providers, but Terraform has made it simple to construct or deploy infrastructure using code, improving our current processand increasing efficiency as we worked on several projects at once."
"Terraform: Infrastructure as Code","https://scispace.com/papers/terraform-infrastructure-as-code-vdc83lufey","2023","Book Chapter","","","10.1007/979-8-8688-0074-0_1","","No","In this chapter, we embark on a journey through the realm of modern IT and infrastructure as code (IaC). We will discover the tremendous importance of IaC in today’s technology landscape. Terraform, the powerful instrument that is transforming the face of IT infrastructure management, will be the focus of our attention. We will delve into the core aspects that set Terraform apart and make it an industry game-changer. We will begin by exploring the tangible use cases that demonstrate Terraform’s power in orchestrating IT environments with unparalleled agility and efficiency."
"End-To-End Automation of Multi-Cloud Deployments Using Terraform, Ansible, and Kubernetes","https://scispace.com/papers/end-to-end-automation-of-multi-cloud-deployments-using-cq2x3viq5uth","2020","Journal Article","International journal of innovative research in engineering & multidisciplinary physical sciences","Ravi Chandra Thota -","10.37082/ijirmps.v8.i4.232184","","No","Organizations now adopt multi-cloud strategies because cloud computing development enabled them to choose multiple cloud service providers for better performance combined with cost-effectiveness and reliability. The need for IT agility and organizational scalability creates a problematic situation for managing various cloud environments. The document investigates detailed automation solutions for multi-cloud deployments integrating Terraform with Ansible and Kubernetes. Organizations achieve better business response capabilities by combining these strong automation tools, optimizing deployment streamlining while managing resources better and minimizing operational expenses. The primary function of Terraform is to provide an automation framework backbone that enables IaC infrastructure provisioning. Users can deploy cloud infrastructure consistently and repeatedly through Terraform because they define resources in declarative codes that work across major cloud providers. The ability to streamline cloud management across multiple platforms becomes more effective through this feature when operating in a multi-cloud environment. The automation process reaches a higher degree of robustness when using Ansible alongside its configuration management and application deployment capabilities. With a structure that needs no agent, Ansible provides users with straightforward orchestration processes between different platforms, ensuring they can easily manage their resources regardless of their cloud provider types. With its fundamental capabilities to orchestrate containers, Kubernetes plays a crucial role in a multi-cloud environment. It enables the deployment and management of applications, thereby automating application deployment and management for enterprise organizations. This results in consistent and reliable execution across various cloud systems. Developers can create an automated workflow connecting infrastructure provisioning to application deployment processes. This end-to-end automation framework significantly improves operational efficiency, reduces product delivery schedules, and helps organizations develop a robust cloud strategy, enhancing market competitiveness."
"Enterprise Cloud Infrastructure Automation and Platform Engineering for Multi-Cloud Global Systems","https://scispace.com/papers/enterprise-cloud-infrastructure-automation-and-platform-mdkg6qr5qdu2","2025","Journal Article","Journal of Information Systems Engineering and Management","Lakshmi Priyanka Pillati","10.52783/jisem.v10i57s.12545","","No","The contemporary enterprise technology landscape has undergone a fundamental transformation as organizations seek enhanced agility, scalability, security, and innovation capabilities through cloud computing adoption. Multi-cloud environments have emerged as strategic responses to diverse business, technical, and regulatory requirements, though they introduce significant operational complexity through heterogeneous infrastructure management challenges. The convergence of cloud infrastructure automation and platform engineering represents a paradigmatic shift in how enterprises address these complexities, enabling organizations to achieve superior operational outcomes through integrated approaches. Cloud infrastructure automation employs programmatic management of computing, networking, and storage resources via declarative models and software-defined configurations, while platform engineering focuses on designing internal platforms that provide developers with secure, self-service access to essential tools and services. Organizations implementing these converged disciplines demonstrate enhanced capabilities in managing complexity, accelerating innovation, and maintaining compliance across distributed environments. Interoperability-driven workflow engines serve as critical enablers, providing abstraction and orchestration capabilities necessary for effective heterogeneous cloud environment management. The integration enables substantial improvements in development velocity, operational efficiency, and cost optimization while addressing implementation challenges, including technical complexity, cultural transformation requirements, and specialized skill demands. Strategic implications indicate that successful multi-cloud strategies require investments in both technical capabilities and organizational transformation to realize comprehensive benefits."
"Terraform and AWS CDK: A Comparative Analysis of Infrastructure Management Tools","https://scispace.com/papers/terraform-and-aws-cdk-a-comparative-analysis-of-2mtfanj6nfhl","2024","Journal Article","","João Frois
Lucas Padrão
Johnatan Oliveira
Laerte Xavier
Cleiton Silva Tavares","10.5753/sbes.2024.3577","","No","Infrastructure as Code is a fundamental concept in DevOps that automates infrastructure management processes using code. Several tools, such as Terraform and CDK, support this environment. Selecting the appropriate tool is crucial to a project’s success, yet there is ambiguity about the circumstances in which developers should choose between these tools. Therefore, this study aims to compare Terraform and CDK across four aspects: abstraction, scalability, maintainability, and performance. Our findings indicate that each tool performs particularly well in specific scenarios. For instance, Terraform is better suited for experienced teams focused on rapid implementations, while CDK is more appropriate for less experienced teams prioritizing resource efficiency during implementation."
"Terraform","https://scispace.com/papers/terraform-33o2fher","2022","Book Chapter","","Moshe Zadka","10.1007/978-1-4842-7996-0_15","","No","Terraform is an open source project maintained by HashiCorp, which gives an infrastructure as code (IaC) interface to cloud providers."
"Infrastructure From Code: The Next Generation of Cloud Lifecycle Automation","https://scispace.com/papers/infrastructure-from-code-the-next-generation-of-cloud-3q2oje9n","2023","Journal Article","IEEE Software","Itzhak Aviv
Ruti Gafni
Sofia Sherman
Berta Aviv
Asher Sterkin
Etzik Bega","10.1109/MS.2022.3209958","","No","We identify 14 fundamental cloud infrastructure procedures (CIPs) applicable to software development processes on the public cloud and their associated challenges. We then evaluate the capabilities of leading cloud automation technologies, such as infrastructure as code, and pinpoint their gaps in enabling the CIPs."
"Business Solutions with Infrastructure as Code","https://scispace.com/papers/business-solutions-with-infrastructure-as-code-1ldxvavn","2022","Book Chapter","","","10.1007/978-1-4842-8689-0_5","","No","Utilizing infrastructure as code (IaC) is now among the most often used approaches to automate a company’s infrastructure. In terms of the distribution of innovative technologies, it is possible to compare it to a factory floor. In the field of technology, having reliable manufacturing procedures is essential to the operations of a corporation."
"Optimizing DevOps Pipelines with Automation: Ansible and Terraform in AWS Environments","https://scispace.com/papers/optimizing-devops-pipelines-with-automation-ansible-and-32o5hbap2jsu","2024","Journal Article","International journal of scientific research in science, engineering and technology","Venkat Marella","10.32628/ijsrset2410614","","No","In order to improve operational efficiency and agility in contemporary IT systems, this study investigates the integration of DevOps methods with cloud management. It offers a thorough rundown of the main DevOps tools and technologies needed to manage cloud infrastructure, including as monitoring systems, CI/CD pipelines, Infrastructure as Code (IaC) tools, and configuration management systems. The inability to allow concurrent project development and deployment on the same operational infrastructure (such as a cluster of Docker containers) is a practical shortcoming of current DevOps systems. In order to fill the gaps in the current Development and Operations (DevOps) methods, this paper offers a thorough study and explores how such integrations in Amazon Web Services might enhance deployment efficiency, dependability in software and infrastructure delivery, and security. Thus, the goal of this research is to use the AWS platform to automate the processes of developing and maintaining IT infrastructure. Therefore, we provide a mathematical model in this research to ascertain the ideal arrangement for IT infrastructure. This study investigates in detail how Kubernetes clusters in the AWS environment may be efficiently automated, scaled, and managed using Terraform, an Infrastructure as Code (IaC) tool. It thoroughly examines the advantages of using Terraform, highlighting how it may enhance productivity, automation, scalability, and security while managing Kubernetes clusters. To demonstrate Terraform's capabilities in infrastructure management, the paper contrasts it with other popular (IaC) tools and techniques. It also explores how Terraform works with AWS services to streamline procedures and cut down on complexity. Trends and possible developments in combining Kubernetes and Terraform to improve the administration of cloud-native apps are also covered in the paper."
"Decentralizing Infrastructure as Code","https://scispace.com/papers/decentralizing-infrastructure-as-code-2jtei9im","2023","Journal Article","IEEE Software","","10.1109/ms.2022.3192968","","No","Infrastructure as code (IaC) automates deployments for single teams, falling short of decentralized deployments across groups. We need mature IaC solutions that embrace and consolidate software engineering principles to enable testing and automation advances for decentralized organizations."
"DevOps Dynamics: Tools Driving Continuous Integration and Deployment","https://scispace.com/papers/devops-dynamics-tools-driving-continuous-integration-and-2rfvkhom7fuj","2024","Proceedings Article","","Pradeep Gopal Gowda
Norton Stanley S A
Josephine Eskaline Joyce","10.1109/iciteics61368.2024.10624986","","No","In the ever-evolving landscape of software development, the integration of development and operations (DevOps) practices has become instrumental for achieving agility, collaboration, and rapid delivery. This paper provides an in-depth analysis and review of various DevOps tools that facilitate continuous integration, deployment, and collaboration within software development teams. The study explores the features, strengths, and limitations of prominent tools in the DevOps landscape. This paper delves into the dynamic realm of DevOps, with a specific focus on the tools that steer continuous integration and deployment (CI/CD) processes. Through an extensive examination of key DevOps tools, their functionalities, and real-world applications, this research aims to provide a comprehensive understanding of how these tools contribute to the seamless integration of code changes, automated testing, and continuous delivery. By exploring the nuances of popular DevOps tools, the paper aims to empower software practitioners, teams, and organizations with insights to make informed decisions about tooling choices, fostering a culture of efficiency, reliability, and innovation in the software development lifecycle."
"Terraform -- Automating Infrastructure as a Service","https://scispace.com/papers/terraform-automating-infrastructure-as-a-service-2koqcrxz","2022","Posted Content","","Andre Lukas","10.48550/arxiv.2205.10676","https://scispace.com/pdf/terraform-automating-infrastructure-as-a-service-2koqcrxz.pdf","Yes","Developing a software service requires a strict software development life cycle and process. This process demands controlling all application code through source control management as well as a rigorous versioning and branching strategy. However, the platform and infrastructure also benefit from this rigor. Software services must be deployed to a target run time environment and provisioning that environment through manual user actions is tedious and error-prone. Provisioning manually also becomes prohibitive as the number of resources grow and spread globally over multiple regions. The answer is to apply the same rigor to provisioning the infrastructure as applied to developing the application software. Terraform provides a platform allowing infrastructure resources to be defined in code. This code not only allows the automation of the infrastructure provisioning but also allows for a strict development and review life cycle, same as the application software."
"Enhancing Devops Infrastructure For Efficient Management Of Microservice Applications","https://scispace.com/papers/enhancing-devops-infrastructure-for-efficient-management-of-2w2ey0d4q2","2023","Proceedings Article","","E.M.I.M Ekanayaka
J.K.K.H Thathsarani
D.S Karunanayaka
N. Kuruwitaarachchi
N. Skandakumar","10.1109/icebe59045.2023.00035","","No","Deploying and managing microservice applications present significant challenges in the software development process. Existing DevOps infrastructures often lack automation and monitoring capabilities, resulting in time-consuming and error-prone deployments. To address these issues, we propose KubFlow, an All-in-One DevOps infrastructure that enhances microservice management. KubFlow integrates leading DevOps technologies such as Jira, GIT, Jenkins, ArgoCD, Terraform, Docker, Kubernetes, Grafana, and Prometheus. Through automation, containerization, and orchestration, KubFlow streamlines the deployment process for faster and more reliable application delivery. It leverages containers to enhance scalability, resource efficiency, and high availability. The architecture includes a Kubernetes cluster deployment using Terraform, an Ingress controller for external access, Jenkins for continuous integration and delivery, ArgoCD for automated deployments, and Prometheus and Grafana for monitoring and visualization. Implemented successfully, KubFlow simplifies microservice deployment and improves monitoring capabilities. By reducing errors, time, and costs associated with complex deployments, KubFlow allows developers to focus on application development while ensuring efficient and reliable software delivery."
"Infrastructure as Code als Maßnahme zur Cloud Automatisierung – Hilfestellung zur Auswahl des richtigen Werkzeugs","https://scispace.com/papers/infrastructure-as-code-als-masnahme-zur-cloud-ive8j7vjpw","2020","Journal Article","Praxis Der Wirtschaftsinformatik","Abdullah Özel
Tobias Pautz
Nikolaus Schmidt","10.1365/S40702-020-00657-0","https://scispace.com/pdf/infrastructure-as-code-als-masnahme-zur-cloud-ive8j7vjpw.pdf","Yes","Es stehen mittlerweile mehrere IaC-Tools zur Verfugung, um die Bereitstellung und Konfiguration der Cloud-Infrastruktur zu automatisieren. Mit der Fulle an Auswahlmoglichkeiten gestaltet sich der Auswahlprozess fur das geeignete IaC-Tool zunehmend schwieriger. Zusatzlich mangelt es an einer Entscheidungshilfe fur den Auswahlprozess des geeigneten IaC-Tools. Wir glauben, dass eine Entscheidungshilfe fur den Auswahlprozess des IaC-Tools dazu beitragen kann, bei der Cloud Migration von Anwendungen einen besseren Service zu bieten. Daher zielt diese Forschungsarbeit darauf ab, den Auswahlprozess zu unterstutzen, indem eine Hilfestellung bei der Auswahl des richtigen IaC-Tools gegeben wird."
"Automating CI/CD Pipelines Using Terraform and GitLab: Best Practices for Scalability and Efficiency","https://scispace.com/papers/automating-ci-cd-pipelines-using-terraform-and-gitlab-best-inhohvuculro","2025","Journal Article","Deleted Journal","Naga Murali Krishna Koneru","10.55640/ijefms/volume10issue04-03","","No","Modern software development uses CI/CD pipelines to speed up software systems' delivery timelines. Most technical teams face pipeline system expansion as a critical engineering hurdle. The paper presents a detailed framework for the automation of CI/CD pipelines, which combines Terraform and GitLab specifically to achieve maximum scalability and efficiency. Organizations can create affordable and secure cloud infrastructure deployment management through a GitLab CI/CD platform integrated with Infrastructure as Code (IaC) frameworks. This allows them to manage infrastructure deployment simultaneously with application deployments while ensuring repeatability. Application and process efficiency and automated infrastructure deployment stem from the connection between IaC technology and GitLab CI/CD tools. The document shows deployment processes by demonstrating actual code, which helps organizations gain competence in tool usage. During the actual implementation of the framework, deployment speed increased by 55%, as the framework reduced infrastructure costs by 25% and improved deployment reliability to 70%. Terraform and GitLab work together to transform DevOps operational frameworks based on the provided results. Implementing such a framework enables organizations to optimize their DevOps workflows, lowering manual tasks while expanding their CI/CD pipeline capabilities. The paper presents essential best practices and integration methods that provide essential knowledge about present-day software development requirements for automated deployments."
"A Conceptual Model for Secure DevOps Architecture Using Jenkins, Terraform, and Kubernetes","https://scispace.com/papers/a-conceptual-model-for-secure-devops-architecture-using-02omcpfe93s8","2023","Journal Article","International Journal of Multidisciplinary Research and Growth Evaluation","Adewale O Adebayo
Afeez A Afuwape
Ayorinde Olayiwola Akindemowo
Eseoghene Daniel Erigha
Ehimah Obuse
Joshua Oluwagbenga Ajayi
Olabode Michael Soneye","10.54660/.ijmrge.2023.4.1.1300-1317","","No","In the evolving landscape of software development, the integration of security into the DevOps lifecycle—often termed DevSecOps—has become a critical imperative. This paper proposes a conceptual model for a secure DevOps architecture that leverages Jenkins, Terraform, and Kubernetes to ensure continuous integration, continuous delivery, infrastructure as code (IaC), and container orchestration, all underpinned by robust security principles. Jenkins facilitates automated building, testing, and deployment pipelines, while Terraform enables secure infrastructure provisioning through immutable, version-controlled configurations. Kubernetes orchestrates containerized applications, providing dynamic scaling, automated failover, and efficient resource utilization. Together, these tools offer a powerful synergy that can automate development workflows while embedding security measures throughout the software delivery process. The proposed model introduces a security-first approach across the development lifecycle, encompassing code validation, vulnerability scanning, secrets management, policy enforcement, and runtime security. Jenkins pipelines integrate security scanners at multiple stages to detect vulnerabilities early. Terraform configurations are audited for compliance using tools such as Checkov and Terraform Compliance, ensuring secure infrastructure deployment. Kubernetes clusters are fortified with role-based access control (RBAC), network policies, admission controllers, and runtime threat detection solutions like Falco. This conceptual model emphasizes automation, scalability, and proactive threat mitigation, minimizing human error and enabling organizations to achieve secure, rapid software delivery. Additionally, it addresses challenges such as secrets management, with integrations like Vault and Sealed Secrets, and policy enforcement through tools like OPA-Gatekeeper. The model also recommends continuous monitoring and feedback loops to detect anomalies and enforce corrective actions in near real-time. By adopting this secure DevOps architecture, organizations can bridge the gap between agility and security, meeting modern demands for rapid innovation without compromising system integrity. This work contributes to the growing body of DevSecOps knowledge by providing a comprehensive framework that operationalizes security from infrastructure provisioning to application deployment. Future extensions of the model could explore the integration of AI-driven security analytics and self-healing capabilities to further enhance resilience."
"Automatic deployment method for application cluster architecture based on Terraform and Ansible","https://scispace.com/papers/automatic-deployment-method-for-application-cluster-1qejsduw27","2019","Patent","","Zhao Jianchang
Zhao Shan
Wang Yang
Yang Chao
Li Ying","","","No","The invention provides an automatic deployment method for an application cluster architecture based on Terraform and Ansible. The invention belongs to the technical field of architecture deployment, and discloses an architecture deployment method and a system, which can realize the functions of automatic deployment of infrastructure architecture and application architecture and version managementof the architecture by packaging Terraform and Ansible. A user stores the infrastructure architecture and application architecture deployment scheme in a code form and manages the infrastructure architecture and application architecture deployment scheme through a version warehouse; when the environment is deployed again, the environment can be directly built in a code form, manual deployment is not needed any more, and the error probability is reduced; multi-thread operation is supported, a plurality of cluster architectures can be deployed at the same time, and rapidness and convenience areachieved; transverse expansion is supported, nodes have no interdependence relationship, and the deployment efficiency is greatly improved."
"Enhancing DevOps Efficiency: Best Practices for Cloud Infrastructure Management","https://scispace.com/papers/enhancing-devops-efficiency-best-practices-for-cloud-mxwdvm2k20vm","2025","Journal Article","","Anthony Carignan
Olanite Enoch","10.20944/preprints202503.1143.v1","","No","In the fast-evolving world of software development, DevOps efficiency plays a critical role in ensuring rapid deployments, scalability, and system reliability. This study explores best practices for cloud infrastructure management to optimize DevOps workflows, enhance deployment speed, improve resource utilization, and strengthen security. Key strategies discussed include Infrastructure as Code (IaC), automated CI/CD pipelines, containerization, multi-cloud strategies, and AI-driven cloud monitoring. The findings indicate that implementing these cloud-native best practices leads to faster time-to-market, reduced operational costs, and improved system resilience. Additionally, the study highlights the importance of security automation, proactive cost optimization, and strategic multi-cloud adoption to ensure long-term DevOps success. By adopting these approaches, organizations can streamline cloud management, enhance collaboration between development and operations teams, and drive continuous innovation."
"CloudCAMP: Automating Cloud Services Deployment and Management","https://scispace.com/papers/cloudcamp-automating-cloud-services-deployment-and-3s78gzbxla","2019","Posted Content","arXiv: Software Engineering","Anirban Bhattacharjee
Yogesh Barve
Aniruddha Gokhale
Takayuki Kuroda","","https://arxiv.org/pdf/1904.02184","Yes","Users of cloud platforms often must expend significant manual efforts in the deployment and orchestration of their services on cloud platforms due primarily to having to deal with the high variabilities in the configuration options for virtualized environment setup and meeting the software dependencies for each service. Despite the emergence of many DevOps cloud automation and orchestration tools, users must still rely on specifying low-level scripting details for service deployment and management using Infrastructure-as-Code (IAC). Using these tools required domain expertise along with a steep learning curve. To address these challenges in a tool-and-technology agnostic manner, which helps promote interoperability and portability of services hosted across cloud platforms, we present initial ideas on a GUI based cloud automation and orchestration framework called CloudCAMP. It incorporates domain-specific modeling so that the specifications and dependencies imposed by the cloud platform and application architecture can be specified at an intuitive, higher level of abstraction without the need for domain expertise using Model-Driven Engineering(MDE) paradigm. CloudCAMP transforms the partial specifications into deployable Infrastructure-as-Code (IAC) using the Transformational-Generative paradigm and by leveraging an extensible and reusable knowledge base. The auto-generated IAC can be handled by existing tools to provision the services components automatically. We validate our approach quantitatively by showing a comparative study of savings in manual and scripting efforts versus using CloudCAMP."
"An Advanced DevOps Environment for Microservice-based Applications","https://scispace.com/papers/an-advanced-devops-environment-for-microservice-based-4gswsssohr","2021","Proceedings Article","Service Oriented Software Engineering","Stefan Throner
Heiko Hutter
Niklas Sanger
Michael Schneider
Simon Hanselmann
Patrick Petrovic
Sebastian Abeck","10.1109/SOSE52839.2021.00020","","No","Complex applications consisting of many interdependent microservices require an advanced environment that allows their efficient Development and Operations (DevOps). One of the central components of a DevOps environment is a pipeline concept that supports the Continuous Integration/ Continuous Deployment (CI/CD) of single microservices, usually in the form of a container-virtualized cloud infrastructure based on advanced technologies such as Docker, Kubernetes, or Helm. Although there are available concepts and technologies to implement these concepts, it remains unclear how to combine the concepts and technologies into an advanced DevOps environment which specifically supports the different roles involved in the process. This paper describes the DevOps environment set up to develop microservice-based applications and focuses on the following aspects: (i) a flexible CI/CD pipeline based on reusable templates, (ii) support for developers to use the DevOps environment efficiently, and (iii) the security of the environment against attacks."
"(WIP) CloudCAMP: Automating the Deployment and Management of Cloud Services","https://scispace.com/papers/wip-cloudcamp-automating-the-deployment-and-management-of-4nar4e7xw8","2018","Proceedings Article","IEEE International Conference on Services Computing","Anirban Bhattacharjee
Yogesh Barve
Aniruddha Gokhale
Takayuki Kuroda","10.1109/SCC.2018.00038","","No","Users of cloud platforms often must expend significant manual efforts in the deployment and orchestration of their services on cloud platforms due primarily to having to deal with the high variabilities in the configuration options for virtualized environment setup and meeting the software dependencies for each service Despite the emergence of many DevOps cloud automation and orchestration tools, users must still rely on specifying low-level scripting details for service deployment and management Using these tools required domain expertise along with a steep learning curve To address these challenges in a tool-and-technology agnostic manner, which helps promote interoperability and portability of services hosted across cloud platforms, we present initial ideas on a GUI based cloud automation and orchestration framework called CloudCAMP CloudCAMP uses model-driven engineering techniques to provide users with intuitive and higher-level modeling abstractions that preclude the need to specify all the low-level details CloudCAMP's generative capabilities leverage a built-in knowledge-base to automate the synthesis of Infrastructure-as-Code (IAC) solution that subsequently can be used to deploy and orchestrate services in the cloud Preliminary results from a small user study are presented in the paper"
"Enhancing cloud application devops using dynamically tailored deployment engines","https://scispace.com/papers/enhancing-cloud-application-devops-using-dynamically-1adwfpmqdl","2016","Journal Article","IEEE International Conference on Cloud Computing Technology and Science","Johannes Wettinger
Uwe Breitenbücher
Frank Leymann","10.29268/STCC.2016.0002","http://www.hipore.com/stcc/2016/IJCC-Vol4-No1-2016b.pdf","Yes","Shortening software release cycles increasingly becomes a critical competitive advantage as today’s users, customers, and other stakeholders expect quick responses to occurring issues and feature requests. DevOps practices and Cloud computing are two key paradigms to tackle these issues by enabling rapid and continuous delivery of applications, utilizing automated software delivery pipelines. However, it is a complex and sophisticated challenge to implement such pipelines by installing, configuring, orchestrating, and integrating the required deployment automation solutions. Therefore, we present a method in conjunction with a framework and implementation to dynamically generate tailored deployment automation engines for specific application stacks, which are packaged in a portable manner to run them on various platforms and infrastructures. The core of our work is based on generating APIs for arbitrary deployment executables such as scripts and plans that perform different tasks in the automated deployment process. As a result, deployment tasks can be triggered through generated API endpoints, abstracting from lower-level, technical details of diverse deployment automation tooling. Beside a quantitative evaluation, we discuss two case studies in this context, one focusing on microservice architectures, the other one considering application functionality and its relation to deployment functionality."
"Enabling DevOps Collaboration and Continuous Delivery Using Diverse Application Environments","https://scispace.com/papers/enabling-devops-collaboration-and-continuous-delivery-using-18e9wb6f2d","2015","Book Chapter","","Johannes Wettinger
Vasilios Andrikopoulos
Frank Leymann","10.1007/978-3-319-26148-5_23","","No","Aiming to provide the means for efficient collaboration between development and operations personnel, the DevOps paradigm is backed by an increasingly growing collection of tools and reusable artifacts for application management. Continuous delivery pipelines are established based on these building blocks by implementing fully automated, end-to-end application delivery processes, which significantly shorten release cycles to reduce risks and costs as well as gaining a critical competitive advantage. Diverse application environments need to be managed along the pipeline such as development, build, test, and production environments. In this work we address the need for systematically specifying and maintaining diverse application environment topologies enriched with environment-specific requirements in order to implement continuous delivery pipelines. Beside the representation of such requirements, we focus on their systematic and collaborative resolution with respect to the individual needs of the involved application environments."
"Comparative Analysis of GitOps Tools and Frameworks","https://scispace.com/papers/comparative-analysis-of-gitops-tools-and-frameworks-ir3b99c32f4g","2025","Journal Article","Traektoriâ Nauki","Abiola Samuel Ajayi
Oriyomi Badmus
Godwin Okechukwu Iheuwa
Lucky Ehizojie
Shokenu Emmanuel Segun","10.22178/pos.117-9","","No","This paper presents an in-depth assessment of four notable GitOps tools: Argo CD, Flux, Jenkins X, and Weaveworks. GitOps is a methodology used for the uninterrupted delivery of cloud-native applications, facilitating the seamless encapsulation of infrastructure as code. The study presents these assessments based on key effectiveness indices, including performance, scalability, integration, usability, and security. It contains benchmark tests to demonstrate the applicability of each tool in various multi-cloud and hybrid-cloud scenarios, as well as other realistic settings.Furthermore, the paper examines the security aspect of these tools and their relevance as one of the components of DevSecOps. The book also presents case studies that show how organisations have used these tools, highlighting both the benefits and drawbacks of their application. The result presents a matrix for decision-making for organisations that wish to implement the GitOps mode of operation within their DevOps workflows in both small and large organisational contexts. This section examines the prospects of GitOps and explains its necessity in the context of emerging developments in cloud-native development, with special emphasis on scalability and security issues."
"Особливості автоматичного розгортання інфраструктури як коду для хмарних сервісів","https://scispace.com/papers/osoblivosti-avtomatichnogo-rozgortannia-infrastrukturi-iak-4p5tw4u2hu","2024","Journal Article","Sistemi upravlìnnâ, navìgacìï ta zvʼâzku","Oleg Koptsev
Vitalii Martovytskyi
Nataliia Bolohova
Ilko Fedak","10.26906/sunz.2024.1.104","https://scispace.com/pdf/osoblivosti-avtomatichnogo-rozgortannia-infrastrukturi-iak-4p5tw4u2hu.pdf","No","Хмарні сервіси надають сучасні обчислювальні ресурси, доступні на вимогу через Інтернет. Завдяки хмарним обчисленням команди стають більш ефективними та скорочують час виходу на ринок, оскільки вони можуть швидко набувати та масштабувати послуги без значних зусиль, які потребує управління традиційною інфраструктурою. Автоматизація дозволяє командам покращувати ключові показники. Команди відмовляються від тривалих процесів, пов'язаних із внесенням змін та запланованими розгортаннями. Вони також переходять від реактивного виявлення проблем до запобіжного моніторингу та забезпечення прозорості. Мета статті – дослідити популярні засоби для реалізації інфраструктури як коду, що включають Terraform, AWS CloudFormation, ARM Templates, Ansible, Puppet, Chef та інші. Ці інструменти допомагають створювати, керувати та відстежувати інфраструктурні ресурси через програмний код. Використання автоматизованих практик IaC дозволить зберегти час, зменшити ризики, підвищити сумісність та спростити процеси розгортання та управління інфраструктурою. Розглянувши популярні засоби для реалізації інфраструктури як коду, що допомагають створювати, керувати та відстежувати інфраструктурні ресурси через програмний код, ми дійшли висновку, що Bicep дозволяє більш ефективно та зрозуміло працювати з розгортанням інфраструктури в Azure, а також полегшує роботу з ARM Templates. Використання Bicep, у порівнянні з ARM шаблонами та іншими інструментами IaC, дає можливість створювати скрипти, які є значно компактнішими за розміром. Це досягається завдяки більш лаконічному та зрозумілому синтаксису Bicep, що дозволяє описувати однакові набори ресурсів меншою кількістю коду. Такий підхід не тільки спрощує розробку та підтримку інфраструктурного коду, але й знижує поріг входження для нових користувачів, які мають досвід роботи з програмуванням."
"Integrasi Infrastructure as Code dengan Continuous Integration/Continuous Deployment di Google Cloud Platform","https://scispace.com/papers/integrasi-infrastructure-as-code-dengan-continuous-4z8nueg6uyav","2024","Journal Article","Jurnal Fasilkom","Deden Setyawan Wayan
Piarsa I Nyoman
Putu Wira Buana","10.37859/jf.v14i2.7236","","No","Integrasi IaC (Infrastructure as Code) dengan CI/CD (Continuous Integration/Continuous Deployment) membantu dalam menghasilkan perangkat lunak yang memiliki kualitas dan produktivitas yang tinggi. Pengujian yang dilakukan berupa perbandingan deployment infrastruktur secara manual dan otomatis dan menilai efektivitas dan efisiensi cara deployment. Pengujian untuk memastikan infrastruktur yang dibuat sudah berjalan dengan baik yaitu melakukan deployment aplikasi sederhana. Penelitian dimulai dari membuat desain infrastruktur, konfigurasi IaC Terraform, pembuatan script CI/CD, deployment infrastruktur dengan cara manual dan otomatis, konfigurasi aplikasi beserta CI/CD, dan deployment aplikasi. Rata-rata waktu yang dibutuhkan cara manual yaitu selama 13 menit 34 detik, sedangkan rata-rata waktu yang dibutuhkan cara otomatis yaitu selama 14 menit 5 detik. Nilai efektivitas yang diperoleh menunjukkan kedua cara tersebut berhasil dalam melakukan deployment infrastruktur, sedangkan untuk nilai efisiensinya, cara manual dan otomatis sama-sama memiliki kelebihan dan kekurangannya masing-masing. Aplikasi Go – Gin yang di deploy membutuhkan rata-rata waktu selama 3 menit 7 detik, sedangkan aplikasi PHP – Laravel membutuhkan rata-rata waktu selama 3 menit 8 detik. Aplikasi yang di deploy pada infrastruktur yang sama menunjukkan perbedaan waktu yang tidak jauh berbeda dan perbedaan konfigurasi aplikasi yang diperoleh yaitu pada Dockerfile dan file kubernetes object yang digunakan"
"Infraestrutura como Código: A prova de conceito para o melhor resultado em uma pipeline de desenvolvimento de software","https://scispace.com/papers/infraestrutura-como-codigo-a-prova-de-conceito-para-o-melhor-alepk6nqvr","2024","Journal Article","","Denis B. Citadin
Arthur Francisco Lorenzon","10.5753/eradrs.2024.238663","","No","O objetivo deste trabalho é analisar as ferramentas de infraestrutura como código, apresentando suas funcionalidades e comparando-as entre si. Não somente, como também, trazer novas perspectivas através de um olhar crítico, definições e práticas que possam contribuir com implantações de softwares mais atraentes, ágeis, simples e robustas."
"An Overview of Infrastructure as Code (IaC) with Performance and Availability Assessment on Google Cloud Platform","https://scispace.com/papers/an-overview-of-infrastructure-as-code-iac-with-performance-4cr8c0q39i","2024","Book Chapter","","Hongyu Wang
Brian Kishiyama
Dolores Romero López
Jeong Yang","10.1007/978-3-031-56950-0_41","","No","This paper presents the results of an exploratory study on the performance and availability of two prominent Infrastructure as Code (IaC) tools - Google Cloud Deployment Manager and Terraform. The Deployment Manager is native to Google Cloud Services while Terraform is not. The study assesses the deployment and management of cloud resources by using these tools, and examines their integration benefits, flexibility, and multi-cloud capabilities. It highlights Terraform's consistently faster resource destruction times compared to Google Cloud Deployment Manager, as evidenced by tests using the Linux 'time' command, providing insights into their operational efficiency and adaptability in cloud environments. Our findings indicate that the native Google Cloud Deployment Manager better integrates with its resources. In contrast, Terraform is versatile, provides better flexibility and deploys faster. Its independence is more useful in working with various cloud environments – and is not limited to GCP. Additionally, to gain insight, this study discusses the benefits and inherent challenges associated with IaC. This paper underlines the significance of technical expertise in effectively leveraging these tools for cloud infrastructure management."
"Herramientas De Infraestructura Como Código: Ansible, Terrafom, Chef, Puppet","https://scispace.com/papers/herramientas-de-infraestructura-como-codigo-ansible-terrafom-4tz3brccx2sy","","","","Luis Dominguez-Quintero
Miguel Vargas-Lombardo","10.33412/idt.v17.2.3143","","No","Las herramientas de Infraestructura como código (IaC) permiten automatizar las tareas realizadas por los departamentos de IT de forma rápida y dinámica mediante el uso de lenguajes de programación de scripts, que permiten administrar, crear, manipular y distribuir múltiples recursos informáticos a gran escala dentro de una infraestructura de Cloud Computing. Las herramientas de Infraestructura como código Ansible, Terrafom, Chef, Puppet generan una representación virtual de toda la infraestructura física y escalable de una plataforma Cloud Computing y de Centro de Datos, facilitando que esta sea programable y dinámica."
"Deploying Hadoop Architecture Using Ansible and Terraform","https://scispace.com/papers/deploying-hadoop-architecture-using-ansible-and-terraform-bfp4tx9tn5lt","","","","Manu Gupta
Mandepudi Nobel Chowdary
Sankeerth Bussa
Chennupati Kumar Chowdary","10.1109/iscon52037.2021.9702299","","No","Management of excessive data in the Big Data world is difficult. Software frameworks and clusters help in the management of the data. Although the setting up of the cluster consumes greater time and effort to implement for the distributed data storage and processing. This problem can be automated with the usage of various Development Operation tools. Terraform is a powerful tool for Provisioning and Ansible is used for Configuration management and Application deployment tool. The proposed work is about using this tool to completely automate the process of setting up the Hadoop cluster with no human intervention. Ansible provides Infrastructure as a Code. There are many pre-created modules available in Ansible to make our task simpler and easier. The main feature of these modules is that they are idempotent. Making efficient use of these modules in building the code is foundation of this work. Ansible is preferred over the other tools because it is agentless and it uses SSH protocol to connect to Linux systems and Win RM protocol to connect to Windows systems. The entire architecture can be deployed with in no time using the automation of the Ansible and Terraform over the cloud servers."
"Comparison of Automation Deployment Implementation on Google Cloud Virtual Machine Using Deployment Manager and Terraform","https://scispace.com/papers/comparison-of-automation-deployment-implementation-on-google-77pbfbz8ogr3","2025","Journal Article","Jurnal teknologi informasi dan pendidikan","Naila Ardelia
Lindawati Lindawati
Nurhajar Anugraha","10.24036/jtip.v17i2.869","","No","Software development has significantly transformed in recent years, with organizations increasingly turning to cloud computing infrastructure to speed up and ease the development and implementation processes. Up until now, there are few studies testing the efficiency and performance of deployment automation using Google Cloud Deployment Manager, which is essentially a built-in infrastructure deployment service provided by Google Cloud Platform. Most studies tend to prefer using open-source software such as Terraform, Ansible, and Kubernetes. This research aims to compare the implementation of deployment automation using Google Cloud Deployment Manager and Terraform. Three parameters are used to compare the results of automation deployment implementation: deployment efficiency, website performance, and cost efficiency. The test results indicate that Google Cloud Deployment Manager outperforms Terraform in all three test parameters. Specifically, Google Cloud Deployment Manager demonstrated superior deployment efficiency, enhanced website performance, and better cost efficiency. Thus, it is concluded that Google Cloud Deployment Manager is a more effective solution for deployment automation compared to Terraform."
"Extended Model of Code Orchestration and Deployment Platform","https://scispace.com/papers/extended-model-of-code-orchestration-and-deployment-platform-38iew1wp","2022","Journal Article","TEM Journal","Todor Trendafilov Ivanov
Nikola Velizariev Valchanov","10.18421/tem112-45","","Yes","This paper is focused on the process of continuous integration and respective orchestration tooling. It provides a summary on existing tooling with feature analysis and applications. The research explores techniques, processes, and solutions for code orchestration. It includes a comparison of the modern platforms and discusses the topic of extendibility of such products by presenting an architectural model that supports the integration of general-purpose extensions."
"From Theory to Practice: The Challenges of a DevOps Infrastructure as Code Implementation","https://scispace.com/papers/from-theory-to-practice-the-challenges-of-a-devops-1nqh1rt830","2018","Proceedings Article","International Conference on Software and Data Technologies","Clauirton Siebra
Rosberg Lacerda
Italo Cerqueira
Jonysberg P. Quintino
Fabiana Florentin
Fabio Q. B. da Silva
André L. Santos","10.5220/0006826104270436","","No","DevOps is a recent approach that intends to improve the collaboration between development and IT operations teams, in order to establish a continuous and efficient deployment process. Previous studies show that DevOps is based on dimensions, such as culture of collaboration, automation and monitoring. However, few studies discuss the current frameworks that support such dimensions, so that there is a lack in information that could assist development teams in deciding for the most adequate framework according to their needs. This work aims at presenting a practical DevOps implementation and analysing how the process of software delivery and infrastructure changes was automated. Our approach follows the principles of infrastructure as code, where a configuration platform – PowerShell DSC – was used to automatically define reliable environments for continuous software delivery. Then, we compare this approach with other alternative such as Chef and Puppet tools, stressing the features, advantages and challenges of each strategy. The lessons learned from this work are then used to create a more concrete set of practices that could assist the transition from traditional approaches to an automation process of continuous software delivery."
"Automation Deployment in Azure Cloud with a Modular Terraform Approach","https://scispace.com/papers/automation-deployment-in-azure-cloud-with-a-modular-5ale1ygjrrhl","2024","Journal Article","","Vladislav Manolov
Daniela Gotseva
Невен Николов","10.1109/telecom63374.2024.10812297","","No","Resource deployment in the cloud environment can be automated using infrastructure-as-code tools. By leveraging their capabilities, provisioning and managing cloud resources can be streamlined, ensuring consistency, repeatability and efficiency. The study demonstrates how automation tools facilitate the management of complex cloud infrastructures in a way that can be directly applied in a real environment. The findings highlight the benefits of a modular approach for automation in cloud operations, including reduced deployment times and improved scalability."
"Automate System Deployments with Terraform","https://scispace.com/papers/automate-system-deployments-with-terraform-1c0lzoyh","2022","Book Chapter","","John S. Tonello","10.1007/978-1-4842-8318-9_11","","No","As you dive deeper into DevOps workflows, you’ll find your Git skills come in handy when you really start automating your system and application deployments with infrastructure as code. Rather than manually deploying systems or making image templates (or cloning snapshots), you can describe what you want in a few code files and have fresh systems up and running in moments. The idea is to define once and deploy repeatedly anywhere."
"Implementação de infraestrutura como código para provisionamento e deploy de aplicações","https://scispace.com/papers/implementacao-de-infraestrutura-como-codigo-para-bcp11otcrm","2020","Journal Article","","Jones Luis Noll
Fabrício Pretto","10.22410/ISSN.2176-3070.V12I4A2020.2760","https://www.univates.br/bdu/bitstream/10737/2888/6/2020JonesNoll.pdf","Yes","A evolucao tecnologica dos ultimos anos trouxe uma necessidade crescente por softwares, devendo estes, estarem sempre disponiveis, acessiveis e atualizados para seus usuarios. Para atender as demandas dos sistemas de informacao, a infraestrutura passou a ser construida atraves de codigo, tornando-se assim, dinâmica e escalavel. Ao utilizar os conceitos de DevOps e Infraestrutura como Codigo, este trabalho teve como objetivo a criacao automatizada de toda a infraestrutura necessaria para execucao do ciclo de desenvolvimento de um software, desde o registro da mudanca ate sua entrega. Foram realizadas a criacao e a configuracao das maquinas virtuais e conteineres necessarios, a orquestracao dos mesmos em um cluster Kubernetes, finalizando com o deploy da aplicacao e do banco de dados. Como resultado, apos a execucao de todos os processos, um sistema de informacao encontrou-se em execucao na estrutura e disponivel aos usuarios. Foram analisados os tempos necessarios para a criacao automatizada da estrutura e os beneficios na adocao da Infraestrutura como Codigo."
"Ansible for Enterprise","https://scispace.com/papers/ansible-for-enterprise-19zos3t4","2023","Book Chapter","","Hannes Gohli","10.1007/978-1-4842-9285-3_8","","No","One of the main benefits of Ansible is that it standardizes infrastructure automation among different technologies and programming styles (Perl, bash, Puppet, Chef, and so on). It is the Swiss Army Knife tool of modern operations engineers and can easily be used in Infrastructure as Code (IaC), Configuration as a Code (CaC), Policy as a Code, Code pipelines, orchestration (K8s), and event-driven automation."
"Multicloud Orchestration using Terraform","https://scispace.com/papers/multicloud-orchestration-using-terraform-2j87qkot","2022","Journal Article","International Journal For Science Technology And Engineering","Btissame Es-Sabbahi , Abir Bouhamdi , Rajae Amiali , Mounia Serraj , Mohammed Elbiaze , Mohammed …","10.22214/ijraset.2022.44760","https://scispace.com/pdf/multicloud-orchestration-using-terraform-2j87qkot.pdf","Yes","Abstract: In the past ten years, innovations in the field of cloud computational infrastructure have made a major impact and became an essential part of every organization. Most of the cloud service providers are improvising their service and they are making the user experience better. Even though the providers have provided many services, they are facing the situations like vendor lock-in, unreliability, lower performance and increased costs. A new methodology has been introduced to help overcome these problems being faced. Multi-cloud technology provides the utility of using various cloud functionalities provided by different cloud vendors that gives organizations a great number of options to optimize performance, reduced financial overhead and chose the best cloud technologies available without creating any platform complexities. There are different tools available that are used for cloud provisioning, orchestration and management like AWS CloudFormation, Ansible, Terraform, Cloudify etc. This paper summarizes the analysis of the evolution of multi-cloud strategy and also shows the role of terraform in cloud orchestration with a small comparison with one of the other cloud orchestration tools"
"Hands-on Infrastructure as Code with Hashicorp Terraform","https://scispace.com/papers/hands-on-infrastructure-as-code-with-hashicorp-terraform-4xm5u5tc","2022","Book Chapter","","","10.1007/978-1-4842-8689-0_6","","No","Cloud-native systems are characterized by increased speed and agility because of the utilization of microservices, containers, and a contemporary system design. They automate the build and release stages so that they can guarantee the quality and integrity of the code. Cloud technologies allow for quick and scalable deployment by layering abstractions on top of complex infrastructure services like Amazon Elastic Compute Cloud (EC2), Amazon Simple Storage Service (S3), and Kubernetes. With Terraform’s user-friendly interface, automating the rollout of these services is a breeze. But there is more to the story than meets the eye. You will now understand how the virtual cloud environments with these technologies are deployed and provisioned."
"Infrastructure as a Code (IaC) to Software Defined Infrastructure using Azure Resource Manager (ARM)","https://scispace.com/papers/infrastructure-as-a-code-iac-to-software-defined-3cihseq8ur","2020","Proceedings Article","","Jagdish Chandra Patni
Souradeep Banerjee
Devyanshi Tiwari","10.1109/COMPE49325.2020.9200030","","No","As the scale of cloud infrastructure is augmenting, so is the number of instances that needs to be provisioned. As a result, there is a requirement for automating the process of managing infrastructure instances to facilitate development, staging, and production environments. The purpose of this paper is to understand ‘Infrastructure as a code’ (IaC) in relation to Software Defined Infrastructure. Using Azure Resource Manager (ARM) Templates we will demonstrate the benefit and importance of IaC by deploying a web application on Microsoft Azure using only code. The use of ARM templates was found to increase the agility of the deployment and management process. We will also demonstrate IaC using Terraform and Pulumi. The paper also discusses the correlation of IaC with the concept of code reusability and repeatability."
"Cloud Infrastructure Automation Tools: A Review","https://scispace.com/papers/cloud-infrastructure-automation-tools-a-review-59dubq9j2u","2021","Journal Article","Journal of the University of Shanghai for Science and Technology","Nishchal Shetty
H K Krishnappa","10.51201/JUSST/21/05397","","No","Many businesses have moved their services to the cloud throughout the years. One of the main reasons for this is its less expensive infrastructure and scalability. The necessity for infrastructure automation develops as a result of the increased usage of the cloud. There are multiple cloud automation tools available but there is no single tool suitable for every situation. This paper summarizes the various features offered by the different types of cloud automation tools."
"Подход Infrastructure as a Code как один из ведущих способов автоматизации развертывания облачной инфраструктуры","https://scispace.com/papers/podkhod-infrastructure-as-a-code-kak-odin-iz-vedushchikh-30oosw1z","","Journal Article","","И. В. Аксенов","10.18411/trnio-05-2023-643","","No","В статье представлен один из способов автоматизации развертывания и поддержки облачной инфраструктуры – «Инфраструктура как код». Рассматриваются преимущества и проблемы данного подхода, инструменты, с помощью которых он может быть внедрен в организациях. Также приведен пример построения инфраструктуры с помощью инструмента Terraform в облаке Yandex Cloud."
"Analysis and development of a platform for automated services deployment and management","https://scispace.com/papers/analysis-and-development-of-a-platform-for-automated-hlbptk4upop1","2025","Journal Article","Komp'ûternì sistemi proektuvannâ. Teorìâ ì praktika","Nazar Pleskanka
Maryana Pleskanka
Bogdan Tymoshchuk","10.23939/cds2025.01.251","","No","Software deployment automation plays a key role in improving the efficiency and reliability of workflows in the field of development and implementation of IT solutions. Existing services such as Jenkins, TeamCity have certain limitations, including insufficient flexibility in visualizing the history of changes, limited capabilities for managing configuration parameters, and difficulties in coordinating teamwork. Improving these aspects can significantly increase the productivity of development teams and accelerate the release of updates. The goal of the research is to develop a platform that integrates with Jenkins and GitHub version control systems, performs deployment launches, provides advanced tools for visualizing the history of launches and updates, provides relaunch with saved parameters, and team collaboration. The project is based on the analysis of modern CI/CD practices, infrastructure as code management, and comparative evaluation of automation platforms."
"Abstractions of Abstractions: Metadata to Infrastructure-as-Code","https://scispace.com/papers/abstractions-of-abstractions-metadata-to-infrastructure-as-20k0gemd","2022","Journal Article","","James DesLauriers
József Gábor Kovács
Tamas Kiss","10.1109/ICSA-C54293.2022.00051","","No","To support cloud newcomers and empower them with the full suite of benefits afforded by the DevOps toolkit, we propose a solution for generating infrastructure-as-code from metadata. Key-value pairs will describe the containers, volumes, configurations and virtual machines that make up a complex microservices architecture. This metadata will be first compiled down to an intermediate template based on the OASIS TOSCA Specification. There, it will be processed by a deployment and execution engine called MiCADO, which will further compile relevant sections of the template into the respective infrastructure-as-code for tools like Kubernetes, Terraform and Ansible. An implementation of the solution is currently being developed for a European project investigating Manufacturing-as-a-Service and Digital Twins, with the hopes of providing an approachable interface for users who are new to the unfamiliar environment of the cloud."
"Introduction to Infrastructure as Code","https://scispace.com/papers/introduction-to-infrastructure-as-code-g6eswk14","2022","Book Chapter","","","10.1007/978-1-4842-8689-0_1","","No","As a consequence of the incredible advancement of new technology, both large and small companies are more reliant on the digital world for survival and success in the global market. Businesses that are not online are unable to reap the many advantages of the digital world, and as a result, they are losing out on a plethora of possibilities. In today’s fast-paced and competitive corporate environment, there is an extraordinary demand for a quick development process, rapid deployment and delivery, bug fixes with little downtime, and prompt release of new features."
"Single and Multi-Cloud Disaster Recovery Management using Terraform and Ansible","https://scispace.com/papers/single-and-multi-cloud-disaster-recovery-management-using-13cntsbo3u","2020","Dissertation","","Ram Barath Thiyagarajan","","","Yes","With Disaster recovery (DR) in cloud computing, services provided by cloud providers are mostly managed by third-party disaster recovery providers. Therefore, it creates the necessity to develop an effective DR method to minimize the total cost of recovery along with the Recovery Point Objective (RPO) and Recovery Time Objective (RTO). This paper proposes an idea of DevOps -Infrastructure as a code (IaaC) disaster recovery management using Terraform and Ansible. In this study, Terraform and Ansible templates are developed to build single and Multi-Cloud Infrastructure based on Amazon Web Services (AWS) and Google Cloud Platform (GCP). Our main aim is to study the process of automated disaster recovery during an emergency, along with the total time taken to bring up the services to regular operation. The study compares the automatic concept with manual actions taken during the recovery period and shows the benefits of using IaaC."
"Recent Research Into Infrastructure as Code","https://scispace.com/papers/recent-research-into-infrastructure-as-code-nchdvpc8","2023","Journal Article","IEEE Software","Miroslaw Staron
S. Abrahão
Birgit Penzenstadler
Lorin Hochstein","10.1109/ms.2022.3212035","","No","This edition of the “Practitioner’s Digest” summarizes five recently published conference and journal pages on the topic of infrastructure-as-code."
"Deployment coordination for cross-functional DevOps teams","https://scispace.com/papers/deployment-coordination-for-cross-functional-devops-teams-3q4gz6z163","2021","Proceedings Article","Foundations of Software Engineering","Daniel Sokolowski","10.1145/3468264.3473101","","No","Software stability and reliability are the core concerns of DevOps. They are improved by tightening the collaboration between developers and operators in cross-functional teams on the one hand and by automating operations through continuous integration (CI) and infrastructure as code (IaC) on the other hand. Ideally, teams in DevOps are fully independent. Still, their applications often depend on each other in practice, requiring them to coordinate their deployment through centralization or manual coordination. With this work, we propose and implement the novel IaC solution µs ([mju:z] ”muse”), which automates deployment coordination in a decentralized fashion. µs is the first approach that is compatible with the DevOps goals as it enables truly independent operations of the DevOps teams. We define our research problem through a questionnaire survey with IT professionals and evaluate the solution by comparing it to other modern IaC approaches, assessing its performance, and applying it to existing IaC programs."
"How to Organise Your Infrastructure As Code","https://scispace.com/papers/how-to-organise-your-infrastructure-as-code-9vmc6cauzy2u","","","","Abhishek Tiwari","10.59350/6ey3f-dxa55","","No","DevOps is a cultural shift with immediate focus on maximising the business value by opting better communication, collaboration and feedback within and across IT development and operation teams. Infrastructure as Code (IaC) is a key element of DevOps philosophy with benefits for both development and operation teams. The term infrastructure as code is sometimes also referred to as programmable infrastructure."
"Streamlining Application Deployment: A CI/CD Pipeline for Kubernetes","https://scispace.com/papers/streamlining-application-deployment-a-ci-cd-pipeline-for-4in7bjyqzc41","2024","Journal Article","","Raju Shrestha
Ashok K Ray","10.1109/ic2e61754.2024.00038","","No","This paper presents the design and implementation of a Continuous Integration and Continuous Deployment (CI/CD) pipeline aimed at automating application containerization and deployment within Kubernetes clusters, using free or open-source tools and technologies. The CI part leverages Jenkins, integrating tools such as Git, SonarQube, and Docker while the CD part, managed by ArgoCD, pulls code from a Git repository and deploys the application into Kubernetes. Continuous monitoring is provided by Prometheus and Grafana, while Kubecost facilitates cost analysis to optimize resource utilization. Comprehensive load tests evaluate performance and stability under various workloads, offering a robust and scalable framework that enhances development efficiency, system reliability, and operational agility."
"A review of existing cloud automation tools","https://scispace.com/papers/a-review-of-existing-cloud-automation-tools-1qtkiqxx7g","2017","Journal Article","Asian Journal of Pharmaceutical and Clinical Research","J. Prassanna
Anjali R Pawar
Neelanarayanan","10.22159/AJPCR.2017.V10S1.20519","https://scispace.com/pdf/a-review-of-existing-cloud-automation-tools-1qtkiqxx7g.pdf","Yes","Many enterprises are running distributed applications on their on-premise servers. However, if load on those servers changes unexpectedly, then it becomes tedious to scale the resources and requires skilled human power to manage such situations. It may increase the capital expenditure. Hence, many companies have started to migrate their on-premise applications to the cloud. This migration of the applications to the cloud is one of the major challenges. To setup and manage the growing complex infrastructure, after migrating these applications to the cloud are really a time-consuming and tedious process which results in downtime. Hence, we need to automate this environment. To achieve architecture for the distributed systems which support security, repeatability, reliability, and scalability, we require some cloud automation tools. This paper summarizes tools such as Terraform and cloud formation for infrastructure automation and Docker and Habitat for application automation."
"A Survey on Infrastructure-as-Code Solutions for Cloud Development","https://scispace.com/papers/a-survey-on-infrastructure-as-code-solutions-for-cloud-341fxncd","2022","Proceedings Article","","Håkon Teppan
L. Flå
Martin Gilje Jaatun","10.1109/CloudCom55334.2022.00019","","No","Cloud software is increasingly written according to the DevOps paradigm, where use of virtualization and Infrastructure-as-Code is prevalent. This paper surveys the state of the art of IaC cloud development, and proposes a combination of Cloud-Native software to build an on-premise PaaS for a Security Lab."
"Automation and orchestration in hybrid clouds","https://scispace.com/papers/automation-and-orchestration-in-hybrid-clouds-45xt282oiqe8","2025","Journal Article","","Ravi Kumar Vankayalapati","10.70593/978-81-984306-5-6_9","","No","Automation and orchestration are key enablers of efficiency and agility in hybrid cloud environments, allowing businesses to streamline complex workflows across public and private cloud platforms. This abstract explores how automation tools facilitate the provisioning, scaling, and management of cloud resources, while orchestration ensures seamless coordination of these tasks across multiple cloud environments. It highlights the role of technologies like containerization, microservices, and CI/CD pipelines in optimizing cloud operations. By implementing automation and orchestration, organizations can improve operational efficiency, reduce human error, and enhance resource utilization, enabling faster deployment and more responsive IT operations in hybrid cloud settings. Keywords Automation, Orchestration, Hybrid Cloud, Cloud Operations, Cloud Provisioning, Cloud Scaling, Containerization, Microservices, CI/CD Pipelines, Cloud Management, Workflow Automation, Resource Utilization, IT Operations, Cloud Efficiency, Hybrid Cloud Environments, Cloud Coordination, Operational Efficiency. 9.1. Introduction Private cloud infrastructures have been widely deployed across technology industries, research institutions and e-infrastructures in the past few years. The main motivations for this dedicated cloud infrastructures are the need to execute applications with bias in a single hardware architecture or software framework, security concerns and compliance with approved methodologies. However, as cloud federation is being adopted in commercial and open access environments, the limitations of relying on a single cloud provider have become apparent in terms of asset portability (virtual machine (VM) images, network/software configurations, user management, credentials, etc.), cloud interfaces and performance of public APIs (Nampalli, 2023). The natural evolution of this approach has been the development and deployment of application level plugins, capable of orchestrating the capabilities of several cloud interfaces. Fig 9.1: Cloud Automation vs Cloud Orchestration 9.1.1. Background and Significance Hybrid environments of data, applications, and services hosted in data centres, either on-premise or in the cloud, intersected by data flows across the network, have been used in many use cases. It is time to provide guarantees about the quality of the data and the computational resources that are exchanged. Through a layered architecture, we propose a novel solution to guarantee the Service Level Agreement compliance of complex applications in hybrid environments that cross administrative domains. This solution includes monitoring and control mechanisms capable of generating real-time alerts and coarse/fine grained actions in the data-centre and end-host transport devices to provide timely responses. In addition, controllers in each domain are fed-on with data plane metrics such as network and server performance. It is operators' duty to deploy and operate the tools needed to monitor and manage the domain carefully. Therefore, we rely on widely supported standards for modelling and orchestrating the behavior of complex applications, and for the definition of a common control plane with the enterprise. 9.1.2. Research Objectives Research has been initiated with the aim of contributing to the state-of-the-art in Automation and Orchestration in Hybrid Clouds. There are three key objectives: (1) to analyse novel approaches and commercial tools for Automation and Orchestration in Hybrid Clouds, (2) to propose a theoretical model and solution for the Automation and Orchestration of Hybrid Clouds considering heterogeneous cloud computing environments and multiple providers, and (3) to validate the proposed automation and orchestration model and solution by applying it to a practical use-case scenario—a Science Gateway for a bioinformatics VRE. Starting with an analysis of existing work in the field, the focus on open-source tools often based on general-purpose programming languages stands out. Containerization technologies are favoured for this purpose, either combined with a Container Orchestrator (Syed, 2023). Relatively little attention is paid to modelling languages in the Cloud Application Programming Interface domain or to commercial platforms. However, novel approaches and commercial tools for the subject under study are being continuously developed and disseminated. Amongst other objectives throughout this work, a systematic review is presented of the available approaches and tools for Automation and Orchestration in Hybrid Clouds encompassing cost and efficiency issues plus new demands which may factor into the choice of tools or methods. 9.2. Fundamentals of Automation and Orchestration There is no denying the pervasion of cloud technologies into any kind of ICT environment: having in 2016 passed the tipping point of application workloads running in the cloud in data centers versus running on traditional IT, projections estimate that the ratio might be in 80%/20% (cloud/IT) by 2024. Cloud services reach or exceed a most privileged position in the 5G E2E service provisioning chain. Within the cloud stack, as type of usage estimate increases, and software-defined clouds generalize, the pressure of exposing and consuming cloud services/APIs increases (Danda, 2024). Enhanced cloud services/APIs for real-time scaling, chaining, metering, charging, QoS, KPI exposure and transfer across CSP domains, end-to-end analytics, SLA negotiation and enforcement are foreseen. Such enhancements will span across cloud-orchestration interfaces and will apply on both public and private clouds. In addition to enhancing cloud functionalities, there is a considerable part of those enhancements to extend or partially overlap on the contact point to the carrier cloud, consisting in NFV POPs with additional capabilities. It applies particularly in the case of closed groups of NFVI within a Carrier DC. Besides APIs and policies, enhancements relate to VNF/PNF modeling, descriptors, and monitoring data. Equation 1: Load Balancing Equation 9.2.1. Definition and Concepts Private cloud infrastructures are now widely deployed and adopted across technology industries and research institutions. Public cloud providers offer large compute and storage resources on-demand and deliver a pay-as-you-go model. Although cloud computing has emerged as a reality, a single cloud provider cannot fully satisfy the complex requirements of some scientific user communities who need specific applications, particular software stacks and special configurations. In this context, there is a growing interest in developing hybrid cloud solutions that bind together distinct and heterogeneous cloud infrastructures. Those approaches aim at simplifying the access to global and integrated e-resources for the final users. Moreover, the seamless integration of resources accessible through public or private cloud systems and through grid middleware is a major challenge for the Hybrid Grid/Cloud Activity. 9.2.2. Key Technologies Private cloud infrastructures are now widely deployed, adopted and well recognized across technology industries and research institutions, since they provide a new service-based approach for the flexible on-demand usage of virtualized resources (Syed, 2023). In particular, private clouds are considered a good choice for virtualizing industry and research legacy clusters in order to facilitate an evolution from traditional high performance computing to more complex and large scale processing and data analysis. However, they are often not enough by themselves and a growing interest is emerging for the development of hybrid cloud solutions that bind together distinct and heterogeneous cloud infrastructures. There is an increasing number of companies operating cloud marketplaces offering a very broad variety of different types of cloud resources. Joined with the developments carried out in the third platform technologies like Internet of Things (IoT) and big data analytics, complex hybrid cloud scenarios may be composed. Fig: NetDevOps Is Driving the Future of Hybrid Cloud Automation 9.3. Challenges and Benefits in Hybrid Cloud Environments Companies and organizations are increasingly enthusiastic about deploying applications, services, and storing data in public cloud environments, attracted by the flexibility, scalability and pay-per-use cost models offered by these services. However, private clouds are still essential for management of resources and storage of critical and data-sensitive applications inside the boundaries of companies and institutions. For these reasons, a growing number of industries and research organizations are now investing in solutions that combine private and public cloud platforms. With the growth of hybrid cloud and multi-cloud infrastructures, interoperability can become an issue. Among the different technologies being developed to overcome this challenge, orchestration has gained a leading role. This technology can be understood as the automation of workflows representing complex services that contain other services with the aim of providing the requested service (Nampalli, 2022). In the context of cloud, these complex services are composed of simple services such as virtual machines, storage appliances, load balancers or application servers. Fig 9.2: Hybrid Cloud Challenges 9.3.1. Security and Compliance Today's demanding and evolving business environment forces companies to react quickly to innovations and new trends. Cloud computing was adopted to address flexibility, scalability and agility requirements. The advances in cloud technologies and adoption of IT as a Service (ITaaS) concept in enterprise environments lead to Hybrid Cloud infrastructures that allow the orchestration and automation of cross-domain services. After the infrastructure, that should be as a service itself, in its Infrastructure as a Service (IaaS) approach, it is possible to orchestrate services across cloud providers using new mechanisms to automate the management and control of resources, security and networking aspects. Running a cloud service starting from the allocation of virtual network and computing resources to the plugging of specific security mechanisms normally requires not standardized and hardly programmable steps. Automation and orchestration technologies can be adopted for automating cloud infrastructures management. Orchestrators receive high level instructions and requests to provide some services and may decompose complex service manuals into a chain of individual API calls to low-level components. Hybrid Cloud Management allows to simplify the operations rules and the control of private and public resources, easing the automation and increasing the service level agreement guarantees that can be offered. Standards have been designed to ease the request of services to different providers. TOSCA can be the choice for this challenge, where the goal is to deploy complex web services. 9.3.2. Scalability and Flexibility Existing solutions offer some automation with the advantage that most of them allow composing custom workflows, i.e., chaining multiple tasks that can range between deploying complex distributed applications in different clouds to simple steps like downloading and uploading files. The scalability and performance of cloud applications are improved with the suggested solution that is based on microservices and their dynamic orchestration in a cloud computing environment. The purpose is to define a generic microservices-based architecture for application-level cloud orchestration and to describe its reference implementation utilizing container-based open source cloud technologies (Kothapalli et al., 2022). Hybrid cloud setups combining private data centers and public cloud providers are a norm for a larger class of users, than public clouds alone. However, as a consequence, the number of involved sites often exceeds the support of existing solutions which are built either for a single infrastructure or rather focused on orchestrating a single application. Nevertheless, the scalability problem is investigated and (partially) solved in connection with the WS-PGRADE/gUSE gateway framework, particularly for the data staging service that needs such scalability. 9.4. Case Studies and Best Practices Article writing is a very important part of automation as users either ask for more functionality, or try to adjust current functions to work more efficiently. This article presents an overview of current work on IT and cybersecurity challenges for the future Internet and presents perspectives on the responses and needs to manage the significant challenges that arise in the course of the advent of 5G and beyond mobile networks. New standards and new IT technologies, such as cloud computing, software-down networks, and network functions virtualization, are fundamentally changing the telecommunications sector. A task force has been established to explore the impact of cloudification of future telecommunication networks. The work relies on a two-strand approach: first, a set of scenarios are presented detailing the implementation of the cloud environment of the network operator in the short-term future; secondly, to evaluate the impact of scenarios on network performance and interpretation. A new industry and academic report discusses a network operator's view of the changing environment and its effects, looking at network performance and other implications for regulation and general social networks comment. Equation 2: Service Level Agreement (SLA) Compliance Equation 9.4.1. Successful Implementations Public and private clouds are now widely adopted by academia, research, and enterprise, to the extent that almost every institution lacks the capacity or will to maintain on-premises small or medium data centres. Still, the IT scenarios for institutions are so varied that no single cloud model can fit them all. Many institutions can leverage their private clouds to meet their unique requirements, while also exploiting capabilities of industrial clouds for heavy computations or offloading specific services. This is also the hybrid cloud model, where a private cloud solution is federated with one or more industrial clouds (Subhash et al., 2022). Despite being a very promising paradigm, it poses some challenges in application deployment, particularly when services from multiple clouds should be orchestrated. There are several successful implementations of fully automated application deployments on public or federated clouds. Solutions for complex multi-instance architectures can deploy complex multi-instance architectures. There are solutions to manage and effectively use resources from different cloud providers. In the commercial scene, there are offerings for the management of a variety of public cloud providers. Fig: Service design and orchestration revenue grew 9.4.2. Lessons Learned Hybrid Clouds are cost-effective solutions for enterprises aiming at expanding their in-house computational resources with computing capacity rented from commercial cloud providers. Expanding in-house resources with others on demand in public clouds constitutes a hybrid cloud scenario and it is a very good solution as it allows companies to operate profitably, being able to absorb sudden workload spikes. The System is composed of an in-house private cloud infrastructure, interfacing with the European private cloud infrastructure that offers connections to public cloud providers as well. A pilot deployment on private and public resources is considered. A basic requirement to enable hybrid clouds is to provide access to the internal private cloud (Cloud A in the rest of the document) and isolation also from other tenants, the user's workload will run on a new cheap Open Nebula cloud cluster installation located on its own premises. Once the simple initial setup is completed, a major service running on the private cloud demands the intensive usage of computational resources to consider a commercial public cloud (namely Cloud B) (Sondinti et al., 2023). Cloud configuration will be done automatically relying on software tools. Two tools work in sequence, the multi IaaS Orchestrator and the IaaS Agent. The former is asked by a client to set up a new environment and triggers the latter, which modifies the infrastructures in order to host applications of a given Topology and Capacity on private and/or public IaaS cloud providers. The implemented procedure and the scalability of the multi cloud service are described in context with the INDIGO initiative. 9.5. Future Directions In this paper, automation of Virtualized Network Functions (VNFs) is considered, i.e., how to render inter-network element services to automatically instantiate VNFs over network domains that rely on different technologies and are under different administrations. The proposed approach, referred to as cross-domain Orchestration, is also able to configure underlying connectivity services required by the VNFs. The employment of a common Information Model (IM) and Southbound Interface (SBI) with common interface primitives and request/reply messages are proposed for the standardized API between domains. The functionality and interfaces of a multi-domain Orchestrator are also described. This work falls within the context of the T-NOVA project, which focuses on the definition of a reference architecture for a Stub-Orchestrator for Composition and Rendition (SOC-R) Platform. Two solutions for new service operations are presented, one for zero-touch operations and another for predictive maintenance and reconfiguration (Vankayalapati et al., 2023). Besides, federated access and controlled sharing of resources across different operators for the provisioning of advanced services are envisioned. The cloud systems are an incarnation of the economic principles of software service delivery - effective utilization of common resources and commodification. This paper focuses on the automation of Virtualized Network Functions (VNFs) and the seamless instantiation of these functions across network domains that utilize diverse technologies and are governed by different administrations. The proposed solution, termed cross-domain orchestration, not only automates the instantiation of VNFs but also manages the underlying connectivity services necessary for their operation. A key feature of this approach is the use of a common Information Model (IM) and Southbound Interface (SBI), which facilitates standardized communication between different domains through consistent interface primitives and request/reply messages. The paper outlines the functionality and interfaces of a multi-domain orchestrator within the context of the T-NOVA project, which aims to develop a reference architecture for the Stub-Orchestrator for Composition and Rendition (SOC-R) platform. Fig 9.3: Thoughts on The Future of Hybrid Cloud IT 9.6. Conclusion The automation of the service provisioning implies the dynamic allocation and management across different operative domains. The networking community is adopting cloud computing to answer to emerging requirements and use cases, whereas the cloud community is building geographically distributed computing infrastructure requiring interconnection. Furthermore, up to now, the focus on cloud automation has been set on the computational and the storage side, paying little or no attention to the corresponding required networking resources, which are fundamental to ensure the end-to-end performance required by the services. Common uses of orchestration involve heterogeneous network domains, known as network orchestration, or cloud and network resources, exemplified by the emerging use case of interconnection of segregated data centers. A data-center could be defined as a centralized resource pool for the storage, management, processing and distribution of data and information organized pertaining to a particular business. Whereas at an early stage of the development of data-center terrestrial network access has been enough, the exponentially increasing amount and mobility of data have forced data-center to widely adopt hybrid satellite/fixed networks. 9.6.1. Future Trends Private cloud infrastructures are widely deployed and adopted across technology industries and research institutions. This situation has led to increased interest in the development of hybrid cloud solutions that bind together distinct and heterogeneous cloud infrastructures. Nevertheless, this situation opens a new challenging landscape regarding the management of such hybrid cloud environments (Maguluri et al., 2022). The challenge can be approached by enabling interoperability among the distinct cloud environments. In this context two different conventions emerge when referring to the way the different cloud environments are interconnected: The Inter-Cloud and the Multi-Cloud. Broadly speaking, the Multi-Cloud is focused on bundling together different (similar or not) cloud providers to cope the computational needs of a given application. It refers to the fact that there are a certain number of commercial and/or academic cloud providers offering distinct cloud environments to deploy applications. In Multi-Cloud approaches, neither a priori agreements are necessary with the cloud providers about technologies, interfaces or services to be offered, nor affiliations are needed among the cloud providers. This way, the distinct cloud environments are hidden from the users. Inter-Cloud approaches are focused on the federation of different cloud provider's environments. This is achieved by establishing agreements between the cloud providers to define the interfaces and services to be offered, ensuring pre-defined Service Level Agreements (SLA). Such agreements refer to the formal thresholds in relation to the quality and value of the services. References Danda, R. R. (2024). Generative AI in Designing Family Health Plans: Balancing Personalized Coverage and Affordability. Utilitas Mathematica, 121, 316-332. Kothapalli Sondinti, L. R., & Yasmeen, Z. (2022). Analyzing Behavioral Trends in Credit Card Fraud Patterns: Leveraging Federated Learning and Privacy-Preserving Artificial Intelligence Frameworks. Universal Journal of Business and Management, 2(1), 1224. Retrieved from https://www.scipublications.com/journal/index.php/ujbm/article/view/1224 Maguluri, K. K., Pandugula, C., Kalisetty, S., & Mallesham, G. (2022). Advancing Pain Medicine with AI and Neural Networks: Predictive Analytics and Personalized Treatment Plans for Chronic and Acute Pain Managements. In Journal of Artificial Intelligence and Big Data (Vol. 2, Issue 1, pp. 112–126). Science Publications (SCIPUB). https://doi.org/10.31586/jaibd.2022.1201 Nampalli, R. C. R. (2022). Neural Networks for Enhancing Rail Safety and Security: Real-Time Monitoring and Incident Prediction. In Journal of Artificial Intelligence and Big Data (Vol. 2, Issue 1, pp. 49–63). Science Publications (SCIPUB). https://doi.org/10.31586/jaibd.2022.1155 Nampalli, R. C. R. (2023). Moderlizing AI Applications In Ticketing And Reservation Systems: Revolutionizing Passenger Transport Services. In Journal for ReAttach Therapy and Developmental Diversities. Green Publication. https://doi.org/10.53555/jrtdd.v6i10s(2).3280 Sondinti, L. R. K., Kalisetty, S., Polineni, T. N. S., & abhireddy, N. (2023). Towards Quantum-Enhanced Cloud Platforms: Bridging Classical and Quantum Computing for Future Workloads. In Journal for ReAttach Therapy and Developmental Diversities. Green Publication. https://doi.org/10.53555/jrtdd.v6i10s(2).3347 Subhash Polineni, T. N., Pandugula, C., & Azith Teja Ganti, V. K. (2022). AI-Driven Automation in Monitoring Post-Operative Complications Across Health Systems. Global Journal of Medical Case Reports, 2(1), 1225. Retrieved from https://www.scipublications.com/journal/index.php/gjmcr/article/view/1225 Syed, S. (2023). Big Data Analytics In Heavy Vehicle Manufacturing: Advancing Planet 2050 Goals For A Sustainable Automotive Industry. Syed, S. (2023). Shaping The Future Of Large-Scale Vehicle Manufacturing: Planet 2050 Initiatives And The Role Of Predictive Analytics. Nanotechnology Perceptions, 19(3), 103-116. Vankayalapati, R. K., Sondinti, L. R., Kalisetty, S., & Valiki, S. (2023). Unifying Edge and Cloud Computing: A Framework for Distributed AI and Real-Time Processing. In Journal for ReAttach Therapy and Developmental Diversities. Green Publication. https://doi.org/10.53555/jrtdd.v6i9s(2).3348"
"A Survey and Comparative Study on Multi-Cloud Architectures: Emerging Issues And Challenges For Cloud Federation","https://scispace.com/papers/a-survey-and-comparative-study-on-multi-cloud-architectures-4qx7gswao2","2021","Posted Content","arXiv: Distributed, Parallel, and Cluster Computing","Deepika Saxena
Rishabh Gupta
Ashutosh Kumar Singh","","https://arxiv.org/pdf/2108.12831","Yes","Multi-cloud concept has broaden the world of cloud computing and has become a buzzword today. The word Multi-cloud envisions utilization of services from multiple heterogeneous cloud providers via a single architecture at customer premises. Though cloud computing has many issues and offers open research challenges, still the academics and industrial research has paved a pathway for multi-cloud environment. The concept of multi-cloud is in maturing phase, and many research projects are in progress to provide a multi-cloud architecture which is successfully enabled in all the respects like easy configuration, security, management etc. In this paper, concepts, challenges, requirement and future directions for multi-cloud environment are discussed. A survey of existing approaches and solutions provided by different multi-cloud architectures is entailed along with analysis of the pros and cons of different architectures while comparing the same."
"AI-Powered Cloud Orchestration: Automating Multi-Cloud &amp; Hybrid Cloud Workloads","https://scispace.com/papers/ai-powered-cloud-orchestration-automating-multi-cloud-hybrid-6zt3z7vhhs4h","2025","Journal Article","European journal of computer science and information technology","Prasanna Kumar Natta","10.37745/ejcsit.2013/vol13n8138147","","No","AI-powered cloud orchestration revolutionizes how enterprises manage and optimize their multi-cloud and hybrid cloud environments. Integrating artificial intelligence into cloud management addresses complexity, manual intervention, and reactive problem-solving challenges that plague traditional orchestration methods. By implementing intelligent algorithms for resource allocation, workload balancing, predictive scaling, security enhancement, and self-healing capabilities, organizations can transform their cloud operations from manually-defined workflows to autonomous systems capable of continuous optimization. These advanced orchestration technologies enable dynamic resource distribution based on usage patterns and forecasted demand while simultaneously identifying cost-saving opportunities through workload consolidation and intelligent scheduling. Security frameworks are significantly strengthened through anomaly detection, predictive threat intelligence, and adaptive access control policies that evolve with changing organizational needs. Perhaps most transformative is the ability of self-healing infrastructure to automatically detect, diagnose, and remediate issues before they cause service disruptions, dramatically reducing the operational burden on technical teams and allowing them to focus on innovation rather than troubleshooting. This technological shift represents a fundamental evolution in cloud management, offering enterprises unprecedented efficiency, reliability, and cost optimization across their distributed computing environments."
"Multi-Cloud and Hybrid Infrastructure: Addressing Consistency Challenges Across Cloud Providers","https://scispace.com/papers/multi-cloud-and-hybrid-infrastructure-addressing-consistency-myt3s73afe68","2025","Journal Article","International Journal of Advanced Research in Science, Communication and Technology","Prabhu Govindasamy Varadaraj","10.48175/ijarsct-24465","","No","The adoption of multi-cloud and hybrid cloud environments enables organizations to optimize flexibility, scalability, and cost efficiency. However, maintaining consistency across platforms such as Amazon Web Services (AWS), Google Cloud Platform (GCP), Microsoft Azure, and on-premises systems presents significant technical and operational challenges. This article investigates key issues in architecture, security, data synchronization, and operational practices across these platforms while focusing on integration obstacles, security gaps, data consistency issues, and standardized management tools. The article proposes a comprehensive framework addressing these challenges through cross-platform integration technologies, unified security policies, data management strategies, and centralized monitoring solutions, contributing to an enhanced understanding of multi-cloud infrastructure management and providing actionable insights for organizations implementing hybrid and multi-cloud architectures"
"Multi-Cloud Architectures: Principles, Implementation and Strategic Benefits","https://scispace.com/papers/multi-cloud-architectures-principles-implementation-and-5u0gamvw38x6","2025","Journal Article","International Journal of Advanced Research in Science, Communication and Technology","Srikanth Gurram","10.48175/ijarsct-25526","","No","Multi-cloud architectures have transformed enterprise infrastructure strategies by enabling organizations to distribute workloads across multiple providers for optimized performance, availability, and vendor independence. This architectural approach capitalizes on the distinctive capabilities of various cloud platforms, allowing strategic deployment of applications based on the comparative advantages offered by different providers for specific computing requirements. The inherent diversity creates resilience against provider-specific outages while establishing a foundation for geographic expansion, competitive pricing negotiations, and access to specialized services. Organizations achieve portability and avoid provider lock-in through architectural abstraction principles, containerization technologies, and platform-agnostic interfaces. Essential components, including cloud management platforms, unified identity frameworks, data orchestration tools, and software-defined networking, create the integration framework necessary for coherent operations. Despite implementation challenges related to operational complexity, governance inconsistencies, financial management, and technical compatibility, organizations implementing appropriate mitigation strategies realize substantial business advantages. These benefits encompass enhanced negotiating position, business continuity improvements, accelerated market entry, innovation capabilities, and technology talent advantages, collectively delivering competitive differentiation in increasingly dynamic business environments."
"An Orchestration Framework for a Global Multi-Cloud","https://scispace.com/papers/an-orchestration-framework-for-a-global-multi-cloud-4t0iu15i47","2018","Proceedings Article","IEEE International Conference on Cloud Computing Technology and Science","Lu Ming
Wang Lijuan
Wang Youyan
Fan Zhicheng
Feng Yatong
Xiaodong Liu
Xiaofang Zhao","10.1145/3299819.3299823","","No","Orchestration management in a global multi-cloud environment encounters many challenges, such as the centralized management of global cloud computing and application resources, more diverse cloud platforms and APIs, differentiated service catalogs. Network latency and instability between cloud platforms in various countries and accessibility between data centers of different security levels also makes orchestration not easy to manage. Orchestration tools, such as Ansible[1], has high requirements for many server ports and network quality. In a complex network environment, SaltStack[2] or Puppet[3], cannot deal with the multi-cloud management of large-scale computing and storage resource nodes. Apache Ambari[4], for applications that run on different cloud computing service providers, it lacks effective management capabilities. Therefore, it is difficult for common orchestration management tools to overcome these problems. In this paper, we propose a global multi-cloud orchestration framework (MCOF), which converts the orchestration instructions initiated from the MCOF master into a standardized orchestration definition model that is distributed to the MCOF workers inside each data center through the message queue. Then the MCOF workers perform the orchestration activities suitable for the corresponding cloud service provider behind the data center firewall to adapt to the complex cloud platform operating environment, and achieve standardization, efficiency, quality, reliability, and traceable orchestration management."
"Orchestration Based Hybrid or Multi Clouds and Interoperability Standardization","https://scispace.com/papers/orchestration-based-hybrid-or-multi-clouds-and-4zmux67s0h","2018","Proceedings Article","International Conference on Cloud Computing","Dinkar Sitaram
Sudheendra Harwalkar
Chetna Sureka
Harsh Garg
Manusarvathra Dinesh
Mayank Kejriwal
Shikhar Gupta
Vivek Kapoor","10.1109/CCEM.2018.00018","","No","In the present scenario, hybrid or multi-cloud environments are most suitable for Enterprises and Communities (like Government of India) for cloud bursting, disaster recovery, migration, and there is growing need for unified monitoring and management, however, it's challenging to setup a viable hybrid/multi-cloud environment. Currently, there are multiple solutions available in the market with limited success due to hidden drawbacks, for instance, vendor-lock-in, portability issues in migration, security threats and expensive in the long run and also, unfortunately, interoperability standardization is still work in progress. In this paper, we explore few hybrid/multi cloud use cases and demonstrate how these can be accomplished with our Federated Cloud Services Framework (middleware), which is built upon OpenStack [5], an open source cloud and by leveraging existing OpenStack functionalities."
"Cloud resource orchestration in the multi-cloud landscape: a systematic review of existing frameworks","https://scispace.com/papers/cloud-resource-orchestration-in-the-multi-cloud-landscape-a-4nkjt08nv6","2020","Journal Article","Journal of Cloud Computing","Orazio Tomarchio
Domenico Calcaterra
Giuseppe Di Modica","10.1186/S13677-020-00194-7","https://scispace.com/pdf/cloud-resource-orchestration-in-the-multi-cloud-landscape-a-4nkjt08nv6.pdf","Yes","The number of both service providers operating in the cloud market and customers consuming cloud-based services is constantly increasing, proving that the cloud computing paradigm has successfully delivered its potential. Nevertheless, the unceasing growth of the cloud market is posing hard challenges on its participants. On the provider side, the capability of orchestrating resources in order to maximise profits without failing customers’ expectations is a matter of concern. On the customer side, the efficient resource selection from a plethora of similar services advertised by a multitude of providers is an open question. In such a multi-cloud landscape, several research initiatives advocate the employment of software frameworks (namely, cloud resource orchestration frameworks - CROFs) capable of orchestrating the heterogeneous resources offered by a multitude of cloud providers in a way that best suits the customer’s need. The objective of this paper is to provide the reader with a systematic review and comparison of the most relevant CROFs found in the literature, as well as to highlight the multi-cloud computing open issues that need to be addressed by the research community in the near future."
"Cloud Architectures for Distributed Multi-Cloud Computing: A Review of Hybrid and Federated Cloud Environment","https://scispace.com/papers/cloud-architectures-for-distributed-multi-cloud-computing-a-20s9tjh2zt","2024","Journal Article","Indonesian Journal of Computer Science","Karwan Jameel Merseedi
Dr. Subhi R. M. Zeebaree","10.33022/ijcs.v13i2.3811","","No","The concept of several clouds has greatly extended the use of cloud computing and gained popularity in academic and business circles. The use of multi-cloud techniques has increased as businesses use cloud computing more and more to meet their computational demands. A thorough analysis of cloud architectures intended for distributed multi-cloud computing is presented in this study, with an emphasis on federated and hybrid cloud systems. The study looks at the opportunities and difficulties of adopting and overseeing a variety of cloud resources from several providers. The review starts out by going over the basic ideas and reasons for using multi-cloud strategies, emphasizing how important flexibility, scalability, and resilience are in contemporary computing settings. The study then explores the nuances of hybrid cloud architectures, with a focus on how private and public cloud resources can be seamlessly combined. In the context of hybrid cloud installations, important factors including data sovereignty, security, and workload orchestration are covered. In addition, the research delves into federated cloud architectures, clarifying how enterprises can coordinate and oversee workloads across several cloud providers. An examination of resource identification, policy enforcement, and interoperability procedures sheds light on the intricacies of federated cloud computing. The review delves into new developments in standards, best practices, and technology that help multi-cloud ecosystems mature. The study analyses the state of research and industry practices now, pointing out gaps and possible directions for future development. The intention is to provide decision-makers, researchers, and practitioners with a comprehensive grasp of the changing cloud architectural scene so they can plan and execute distributed multi-cloud solutions with knowledge. In conclusion, this article provides a thorough overview of hybrid and federated cloud architectures by combining information from many sources. Through a comprehensive analysis of the difficulties and possibilities associated with multi-cloud computing, the study hopes to add to the current conversation on cloud environment design and optimization in the rapidly changing technological landscape."
"Orchestrating Multi-Cloud Environments for Enhanced Flexibility and Resilience","https://scispace.com/papers/orchestrating-multi-cloud-environments-for-enhanced-1m9k0b2myl","2024","Journal Article","Journal of Technology and Systems","Kiran Kumar Voruganti","10.47941/jts.1810","","No","Purpose: This paper examines the essential role of multi-cloud orchestration in navigating the complexities of the contemporary cloud computing landscape, aimed at optimizing the deployment and management of cloud resources across diverse environments. Methodology: Utilizing a systematic review of scholarly articles, industry reports, and case studies, including the Flexera 2021 State of the Cloud Report and insights from Gartner, alongside academic contributions from researchers like Jamshidi et al. and Garg et al., this study delves into the strategies and tools facilitating effective multi-cloud orchestration. Findings: The research highlights multi-cloud orchestration as a critical enabler for enhancing operational efficiency, resilience, and cost-effectiveness in cloud deployments. It emphasizes the strategic benefits of orchestrating a heterogeneous mix of cloud services, including public, private, and hybrid clouds, to meet the intricate demands of modern applications. The study underscores the importance of advanced orchestration tools in ensuring seamless operations, security, and compliance across multi-cloud architectures. Unique contributor to theory, policy and practice: By following the principles outlined in this paper, organizations can leverage multi-cloud orchestration to unlock the full potential of their cloud investments and achieve a well-orchestrated symphony of success."
"Systematic Review of Integration Techniques in Hybrid Cloud Infrastructure Projects","https://scispace.com/papers/systematic-review-of-integration-techniques-in-hybrid-cloud-ryhv3zjb4p0u","2023","Journal Article","Deleted Journal","Ejielo Ogbuefi
Jeffrey Chidera Ogeawuchi
Bright Chibunna Ubamadu
Oluwademilade Aderemi Agboola
Oyinomomo-emi Emmanuel Akpe","10.62225/2583049x.2023.3.6.4323","","No","The growing adoption of hybrid cloud infrastructures combining public and private cloud environments has introduced complex integration challenges for organizations striving to optimize performance, scalability, and data security. This systematic review aims to evaluate and synthesize the current landscape of integration techniques used in hybrid cloud infrastructure projects, with a focus on interoperability, orchestration, data synchronization, and security compliance. This examines peer-reviewed literature, technical white papers, and industry reports published between 2015 and 2024 to identify dominant patterns, frameworks, and tools employed in hybrid cloud integration. Findings indicate that integration strategies in hybrid cloud environments often rely on middleware platforms, API gateways, container orchestration (e.g., Kubernetes), and Infrastructure as Code (IaC) tools. Middleware and APIs serve as critical enablers for seamless communication between heterogeneous systems, while containerization ensures portability across cloud boundaries. Moreover, service mesh architectures and microservices-based designs are increasingly adopted to enhance scalability and observability. Security and compliance integration techniques, including identity federation, encryption standards, and policy-as-code frameworks, are also frequently cited to address regulatory requirements. The review highlights a growing interest in using AI-driven automation to manage integration complexity, especially for real-time monitoring and anomaly detection. Despite significant advances, challenges remain in achieving seamless hybrid cloud integration, particularly in areas related to latency, data governance, and vendor lock-in. The review concludes with a proposed research agenda and best practices for selecting integration techniques based on organizational needs, application architecture, and compliance considerations. By providing a consolidated view of current practices and emerging trends, this review offers valuable insights for IT professionals, cloud architects, and decision-makers involved in hybrid cloud projects."
"Roboconf: A Hybrid Cloud Orchestrator to Deploy Complex Applications","https://scispace.com/papers/roboconf-a-hybrid-cloud-orchestrator-to-deploy-complex-55frv8ohvn","2015","Proceedings Article","International Conference on Cloud Computing","Linh Manh Pham
Alain Tchana
Didier Donsez
Noel De Palma
Vincent Zurczak
Pierre-Yves Gibello","10.1109/CLOUD.2015.56","https://scispace.com/pdf/roboconf-a-hybrid-cloud-orchestrator-to-deploy-complex-55frv8ohvn.pdf","Yes","This paper presents Roboconf, an open-source distributed application orchestration framework for multi-cloud platforms, designed to solve challenges of current Autonomic Computing Systems in the era of Cloud computing. It provides a Domain Specific Language (DSL) which allows to describe applications and their execution environments (cloud platforms) in a hierarchical way in order to provide a fine-grained management. Roboconf implements an asynchronous and parallel deployment protocol which accelerates and makes resilient the deployment process. Intensive experiments with different type of applications over different cloud models (e.g. Private, hybrid, and multi-cloud) validate the genericity of Roboconf. These experiments also demonstrate its efficiency comparing to existing frameworks such as Right Scale, Scalr, and Cloudify."
"Enabling End-to-End Orchestration of Multi-Cloud Applications","https://scispace.com/papers/enabling-end-to-end-orchestration-of-multi-cloud-2mrvtbk8dj","2017","Journal Article","IEEE Access","Kena Alexander
Choonhwa Lee
Eunsam Kim
Sumi Helal","10.1109/ACCESS.2017.2738658","","Yes","The orchestration of application components across heterogeneous cloud providers is a problem that has been tackled using various approaches, some of which led to the creation of cloud orchestration and management standards, such as TOSCA and CAMP. Standardization is a definitive method of providing an end-to-end solution capable of defining, deploying, and managing applications and their components across heterogeneous cloud providers. TOSCA and CAMP, however, perform different functions with regard to cloud applications. TOSCA is focused primarily on topology modeling and orchestration, whereas CAMP is focused on deployment and management of applications. This paper presents a novel solution that not only involves the combination of the emerging standards TOSCA and CAMP, but also introduces extensions to CAMP to allow for multi-cloud application orchestration through the use of declarative policies. Extensions to the CAMP platform are also made, which brings the standards closer together to enable a seamless integration. Our proposal provides an end-to-end cloud orchestration solution that supports a cloud application modeling and deployment process, allowing a cloud application to span and be deployed over multiple clouds. The feasibility and the benefit of our approach are demonstrated in our validation study."
"Efficient Unified Self-Service Sustainable Cloud Portal with Cloud Connectors for Multi-Platform Orchestration","https://scispace.com/papers/efficient-unified-self-service-sustainable-cloud-portal-with-yj4ys2604izn","2025","Journal Article","","Beena B.M.
Aryan Kothari
V. R. N. S. Nikhil
Namana Rohit
Prashanth Cheluvasai Ranga CSR","10.21203/rs.3.rs-6218612/v1","","No","<title>Abstract</title> Many businesses today are adopting multi-cloud services to optimize performance , control cost and avoid Vendor lock-in. Managing multiple cloud platforms simultaneously creates significant challenges for organizations, often resulting in operational inefficiencies due to platform heterogeneity, fragmented security policies , and poor resource utilization that negatively impacts cost management and environmental sustainability. The proposed research introduces a unified self-service cloud portal with custom-built cloud connectors that enables seamless orchestration across major cloud service providers including AWS, Azure, and Google Cloud Platform. Implementing a modular architecture with standardized interfaces, automated resource management, and comprehensive security controls, reducing operational complexity by 40% while maintaining consistent governance across platforms. One key innovation is combining intelligent cross-platform resource optimization with a novel Green Score metric that integrates real-time utilization, energy efficiency, and application performance data—through integration with provider-specific sustainability tools and intelligent workload placement, achieving up to 45% reduction in carbon footprint for flexible workloads and 35% improvement in resource utilization. Optimizing cloud resources helps avoid unnecessary costs and efficiently provision resources 1 thus making the cloud systems greener. The proposed solution’s work advances multiple UN Sustainable Development Goals, particularly SDG 9 (Industry, Innovation, and Infrastructure), SDG 12 (Responsible Consumption and Production), and SDG 13 (Climate Action), demonstrating that operational efficiency and environmental sustainability can be simultaneously achieved in multi-cloud environments."
"Towards Secure Cloud Orchestration for Multi-Cloud Deployments","https://scispace.com/papers/towards-secure-cloud-orchestration-for-multi-cloud-34zntq2ovl","2018","Proceedings Article","European Conference on Computer Systems","Nicolae Paladi
Antonis Michalas
Hai-Van Dang","10.1145/3195870.3195874","https://scispace.com/pdf/towards-secure-cloud-orchestration-for-multi-cloud-34zntq2ovl.pdf","Yes","Cloud orchestration frameworks are commonly used to deploy and operate cloud infrastructure. Their role spans both vertically (deployment on infrastructure, platform, application and microservice levels) and horizontally (deployments from many distinct cloud resource providers). However, despite the central role of orchestration, the popular orchestration frameworks lack mechanisms to provide security guarantees for cloud operators. In this work, we analyze the security landscape of cloud orchestration frameworks for multi-cloud infrastructure. We identify a set of attack scenarios, define security enforcement enablers and propose an architecture for a security-enabled cloud orchestration framework for multi-cloud application deployments."
"Orchestrating the Deployment of High Availability Services on Multi-zone and Multi-cloud Scenarios","https://scispace.com/papers/orchestrating-the-deployment-of-high-availability-services-5bicx0tbd7","2018","Journal Article","Journal of Grid Computing","Rafael Moreno-Vozmediano
Rubén S. Montero
Eduardo Huedo
Ignacio M. Llorente
Ignacio M. Llorente","10.1007/S10723-017-9417-Z","","No","Cloud computing has become one of the most used platforms to deploy High Availability (HA) solutions for its flexibility, on-demand provisioning, and elasticity. However, although many providers offer specific tools for HA support, like floating IPs and load balancing, the analysis of downtime at public cloud providers in previous years shows that a combination of several availability zones or cloud providers is required to achieve “five nines” availability. Besides reducing the chances of failure, the use of multiple availability zones and geographically distributed clouds may additionally bring performance and cost benefits. However, the orchestration, in an efficient and adaptive way, of HA multi-tier services in multi-zone and multi-cloud environments brings several challenges. This paper presents a novel orchestration method to automate the deployment and management of high availability multi-tier services on multiple availability zones, by introducing new affinity mechanisms, such as VM to location and role to role affinity/anti-affinity rules. Furthermore, we also extend this solution to multi-cloud scenarios, based on the replication or distribution of the service components among various clouds, along with their corresponding affinity rules."
"MCDA Framework for Edge-Aware Multi-Cloud Hybrid Architecture Recommendation","https://scispace.com/papers/mcda-framework-for-edge-aware-multi-cloud-hybrid-1ugef31z","2022","Proceedings Article","International Conference on Automated Software Engineering","Manish Ahuja
Narendranath Sukhavasi
Swapnajeet Gon Choudhury
Kaushik Das
Kapil Singi
Kuntal Dey
Vikrant Kaulgud","10.1145/3551349.3559501","","Yes","Deploying applications on hybrid clouds with computational artifacts distributed over public backends and private edges involve several constraints. Designing such deployment requires application architects to solve several challenges, spanning over hard regulatory policy constraints as well as business policy constraints such as enablement of privacy by on-prem processing of data to the extent the business wants, backend support of privacy enabling technologies (PET), sustainability in terms of green energy utilization, latency sensitivity of the application. In this paper, we propose to optimize hybrid cloud application architectures, while taking all those factors into consideration, and empirically demonstrate the effectiveness of our approach. To the best of our knowledge, this work is the first of its kind."
"Understanding the challenges and novel architectural models of multi-cloud native applications – a systematic literature review","https://scispace.com/papers/understanding-the-challenges-and-novel-architectural-models-iymm865s","2023","Journal Article","Journal of cloud computing","Juncal Alonso
Leire Orúe Echevarría Arrieta
Valentina Casola
Ana I. Torre-Bastida
Maider Huarte
Eneko Osaba
Jesus L. Lobo","10.1186/s13677-022-00367-6","https://scispace.com/pdf/understanding-the-challenges-and-novel-architectural-models-iymm865s.pdf","Yes","Abstract The evolution of Cloud Computing into a service utility, along with the pervasive adoption of the IoT paradigm, has promoted a significant growth in the need of computational and storage services. The traditional use of cloud services, focused on the consumption of one provider, is not valid anymore due to different shortcomings being the risk of vendor lock-in a critical. We are assisting to a change of paradigm, from the usage of a single cloud provider to the combination of multiple cloud service types, affecting the way in which applications are designed, developed, deployed and operated over such heterogeneous ecosystems. The result is an effective heterogeneity of architectures, methods, tools, and frameworks, copying with the multi-cloud application concept. The goal of this study is manifold. Firstly, it aims to characterize the multi-cloud concept from the application development perspective by reviewing existing definitions of multi-cloud native applications in the literature. Secondly, we set up the basis for the architectural characterization of these kind of applications. Finally, we highlight several open research issues drawn up from the analysis carried out. To achieve that, we have conducted a systematic literature review (SLR), where, a large set of primary studies published between 2011 and 2021 have been studied and classified. The in-depth analysis has revealed five main research trends for the improvement of the development and operation DevOps lifecycle of “multi-cloud native applications”. The paper finishes with directions for future work and research challenges to be addressed by the software community."
"Multi-Cloud Automation : A Strategic Approach to Cloud Infrastructure Management","https://scispace.com/papers/multi-cloud-automation-a-strategic-approach-to-cloud-3rmxbw1kuru8","2024","Journal Article","International journal of scientific research in computer science, engineering and information technology","Saili Krishna Maliye -","10.32628/cseit24106167","","No","This article examines the evolution and impact of multi-cloud automation strategies in modern enterprise environments, supported by comprehensive industry research and case studies. Drawing from multiple industry reports, including Flexera's 2024 State of the Cloud Report and PwC's Cloud and AI Business Survey, the research reveals that 89% of enterprises now employ multi-cloud strategies, with the global multi-cloud management market projected to grow at a CAGR of 27.3% through 2030. The article analyzes key components of successful multi-cloud automation, including deployment automation, operational excellence through monitoring, and incident management, while providing detailed metrics on their effectiveness. Through examination of real-world implementations across retail, financial services, and SaaS sectors, the research demonstrates how organizations achieve significant improvements in operational efficiency, cost optimization, and business agility through comprehensive automation strategies."
"Multi-Cloud Management: Orchestrating and Securing Distributed Cloud Environments","https://scispace.com/papers/multi-cloud-management-orchestrating-and-securing-2re3ltzkis","2023","Preprint","","Mathias Lea","10.31219/osf.io/248tk","https://scispace.com/pdf/multi-cloud-management-orchestrating-and-securing-2re3ltzkis.pdf","No","Multi-Cloud Management: Orchestrating and Securing DistributedCloud Environments"
"Cloud Resource Orchestration Programming: Overview, Issues, and Directions","https://scispace.com/papers/cloud-resource-orchestration-programming-overview-issues-and-523kjlayz1","2015","Journal Article","IEEE Internet Computing","Rajiv Ranjan
Boualem Benatallah
Schahram Dustdar
Mike P. Papazoglou","10.1109/MIC.2015.20","https://scispace.com/pdf/cloud-resource-orchestration-programming-overview-issues-and-523kjlayz1.pdf","Yes","Cloud computing provides on-demand access to affordable hardware (such as multicore CPUs, GPUs, disk drives, and networking equipment) and software (databases, application servers, load-balancers, data processors, and frameworks). The pervasiveness and power of cloud computing alleviates some of the problems that application administrators face in their existing hardware and locally managed software environments. However, the rapid increase in scale, dynamicity, heterogeneity, and diversity of cloud resources necessitates having expert knowledge about programming complex orchestration operations (for example, selection, deployment, monitoring, and runtime control) on those resources to achieve the desired quality of service. This article provides an overview of the key cloud resource types and resource orchestration operations, with special focus on research issues involved in programming those operations. The Web Extra can be found at https://s3.amazonaws.com/ieeecs.cdn.csdl.public/mags/ic/2015/05/mic2015050046s1.docx."
"Orchestrated Multi-Cloud Application Deployment in OpenStack with TOSCA","https://scispace.com/papers/orchestrated-multi-cloud-application-deployment-in-openstack-2ilg8k0o2i","2017","Proceedings Article","IEEE International Conference on Smart Computing","Giuseppe Tricomi
Alfonso Panarello
Giovanni Merlino
Francesco Longo
Dario Bruneo
Antonio Puliafito","10.1109/SMARTCOMP.2017.7947027","","No","Cloud computing is becoming a relatively mature paradigm in the ICT landscape. In light of the growing appetite for resources and service levels on par with user expectations, multi-cloud scenarios are becoming the next frontier in the usage of distributed datacenters for private and hybrid Cloud scenarios. Application deployment in particular is a noteworthy feature to be evaluated as microservices become mainstream in adoption. Especially so when considered jointly with orchestration services; indeed OpenStack, as the most widely adopted Cloud middleware among the OpenSource community, features an orchestration subsystem, and may orchestrate the deployment of applications and services. In this work the authors will describe an architecture, developed within the H2020 BEACON project, for a standardized approach to orchestrated application deployment in multi-Cloud OpenStack- based setups, with TOSCA providing the specifications."
"CYCLONE unified deployment and management of federated, multi-cloud applications","https://scispace.com/papers/cyclone-unified-deployment-and-management-of-federated-multi-zu0zwmqm9i","2015","Proceedings Article","IEEE/ACM International Conference Utility and Cloud Computing","Mathias Slawik
Begüm İlke Zilci
Yuri Demchenko
José Ignacio Aznar Baranda
Robert Branchat
Charles Loomis
Oleg Lodygensky
Christophe Blanched","10.1109/UCC.2015.81","","Yes","Various Cloud layers have to work in concert in order to manage and deploy complex multi-cloud applications, executing sophisticated workflows for Cloud resource deployment, activation, adjustment, interaction, and monitoring. While there are ample solutions for managing individual Cloud aspects (e.g. network controllers, deployment tools, and application security software), there are no well-integrated suites for managing an entire multi cloud environment with multiple providers and deployment models. This paper presents the CYCLONE architecture that integrates a number of existing solutions to create an open, unified, holistic Cloud management platform for multi-cloud applications, tailored to the needs of research organizations and SMEs. It discusses major challenges in providing a network and security infrastructure for the Intercloud and concludes with the demonstration how the architecture is implemented in a real life bioinformatics use case."
"A Taxonomy and Survey of Cloud Resource Orchestration Techniques","https://scispace.com/papers/a-taxonomy-and-survey-of-cloud-resource-orchestration-2nhpex4ar7","2017","Journal Article","ACM Computing Surveys","Denis Weerasiri
Moshe Chai Barukh
Boualem Benatallah
Quan Z. Sheng
Rajiv Ranjan","10.1145/3054177","https://scispace.com/pdf/a-taxonomy-and-survey-of-cloud-resource-orchestration-2nhpex4ar7.pdf","Yes","Cloud services and applications prove indispensable amid today’s modern utility-based computing. The cloud has displayed a disruptive and growing impact on everyday computing tasks. However, facilitating the orchestration of cloud resources to build such cloud services and applications is yet to unleash its entire magnitude of power. Accordingly, it is paramount to devise a unified and comprehensive analysis framework to accelerate fundamental understanding of cloud resource orchestration in terms of concepts, paradigms, languages, models, and tools. This framework is essential to empower effective research, comprehension, comparison, and selection of cloud resource orchestration models, languages, platforms, and tools. This article provides such a comprehensive framework while analyzing the relevant state of the art in cloud resource orchestration from a novel and holistic viewpoint."
"Towards Model-Driven Provisioning, Deployment, Monitoring, and Adaptation of Multi-cloud Systems","https://scispace.com/papers/towards-model-driven-provisioning-deployment-monitoring-and-2toucnu2d1","2013","Proceedings Article","International Conference on Cloud Computing","Nicolas Ferry
Alessandro Rossini
Franck Chauvel
Brice Morin
Arnor Solberg","10.1109/CLOUD.2013.133","https://scispace.com/pdf/towards-model-driven-provisioning-deployment-monitoring-and-2toucnu2d1.pdf","Yes","In the landscape of cloud computing, the competition between providers has led to an ever growing number of cloud solutions offered to consumers. The ability to run and manage multi-cloud systems (i.e., applications on multiple clouds) allows exploiting the peculiarities of each cloud solution and hence optimising the performance, availability, and cost of the applications. However, these cloud solutions are typically heterogeneous and the provided features are often incompatible. This diversity hinders the proper exploitation of the full potential of cloud computing, since it prevents interoperability and promotes vendor lock-in, as well as it increases the complexity of development and administration of multi-cloud systems. This problem needs to be addressed promptly. In this paper, we provide a classification of the state-of-the-art of cloud solutions, and argue for the need for model-driven engineering techniques and methods facilitating the specification of provisioning, deployment, monitoring, and adaptation concerns of multi-cloud systems at design-time and their enactment at run-time."
"Designing multi-cloud architecture models for enterprise scalability and cost reduction","https://scispace.com/papers/designing-multi-cloud-architecture-models-for-enterprise-1ieq6n8tvr4m","2024","Journal Article","Open access research journal of engineering and technology","Olin Johnson
Jeremiah Olamijuwon
Emmanuel Cadet
Olajide Soji Osundare
Zein Samira","10.53022/oarjet.2024.7.2.0061","","No","Designing multi-cloud architecture models has become a critical strategy for enterprises seeking scalability and cost reduction in their cloud operations. Multi-cloud environments, which involve the use of multiple cloud service providers (CSPs), offer businesses the flexibility to optimize performance, improve resource allocation, and mitigate risks such as downtime, vendor lock-in, and service interruptions. This review explores the design principles and best practices for creating multi-cloud architectures that enhance enterprise scalability while simultaneously driving cost efficiencies. By leveraging the strengths of various CSPs such as Amazon Web Services (AWS), Microsoft Azure, and Google Cloud businesses can tailor their infrastructure to meet specific workload requirements and capitalize on competitive pricing models, ensuring better resource utilization and reducing the risk of under or over-provisioning. Scalability in multi-cloud architectures is achieved by implementing load balancing, auto-scaling, and failover mechanisms across multiple platforms. These systems can dynamically allocate resources in response to fluctuating demand, ensuring high availability and optimized performance. Additionally, the review discusses the key technologies that enable multi-cloud management, such as cloud management platforms (CMPs), containerization, and orchestration tools like Kubernetes, which help streamline operations and simplify the complex task of managing resources across disparate cloud environments. Cost reduction in multi-cloud is achieved by optimizing resource usage, selecting the right pricing models (e.g., on-demand, reserved, or spot pricing), and automating scaling and resource management. The review also highlights the importance of adopting security best practices to manage data privacy and compliance across multiple clouds. Finally, the review presents real-world case studies that demonstrate the tangible benefits of multi-cloud strategies, illustrating how enterprises can scale operations effectively while reducing infrastructure costs. This research underscores the transformative potential of multi-cloud architectures in modern enterprise environments, emphasizing their role in achieving business agility, cost optimization, and operational efficiency."
"Declarative automated cloud resource orchestration","https://scispace.com/papers/declarative-automated-cloud-resource-orchestration-1lkkyst0lw","2011","Proceedings Article","Symposium on Cloud Computing","Changbin Liu
Boon Thau Loo
Yun Mao","10.1145/2038916.2038942","https://scispace.com/pdf/declarative-automated-cloud-resource-orchestration-1lkkyst0lw.pdf","Yes","As cloud computing becomes widely deployed, one of the challenges faced involves the ability to orchestrate a highly complex set of subsystems (compute, storage, network resources) that span large geographic areas serving diverse clients. To ease this process, we present COPE (Cloud Orchestration Policy Engine), a distributed platform that allows cloud providers to perform declarative automated cloud resource orchestration. In COPE, cloud providers specify system-wide constraints and goals using COPElog, a declarative policy language geared towards specifying distributed constraint optimizations. COPE takes policy specifications and cloud system states as input and then optimizes compute, storage and network resource allocations within the cloud such that provider operational objectives and customer SLAs can be better met. We describe our proposed integration with a cloud orchestration platform, and present initial evaluation results that demonstrate the viability of COPE using production traces from a large hosting company in the US. We further discuss an orchestration scenario that involves geographically distributed data centers, and conclude with an ongoing status of our work."
"soCloud: a service-oriented component-based PaaS for managing portability, provisioning, elasticity, and high availability across multiple clouds","https://scispace.com/papers/socloud-a-service-oriented-component-based-paas-for-managing-40ffdqrdav","2016","Journal Article","Computing","Fawaz Paraiso
Philippe Merle
Lionel Seinturier","10.1007/S00607-014-0421-X","https://scispace.com/pdf/socloud-a-service-oriented-component-based-paas-for-managing-40ffdqrdav.pdf","Yes","Multi-cloud computing is a promising paradigm to support very large scale world wide distributed applications. Multi-cloud computing is the usage of multiple, independent cloud environments, which assumed no priori agreement between cloud providers or third party. However, multi-cloud computing has to face several key challenges such as portability, provisioning, elasticity, and high availability. Developers will not only have to deploy applications to a specific cloud, but will also have to consider application portability from one cloud to another, and to deploy distributed applications spanning multiple clouds. This article presents soCloud a service-oriented component-based Platform as a Service for managing portability, elasticity, provisioning, and high availability across multiple clouds. soCloud is based on the OASIS Service Component Architecture standard in order to address portability. soCloud provides services for managing provisioning, elasticity, and high availability across multiple clouds. soCloud has been deployed and evaluated on top of ten existing cloud providers: Windows Azure, DELL KACE, Amazon EC2, CloudBees, OpenShift, dotCloud, Jelastic, Heroku, Appfog, and an Eucalyptus private cloud."
"Towards Formal-Based Semantic Interoperability in Multi-Clouds: The FCLOUDS Framework","https://scispace.com/papers/towards-formal-based-semantic-interoperability-in-multi-46z4af474x","2017","Proceedings Article","International Conference on Cloud Computing","Stéphanie Challita
Fawaz Paraiso
Philippe Merle","10.1109/CLOUD.2017.98","","No","Multi-cloud computing has been proposed as a way to reduce vendor lock-in, to improve resiliency during outages and geo-presence, to boost performance and to lower costs. However, semantic differences between cloud providers, as well as their heterogeneous management interfaces, make changing from one provider to another very complex and costly. This is quite challenging for the implementation of multi-cloud systems. In this paper, we aim to take advantage of formal methods to define a precise semantics for multi-clouds. We propose fclouds, a formal-based framework for semantic interoperability in multi-clouds. This framework contains a catalogue of formal models that mathematically describe cloud APIs and reason over them. A precise alignment can be described between their concepts, which promotes semantic interoperability."
"Adaptive management of applications across multiple clouds: The SeaClouds Approach","https://scispace.com/papers/adaptive-management-of-applications-across-multiple-clouds-1xwkdxm7g9","2015","Journal Article","Clei Electronic Journal","Antonio Brogi
Jose Carrasco
Javier Cubo
Elisabetta Di Nitto
Francisco Durán
Michela Fazzolari
Ahmad Ibrahim
Ernesto Pimentel
Jacopo Soldani
Pengwei Wang
Francesco D'Andria","10.19153/CLEIEJ.18.1.1","https://scispace.com/pdf/adaptive-management-of-applications-across-multiple-clouds-1xwkdxm7g9.pdf","Yes","How to deploy and manage, in an ecient and adaptive way, complex applications across multiple heterogeneous cloud platforms is one of the problems that have emerged with the cloud revolution. In this paper we present context, motivations and objectives of the EU research project SeaClouds, which aims at enabling a seamless adaptive multi-cloud management of complex applications by supporting the distribution, monitoring and migration of application modules over multiple heterogeneous cloud platforms. After positioning SeaClouds with respect to related cloud initiatives, we present the SeaClouds architecture and discuss some of its aspect, such as the use of the OASIS standard TOSCA and the compatibility with the OASIS CAMP initiative."
"Occopus: a Multi-Cloud Orchestrator to Deploy and Manage Complex Scientific Infrastructures","https://scispace.com/papers/occopus-a-multi-cloud-orchestrator-to-deploy-and-manage-fu0ectuh7t","2018","Journal Article","Journal of Grid Computing","József Kovács
Péter Kacsuk
Péter Kacsuk","10.1007/S10723-017-9421-3","","No","This paper presents Occopus, an open-source cloud orchestration and management framework for heterogeneous multi-cloud platforms. Occopus provides a language to specify infrastructure descriptions and node definitions based on which Occopus can automatically deploy and maintain the specified virtual infrastructures in the target clouds. The paper introduces the required structure of the infrastructure descriptions and node definitions in an informal way and shows two use cases (Hadoop cluster and MICADO framework) how Occopus can be used to deploy complex virtual infrastructures. The paper also explains the architecture and implementation aspects of Occopus and describes its main distinguishing features compared to other cloud orchestrator frameworks."
"EasyCloud: Multi-clouds made easy","https://scispace.com/papers/easycloud-multi-clouds-made-easy-18vdlb3t8e","2021","Proceedings Article","Computer Software and Applications Conference","Cosimo Anglano
Massimo Canonico
Marco Guazzone","10.1109/COMPSAC51774.2021.00078","","No","Interoperability between different cloud platforms is a critical requirement for letting users to smoothly switch between different cloud providers and combine their services. However, the lack of standard interfaces to access these cloud platforms may result in the vendor lock-in situation, whereby users are locked into a specific cloud provider. In this paper, we present EasyCloud, a toolkit able to effectively support the creation and usage of Multi-cloud Systems (MSs) by providing interoperability, platform independence, effective resource provisioning, and ease of use. We describe its architecture and implementation, and experimentally assess the performance of EasyCloud, and compare it to existing alternative MS toolkits that are representative of the state-of-the-art. Our results clearly show that EasyCloud is highly scalable, quite efficient, and outperforms the other alternative toolkits."
"Supercloud: Opportunities and Challenges","https://scispace.com/papers/supercloud-opportunities-and-challenges-1h29np8xt1","2015","Journal Article","Operating Systems Review","Qin Jia
Zhiming Shen
Weijia Song
Robbert van Renesse
Hakim Weatherspoon","10.1145/2723872.2723892","https://scispace.com/pdf/supercloud-opportunities-and-challenges-1h29np8xt1.pdf","No","Infrastructure as a Service (IaaS) clouds couple applications tightly with the underlying infrastructures and services. This vendor lock-in problem forces users to apply ad-hoc deployment strategies in order to tolerate cloud failures, and limits the ability of doing virtual machine (VM) migration and resource scaling across different clouds. This paper presents the Supercloud, a cloud service comprising resources obtained from several diverse IaaS cloud providers, and discusses opportunities, limitations, and future research directions. Currently, the Supercloud has been deployed using resources from several major cloud providers, including Amazon EC2, Rackspace, HP Cloud, and some private clouds. VMs run in a virtual network and can be migrated seamlessly across different clouds, with different hypervisors and device models. Using case studies we demonstrate that, being able to deploy applications to more regions and granting more control to end-users, the Supercloud can reduce latency and cost compared to the underlying cloud providers."
"A survey on cloud interoperability: taxonomies, standards, and practice","https://scispace.com/papers/a-survey-on-cloud-interoperability-taxonomies-standards-and-3nqlh7gwto","2013","Journal Article","Measurement and Modeling of Computer Systems","Zhizhong Zhang
Chuan Wu
David W. Cheung","10.1145/2479942.2479945","https://scispace.com/pdf/a-survey-on-cloud-interoperability-taxonomies-standards-and-3nqlh7gwto.pdf","No","Cloud computing is a new computing paradigm that allows users with different computing demands to access a shared pool of configurable computing resources (e.g., servers, network, storage, database, applications and services). Many commercial cloud providers have emerged in the past 6-7 years, and each typically provides its own cloud infrastructure, APIs and application description formats to access the cloud resources, as well as support for service level agreements (SLAs). Such vendor lock-in has seriously limited the flexibility that cloud end users would like to process, when it comes to deploy applications over different infrastructures in different geographic locations, or to migrate a service from one provider's cloud to another. To enable seamless sharing of resources from a pool of cloud providers, efforts have emerged recently to facilitate cloud interoperability, i.e., the ability for multiple cloud providers to work together, from both the industry and academia. In this article, we conduct a comprehensive survey on the state-of-the-art efforts, with a focus on interoperability among different IaaS (infrastructure as a service) cloud platforms. We investigate the existing studies on taxonomies and standardization of cloud interoperability, as well as practical cloud technologies from both the cloud provider's and user's perspectives to enable interoperation. We pose issues and challenges to advance the topic area, and hope to pave a way for the forthcoming research."
"ICOMF: Towards a Multi-cloud Ecosystem for Dynamic Resource Composition and Scaling","https://scispace.com/papers/icomf-towards-a-multi-cloud-ecosystem-for-dynamic-resource-48c4d15m65","2013","Proceedings Article","IEEE International Conference on Cloud Computing Technology and Science","Ana-Maria Oprescu
Alexandru-Florian Antonescu
Yuri Demchenko
Cees de Laat","10.1109/CLOUDCOM.2013.14","","No","Modern cloud-based applications and infrastructures may include resources and services (components) from multiple cloud providers, are heterogeneous by nature and require adjustment, composition and integration. The specific application requirements can be met with difficulty by the current static predefined cloud integration architectures and models. In this paper, we propose the Intercloud Operations and Management Framework (ICOMF) as part of the more general Intercloud Architecture Framework (ICAF) that provides a basis for building and operating a dynamically manageable multi-provider cloud ecosystem. The proposed ICOMF enables dynamic resource composition and decomposition, with a main focus on translating business models and objectives to cloud services ensembles. Our model is user-centric and focuses on the specific application execution requirements, by leveraging incubating virtualization techniques. From a cloud provider perspective, the ecosystem provides more insight into how to best customize the offerings of virtualized resources."
"Cloud MF: Applying MDE to Tame the Complexity of Managing Multi-cloud Applications","https://scispace.com/papers/cloud-mf-applying-mde-to-tame-the-complexity-of-managing-45f55v2wtk","2014","Proceedings Article","IEEE/ACM International Conference Utility and Cloud Computing","Nicolas Ferry
Hui Song
Alessandro Rossini
Franck Chauvel
Arnor Solberg","10.1109/UCC.2014.36","","No","The market of cloud computing encompasses an ever-growing number of cloud providers offering a multitude of infrastructure-as-a-service (IaaS) and platform-as-a-service (PaaS) solutions. The heterogeneity of these solutions hinders the proper exploitation of cloud computing since it prevents interoperability and promotes vendor lock-in, which increases the complexity of executing and managing multi-cloud applications (i.e., Applications that can be deployed across multiple cloud infrastructures and platforms). Providers of multi-cloud applications seek to exploit the peculiarities of each cloud solution and to combine the delivery models of IaaS and PaaS in order to optimise performance, availability, and cost. In this paper, we show how the Cloud Modelling Framework leverages upon model-driven engineering to tame this complexity by providing: (i) a tool-supported domain-specific language for specifying the provisioning and deployment of multi-cloud applications, and (ii) a models@run-time environment for enacting the provisioning, deployment, and adaptation of these applications."
"Cloud Integration and Orchestration","https://scispace.com/papers/cloud-integration-and-orchestration-1l5gm27dvh","2023","Book Chapter","Texts in computer science","Chellammal Surianarayanan
Pethuru Raj","10.1007/978-3-031-32044-6_11","","No","The objective of this chapter is to introduce the basics of cloud integration and orchestration in multi-cloud environments. Through this chapter, the reader will come to why do we need multi-cloud environment and hybrid IT, its challenges and how cloud integration and orchestration help to resolve some of the challenges. The reader also comes to know about existing tools for cloud orchestrationCloud orchestration."
"An Overview of Multi-cloud Computing","https://scispace.com/papers/an-overview-of-multi-cloud-computing-5c50sn81ug","2019","Book Chapter","Advanced Information Networking and Applications","Jiangshui Hong
Thomas Dreibholz
Joseph Adam Schenkel
Jiaxi Alessia Hu","10.1007/978-3-030-15035-8_103","","No","The purpose of this paper is to provide a brief overview of cloud computing technologies, particularly with respect to multi-cloud networks. First, the basics of cloud computing concepts are discussed. Next we outline some challenges facing cloud computing, and discuss how multi-cloud systems including multi-clouds, hybrid clouds, federated clouds, and cross-clouds may be used to deal with some of these issues. Finally, multi-cloud systems may also be used in conjunction with new developing technologies such as Big Data and Machine Learning, leading to exciting innovations. These are reviewed in brief. Our goal is to provide a modern look at the state of the art in multi-cloud computing and review open issues in the field. The goal is that this paper will help the reader to understand challenges facing cloud computing, how multi-cloud computing addresses some of these issues, and inspire community excitement at the future integration of multi-cloud platforms with other novel technologies."
"Cloud Orchestration","https://scispace.com/papers/cloud-orchestration-29cgik78559r","","","","Chellammal Surianarayanan
Pethuru Raj Chelliah","10.1007/978-3-030-13134-0_11","","No","The objective of this chapter is to introduce the reader to the basics of cloud orchestrationCloud orchestration in a multi-cloud environment. By the end of the chapter the reader should have a fair understanding about why we need a multi-cloud environment and hybrid IT, its challenges, and how cloud orchestrationCloud orchestration helps to resolve some of the challenges. The reader should also gain an insight into the currently available tools used in cloud orchestrationCloud orchestration ."
"Problems of multi-cloud solutions deploying and managing","https://scispace.com/papers/problems-of-multi-cloud-solutions-deploying-and-managing-48yg6fzkt7qe","2021","Journal Article","Бионика интеллекта","N. Kravets
M.S. Chernyshov","10.30837/bi.2021.1(96).10","","No","The expediency of deploying software products in a multi-cloud is analyzed, the advantages and disadvantages of this approach, the problems associated with the use of services by several cloud providers are identified. It was investigated which cloud solutions are the most popular today and the cases in which it is better to use them, rather than competitors are considered. Multi-cloud management platforms are considered, which are focused on the use of organizations with a large number of geographically dispersed departments and offices. It has been determined what cloud resource orchestration frameworks support working with multiple clouds, and which technologies they use to make the best choice of a cloud solution."
"Securing Multi-Cloud Architectures: A Machine Learning Perspective","https://scispace.com/papers/securing-multi-cloud-architectures-a-machine-learning-4b93a35g0j","2024","Journal Article","Deleted Journal","Sundeep Reddy Mamidi","10.60087/jaigs.v2i1.160","","No","Multi-cloud computing, the utilization of multiple cloud computing services in a single heterogeneous architecture, has gained significant traction in recent years due to its potential for enhancing flexibility, resilience, and performance. This paper provides an overview of multi-cloud computing, exploring its key concepts, advantages, challenges, and best practices. It examines the motivations behind adopting multi-cloud strategies, the various deployment models, management approaches, and emerging trends. Additionally, the paper discusses the implications of multi-cloud computing for security, interoperability, and vendor lock-in. Through a comprehensive analysis, this paper aims to offer insights into the complexities and opportunities associated with multi-cloud environments."
"Multi-Cloud Deployment with Kubernetes: Challenges, Strategies, and Performance Optimization","https://scispace.com/papers/multi-cloud-deployment-with-kubernetes-challenges-strategies-603mb78v30w7","2025","Journal Article","International Scientific Journal of Engineering and Management","Anila Gogineni","10.55041/isjem00036","","No","In this paper, the challenges, strategies, and techniques involved in the right use of Kubernetes to perform multi-cloud are summarised. Some of them are lack of coordination between different systems and domains, security concerns and costs and providing solutions in terms of how coordination might be most appropriate and how different kinds of automation might be most usefully employed. The following performance optimization techniques are also considered: as the concepts of resource management and load distribution. Keywords: Multiple Cloud Operating Model, Kubernetes Virtualization, Resource Optimization,"
"Multi-Cloud: expectations and current approaches","https://scispace.com/papers/multi-cloud-expectations-and-current-approaches-fez8wotkth","2013","Proceedings Article","","Dana Petcu","10.1145/2462326.2462328","","No","Using resources and services from multiple Clouds is a natural evolution from consuming the ones from in-silo Clouds. Technological and administrative barriers are however slowing the process. Fortunately the recent years are marked by the appearance of several solutions that are partially overpassing them. However, the approaches are quite various and not adopted at large scale. This paper intends to offer a snapshot of the current state-of-the-art and to identify the future steps in building Multi-Clouds. A list of basic requirements for a Multi-Cloud is proposed."
"Orchestration from the cloud to the edge","https://scispace.com/papers/orchestration-from-the-cloud-to-the-edge-5brf3nodh1","2020","Book Chapter","","Sergej Svorobej
Malika Bendechache
Frank Griesinger
Jörg Domaschka","10.1007/978-3-030-41110-7_4","https://scispace.com/pdf/orchestration-from-the-cloud-to-the-edge-5brf3nodh1.pdf","Yes","The effective management of complex and heterogeneous computing environments is one of the biggest challenges that service and infrastructure providers are facing in the cloud-to-thing continuum era. Advanced orchestration systems are required to support the resource management of large-scale cloud data centres integrated with the big data generation of IoT devices. The orchestration system should be aware about all available resources and their current status in order to perform dynamic allocations and enable short time deployment of applications. This chapter will review the state of the art with regards to orchestration along the cloud-to-thing continuum with a specific emphasis on container-based orchestration (e.g. Docker Swarm and Kubernetes) and fog-specific orchestration architectures (e.g. SORTS, SOAFI, ETSI IGS MEC, and CONCERT)."
"Cloud Services Orchestration: A Comparative Study of Existing Approaches","https://scispace.com/papers/cloud-services-orchestration-a-comparative-study-of-existing-580r0dva3v","2014","Proceedings Article","Advanced Information Networking and Applications","Khadija Bousselmi
Zaki Brahmi
Mohamed Mohsen Gammoudi","10.1109/WAINA.2014.72","","No","Cloud Computing is emerging today as a service model used to relocate locally-based data and applications to virtualized services available via Internet at a lower cost. A key to exploit the benefits of this model is orchestration which consists in coordinating effectively the deployment of a set of virtualized services in order to fulfill operational and quality objectives of end users and Cloud providers. Cloud orchestration can be carried out at two levels: hardware level orchestration and software level orchestration. In this paper, we highlight the main challenging points about the Cloud orchestration concept. Then, we carry on a comparative study of some existing research works involved with this concept at hardware and software levels."
"Interoperability and Portability Approaches in Inter-Connected Clouds: A Review","https://scispace.com/papers/interoperability-and-portability-approaches-in-inter-4l8j9vwa8h","2017","Journal Article","ACM Computing Surveys","Kiranbir Kaur
Sandeep Sharma
Karanjeet Singh Kahlon","10.1145/3092698","","No","Inter-connected cloud computing is an inherent evolution of Cloud Computing. Numerous benefits provided by connecting clouds have garnered attraction from the academic as well as the industry sector. Just as every new evolution faces challenges, inter-connected clouds have their own set of challenges such as security, monitoring, authorization and identity management, vendor lock-in, and so forth. This article considers the vendor lock-in problem, which is a direct consequence of the lack of interoperability and portability. An extensive literature review by surveying more than 120 papers has been done to analyze and categorize various solutions suggested in literature for solving the interoperability and portability issues of inter-connected clouds. After categorizing the solutions, the literature has been mapped to a specific solution and a comparative analysis of the papers under the same solution has been done. The term “inter-connected clouds” has been used generically in this article to refer to any collaboration of clouds which may be from the user side (Multi-clouds or Aggregated service by Broker) or the provider side (Federated clouds or Hybrid clouds). Lastly, two closely related issues (Brokers and Meta-scheduling) and the remaining challenges of inter-connected clouds are discussed."
"Hybrid Clouds: Implementation and obstacles","https://scispace.com/papers/hybrid-clouds-implementation-and-obstacles-3m8v3kktgj","2016","","","Victor Bylin","","","Yes","Hybrid cloud is the approach companies want to adopt for its future in the cloud since hybrid cloud allows you to boost the capacity or the capability of a cloud service by aggregation, integration ..."
"Multi Cloud &amp; Hybrid Cloud Architecture Patterns for Fintech Space","https://scispace.com/papers/multi-cloud-hybrid-cloud-architecture-patterns-for-fintech-3v5c8oim0ub8","2022","Journal Article","Journal of Civil Engineering Research & Technology","Ramasankar Molleti -","10.47363/jcert/2022(4)e101","","No","This technical report aims at exploring multi-cloud and hybrid cloud architecture concern to the fintech industry. First, it provides a brief introduction to Cloud computing; second, it explores the fundamentals of multi-cloud and hybrid cloud and discusses them in the context of financial technology organizations. This paper compares the strengths and weaknesses of these architectures, identifies future trends, and provides guidance for fintech firms seeking cloud migration best practices."
"Smart System for Multi-Cloud Pathways","https://scispace.com/papers/smart-system-for-multi-cloud-pathways-2lthdve7","2022","Journal Article","","I. Banipal
Shubhi Asthana","10.1109/BigData55660.2022.10021041","","No","Enterprises are rapidly working on strategies to migrate their applications to cloud. Multi-cloud allows mixing and matching multiple cloud vendors when migrating thousands of applications based on their set of requirements and various different types of constraints. To utilize the advantages of different clouds, achieve maximum flexibility and avoid concentration risk, enterprises spread their applications across cloud providers. But this activity is not trivial as it would require honoring the constraints which the customer has, and at the same time generating the most optimal configuration of cloud resources.There are a few challenges associated with this. Firstly, the applications to be migrated need to be documented well, in order to migrate them successfully. Some applications may be very old (legacy) and need an architect overhaul which means the cloud feasibility needs to be checked. Also, enterprises would like to have an optimal list of cloud vendors that satisfy their need. To overcome these challenges, we propose a smart system for determining multi-cloud pathway for applications. The system identifies cloud feasible applications, understands their requirements and recommends optimal set of cloud vendors honoring their constraints. This is enabled through Reinforcement Learning with Human-in-the-Loop. We show our results with a use case from real world scenario."
"The Prospects for Multi-Cloud Deployment of SaaS Applications with Container Orchestration Platforms","https://scispace.com/papers/the-prospects-for-multi-cloud-deployment-of-saas-12jdm1z61r","2016","Proceedings Article","International Middleware Conference","Vincent Reniers","10.1145/3009925.3009930","","No","Recent years have seen an increased adoption of container technology for software deployment and lightweight virtualization. More recently, container orchestration systems provide a platform for container deployment and management of cluster resources.Software-as-a-Service (SaaS) providers traditionally make use of middleware to facilitate multi-tenancy in a federated cloud. Container orchestration presents many opportunities in achieving scalability and providing cost-efficient multi-tenancy. In this paper, we outline opportunities and challenges for multi-cloud deployment of containerized SaaS applications."
"Future of cloud computing: Innovations in multi-cloud and hybrid architectures","https://scispace.com/papers/future-of-cloud-computing-innovations-in-multi-cloud-and-1fgzezeq2iqb","2019","Journal Article","World Journal Of Advanced Research and Reviews","Bangar Raju Cherukuri","10.30574/wjarr.2019.1.1.0002","","No","In this article, the author discusses new trends associated with multi-cloud and hybrid cloud realigning Enterprise ICT. I examined complex requirements, multitasking, business benefits of multi-cloud solutions, and hybrid-cloud implementing multiple CSPs with public and private, engaging that multi-cloud and hybrid architectures are how businesses can achieve flexibility, scalability, and great resiliency. Such improvements relate to significant issues like vendor capture, security issues, and runtime performance optimization. The paper also analyzes some case examples of such enterprises to discuss their experience, lessons learned, and results achieved. In this empirical review, the authors analyze performance indicators, describe potential scenarios, and classify such tactics as valuable in achieving increased critical enterprise flexibility and utilization. Besides, the discussion covers integration issues, skills shortage, and costs and provides practical solutions for the implementation process. Therefore, while claiming the applicability of the multi-cloud and hybrid-cloud approaches to scalability and security, this article reveals critical facts about their future for the further development of cloud services to enterprises."
"Good Bye Vendor Lock-in: Getting your Cloud Applications Multi-Cloud Ready!","https://scispace.com/papers/good-bye-vendor-lock-in-getting-your-cloud-applications-2rgqjlx87u","2019","Proceedings Article","IEEE/ACM International Conference Utility and Cloud Computing","Marta Rozanska
Kyriakos Kritikos","10.1145/3368235.3370267","","No","Clouds offer significant advantages over traditional cluster computing architectures including flexibility, high-availability, ease of deployment, and on-demand resource allocation -- all packed up in an attractive pay-as-you-go economic model for the users. However, cloud users are often forced into vendor lock-in due to the use of incompatible APIs, cloud-specific services, and complex pricing models of the cloud service providers (CSPs). Cloud management platforms (CMPs), supporting hybrid and multi-cloud deployment, offer an answer by providing a unified abstract interface to multiple cloud platforms. Nonetheless, modelling applications to use multi-clouds, automated resource selection based on user requirements from various available CSPs, cost optimization, security, and runtime adaptation of deployed applications still remain a challenge. In this tutorial, we provide a practical introduction to multi-cloud application modelling, configuration, deployment, and adaptation. We survey existing CMPs, compare their features and modelling methods. Finally, we provide a practical hands-on training for getting your applications ready for multi-cloud using selected tools. By the end of this tutorial, attendees should be able to understand the benefits of the multi-cloud approach, and prepared to deploy their first managed multi-cloud application."
"Towards Model-Driven Multi-Cloud Resource Management","https://scispace.com/papers/towards-model-driven-multi-cloud-resource-management-4pg5jv6gpo","2016","","","Fawaz Paraiso
Stéphanie Challita
Yahya Al-Dhuraibi
Philippe Merle","","https://hal.inria.fr/hal-01534785/document","Yes","Multi-Cloud computing has established itself as a paradigm of choice for acquiring resources from different providers and get the best of each of them to run their applications. However, managing resources in Multi-Cloud remains a challenging task. Several multi-cloud libraries based approaches include Apache Libcloud, Apache jclouds, δ-cloud, Daseincloud, fog, and pkgcloud exist in the cloud market. But these are still low level as Multi-Cloud management tasks must always be programmed. Therefore, application platforms are need to help developers to succeed. In this paper we give a model-driven approach for managing resources of multiple clouds at high level. We illustrate our proposal by providing a prototype of Multi-Cloud Designer for managing resource from multiple clouds."
"Optimizing Cloud Computing Performance: A Comparative Study of Hybrid and Multi-Cloud Architectures","https://scispace.com/papers/optimizing-cloud-computing-performance-a-comparative-study-vl7w2k9hy24m","2024","Journal Article","Journal of Sustainable Solutions.","Mukta Sharma","10.36676/j.sust.sol.v1.i4.47","","No","The scalability, flexibility, and cost-efficiency offered by cloud computing have completely transformed the way organisations and enterprises handle their IT infrastructure. There has been a lot of buzz around hybrid and multi-cloud architectures recently due to the rising demand for efficient and dependable cloud services. To prevent vendor lock-in and increase redundancy, hybrid cloud architectures mix on-premises infrastructure with public and private cloud environments, while multi-cloud makes use of numerous cloud service providers. The performance optimisation methodologies of hybrid and multi-cloud systems are the main subject of this paper's comparative investigation. Using metrics like efficiency, adaptability, security, scalability, and performance, we compare and contrast the two designs and highlight their respective benefits and drawbacks. We also investigate and assess the effects of numerous optimisation methods on the system's overall performance, such as load balancing, resource allocation, and network performance management. The study's overarching goal is to help businesses optimise their cloud computing strategies by illuminating the factors that should be considered when choosing an architecture."
"Autonomous Multi-Cloud Application Deployment and Optimized Management Using Open Source Frameworks","https://scispace.com/papers/autonomous-multi-cloud-application-deployment-and-optimized-1d5qeuevs6","2020","Proceedings Article","International Conference on Autonomic Computing","Marta Rozanska
Geir Horn","10.1109/ACSOS-C51401.2020.00072","","No","The dynamic development of Cloud Computing with the introduction of novel Cloud Computing models creates new challenges for the Cloud deployment. This tutorial describes how to implement Multi-Cloud native strategies using an advanced open source framework that allows for Cloud agnostic Cross-Cloud deployment and optimized management of a Cloud application based on flexible monitoring, context aware maximization of the application owner’s utility of the deployed application, and autonomic reconfiguration based on the application’s current execution context. In this tutorial, we provide a practical introduction to the Multi-Cloud application modelling, configuration, deployment, and adaptation. All stages of the Cloud deployment planning and designing process will be shown. Also, all the key steps in the deployment and autonomic application management will be demonstrated."
"Hybrid Clouds Arising from Software as a Service Adoption: Challenges, Solutions, and Future Research Directions","https://scispace.com/papers/hybrid-clouds-arising-from-software-as-a-service-adoption-2olp1iwj","2022","Journal Article","ACM Computing Surveys","Michael J. Seifert
Stephan Kühnel
Stefan Sackmann","10.1145/3570156","https://scispace.com/pdf/hybrid-clouds-arising-from-software-as-a-service-adoption-2olp1iwj.pdf","Yes","Information technology (IT) departments are increasingly challenged to replace legacy applications with novel public cloud software as a service (SaaS) to innovate the organization's business processes. The resulting hybrid cloud is formed by integrating the added SaaS with existing IT services. The decision to adopt SaaS in such a hybrid cloud service composition requires appropriate consideration of the respective service level agreements (SLA) to ensure the proper execution of the supported business process. Previous studies focused strongly on cloud service selection or SLA negotiation rather than functionally desired SaaS adoption from the perspective of the hybrid cloud provider as integrator. This research paper identifies economic and technical issues in hybrid cloud arising from SaaS adoption and discusses challenges and existing solutions. A structured literature survey revealed that 52 issues in 36 identified publications are transferable to our context. These issues were classified in six different challenges. We were able to explore the relations between solution artifacts of various challenges and provide guidance for future research concerning hybrid clouds. The relations between the challenges are also found to vary in their research maturity and offer promising fields for further research."
"Policy-based Deployment in a Hybrid and Multicloud Environment","https://scispace.com/papers/policy-based-deployment-in-a-hybrid-and-multicloud-19in34eh3h","2019","Proceedings Article","International Conference on Cloud Computing and Services Science","Giuseppe Di Modica
Orazio Tomarchio
Hao Wei
Joaquín Salvachúa Rodríguez","10.5220/0007726503880395","","Yes","Hybrid and multi-cloud become prominent infrastructure strategy of enterprise. However, the complexity of such infrastructure is a considerable challenge. It is common to see that multi-cloud infrastructure is divided into several smaller units to facilitate the management. The division criteria are geolocation, cost, security, etc. Therefore, how to manage application deployment in such partitioned environment is an intriguing topic of multi-cloud management. We propose a policy-based deployment in multi-cloud infrastructure, which contains policy evaluation and TOSCA standard based orchestration. The system architecture is introduced and a case study with two empirical scenarios is discussed. The results indicate that the proposed policy-based deployment is useful in finding suitable resource and improving deployment efficiency."
"Multicloud service composition: A survey of current approaches and issues","https://scispace.com/papers/multicloud-service-composition-a-survey-of-current-2m67j50e2g","2018","Journal Article","Journal of Software: Evolution and Process","Fatma Lahmar
Haithem Mezni","10.1002/SMR.1947","","No","During the last decade, cloud computing became a natural choice to host and provide various computing resources as on‐demand services. To better satisfy user requirements, cloud services m..."
"State-of-the-Art Architectures for Interoperability of Heterogeneous Clouds","https://scispace.com/papers/state-of-the-art-architectures-for-interoperability-of-74spwjfb","2022","Proceedings Article","2022 IEEE 16th International Conference on Advanced Trends in Radioelectronics, Telecommunications and Computer Engineering (TCSET)","Anton Caceres
Larysa Globa","10.1109/tcset55632.2022.9766965","","No","Cloud computing provides convenient access to abstract computational resources over the Internet. In addition to common services like virtual machines, cloud providers are offering own proprietary domain-specific services and frameworks. The absence of common standards and interfaces makes it difficult to connect services of different clouds, migrate between them, or to distribute tasks across various providers. Extensive research in industry and academia has partially addressed the problem of vendor lock-in for cloud migration, however, no solutions are known to enable running applications in a dynamic multi-cloud infrastructure on a permanent basis. This paper describes state-of-the art of cloud infrastructure and considers the combined usage of multiple providers. It analyses approaches of multi-cloud usage that takes advantage of combining platform-specific features of different cloud providers."
"Orchestrating Hybrid Cloud Deployment: An Overview","https://scispace.com/papers/orchestrating-hybrid-cloud-deployment-an-overview-3078we4vse","2014","Journal Article","IEEE Computer","Edwin Sturrus
Olga Kulikova","10.1109/MC.2014.159","","No","Balancing enterprise control over cloud data with hybrid cloud benefits will increasingly require cloud ""orchestration."""
"A Survey on Autonomic Multi-cloud Computing","https://scispace.com/papers/a-survey-on-autonomic-multi-cloud-computing-3qnbi92p","2022","Proceedings Article","","Diego Cananea Nobrega De Azevedo
Carlos Ferraz","10.1109/CloudCom55334.2022.00015","","No","Multi-cloud computing has emerged in the last years to address problems like avoiding vendor lock-in and improving resilience in cloud computing. Recent reports have shown a growing interest from companies in this type of technology. On the other hand, architecting and managing a multi-cloud environment is more complex and brings challenges to be tackled. This work aims to understand how autonomic computing (AC) can help to solve multi-cloud problems. We surveyed six research databases and applied a methodology using objective criteria to select studies and analyze them. The results showed that complexity is the main reason for using AC. In addition, we found that most solutions are reactive and use static thresholds. Among the challenges, we noticed that a factor is the lack of standardization in both areas."
"Defining Cross-Cloud Systems","https://scispace.com/papers/defining-cross-cloud-systems-2b4xwdrail","2016","Posted Content","arXiv: Distributed, Parallel, and Cluster Computing","Yehia Elkhatib","","https://arxiv.org/pdf/1602.02698.pdf","Yes","Recent years have seen an increasing number of cross-cloud architectures, i.e. systems that span across cloud provisioning boundaries. However, the cloud computing world still lacks any standards in terms of programming interfaces, which has a knock-on effect on the costs associated with interoperability and severely limits the flexibility and portability of applications and virtual infrastructures. This paper outlines the different types of cross-cloud systems, and the associated design decisions."
"An Approach to Orchestrating and Connecting Workloads Across Multi-clouds","https://scispace.com/papers/an-approach-to-orchestrating-and-connecting-workloads-across-4xcat9np","2022","Book Chapter","International Conference on P2P, Parallel, Grid, Cloud and Internet Computing","Humberto José de Sousa
Douglas Dyllon Jeronimo de Macedo","10.1007/978-3-031-19945-5_4","","No","AbstractNowadays, cloud providers cannot serve applications with low latency requirements. It is possible to run applications closer to the user through Fog and Edge computing. This article presents an architecture capable of orchestrating applications across multi-clouds. We used a fake application composed of six microservices to measure its latency in five different scenarios. Tests showed that the orchestrator allowed connecting data centers in different regions. It was also possible for applications in different data centers to communicate directly through proxies and with security. We observed that in scenarios where part of the microservices ran only on Fog or Fog and Edge, there was lower latency than microservices running on the cloud.KeywordsOrchestrationMulti-cloudService mesh"
"A Survey of Resource Management Challenges in Multi-cloud Environment: Taxonomy and Empirical Analysis","https://scispace.com/papers/a-survey-of-resource-management-challenges-in-multi-cloud-2gfikxs79s","2018","Journal Article","IEEE International Conference on High Performance Computing, Data, and Analytics","Bandar Aldawsari
Thar Baker
Muhammad Asim
Zakaria Maamar
Dhiya Al-Jumeily
Mohammed Al-Khafajiy","10.32010/26166127.2018.1.1.51.65","https://scispace.com/pdf/a-survey-of-resource-management-challenges-in-multi-cloud-2gfikxs79s.pdf","Yes","Cloud computing has seen a great deal of interest by researchers and industrial firms since its first coined Different perspectives and research problems, such as energy efficiency, security and threats, to name but a few, have been dealt with and addressed from cloud computing perspective However, cloud computing environment still encounters a major challenge of how to allocate and manage computational resources efficiently Furthermore, due to the different architectures and cloud computing networks and models used (ie, federated clouds, VM migrations, cloud brokerage), the complexity of resource management in the cloud has been increased dramatically Cloud providers and service consumers have the cloud brokers working as the intermediaries between them, and the confusion among the cloud computing parties (consumers, brokers, data centres and service providers) on who is responsible for managing the request of cloud resources is a key issue In a traditional scenario, upon renting the various cloud resources from the providers, the cloud brokers engage in subletting and managing these resources to the service consumers However, providers’ usually deal with many brokers, and vice versa, and any dispute of any kind between the providers and the brokers will lead to service unavailability, in which the consumer is the only victim Therefore, managing cloud resources and services still needs a lot of attention and effort This paper expresses the survey on the systems of the cloud brokerage resource management issues in multi-cloud environments"
"Supporting the Development and Operation of Multi-cloud Applications: The MODAClouds Approach","https://scispace.com/papers/supporting-the-development-and-operation-of-multi-cloud-4zlu5eqyb6","2013","Proceedings Article","Symbolic and Numeric Algorithms for Scientific Computing","Elisabetta Di Nitto
Marcos Aurélio Almeida da Silva
Danilo Ardagna
Giuliano Casale
Ciprian Dorin Craciun
Nicolas Ferry
Victor Muntes
Arnor Solberg","10.1109/SYNASC.2013.61","","No","Vendor lock-in and cloud outages are two importantchallenges that make IT managers reluctant in widely adopting thecloud within the enterprise. Vendor lock-in happens when the adoptionof cloud provider-specific technologies and APIs forces consumers tostay with the same provider even if they would like to change. Cloudoutages can happen to any provider, as the events of the last yearshave largely demonstrated, and have a critical impact on the actualreliability of cloud applications. A solution to both problems couldbe to support application developers and operators in the adoption ofa multi-cloud approach: applications are built to run andreplicate on different clouds, and mechanisms for fast switching froma cloud installation to the other are offered. In the MODACloudsproject we pursue this approach and rely on model-driven developmentcombined with risk analysis and quality prediction. In this paper weprovide an overview of our approach and present the architecture ofthe corresponding platform."
"Conductor: orchestrating the clouds","https://scispace.com/papers/conductor-orchestrating-the-clouds-1yxjy4wky1","2010","Proceedings Article","","Alexander Wieder
Pramod Bhatotia
Ansley Post
Rodrigo Rodrigues","10.1145/1859184.1859197","","No","Cloud computing enables customers to access virtually unlimited resources on demand and without any fixed upfront cost. However, the commoditization of computing resources imposes new challenges in how to manage them: customers of cloud services are no longer restricted to the resources they own, but instead choose from a variety of different services offered by different providers, and the impact of these choices on price and overall performance is not always clear. Furthermore, having to take into account new cloud products and services, the cost of recovering from faults, or price fluctuations due to spot markets makes the picture even more unclear.This position paper highlights a series of challenges that must be overcome in order to allow customers to better lever-age cloud resources. We also make the case for a system called Conductor that automatically manages resources in cloud computing to meet user-specifiable optimization goals, such as minimizing monetary cost or completion time. Finally, we discuss some of the challenges we will face in building such a system."
"Cloud implementation orchestration","https://scispace.com/papers/cloud-implementation-orchestration-2v5nw3wjzm","2014","Patent","","Rajeev Pandey
Matthew Farina","","","No","In one implementation, a cloud orchestration system can comprise a solution engine, a configuration engine, and an implementation engine. The solution engine can receive an implementation selection of a service. The implementation selection can be based on a plurality of implementations of a cloud to provide the service. The configuration engine can obtain configuration information associated with the implementation selection. The implementation engine can communicate with an endpoint of the service based on the implementation selection and the configuration information. In another implementation, a method for orchestration of a cloud can comprise receiving an implementation selection for a solution of a service, collecting configuration information associated with the implementation selection, instantiating the solution based on the implementation selection and the configuration information, and providing connection information associated with the solution."
"TORCH: a TOSCA-Based Orchestrator of Multi-Cloud Containerised Applications","https://scispace.com/papers/torch-a-tosca-based-orchestrator-of-multi-cloud-47eum5p59m","2021","Journal Article","Journal of Grid Computing","Orazio Tomarchio
Domenico Calcaterra
Giuseppe Di Modica
Pietro Mazzaglia","10.1007/S10723-021-09549-Z","https://scispace.com/pdf/torch-a-tosca-based-orchestrator-of-multi-cloud-47eum5p59m.pdf","Yes","The growth in the number and types of cloud-based services offered to IT customers is supported by the constant entry of new actors in the market and the consolidation of disruptive technologies such as AI, Big Data and Micro-services. From the customer’s perspective, in a market landscape where the cloud offer is highly diversified due to the presence of multiple competing service providers, picking the service that best accommodate their specific needs is a critical challenge. Once the choice is made, so called “cloud orchestration tools” (orchestrators) are required to take care of the customer application’s life-cycle. While big players offer their customers proprietary orchestrators, in the literature quite a number of open-source initiatives have launched multi-cloud orchestrators capable of transparently managing applications on top of the most representative cloud platforms. In this paper, we propose TORCH, a TOSCA-based framework for the deployment and orchestration of cloud applications, both classical and containerised, on multiple cloud providers. The framework assists the cloud customer in defining application requirements by using standard specification models. Unlike other multi-cloud orchestrators, adopts a strategy that separates the provisioning workflow from the actual invocation of proprietary cloud services API. The main benefit is the possibility to add support to any cloud platforms at a very low implementation cost. In the paper, we present a prototypal implementation of TORCH and showcase its interaction with two different container-based cluster platforms. Preliminary performance tests conducted on a small-scale test-bed confirm the potential of TORCH."
"Support Services for Applications Execution in Multi-clouds Environments","https://scispace.com/papers/support-services-for-applications-execution-in-multi-clouds-3pech294yb","2016","Proceedings Article","International Conference on Autonomic Computing","Daniel Pop
Gabriel Iuhasz
Ciprian Craciun
Silviu Panica","10.1109/ICAC.2016.19","","No","Deploying and running applications in multi-cloud environments is a challenging task for a number of reasons:different configuration parameters are needed for differentcloud environments, application's artefacts may vary acrosstechnologies or cloud providers, services provided at IaaSlevel vary from one cloud provider to another. This paperintroduces a run-time platform that enables the deploymentand execution of applications on multi-clouds with guaranteedquality of service (QoS), and details the underlying services ofthe unified layer responsible for connecting to multiple IaaScloud providers, which avoids runtime lock-in and simplifiesthe management of cloud applications."
"A Framework for Controlling and Managing Hybrid Cloud Service Integration","https://scispace.com/papers/a-framework-for-controlling-and-managing-hybrid-cloud-27dda2gpgx","2013","Proceedings Article","IEEE International Conference on Cloud Engineering","G. Breiter
Vijay K. Naik","10.1109/IC2E.2013.48","","No","In this paper, we first describe the challenges and pain points of adopting off-premise cloud-based computing services by enterprise users. To address these challenges, we have developed a hybrid cloud architectural framework for controlling and managing network of integrated computing services in on- and off-premise cloud environments. We identify three types of integration patterns that are commonly observed and describe support in the hybrid cloud framework for such patterns. The framework allows creation, modification, and management of integrated hybrid cloud services. Using this framework, we describe how solutions can be designed for policy-based access to cloud services from on-premise environments and for policy-based secure access to on premise data from off-premise cloud based services. The framework offers capabilities for (i) on-demand capacity expansion or cloud-bursting, (ii) service composition and management across multiple cloud domains, (iii) unification and customization of service offerings from multiple cloud service providers, (iv) seamless integration of common workload management services such monitoring, metering, and security, and (v) unified governance of IT operation across the hybrid cloud. We then describe a realization of this architecture that has served as the basis of IBM's hybrid cloud solution offerings and describe how the hybrid cloud framework described here mitigates some of cloud adoption risks and lowers or eliminates the inhibitors."
"A declarative approach for service enablement on hybrid cloud orchestration engines","https://scispace.com/papers/a-declarative-approach-for-service-enablement-on-hybrid-5aipnz1otq","2018","Proceedings Article","Network Operations and Management Symposium","Asthana Neeraj
Tom Chefalas
Alexei Karve
Alla Segal
Mahika Dubey
Sai Zeng","10.1109/NOMS.2018.8406175","","No","The rapidly increasing complexity and scale of hybrid cloud environments requires improved service management capabilities in orchestration and automation. Current methods focus on provisioning infrastructure but lack functionality for consistently enabling and performing operational activities on managed services. We propose a data-driven approach to dynamically generate Orchestration Engine plugins from service descriptor metadata. Our approach extends Orchestration Engines by representing managed services as code within reusable blueprints in order to accelerate service deployments and ease management activities. In our work, we provide a data model and system architecture to allow service providers to easily author and publish resource definitions for a wide range of public and private services. These definitions may be combined into solution blueprints, forming a declarative and reusable representation of a managed workload. After provisioning a workload, administrators can view service instance data and invoke operational activities. For evaluation, we describe the authoring and orchestration of a hybrid cloud workload and discuss the strengths of our solution versus current methods."
"Orchestrating Complex Application Architectures in Heterogeneous Clouds","https://scispace.com/papers/orchestrating-complex-application-architectures-in-27324j1t7p","2018","Journal Article","Journal of Grid Computing","Miguel Caballer
Sahdev Zala
Álvaro López García
Germán Moltó
Pablo Orviz Fernández
Mathieu Velten","10.1007/S10723-017-9418-Y","https://scispace.com/pdf/orchestrating-complex-application-architectures-in-27324j1t7p.pdf","Yes","Private cloud infrastructures are now widely deployed and adopted across technology industries and research institutions. Although cloud computing has emerged as a reality, it is now known that a single cloud provider cannot fully satisfy complex user requirements. This has resulted in a growing interest in developing hybrid cloud solutions that bind together distinct and heterogeneous cloud infrastructures. In this paper we describe the orchestration approach for heterogeneous clouds that has been implemented and used within the INDIGO-DataCloud project. This orchestration model uses existing open-source software like OpenStack and leverages the OASIS Topology and Specification for Cloud Applications (TOSCA) open standard as the modeling language. Our approach uses virtual machines and Docker containers in an homogeneous and transparent way providing consistent application deployment for the users. This approach is illustrated by means of two different use cases in different scientific communities, implemented using the INDIGO-DataCloud solutions."
"CloudMF: Model-Driven Management of Multi-Cloud Applications","https://scispace.com/papers/cloudmf-model-driven-management-of-multi-cloud-applications-3ie17uboqd","2018","Journal Article","ACM Transactions on Internet Technology","Nicolas Ferry
Franck Chauvel
Hui Song
Alessandro Rossini
Maksym Lushpenko
Arnor Solberg","10.1145/3125621","","No","While the number of cloud solutions is continuously increasing, the development and operation of large-scale and distributed cloud applications are still challenging. A major challenge is the lack of interoperability between the existing cloud solutions, which increases the complexity of maintaining and evolving complex applications potentially deployed across multiple cloud infrastructures and platforms. In this article, we show how the Cloud Modelling Framework leverages model-driven engineering and supports the DevOps ideas to tame this complexity by providing: (i) a domain-specific language for specifying the provisioning and deployment of multi-cloud applications, and (ii) a modelscrun-time environment for their continuous provisioning, deployment, and adaptation."
"Distributed and Intelligent API Mediation Service for Enterprise-Grade Hybrid-Multicloud Computing","https://scispace.com/papers/distributed-and-intelligent-api-mediation-service-for-12s457yhhl","2023","Journal Article","","Hongyi Bian
Rcc Chang
Kumar Bhaskaran
Wensheng Zhang
Carl K. Chang","10.1109/sse60056.2023.00025","","No","In an enterprise-grade hybrid-multicloud computing environment, capability-providing as-a-service endpoints (or aaS-endpoints) can be deployed across diverse computing platforms, e.g., public clouds and on-prem enterprise private clouds. To ensure a seamless, unified, and enterprise-compliant acquisition of the capabilities by client applications, the presence of a cross-cloud API mediation service is crucial. However, as the number and heterogeneity of aaS-endpoints increase, delivering the API mediation service at scale becomes increasingly costly. This paper presents a robust approach to API service mediation in enterprise-grade hybrid-multicloud computing environments. It tackles the challenges, offering a distributed architecture comprising dynamically composed managed microservices, microservice zones, intelligent endpoint selection, and adaptive statistical learning (aiming to exploit localities in performance history of aaS-endpoint invocations and to facilitate adding or removing active aaS-endpoints). The successful reference implementation and <tex xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">$24\mathrm{x}7\mathrm{x}365$</tex> delivery in real-world settings of the approach validate its efficacy as a practical solution for API service mediation."
"Cost Minimization in Multi-cloud Systems with Runtime Microservice Re-orchestration","https://scispace.com/papers/cost-minimization-in-multi-cloud-systems-with-runtime-3ig1zwiy3q","2024","Journal Article","arXiv.org","Marco Zambianco
Silvio Cretti
Domenico Siracusa","10.48550/arxiv.2401.01408","","No","Multi-cloud systems facilitate a cost-efficient and geographically-distributed deployment of microservice-based applications by temporary leasing virtual nodes with diverse pricing models. To preserve the cost-efficiency of multi-cloud deployments, it is essential to redeploy microservices onto the available nodes according to a dynamic resource configuration, which is often performed to better accommodate workload variations. However, this approach leads to frequent service disruption since applications are continuously shutdown and redeployed in order to apply the new resource assignment. To overcome this issue, we propose a re-orchestration scheme that migrates microservice at runtime based on a rolling update scheduling logic. Specifically, we propose an integer linear optimization problem that minimizes the cost associated to multi-cloud virtual nodes and that ensures that delay-sensitive microservices are co-located on the same regional cluster. The resulting rescheduling order guarantees no service disruption by repacking microservices between the available nodes without the need to turn off the outdated microservice instance before redeploying the updated version. In addition, we propose a two-step heuristic scheme that effectively approximates the optimal solution at the expense of close-to-zero service disruption and QoS violation probability. Results show that proposed schemes achieve better performance in terms of cost mitigation, low service disruption and low QoS violation probability compared to baseline schemes replicating Kubernetes scheduler functionalities."
"Disruption-aware Microservice Re-orchestration for Cost-efficient
  Multi-cloud Deployments","https://scispace.com/papers/disruption-aware-microservice-re-orchestration-for-cost-3dht7stgbofh","2025","Journal Article","","Marco Zambianco
Silvio Cretti
Domenico Siracusa","10.48550/arxiv.2501.16143","https://scispace.com/pdf/disruption-aware-microservice-re-orchestration-for-cost-3dht7stgbofh.pdf","No","Multi-cloud environments enable a cost-efficient scaling of cloud-native applications across geographically distributed virtual nodes with different pricing models. In this context, the resource fragmentation caused by frequent changes in the resource demands of deployed microservices, along with the allocation or termination of new and existing microservices, increases the deployment cost. Therefore, re-orchestrating deployed microservices on a cheaper configuration of multi-cloud nodes offers a practical solution to restore the cost efficiency of deployment. However, the rescheduling procedure causes frequent service interruptions due to the continuous termination and rebooting of the containerized microservices. Moreover, it may potentially interfere with and delay other deployment operations, compromising the stability of the running applications. To address this issue, we formulate a multi-objective integer linear programming problem that computes a microservice rescheduling solution capable of providing minimum deployment cost without significantly affecting the service continuity. At the same time, the proposed formulation also preserves the quality of service (QoS) requirements, including latency, expressed through microservice colocation constraints. Additionally, we present a heuristic algorithm to approximate the optimal solution, striking a balance between cost reduction and service disruption mitigation. We integrate the proposed approach as a custom plugin of the Kubernetes scheduler. Results reveal that our approach significantly reduces multi-cloud deployment costs and service disruptions compared to the default Kubernetes scheduler implementation, while ensuring QoS requirements are consistently met."
"A provider-agnostic approach to multi-cloud orchestration using a constraint language","https://scispace.com/papers/a-provider-agnostic-approach-to-multi-cloud-orchestration-3jp5e077cp","2018","Proceedings Article","IEEE/ACM International Symposium Cluster, Cloud and Grid Computing","Daniel Baur
Daniel Seybold
Frank Griesinger
Hynek Masata
Jörg Domaschka","10.1109/CCGRID.2018.00032","https://scispace.com/pdf/a-provider-agnostic-approach-to-multi-cloud-orchestration-3jp5e077cp.pdf","Yes","Cloud computing and its computing as an utility paradigm provides on-demand resources allowing the seamless adaptation of applications to fluctuating demands While the Cloud's ongoing commercialisation has lead to a vast provider landscape, vendor lock-in is still a major hindrance Recent outages demonstrate that relying exclusively on one provider is not sufficient While existing cloud orchestration tools promise to solve the problems by supporting deployments across multiple cloud providers, they typically rely on provider dependent models forcing prior knowledge of offers and obstructing flexibility in case of errors We propose a cloud provider-agnostic application and resource description using a constraint language It allows users to express resource requirements of an application without prior knowledge of existing offers Additionally, we propose a discovery service automatically collecting available offers We combine this with a matchmaking algorithm representing the discovery model and the user-given constraints in a constraint satisfaction problem (CSP) that is then solved Finally, we manipulate this discovery model during runtime to react on errors Our evaluation shows that using a constraint-based language is a feasible approach to the provider selection problem, and that it helps to overcome vendor lock-in"
"PacificClouds: A Flexible MicroServices based Architecture for Interoperability in Multi-Cloud Environments.","https://scispace.com/papers/pacificclouds-a-flexible-microservices-based-architecture-2o6vmysod3","2018","Proceedings Article","International Conference on Cloud Computing and Services Science","Juliana Oliveira de Carvalho
Fernando Trinta
Dario Vieira","10.5220/0006705604480455","","Yes","Cloud Computing has become a popular IT service delivery model in recent years. While the cloud brings several benefits, there are still some challenges that need to be overcome to apply the cloud model in certain scenarios. One such problem is the so-called vendor lock-in since different cloud providers offer peculiar and often incompatible services, which results in the automatic migration impossibility of the application between cloud providers. This issue becomes even more problematic when thinking of future applications composed of services or components hosted by different cloud providers in a multi-cloud environment. Dealing with vendor lock-in in multiple clouds requires addressing two important challenges: interoperability and portability. Some solutions have been proposed to deal with both problems, but most of them fail to provide flexibility. Therefore, we propose PacificClouds, a novel architecture based on microservices for addressing interoperability in a multi-cloud environment. PacificClouds differs from previous works by providing greater flexibility due to the microservices architectural pattern. In this article, we also propose a definition of microservices and a comparative analysis of the works related to PacificClouds. Finally, we show the main challenges of PacificClouds, and we point out the future directions."
"Consuming Resources and Services from Multiple Clouds","https://scispace.com/papers/consuming-resources-and-services-from-multiple-clouds-48euyq57up","2014","Journal Article","Grid Computing","Dana Petcu","10.1007/S10723-013-9290-3","","No","The consumption of resources and services from multiple Clouds for reasons like high availability, cost reductions or special features is a natural evolution from in-silo Clouds. Several middleware are already available for multiple Clouds. However, due to the complexity of the technical solutions, their approaches are quite different and a classification is needed to guide the potential users. This paper looks to the reports on multiple Cloud topics and proposes a specific taxonomy. It identifies the ready-to-use software and services and classifies them according the taxonomy. It also underlines the driving needs and requirements from consumers' and providers' point of views. A particular Cloudware is provided as an example for the degree of requirements fulfillment."
"Deployment Management and Topology Discovery of Microservice Applications in the Multicloud Environment","https://scispace.com/papers/deployment-management-and-topology-discovery-of-microservice-3cxinyg8ng","2021","Journal Article","Journal of Grid Computing","Hao Wei
Joaquín Salvachúa Rodríguez
Octavio Nieto-Taladriz García","10.1007/S10723-021-09539-1","","No","Cloud computing enables the evolution of modern software application design. Applications based on microservice architecture are an example. Meanwhile, multiclouds are widely accepted by enterprise as an infrastructure strategy; however, challenges remain. The autonomous and distributable nature of modern applications, as well as the complexity of multicloud infrastructure, often make universal application deployment management impractical. This phenomenon may further hinder application quality and efficiency. Therefore, deployment resource control and topology discovery in the multicloud infrastructure environment is an intriguing area of cloud computing research. This paper proposes a framework to manage application deployment in the multicloud environment. The framework uses a policy-based deployment control to automatically select and provide deployment resources from the multicloud infrastructure, and it subsequently uses topology discovery to visualize and verify the actual deployment. The proposed framework design is introduced in the paper, and a proof-of-concept prototype is implemented. Experiments in empirical scenarios are conducted. The experimental results indicate that the proposed framework is effective in controlling deployment resources and presenting actual deployment across clouds."
"Orchestration engine blueprint aspects for hybrid cloud composition","https://scispace.com/papers/orchestration-engine-blueprint-aspects-for-hybrid-cloud-4b2lceztwy","2019","Patent","","Asthana Neeraj
Chefalas Thomas
Karve Alexei
Pickover Clifford","","","No","Techniques that facilitate orchestration engine blueprint aspects for hybrid cloud composition are provided. In one example, a system includes a learning component and a hybrid cloud composition component. The learning component learns one or more blueprint-level aspects associated with information for one or more computing resources of a cloud-based computing platform based on historical data associated with the cloud-based computing platform. The hybrid cloud composition component generates a set of resource definitions for the cloud-based computing platform based on the one or more blueprint-level aspects. The hybrid cloud composition component also modifies a blueprint associated with the cloud-based computing platform based on the set of resource definitions."
"Heterogeneous Resource Management and Orchestration in Cloud Environments","https://scispace.com/papers/heterogeneous-resource-management-and-orchestration-in-cloud-3f2gwdd9ai","2017","Book Chapter","International Conference on Cloud Computing and Services Science","Dapeng Dong
Huanhuan Xiong
Gabriel G. Castañé
Paul Stack
John P. Morrison","10.1007/978-3-319-94959-8_4","","No","The addition of heterogeneous resources to conventional homogeneous cloud environments has enabled clouds to embrace a wide variety of new applications that heretofore were traditionally confined to specialized computing environments The enhanced and extended features offered by heterogeneous resources enable service offerings that pose challenges to traditional cloud management throughout the entire service delivery stack The accelerated uptake of heterogeneous resources is exacerbating these challenges, which no longer can be efficiently addressed in an ad-hoc manner Therefore, an integrated approach to heterogeneous resource management that is cognizant of the unique advantages of different hardware types is needed In this paper, two candidate approaches, a platform-integration scheme and a server-integration scheme, are introduced to address this management challenge The platform-integration scheme integrates and coordinates the management of various coexisting resource managers and associated environments each of which may be managing resources of different types using the most appropriate resource abstraction method In contrast, the server-integration scheme provides a single, lower level, fine-grained management mechanism across all hardware resource types Ultimately, the goal of each schemes is to provide a unified view of resources from a capability perspective to consumers"
"Cloud orchestration features: are tools fit for purpose?","https://scispace.com/papers/cloud-orchestration-features-are-tools-fit-for-purpose-41nzhps00l","2015","Proceedings Article","IEEE/ACM International Conference Utility and Cloud Computing","Daniel Baur
Daniel Seybold
Frank Griesinger
Athanasios Tsitsipas
Christopher B. Hauser
Jörg Domaschka","10.1109/UCC.2015.25","","Yes","Even though the cloud era has begun almost one decade ago, many problems of the first hour are still around. Vendor lock-in and poor tool support hinder users from taking full advantage of main cloud features: dynamic and scale. This has given rise to tools that target the seamless management and orchestration of cloud applications. All these tools promise similar capabilities and are barely distinguishable what makes it hard to select the right tool. In this paper, we objectively investigate required and desired features of such tools and give a definition of them. We then select three open-source tools (Brooklyn, Cloudify, Stratos) and compare them according to the features they support using our experience gained from deploying and operating a standard three-tier application. This exercise leads to a fine-grained feature list that enables the comparison of such tools based on objective criteria as well as a rating of three popular cloud orchestration tools. In addition, it leads to the insight that the tools are on the right track, but that further development and particularly research is necessary to satisfy all demands."
"Towards a Classification of Multiple-Cloud Computing Concepts and Terms","https://scispace.com/papers/towards-a-classification-of-multiple-cloud-computing-10bxfytw38","2014","Book Chapter","European Conference on Service-Oriented and Cloud Computing","Hassan Saad Alqahtani
Ghita Kouadri-Mostefaoui","10.1007/978-3-319-14886-1_25","","No","In order to enhance the quality of the delivered services, dependency avoidance, and operational costs optimization, the multiple-cloud computing emerged. The complexity of multiple-clouds causes a lot of opacity in the definitions and classifications. This paper attempts to provide an accurate definition of the multiple-clouds and, a classification of the available types based on a set of pre-defined criteria. It also outlines the differences between the terms that have been used to refer to the multiple-cloud computing concept."
"Model driven advanced hybrid cloud services for big data: paradigm and practice","https://scispace.com/papers/model-driven-advanced-hybrid-cloud-services-for-big-data-4m36t557zz","2016","","","Xi Yang
Tom Lehman","10.5555/3018100.3018105","","Yes","Advanced hybrid cloud services aim to serve big data applications by bridging multi-provider high performance cloud resources including direct connects, hypervisor bypassing VM interfaces, on premise clusters, parallel storage and high speed inter-cloud networks. We present a new ""full-stack model driven orchestration"" paradigm to integrate these diverse resources through semantic modeling and provide complex high-end services through dynamic orchestrated workflows. We also present architectural design of a real-world orchestration system, VersaStack, that implements the paradigm as well as a case study for providing full-scale advanced hybrid cloud services in practice."
"Characterizing the architectures and brokering protocols for enabling clouds interconnection","https://scispace.com/papers/characterizing-the-architectures-and-brokering-protocols-for-3gu5f3snvt","2020","Journal Article","Concurrency and Computation: Practice and Experience","Sajid Latif
S. Mushhad M. Gilani
Liaqat Ali
Saleem Iqbal
Misbah Liaqat
Misbah Liaqat","10.1002/CPE.5676","","No","Interconnecting the computing services of different tiers by multiple cloud providers is indispensable to overcome the exponentially increasing demands of enterprises. In view of highly dynamic and unpredictable environment, cloud providers have to face numerous challenges related to service provisioning of diversified applications while handling the critical management operations on resource layers. Proper configuration and uniform development of architectural components and protocols to setup interconnected clouds are inevitable, which play effective role in management. Various approaches have been proposed by research community to interconnect the geographically dispersed clouds to extend the capabilities of standalone provider. Fundamentally, this study encompasses the requirement factors and classification of interconnected cloud management from various aspects. Mainstream resource management elements, architectural components, and brokering protocols with respect to functional impact, which proposed in literature, have been discussed. These protocols and components play pivotal role for aggregating computing services from distinct providers and maintaining the quality of service parameters of service provisioning. Finally, the analysis of various projects is also presented to highlight the functionality of collaborated ecosystem with issues and further directions."
"Aggregation of cloud providers: A review of opportunities and challenges","https://scispace.com/papers/aggregation-of-cloud-providers-a-review-of-opportunities-and-50g4k14fde","2015","Proceedings Article","International Conference on Computing, Communication and Automation","Rajni Patel
Deepak Dahiya","10.1109/CCAA.2015.7148448","","No","A single cloud provider alone is not able to satisfy the increasing demand for its services as the number of online users and services deployed by organizations grow exponentially To achieve the promises of cloud computing, the necessity of aggregating different cloud provider into a single framework emerges This concept overcomes the limitations of interoperability, portability, vendor lock in problem, scalability and elasticity of contemporary cloud computing Collaborating with different cloud providers is not an easy task because each cloud provider has different kinds of architecture, virtualization technology, service level agreement, enterprise solution and interface for accessing services This scenario is identified by many synonyms in the literature such as cloud federation, Inter-cloud, Multi-Cloud etc This paper discusses various driving forces and advantages that attract researchers towards it Further, this paper concentrates on exploring related work done in addressing different issues and finding gaps that will create opportunities for further research and development This work will tend to emerge as a step towards the next-generation enterprise solution"
"HCA Operator: A Hybrid Cloud Auto-scaling Tooling for Microservice Workloads","https://scispace.com/papers/hca-operator-a-hybrid-cloud-auto-scaling-tooling-for-1g27m5cc","2022","Proceedings Article","International Conference on Mobile Ad-hoc and Sensor Networks","Yuyang Wang
Fan Zhang
Samee U. Khan","10.1109/MSN57253.2022.00143","","No","Elastic cloud platform, e.g. Kubernetes, enables dy-namically scale in or out computing resources in accordance with the workloads fluctuation. As the cloud evolves to hybrid, where public and private clouds co-exist as the underline substrate, autoscaling applications within a hybrid cloud is no longer straightforward. The difficulty lies in all aspects, e.g. global load balancing, hybrid-cloud monitoring and alerting, storage sharing and replication, security and privacy, etc. However, it will significantly pay off if hybrid-cloud autoscaling is supported and boundless computing resources can be utilized per request. In this paper, we design Hybrid Cloud Autoscaler Operator (HCA Operator), a customized Kubernetes Controller that leverages the Kubernetes Custom Resource to auto-scale microservice applications across hybrid clouds. HCA Operator load balances across hybrid clouds, monitors metrics, and autoscales to des-tination clusters that exist in other clouds. We discuss the implementation details and perform experiments in a hybrid cloud environment. The experimental results demonstrate that if the workload changes quickly, our Operator can properly auto-scale the microservice applications across hybrid cloud in order to meet the Service Level Agreement (SLA) requirements."
"Towards Cross-Layer Monitoring of Multi-Cloud Service-Based Applications","https://scispace.com/papers/towards-cross-layer-monitoring-of-multi-cloud-service-based-2eg58ofnjr","2013","Book Chapter","European Conference on Service-Oriented and Cloud Computing","Chrysostomos Zeginis
Kyriakos Kritikos
Panagiotis Garefalakis
Konstantina Konsolaki
Kostas Magoutis
Dimitris Plexousakis","10.1007/978-3-642-40651-5_16","","No","Cloud computing is becoming a popular platform to deliver service-based applications (SBAs) based on service-oriented architecture (SOA) principles. Monitoring the performance and functionality of SBAs deployed on multiple Cloud providers (in what is also known as Multi-Cloud setups) and adapting them to variations/events produced by several layers (infrastructure, platform, application, service, etc.) in a coordinated manner are challenges for the research community. This paper proposes a monitoring framework for Multi-Cloud SBAs with two main objectives: (a) perform cross-layer (Cloud and SOA) monitoring enabling concerted adaptation actions; (b) address new challenges raised in Multi-Cloud SBA deployment. The proposed framework is empirically evaluated on a real-world Multi-Cloud setup."
"A Runtime Architecture Based Framework Managing Hybrid Clouds","https://scispace.com/papers/a-runtime-architecture-based-framework-managing-hybrid-gax1kswbjz","2015","Proceedings Article","Computer Software and Applications Conference","Xuee Zeng
Xingtu Lan
Xing Chen
Wenzhong Guo","10.1109/COMPSAC.2015.25","","No","Cloud management becomes increasingly complex and brings high costs, especially with the advent of hybrid cloud. In a hybrid cloud, numerous resources like Virtual Machines (VMs) and Physical Machines in different clouds have to be managed together to make the whole hybrid cloud work cost-effectively. For controlling the management cost, in particular the manual management cost, many programs have been developed to take over manual management tasks or reduce their complexity and difficulty. These programs are usually hard-coded by languages like Java and C++, which bring enough capability and flexibility but also cause high programming effort and cost. As the architecture-based runtime model is causally connected with the corresponding running system automatically, constructing a hybrid cloud management system based on the architecture-based runtime models of clouds can benefit from the model-specific natures, and thus reduce the development workload. This paper proposes a runtime architecture based approach to developing the management programs in a simple but powerful enough manner. First of all, the manageability (such as APIs, configuration files and scripts) of different kinds of clouds, is abstracted as a runtime architecture based model of cloud software architecture, which can automatically and immediately propagate any observable runtime changes of the target platforms to the corresponding architecture models, and vice versa. Second, we provide a unified model of cloud software architecture, according to the domain knowledge of current cloud platforms, such as Cloud Stack, Open Stack and Eucalyptus. Third, the synchronization between the unified model and cloud runtime models is ensured through model transformation, thus, all the management tasks of the hybrid cloud, could be carried out through executing programs on the unified model, which decreases the complexity of use and management. The experiment on a real-world hybrid cloud demonstrates the feasibility, effectiveness and benefits of the new approach to managing hybrid clouds."
"Advances in Applications Portability and Services Interoperability among Multiple Clouds","https://scispace.com/papers/advances-in-applications-portability-and-services-4qe84yru51","2015","Journal Article","IEEE Cloud Computing","Beniamino Di Martino
Giuseppina Cretella
Antonio Esposito","10.1109/MCC.2015.38","","No","Despite the exponential growth in available services and their broad adoption, cloud computing solutions are still heavily affected by the lack of a shared and worldwide accepted standard for their description and exposition to customers. This is reflected in the portability and interoperability issues often arising when customers try to exploit multicloud solutions. In this article the solutions proposed by the most prominent European research projects are presented, together with a set of emerging de jure and de facto standards and affirmed cloud platforms."
"Model Driven Deployment of Auto-Scaling Services on Multiple Clouds","https://scispace.com/papers/model-driven-deployment-of-auto-scaling-services-on-multiple-1xmdzav5sx","2018","Proceedings Article","","Hanieh Alipour
Yan Liu","10.1109/ICSA-C.2018.00033","","No","Hybrid cloud platforms have been adopted to facilitate different parts of services to deliver functionalities to service consumers. Each cloud platform offers elastic resource allocation, which accommodates fluctuating demands on services by automating the provision/deprovision of resources, referred as auto-scaling. In term of service deployment, auto-scaling is usually not interoperable between multiple cloud platforms. As a result, the service level auto-scaling strategy needs to be configured separately on disparate cloud platforms, which incurs difficulties in tracing the configuration and maintaining consistent deployment. This paper presents a model-driven method to connect a cloud platform independent model of services with cloud specific operations. Through the automated transformation from model to the configuration, we use cloud management tools to deliver auto-scaling deployment across clouds. We demonstrate our method with scaling configuration and deployment of an open source benchmark application - Dell DVD store on two cloud platforms, AWS and Rackspace. The experiment demonstrates our proposed method resolves the vendor lock issues by a model-to-configuration-to-deployment automation. The empirical measurement shows our method reduces the effort of deploying auto-scaling services on cloud platforms."
"Policy as Code: A paradigm shifts in infrastructure security and governance","https://scispace.com/papers/policy-as-code-a-paradigm-shifts-in-infrastructure-security-kvokzawwc4y6","2025","Journal Article","World Journal Of Advanced Research and Reviews","Sundeep Vijayaraghavan","10.30574/wjarr.2025.26.1.1441","","No","Policy as Code represents a transformative approach to infrastructure security and governance in modern cloud environments. By codifying security and compliance policies as machine-readable code, organizations can automate enforcement throughout the development lifecycle. This paradigm shift addresses the velocity gap between rapid development cycles and traditionally slower security processes, enabling consistent policy enforcement without sacrificing agility. The integration with CI/CD pipelines allows for ""shifting left"" security considerations, identifying and remediating issues before they reach production. Various implementation approaches have emerged, from open-source tools like Open Policy Agent to cloud-native solutions, each with distinct advantages. While implementation challenges exist, including policy language complexity and organizational alignment, established best practices help organizations navigate these hurdles. As infrastructure continues to evolve, Policy as Code emerges as an essential strategy for maintaining security and compliance in dynamic, cloud-native environments, transforming governance from a perceived roadblock into an enabler of innovation."
"Ensuring Compliance in Cloud Native Assurance and IT Audits","https://scispace.com/papers/ensuring-compliance-in-cloud-native-assurance-and-it-audits-dhs1pjvmmm2y","2025","Journal Article","","H Abhinav Shankar","10.4018/979-8-3373-3078-5.ch010","","No","This chapter fundamentally redefines compliance strategies for cloud-native environments, moving away from traditional audit practices that no longer align with the ephemeral and automated nature of modern infrastructure. Rather than relying on manual, after-the-fact evidence collection, the chapter advocates integrating compliance directly into development and deployment workflows. Approaches such as Infrastructure as Code and Policy-as-Code are emphasized, alongside automated enforcement mechanisms, immutable audit trails, and robust observability to support ongoing regulatory adherence. However, technology alone is not sufficient—success also hinges on fostering cross-functional collaboration, upskilling teams, and driving cultural change so that compliance becomes an intrinsic part of day-to-day operations. By aligning governance with the agility demanded by contemporary software delivery, this framework supports audit readiness, mitigates risk, and helps organizations maintain trust with stakeholders."
"DevSecOps-Driven Security Framework for CI/CD Pipeline Risk Mitigation","https://scispace.com/papers/devsecops-driven-security-framework-for-ci-cd-pipeline-risk-yjape1hq893s","2025","Journal Article","International journal of computing and engineering","Arpit Mishra","10.47941/ijce.3047","","No","Modern software development organizations face escalating security challenges within their Continuous Integration and Continuous Deployment (CI/CD) pipeline infrastructure, necessitating robust DevSecOps methodologies to counter sophisticated vulnerabilities. Contemporary DevSecOps frameworks establish security controls at every stage of the pipeline lifecycle, systematically addressing threats that pose risks to software delivery operations and organizational assets. By implementing structured security integration strategies, organizations achieve both velocity and protection without sacrificing either priority. The zero-trust frameworks analyzed within this context demonstrate significant efficacy when applied to pipeline components, establishing verification checkpoints at critical junctures. Policy-as-code solutions further automate compliance verification, ensuring that security requirements remain enforceable across evolving infrastructure configurations. Security benchmarking results demonstrate substantial improvements in vulnerability detection timeliness, threat containment capabilities, and overall defensive posture when the prescribed controls operate cohesively. The framework establishes governance structures, validation mechanisms, and monitoring protocols that function effectively within rapid deployment cycles while maintaining appropriate security guardrails. Through systematic implementation of these integrated security practices, development teams and security professionals collaborate effectively to create resilient CI/CD environments capable of withstanding evolving threats while preserving deployment velocity."
"Advancing Organizational Resilience Through Enterprise GRC Integration Frameworks","https://scispace.com/papers/advancing-organizational-resilience-through-enterprise-grc-43i377lbd15r","2024","Journal Article","","Nnennaya Halliday","10.62225/2583049x.2024.4.5.4888","","No","In an era defined by regulatory complexity, escalating cyber threats, and rapid market volatility, organizational resilience has emerged as a critical determinant of long-term competitiveness. Traditional siloed approaches to governance, risk management, and compliance (GRC) are increasingly inadequate for navigating these challenges, as they hinder cross-functional collaboration and real-time decision-making. This examines the role of Enterprise GRC Integration Frameworks as a strategic enabler for resilience, focusing on the unification of governance, risk, and compliance processes into a cohesive, enterprise-wide architecture. By aligning policy, process, and technology layers, integrated GRC frameworks facilitate proactive risk identification, standardized compliance monitoring, and agile incident response capabilities. This explores core framework components—governance oversight, enterprise risk registers, unified compliance reporting, and data governance—underpinned by interoperable technology platforms and automation. Methodologies such as process mapping, workflow standardization, and Policy-as-Code implementation are discussed as pathways to embedding compliance and risk management into operational systems. Moreover, integrated GRC enables predictive analytics, scenario modeling, and adaptive feedback loops, thereby enhancing the organization’s ability to anticipate disruptions and adapt policies in real time. Implementation challenges, including cultural resistance, technology fragmentation, and change management complexities, are analyzed alongside mitigation strategies emphasizing executive sponsorship, phased deployment, interoperable platforms, and continuous GRC literacy programs. Future directions highlight the integration of artificial intelligence for policy interpretation and anomaly detection, as well as the alignment of environmental, social, and governance (ESG) metrics with resilience objectives. Ultimately, Enterprise GRC Integration Frameworks are positioned not merely as compliance mechanisms but as strategic infrastructures that build stakeholder confidence, safeguard operational continuity, and drive sustainable performance. Organizations that embrace integrated GRC as a resilience enabler will be better equipped to navigate uncertainty, meet evolving regulatory demands, and maintain trust in an increasingly volatile global environment."
"ARPaCCino: An Agentic-RAG for Policy as Code Compliance","https://scispace.com/papers/arpaccino-an-agentic-rag-for-policy-as-code-compliance-cnydpthqzszp","2025","Journal Article","arXiv.org","Francesco Romeo
Luigi Arena
Francesco Blefari
F. A. Pironti
Matteo Lupinacci
Angelo Furfaro","10.48550/arxiv.2507.10584","https://scispace.com/pdf/arpaccino-an-agentic-rag-for-policy-as-code-compliance-cnydpthqzszp.pdf","No","Policy as Code (PaC) is a paradigm that encodes security and compliance policies into machine-readable formats, enabling automated enforcement in Infrastructure as Code (IaC) environments. However, its adoption is hindered by the complexity of policy languages and the risk of misconfigurations. In this work, we present ARPaCCino, an agentic system that combines Large Language Models (LLMs), Retrieval-Augmented-Generation (RAG), and tool-based validation to automate the generation and verification of PaC rules. Given natural language descriptions of the desired policies, ARPaCCino generates formal Rego rules, assesses IaC compliance, and iteratively refines the IaC configurations to ensure conformance. Thanks to its modular agentic architecture and integration with external tools and knowledge bases, ARPaCCino supports policy validation across a wide range of technologies, including niche or emerging IaC frameworks. Experimental evaluation involving a Terraform-based case study demonstrates ARPaCCino's effectiveness in generating syntactically and semantically correct policies, identifying non-compliant infrastructures, and applying corrective modifications, even when using smaller, open-weight LLMs. Our results highlight the potential of agentic RAG architectures to enhance the automation, reliability, and accessibility of PaC workflows."
"Devops Compliance-as-Code","https://scispace.com/papers/devops-compliance-as-code-mttanramvmo7","2024","Journal Article","Universal library of engineering technology.","Venkata Surendra Reddy Narapareddy
Suresh Kumar Yerramilli","10.70315/uloap.ulete.2024.0102008","","No","The rising simplicity and speed of software distribution in DevOps chains has exaggerated the problem of assuring conformity with regulations without detriment to agility. However, not only are traditional manual compliance processes error-prone, but they are also unlikely to keep pace with the rapidity and scale of cloud-native development. As a response, the paradigm of Compliance-as-Code (CaC) has emerged, integrating compliance requirements into DevOps workflows through code-based, automated, and version-controlled processes. DevOps Compliance-as-Code is the topic of this article, which covers the theoretical background and technologies that make this approach possible, real-life applications, and the emerging research trends. Drawing from scholarly and industry literature, including recent advances in secure DevOps, cloud automation, and generative AI, the discussion demonstrates how Compliance-as-Code ensures traceability, repeatability, and auditability of compliance actions across the software lifecycle (Vadisetty et al., 2023; Abrahams &amp; Langerman, 2018). With policies embedded as runnable code, organizations may achieve proactive control of risks, regulatory controls, and efficient governance in highly dynamic and decentralized development platforms. This article presents a critical review of the advantages, obstacles, and strategy that is required to implement Compliance-as-Code in Modern DevOps environments."
"Automated Architectural Control: Implementing the Governance as Code","https://scispace.com/papers/automated-architectural-control-implementing-the-governance-4l0akjy63go0","2024","Journal Article","","Igor Panasiuk","10.1109/icecie63774.2024.10815678","","No","Governance as Code (GaC) is an emerging approach aimed at automating software architectural control within the modern software engineering industry. This article addresses the challenges associated with software architectural control and presents the generalized GaC approach as a solution that enables the transformation of the architectural control process from a theoretical framework into an automated, practical tool for ensuring compliance with engineering and security standards. The implementation of GaC is structured around three key tasks: representing software architecture as a universal formal model, performing reverse engineering to extract software architecture from ready-to-deploy systems, and automating the verification of architectural control rules. For each of these tasks, a solution is provided along with the underlying motivations."
"Azure policy implementation for enterprise governance: A framework for regulatory compliance and resource management","https://scispace.com/papers/azure-policy-implementation-for-enterprise-governance-a-7gxlrs8zs4zb","2025","Journal Article","World Journal Of Advanced Research and Reviews","Suresh Kotha Naga Venkata Hanuma","10.30574/wjarr.2025.26.2.2034","","No","Azure Policy implementation provides a transformative approach to enterprise governance in cloud environments, enabling organizations to automate compliance enforcement and standardize resource management. Through examining a multinational corporation's implementation across global infrastructure, this article documents how automated policy enforcement addresses limitations of traditional manual governance processes. It evaluates quantifiable improvements in compliance rates, resource management efficiency, and cost-effectiveness while acknowledging implementation challenges including policy conflicts, performance impacts, and integration complexities. The article of Azure Policy's practical application demonstrates how organizations can maintain consistent governance at scale while reducing administrative overhead. Future directions identified include AI-enhanced predictive compliance, cross-cloud standardization, and zero-trust architecture enforcement, representing evolutionary paths toward more sophisticated governance frameworks that further reduce compliance risks while supporting operational agility."
"A DevSecOps Policy-as-Code Model for Compliance Automation in Lakehouse Environments","https://scispace.com/papers/a-devsecops-policy-as-code-model-for-compliance-automation-wr4jottg5s63","2024","Journal Article","Deleted Journal","Babawale Patrick Okare
Tope David Aduloju
Eunice Nduta Kamau
Chisom Elizabeth Alozie
Okeoma Onunka
Linda Azah","10.62225/2583049x.2024.4.6.4594","","No","In modern data ecosystems, lakehouse architectures unify the flexibility of data lakes with the reliability of data warehouses, enabling versatile analytics and machine learning workflows. However, the dynamic and distributed nature of lakehouses introduces significant governance challenges, particularly in ensuring continuous compliance with evolving regulatory frameworks. This paper proposes a novel DevSecOps Policy-as-Code (PaC) model tailored for lakehouse environments that automates compliance enforcement across data ingestion, transformation, storage, and consumption layers. By integrating declarative policy definitions into CI/CD pipelines, the model enables real-time policy validation and enforcement through a centralized policy registry and a powerful policy engine. It supports multiple enforcement stages, pre-deployment checks, runtime validations, and periodic audits, while generating comprehensive, automated audit logs to ensure traceability and accountability. The architecture facilitates seamless integration with leading lakehouse platforms such as Databricks, Delta Lake, and Apache Iceberg, and automates security controls including role-based and attribute-based access management, secrets handling, and encryption enforcement. Observability features provide continuous monitoring of compliance posture, alerting mechanisms, and remediation workflows, transforming compliance from a static checkpoint to a dynamic, continuous process. This approach reduces manual overhead, mitigates risk, and fosters a compliance-first culture within agile data teams. The paper concludes by discussing practical implications for enterprise data governance and outlining future research directions, including semantic policy modeling, AI-enhanced compliance analytics, and multi-cloud policy harmonization. The proposed model represents a significant step toward scalable, auditable, and adaptive compliance automation in next-generation lakehouse data architectures."
"Policy framework for Cloud Computing: AI, governance, compliance and management","https://scispace.com/papers/policy-framework-for-cloud-computing-ai-governance-39pciiwpy43b","2024","Journal Article","Global Journal of Engineering and Technology Advances","Daniel Olatunde Babalola
Adebisi Adedoyin
Foyeke Ogundipe
Adebola Folorunso
Chineme Edgar Nwatu","10.30574/gjeta.2024.21.2.0212","","No","The rapid evolution of cloud computing has transformed data management, operational efficiency, and artificial intelligence (AI) capabilities across industries. However, this advancement presents new challenges in governance, compliance, and management, necessitating a comprehensive policy framework to ensure secure, ethical, and effective cloud usage. This review examines a robust policy framework designed to address these challenges, focusing on the integration of AI, governance practices, regulatory compliance, and cloud management. The framework outlines specific policies for AI, emphasizing ethical considerations, accountability, and transparency, alongside mechanisms for privacy and bias mitigation to foster responsible AI deployment in cloud environments. Governance policies are structured to establish clear data stewardship, risk management, and continuous monitoring protocols, ensuring that cloud resources align with organizational and regulatory standards. Moreover, compliance is addressed through adherence to global standards such as GDPR and HIPAA, with an emphasis on data sovereignty, auditability, and vendor accountability to maintain regulatory alignment across jurisdictions. Management policies within the framework focus on optimizing resource allocation, enforcing Service Level Agreements (SLAs), and developing disaster recovery and business continuity strategies. These management policies aim to balance cost-efficiency with performance reliability. Recognizing the complexities of multi-cloud and hybrid environments, the framework proposes adaptable guidelines that accommodate rapid technological shifts and address security and privacy risks inherent in cloud computing. Through case studies and best practices, this framework offers actionable insights for organizations seeking to implement secure, compliant, and efficient cloud systems. In exploring the future landscape, the review anticipates emerging regulations and underscores the importance of industry-wide collaboration in refining cloud policies. This policy framework provides a foundation for organizations to harness the full potential of cloud computing while upholding standards in AI ethics, data governance, and regulatory compliance."
"CAG: compliance adherence and governance in software delivery using blockchain","https://scispace.com/papers/cag-compliance-adherence-and-governance-in-software-delivery-vfppwiucm2","2019","Proceedings Article","","Kapil Singi
Vikrant Kaulgud
R. P. Jagadeesh Chandra Bose
Sanjay Podder","10.1109/WETSEB.2019.00011","","No","The software development life cycle (SDLC) starts with business and functional specifications signed with a client. In addition to this, the specifications also capture policy / procedure / contractual / regulatory / legislation / standard compliances with respect to a given client industry. The SDLC must adhere to service level agreements (SLAs) while being compliant to development activities, processes, tools, frameworks, and reuse of open-source software components. In today's world, global software development happens across geographically distributed (autonomous) teams consuming extraordinary amounts of open source components drawn from a variety of disparate sources. Although this is helping organizations deal with technical and economic challenges, it is also increasing unintended risks, e.g., use of a non-complaint license software might lead to copyright issues and litigations, use of a library with vulnerabilities pose security risks etc. Mitigation of such risks and remedial measures is a challenge due to lack of visibility and transparency of activities across these distributed teams as they mostly operate in silos. We believe a unified model that non-invasively monitors and analyzes the activities of distributed teams will help a long way in building software that adhere to various compliances. In this paper, we propose a decentralized CAG - Compliance Adherence and Governance framework using blockchain technologies. Our framework (i) enables the capturing of required data points based on compliance specifications, (ii) analyzes the events for non-conformant behavior through smart contracts, (iii) provides real-time alerts, and (iv) records and maintains an immutable audit trail of various activities."
"Automated compliance management in hybrid cloud architectures: A policy-as-code approach","https://scispace.com/papers/automated-compliance-management-in-hybrid-cloud-7dj1l94yti11","2023","Journal Article","World Journal of Advanced Engineering Technology and Sciences","Adekanmi Miracle Adeyinka","10.30574/wjaets.2023.10.1.0265","","No","Compliance management grew in complexity with the proliferation of hybrid cloud infrastructures that integrate on-premises systems with public cloud services. Manual and traditional methods of compliance enforcement are becoming increasingly ineffective in these dynamic heterogeneous environments, exposing risk elevation and inefficient operations. This study explores the applicability of Policy-as-Code (PaC) as a disruption agent for compliance automation under hybrid cloud architectures. PaC enforces obligations continuously, monitors them in real-time, and remediates them automatically by embedding these obligations as machine-readable, declarative policies. The paper reviews the evolution of compliance automation, introduces a conceptual model for PaC integration across hybrid environments, and presents a reference architecture and workflow design for ensuring continuous compliance. It then evaluates the prominent tools and platforms that have varying support for said reference architecture, such as Open Policy Agent, HashiCorp Sentinel, and Azure Policy, describing their features, interoperability, and domain-specific use cases, e.g., finance, healthcare, and the public sector. Finally, the research establishes benefits, current limitations for alternative directions for adoption, and a future for PaC with respect to achieving scalable auditable compliance strategies that are resilient across cloud ecosystems from another perspective."
"A Matter of Policy","https://scispace.com/papers/a-matter-of-policy-28mifet7b0","2012","Journal Article","IT Professional","David F. Ferraiolo
Jeffrey Voas
George Hurlburt","10.1109/MITP.2012.30","","No","To many, system policy is a statement posted on a website indicating intention to protect personal data. In reality, policy is much broader, and its enforcement far more consequential. What if policy-derived rule sets could be rigorously defined and automated for software-intensive systems? Imagine a ""policy machine"" that allows codification of arbitrary rules stemming from policy to create executable code. Such a tool exists today at the US National Institute of Standards and Technology. The NIST Policy Machine offers a new technology in enforcing the important role of policy in systems design, evolution, management, and policy enforcement."
"ExPDT: Ein Policy-basierter Ansatz zur Automatisierung von Compliance","https://scispace.com/papers/expdt-ein-policy-basierter-ansatz-zur-automatisierung-von-1v9o8bdtti","2008","Journal Article","Wirtschaftsinformatik und Angewandte Informatik","Stefan Sackmann
Martin Kähmer","10.1007/S11576-008-0078-1","","No","Remaining in compliance with growing requirements from new laws, regulations, standards, or contracts demands increasing IT support beyond simple reporting tools or archiving solutions. However, an efficient IT support of compliance management requires a more general approach. In this contribution, a framework for automating compliance is introduced. Policies are seen as the key to aligning non-technical compliance requirements to a technical IT system. The policy language ExPDT is presented and evaluated with regard to maintaining flexibility of business processes and validating compliance."
"Amazon Web Services Cloud Compliance Automation with Open Policy Agent","https://scispace.com/papers/amazon-web-services-cloud-compliance-automation-with-open-21c8o96wzpz5","2024","Journal Article","","Arya Paul
R. Joseph Manoj
S. Udhayakumar","10.1109/icoeca62351.2024.00063","","No","The security challenges posed by Infrastructure as code (IaC) are outgrowing established security procedures in an era of rapidly adopting cloud computing and DevOps methodologies. Using security principles to be integrated into the CI/CD pipeline for continuous validation and remediation, this research work proposes a DevSecOps approach to enable cloud environment IaC security. The proposed architecture evaluates CloudFormation Template file to the specified security policy by utilizing Open Policy Agent (OPA). Any violations are flagged by OPA, which may force the deployment process to stop. By incorporating security and compliance considerations into the development pipeline, this method guarantees that vulnerabilities are kept out of production systems. Organizations can improve the overall security posture of their cloud systems by proactively identifying and remediating security problems by implementing a DevSecOps approach. By ensuring that IaC deployments adhere to specified security policies based on the compliance requirements, OPA's continuous security validation reduces the possibility of misconfigurations and security flaws."
"Modeling laws with nomos 2","https://scispace.com/papers/modeling-laws-with-nomos-2-4jnzvpmhwr","2013","Proceedings Article","International Workshop on Requirements Engineering and Law","Silvia Ingolfo
Alberto Siena
Angelo Susi
Anna Perini
John Mylopoulos","10.1109/RELAW.2013.6671350","","No","Nomos is a framework for modelling law-compliant solutions in software system design. It provides a core set of concepts to enable exploring and selecting alternatives in a variability space defined by laws, a graphical notation to visualize models, and tool support for compliance analysis. This short paper illustrates the features above and sketches some of the research challenges ahead."
"rtGovOps: A Runtime Framework for Governance in Large-Scale Software-Defined IoT Cloud Systems","https://scispace.com/papers/rtgovops-a-runtime-framework-for-governance-in-large-scale-4j8w72molm","2015","Proceedings Article","Mobile Cloud Computing & Services","Stefan Nastic
Michael Vogler
Christian Inzinger
Hong-Linh Truong
Schahram Dustdar","10.1109/MOBILECLOUD.2015.38","https://scispace.com/pdf/rtgovops-a-runtime-framework-for-governance-in-large-scale-4j8w72molm.pdf","Yes","The ongoing convergence of cloud computing and the IoT gives rise to the proliferation of diverse, large-scale IoT and mobile cloud systems Such novel IoT cloud systems offer numerous advantages for all involved stakeholders However, due to scale, complexity, and inherent geographical distribution of such systems, governing new IoT cloud resources poses numerous challenges In this paper we introduce rtGovOps, a novel framework for on-demand runtime operational governance of software-defined IoT cloud systems To illustrate the feasibility of our framework and its practical applicability to implement and execute operational governance processes in large-scale software-defined IoT cloud system, we evaluate our approach using a real-world case study on managing fleets of electric vehicles"
"Understanding Everything as Code: A Taxonomy and Conceptual Model","https://scispace.com/papers/understanding-everything-as-code-a-taxonomy-and-conceptual-gzub1a7p18tv","2025","Journal Article","arXiv.org","Haoran Wei
Nazim H. Madhavji
John Steinbacher","10.48550/arxiv.2507.05100","https://scispace.com/pdf/understanding-everything-as-code-a-taxonomy-and-conceptual-gzub1a7p18tv.pdf","No","Background: Everything as Code (EaC) is an emerging paradigm aiming to codify all aspects of modern software systems. Despite its growing popularity, comprehensive industry standards and peer-reviewed research clarifying its scope and guiding its adoption remain scarce. Aims: This study systematically analyzes existing knowledge and perceptions of EaC, clarifies its scope and boundaries, and provides structured guidance for researchers and practitioners. Method: We conducted a large-scale multivocal literature review (MLR), synthesizing academic and grey literature sources. Findings were analyzed quantitatively and thematically. Based on this analysis, we developed a taxonomy and conceptual model of EaC, validated through collaboration with industry experts. Results: The resulting taxonomy comprises 25 distinct EaC practices organized into six layers based on industry awareness and functional roles. The conceptual model illustrates focus areas, overlaps, and interactions among these EaC practices within the software delivery lifecycle. Additionally, practical code examples demonstrating the implementation of these practices were developed in collaboration with industry experts. Conclusions: This work addresses the current scarcity of academic discourse on EaC by providing the first comprehensive taxonomy and conceptual model. These contributions enhance conceptual clarity, offer actionable guidance to practitioners, and lay the groundwork for future research in this emerging domain."
"Secure Software Engineering: A Synthesis of SSDLC, Devsecops, and Ai-Driven Threat Mitigation","https://scispace.com/papers/secure-software-engineering-a-synthesis-of-ssdlc-devsecops-simvljjoi0w6","2025","Journal Article","Deleted Journal","Augustine Osazee Airhiavbere
Desmond Nomaren Idehen","10.62054/ijdm/0203.13","https://scispace.com/pdf/secure-software-engineering-a-synthesis-of-ssdlc-devsecops-simvljjoi0w6.pdf","No","This study explores the critical convergence of software development and cybersecurity through a mixed-method approach combining systematic literature review, quantitative analysis, and case study evaluation to investigate the effectiveness of secure software development practices. As cyber threats grow in sophistication, traditional software engineering models prioritizing functionality and efficiency have proven inadequate in addressing evolving security challenges. The incorporation of Secure Software Development Lifecycle (SSDLC) and DevSecOps methodologies has emerged as a pivotal strategy, embedding security considerations from the earliest phases of development. This paper provides a comprehensive review of secure software development practices, core cybersecurity principles, regulatory compliance requirements, and technological innovations driving this integration. Drawing on insights from academic research, industry reports, and real-world applications, the findings emphasize the effectiveness of security-centric development paradigms, such as SSDLC and DevSecOps, in mitigating risks and strengthening software resilience. Furthermore, emerging technologies like artificial intelligence, blockchain, and automated security testing are reshaping secure development strategies by enabling predictive analytics, dynamic access control, and proactive vulnerability detection. Empirical results indicate that organizations adopting security-first frameworks report measurable reductions in system vulnerabilities and enhanced response times to incidents. This study underscores the imperative of embedding security within software engineering processes to ensure robust application design, safeguard user data, maintain system integrity, and reinforce the broader digital ecosystem. The findings offer valuable guidance for software developers, cybersecurity professionals, and organizational leaders seeking to enhance the security posture and long-term resilience of their software systems"
"Rubacon: automated support for model-based compliance engineering","https://scispace.com/papers/rubacon-automated-support-for-model-based-compliance-2dc8cc1qb4","2008","Proceedings Article","International Conference on Software Engineering","Sebastian Höhn
Jan Jürjens","10.1145/1368088.1368228","https://rgse.uni-koblenz.de/jj/publications/papers/icse08tooltalk.pdf","No","Compliance frameworks, laws and regulations such as Sarbanes Oxley, Basel II, Solvency II, HIPAA etc. demand from companies in a more and more rigorous way to demonstrate that their organisation, processes and supporting IT landscape implement and follow a set of guidelines at differing levels of abstraction. The work presented in this paper aims to contribute to a software engineering process which is driven by security, risk and compliance management considerations. We concentrate on a part of this approach that focusses on the question how one can use software engineering methods and tools to enforce that the configuration of a system enforces the security policies that arise from business compliance regulations. We present tool support for Model-based Compliance Engineering, i.e. for the model-based development and analysis of software configurations that ensures compliance with security policies. It allows one to check UML models of business applications and their configuration data for adherence to security policies and compliance requirements. The tool is based on standardized data formats, such as UML and XML, which makes its integration into existing business architectures as efficient as possible."
"Assimilating and Optimizing Software Assurance in the SDLC: A Framework and Step-Wise Approach","https://scispace.com/papers/assimilating-and-optimizing-software-assurance-in-the-sdlc-a-41gitpgshc","2010","Journal Article","International Journal of Secure Software Engineering","Aderemi O. Adeniji
Seok-Won Lee","10.4018/JSSE.2010100104","","No","Software Assurance is the planned and systematic set of activities that ensures software processes and products conform to requirements while standards and procedures in a manner that builds trusted systems and secure software. While absolute security may not yet be possible, procedures and practices exist to promote assurance in the software lifecycle. In this paper, the authors present a framework and step-wise approach towards achieving and optimizing assurance by infusing security knowledge, techniques, and methodologies into each phase of the Software Development Lifecycle SDLC."
"Toward (Semi-) Automated End-to-End Model-driven Compliance Framework.","https://scispace.com/papers/toward-semi-automated-end-to-end-model-driven-compliance-gpvbyz55t5","2016","","","Sagar Sunkle
Deepali Kholkar","","http://ceur-ws.org/Vol-1561/paper6.pdf","Yes","For modern enterprises, compliance to regulations has become increasingly important. Yet, substantial manual interventions and lack of interoperable models of various compliance aspects contribute to an ineffective implementation and rising costs of compliance. We propose a (semi-) automated end-to-end compliance framework that has the potential to address these challenges. Our contributions are twofold. We first describe how reliance on domain experts and non-holistic treatment of compliance poses severe problems. We then propose a framework on top of our prior work to address the same. Ongoing explorations suggest that such a framework can better equip enterprises for efficient and effective compliance."
"From Regulatory Policies to Event Monitoring Rules: Towards Model-Driven Compliance Automation","https://scispace.com/papers/from-regulatory-policies-to-event-monitoring-rules-towards-otwqbqf7kw","2006","","","Christopher J. Giblin
Samuel Muller
Birgit Pfitzmann","","","Yes","The complexity and costs of conforming to regulatory objectives in large enterprises has drastically heightened the need for consistent and automated approaches to managing compliance. To uniformly describe and manage compliance policies in distributed and heterogeneous IT environments, we have proposed a compliance metamodel for formally capturing regulatory requirements and managing them in a systematic lifecycle. A key aspect in automating compliance involves the monitoring of application events to determine whether business processes and applications operate within the parameters set forth in formal compliance policies. We show how subsets of the regulations, industry guidances or best practices that are expressed in terms of the metamodel can be (semi-)automatically transformed into event monitoring rules with the help of temporal rule patterns. Using examples of regulatory requirements, we demonstrate their formalization in compliance policies and their automated transformation into event correlation rules."
"DECIDE: DevOps for Trusted, Portable and Interoperable Multi-cloud Applications Towards the Digital Single Market","https://scispace.com/papers/decide-devops-for-trusted-portable-and-interoperable-multi-5amb0rzvim","2019","Book Chapter","Product Focused Software Process Improvement","Leire Orue-Echevarria
Juncal Alonso
Marisa Escalante
Kyriakos Stefanidis
Lorenzo Blasi","10.1007/978-3-030-35333-9_45","https://scispace.com/pdf/decide-devops-for-trusted-portable-and-interoperable-multi-5amb0rzvim.pdf","Yes","The transformation from a product to service economy means that companies need to become software service providers as well as consumers Cloud enables greater business agility by making IT infrastructure more flexible The current trends of deploying applications following a hybrid cloud, multi-cloud or cross-cloud architecture, as well as the design, development and operation of multi-cloud native applications based on microservices present several challenges for their developers and operators This paper presents a solution implemented in the context of the European project DECIDE which aims to support DevOps teams in the design, pre-deployment, contracting, deployment and operation of multi-cloud native applications with the provisioning of an integrated framework The project is entering its late phase, in which the DevOps framework is currently being validated and evaluated in various use cases"
"Security as code: Transforming DevSecOps through CI/CD Integration","https://scispace.com/papers/security-as-code-transforming-devsecops-through-ci-cd-vardsilu587c","2025","Journal Article","World Journal of Advanced Engineering Technology and Sciences","Sundeep Vijayaraghavan","10.30574/wjaets.2025.15.1.0446","","No","Security as Code (Sac) represents a transformative approach to addressing the critical challenge of balancing rapid software delivery with robust security measures. By embedding security directly into continuous integration and continuous deployment pipelines, Sac enables organizations to automate, standardize, and scale security practices throughout the software development lifecycle. This integration transforms security from a bottleneck into an enabler of development velocity while significantly enhancing risk posture. The article explores the theoretical framework of Sac, including its foundations in immutability, shift-left principles, and automated feedback mechanisms. Implementation strategies within Jenkins pipelines highlight practical approaches to security scanning integration, policy as code, secrets management, and compliance automation. The organizational impact of Sac implementation extends beyond technical improvements to catalyze cultural transformation, breaking down traditional silos between development, operations, and security teams. Despite compelling benefits, challenges persist in tool integration, skills availability, governance requirements, and cultural resistance. When properly addressed, these obstacles give way to a security model that is more consistent, efficient, and effective than traditional approaches, ultimately enabling organizations to build more resilient systems without Sacrificing delivery speed."
"Secure DevOps Pipelines for Continuous Compliance in Oracle– Cassandra Hybrid Systems","https://scispace.com/papers/secure-devops-pipelines-for-continuous-compliance-in-oracle-i9q7hybh6xez","2024","Journal Article","","Sai Vamsi Kiran Gummadi","10.62643/ijerst.v20.n4.pp300-307","","No","Hybrid data platforms that pair Oracle RDBMS with Apache Cassandra deliver both ACID guarantees and internet-scale availability, yet they complicate security and regulatory compliance. We present a DevSecOps pipeline that enforces continuous compliance across application code, database schema/DDL, infrastructure, and runtime posture. Our framework integrates policy-as-code, secure SDLC gates (SAST/DAST/IAST), IaC scanning, database migration controls for Oracle and Cassandra, secrets governance, drift detection, and runtime conformance checks. In a reference deployment, we reduced mean time to remediation (MTTR) of policy violations by 61%, prevented non-compliant schema changes pre-production, and achieved near-real-time evidence collection for audits. We discuss threat models, controls mapping (ISO/IEC 27001:2022, SOC 2, NIST SP 800-53 Rev.5, PCI DSS 4.0, GDPR, HIPAA, CIS Benchmarks), and trade-offs between speed and assurance."
"A Survey of Policy-Based Management Approaches for Service Oriented Systems","https://scispace.com/papers/a-survey-of-policy-based-management-approaches-for-service-2i1ferk8na","2008","Proceedings Article","Australian Software Engineering Conference","Tan Phan
Jun Han
Jean-Guy Schneider
T. Ebringer
T. Rogers","10.1109/ASWEC.2008.4483228","https://scispace.com/https://researchbank.swinburne.edu.au/file/e5f7c797-0847-4f18-8dac-47df7954bfd3/1/PDF (Published version).pdf","No","Policy based management in service oriented architecture (SOA) allows organizations to apply rules and regulations on their business processes. Policy has long been employed in the management of traditional distributed systems and many policy frameworks have been proposed. However, SOA differs in several aspects to traditional systems thus there is a unique set of requirements for an effective SOA policy system. In this paper, we evaluate five popular policy frameworks which are IETF, Ponder, KAoS, Rei and WS-policy against a number of general and SOA-specific criteria to identify what features of these existing systems can be adopted for SOA and what are not. We then, based on their feature sets, discuss the applicability of the frameworks for SOA management."
"Policy modeling and compliance verification in enterprise software systems: A survey","https://scispace.com/papers/policy-modeling-and-compliance-verification-in-enterprise-3ac6ykosor","2012","Proceedings Article","","George Chatzikonstantinou
Kostas Kontogiannis","10.1109/MESOCA.2012.6392600","","No","During the past few years we are witnessing a paradigm shift in enterprise computing, from the classic host-based service-oriented architecture pattern, to a more complex or elastic computing pattern that facilitates the provision of on-demand computing resources. This new computing paradigm offers numerous advantages but also, poses significant challenges. Advantages are related to the flexibility service providers have on deploying virtual resources on as-needed-basis, providing thus opportunities for large scale computing capabilities, while limiting the total cost of ownership. However, these benefits come at the cost of the user partially losing control over the deployed resources and the cost managing platforms and applications that are now provisioned at an unprecedented rate and interaction complexity. In order to address the above challenges, a service management and service assurance framework is required, whereby policies should be formally modeled, and consequently be verified against runtime system behavior models. In this paper, we survey a number of policy modeling and policy compliance verification techniques and we propose a corresponding basic taxonomy for these."
"Software Engineering in a Governed World: Opportunities and Challenges","https://scispace.com/papers/software-engineering-in-a-governed-world-opportunities-and-59lyet95sl","2020","Proceedings Article","International Conference on Software Engineering","R. P. Jagadeesh Chandra Bose
Kapil Singi
Vikrant Kaulgud
Sanjay Podder
Adam P. Burden","10.1145/3387940.3392270","","No","Modern software applications are becoming ubiquitous and pervasive affecting various aspects of our lives and livelihoods. At the same time, the risks to which these systems expose the organizations and end users are also growing dramatically. Governments and regulatory bodies are moving towards developing laws, regulations, and guidelines for several software applications (e.g., those that use data, are based on AI/ML etc.) across different domains. These mandates impose several challenges in the way how software is built and delivered, primary amongst them is to ensure that software and its delivery processes are compliant. There is a need for governance frameworks that enable the recording, monitoring, and analysis of various activities throughout the application development life cycle making the development processes transparent, traceable, verifiable, auditable, and adhering to regulations and best practices, thereby enabling trustworthiness of software. In this paper, we discuss about the challenges and opportunities of software engineering in the governance era."
"Towards a compliance support framework for global software companies","https://scispace.com/papers/towards-a-compliance-support-framework-for-global-software-3nicm99uos","2007","Proceedings Article","International Conference on Software Engineering","AbdelKrim Hamou-Lhadj
Abdelwahab Hamou-Lhadj","","","Yes","Regulated companies are required to comply with the laws and regulations that apply to their industries. An important aspect of these authoritative rules is directly related to the way by which software systems, used by the regulated companies, are built, tested, and maintained. As a result, many regulated companies have turned to their software vendors to request their support in the compliance efforts. For most global software vendors, this new situation represents a significant challenge. From the technological standpoint, the complexity and sheer volume of typical authoritative rules poses a serious obstacle to implementing effective compliance support strategies. From the organizational perspective, the delivery of compliance support activities requires efficient business processes, skilled and valued employees, and a strong governance model with commitment at all management levels. To address these issues, we present a compliance support framework that aims to facilitate the linkage between compliance requirements, software development practices, and business process management. We believe that, if implemented properly, this framework can significantly improve the way software companies handle the increasing customer demand for compliance support. It can turn compliance support into a revenue-generating activity, and possibly a competitive advantage."
"Compliance adherence in distributed software delivery: a blockchain approach","https://scispace.com/papers/compliance-adherence-in-distributed-software-delivery-a-24qq5ie2g4","2018","Proceedings Article","International Conference on Global Software Engineering","Kapil Singi
Pradeepkumar D S
Vikrant Kaulgud
Sanjay Podder","10.1145/3196369.3196383","","No","In this extended abstract, we propose a conceptual framework that leverages distributed ledger technology and smart contracts to create a decentralized system to capture the occurrence of interesting development activities (eg, a development build) and associated contextual data, and automatically audit and evaluate compliance to governance policies Our hypothesis is that such a framework will facilitate easier sharing of information across all participants of a distributed development team, compliance evaluation and early mitigation actions, leading to greater visibility and compliance Currently, the proof of concept we are working on is focused on sharing and compliance evaluation of the open-source components used in software development"
"Automated compliance policy enforcement in software systems","https://scispace.com/papers/automated-compliance-policy-enforcement-in-software-systems-30koj69660","2008","Patent","","Nitin Jain
Amit Bhalla
Anurag Singh
Aawardhan Logandan
Sourav Mukherjee","","","No","Some embodiments of the present invention provide a system that maintains a software system. During operation, the system obtains a compliance policy for the software system and monitors the software system for a violation of the compliance policy. If such a violation is detected, the system retrieves a change package associated with the violation based on the compliance policy and automatically deploys the change package to the software system to resolve the violation."
"Governance Policies for Verification and Validation of Service Choreographies .","https://scispace.com/papers/governance-policies-for-verification-and-validation-of-4cqsbf890u","2012","Book Chapter","International Conference on Web Information Systems and Technologies","Antonia Bertolino
Guglielmo De Angelis
Andrea Polini","10.1007/978-3-642-36608-6_6","","No","The Future Internet (FI) sustains the emerging vision of a software ecosystem in which pieces of software, developed, owned and run by different organizations, can be dynamically discovered and bound to each other so to readily start to interact. Nevertheless, without suitable mechanisms, paradigms and tools, this ecosystem is at risk of tending towards chaos. Indeed the take off of FI passes through the introduction of paradigms and tools permitting to establish some discipline. Choreography specifications and Governance are two different proposals which can contribute to such a vision, by permitting to define rules and functioning agreements both at the technical level and at the social (among organizations) level. In this paper we discuss such aspects and introduce a policy framework so to support a FI ecosystem in which V&V activities are controlled and perpetually run so to contribute to the quality and trustworthiness perceived by all the involved stakeholders."
"A Security Compliance-by-Design Framework Utilizing Reusable Formal Models","https://scispace.com/papers/a-security-compliance-by-design-framework-utilizing-reusable-18howcgbbl","2023","Proceedings Article","","Quentin Rouland
Stojanche Gjorcheski
Jason Jaskolka","10.1109/qrs-c60940.2023.00054","","No","In recent years, increasing concerns about the security of critical infrastructure have led to the development of various security standards, policies, and regulations. Consequently, it has become essential for any organization responsible for such infrastructure to ensure that their system software architecture complies with these security guidelines. As a result, in this paper we propose a methodology to enhance the security of software systems by incorporating compliance verification from the early stages of design, thereby proactively addressing potential flaws. Furthermore, we present a novel method for modeling a security compliance baseline based on the specification and reuse of analysis models targeting standards, policies, and regulations. This approach streamlines the compliance process, facilitating adherence to multiple security standards while promoting the reuse of security compliance analysis models. To demonstrate the practicality of the suggested framework and technique, we illustrate representative architecture compliance checks on a Supervisory Control and Data Acquisition (SCADA) system."
"Embracing policy engineering","https://scispace.com/papers/embracing-policy-engineering-1rigry7qg9","2010","Proceedings Article","International Conference on Software Engineering","Kathi Fisler
Shriram Krishnamurthi
Daniel J. Dougherty","10.1145/1882362.1882385","https://scispace.com/pdf/embracing-policy-engineering-1rigry7qg9.pdf","No","Declarative policies play a central role in many modern software systems. Engineering policies and their interactions with programs raises many interesting open questions."
"Security Policy Enforcement and Behavioral Threat Detection in DevSecOps Pipelines","https://scispace.com/papers/security-policy-enforcement-and-behavioral-threat-detection-rq4gc9he8czw","2022","Journal Article","European journal of technology","Khaja Kamaluddin","10.47672/ejt.2723","","No","Purpose: The evolution of DevSecOps reflects a critical shift from traditional DevOps by embedding security seamlessly throughout the software development lifecycle. This research explores the convergence of security policy enforcement with behavioral threat detection within CI/CD pipelines, focusing on practices and tools. We discuss the limitations of legacy DevOps security approaches, including late-stage vulnerability identification and insufficient runtime protection, and highlight the rising need for behavior-based detection to counter advanced threats and insider breaches. Materials and Methods: While static analysis and Infrastructure-as-Code scanning are useful strategies for evaluating security policies, a more comprehensive approach examines both compliance-focused tools and behavioral monitoring techniques. Findings: Compliance as-code frameworks define policies that are automatically checked, yet anomaly detection within system calls, container events, and source code changes offers a dynamic perspective on threats. Previously, integration of these checks into CI/CD platforms like Jenkins and GitLab relied on manual security reviews of alerts and build checkpoints to demonstrate how security checkpoints and alerts were managed before the adoption of AI-driven automation. Through case studies such as the Solar Winds breach and practical pipeline examples, we illustrate how combined policy and behavior-based controls can enhance threat prevention. However, we also identify the significant challenges to solutions, including high false positive rates and limited cross-layer correlation capabilities. Unique Contribution to Theory, Practice and Policy: Finally, the article looks ahead to the anticipated future of DevSecOps, emphasizing machine learning-driven behavior modelling, unified enforcement engines, and a zero-trust approach centered on identity and behavior analytics."
"Towards Software Compliance Specification and Enforcement Using TOSCA.","https://scispace.com/papers/towards-software-compliance-specification-and-enforcement-00nvuxxt4hjb","","","","Mohammed Mubarkoot
Jörn Altmann","10.1007/978-3-030-92916-9_14","","No","According to the laws of software evolution, the size and complexity of software systems continue to increase over time and, simultaneously, if not maintained rigorously, the quality decreases. Quality degradation typically happens due to changes in policies, regulations, and industry requirements, which, in turn, complicates compliance management over time. Among the key challenges in managing the evolution of software are the modelling and the enforcement of compliance rules. Moreover, the gap between compliance experts and software engineers has worsened the problem. The topology and orchestration specifications for cloud applications (TOSCA), which is an OASIS standard, has the potential to offer a relief by enabling different levels of abstractions for modeling and enforcing compliance policies. This work aims at investigating the potential of using TOSCA service templates for modelling and enforcing non-functional requirements and policies. Then, it proposes an approach that maximizes involvement of stakeholders in modeling and auditing such requirements and policies. Findings can help enterprises and policy makers achieve better governance and compliance on software services."
"Enforcing system-wide properties","https://scispace.com/papers/enforcing-system-wide-properties-2jh8ychfw3","2004","Proceedings Article","Australian Software Engineering Conference","Michael Eichberg
M. Meizini
Thorsten Schäfer
C. Beringer
K.M. Hamel","10.1109/ASWEC.2004.1290468","","No","Policy enforcement is a mechanism for ensuring that system components follow certain programming practices, comply with specified rules, and meet certain assumptions. Unfortunately, the most common mechanisms used today for policy enforcement are documentation, training, and code reviews. The fundamental problem is that these mechanisms are expensive, time-consuming, and still error-prone. To cope with this problem, we present IRC (Implementation Restriction Checker), an extensible framework for automatically enforcing system-wide policies or contracts. The framework is built on top of a platform for aspect-oriented programming at the level of Java byte-code instructions and is available as an eclipse plug-in as well as a standalone application. It includes a set of directly usable checkers and can be easily extended to implement new ones."
"Compliance-as-Code for Cybersecurity Automation in Hybrid Cloud","https://scispace.com/papers/compliance-as-code-for-cybersecurity-automation-in-hybrid-201xbkns","2022","Proceedings Article","IEEE International Conference on Cloud Computing","Vikas Agarwal
Chris Butler
Louis R. Degenaro
Arun Kumar
Anca Sailer
Gosia Steinder","10.1109/CLOUD55607.2022.00066","","No","Automation of cybersecurity processes has become crucial with large scale deployment of sensitive workloads in regulated on-prem, private, and public cloud environments. Regulatory and standards bodies such as Payment Card Industry (PCI), Federal Financial Institutions Examination Council (FFIEC), International Organization for Standardization (ISO), and others govern the minimal set of cybersecurity controls that an organization must implement. To meet such requirements while maintaining business agility, organizations need to modernize from manual document based compliance management to automated processes for continuous compliance. This modernized process is called compliance-as-code. In this paper, we present an architecture for compliance-as-code based on a standardized framework. We identify several design choices and our rationale behind those. Specifically, we introduce a system for manipulating compliance information in a standardized manner and a data interchange protocol for inter-operable communication of compliance information. We demonstrate the scalability of our approach and briefly describe deployment and experimental results in real world settings."
"Policy-driven infrastructure hardening using CI/CD pipelines in enterprise environments","https://scispace.com/papers/policy-driven-infrastructure-hardening-using-ci-cd-pipelines-9yycoys92c3h","2022","Journal Article","International Journal of Science and Research Archive","Rohith Aitharaju","10.30574/ijsra.2022.7.1.0280","","No","The way modern businesses are speeding up software implementation using CI/CD, securely managing infrastructure automatically has never been more essential. Old methods of protecting systems, made by hand and only done when problems arise, cannot catch up to what DevOps pipelines require. This research looks at using Policy-as-Code (PaC) in CI/CD pipelines to apply policy-driven hardening to infrastructure which helps maintain compliance, consistency and robustness. The research further examines basic ideas like Infrastructure as Code (IaC), managing configurations and the important security benchmarks CIS and NIST. It guides readers on how to use the following tools to ensure security when deployments are undertaken: Jenkins, GitHub Actions, Open Policy Agent (OPA) and HashiCorp Sentinel. False positives, complicated integration and resistance in the organization are discussed and solutions are given using a unified DevSecOps approach and intelligent policy engines. With this strategy, real-time enforcement of safety and compliance rules makes security an asset that helps enterprises scale, remain automated and use contextual protection. The findings end by sharing useful tips and possibilities for the future, helping businesses integrate strong security into their CI/CD workflows"
"An End-to-End Framework for Business Compliance in Process-Driven SOAs","https://scispace.com/papers/an-end-to-end-framework-for-business-compliance-in-process-mc64ta2n3i","2010","Proceedings Article","Symbolic and Numeric Algorithms for Scientific Computing","Huy Tran
Ta'id Holmes
Ernst Oberortner
Emmanuel Mulo
Agnieszka Betkowska Cavalcante
Jacek Serafinski
Marek Tluczek
Aliaksandr Birukou
Florian Daniel
Patrícia Silveira
Uwe Zdun
Schahram Dustdar","10.1109/SYNASC.2010.52","https://scispace.com/pdf/an-end-to-end-framework-for-business-compliance-in-process-mc64ta2n3i.pdf","No","It is significant for companies to ensure their businesses conforming to relevant policies, laws, and regulations as the consequences of infringement can be serious. Unfortunately, the divergence and frequent changes of different compliance sources make it hard to systematically and quickly accommodate new compliance requirements due to the lack of an adequate methodology for system and compliance engineering. In addition, the difference of perception and expertise of multiple stakeholders involving in system and compliance engineering further complicates the analyzing, implementing, and assessing of compliance. For these reasons, in many cases, business compliance today is reached on aper-case basis by using ad hoc, hand-crafted solutions for specific rules to which they must comply. This leads in the long run to problems regarding complexity, understandability, and maintainability of compliance concerns in a SOA. To address the aforementioned challenges, we present in this invited paper a comprehensive SOA business compliance software framework that enables a business to express, implement, monitor, and govern compliance concerns."
"Demystifying Enterprise Infrastructure in FinTech: Introductory Framework to Platform Engineering, Hybrid Cloud, and Regulatory Compliance","https://scispace.com/papers/demystifying-enterprise-infrastructure-in-fintech-3btg2ojzapjo","2025","Journal Article","European journal of computer science and information technology","Satish Manchana","10.37745/ejcsit.2013/vol13n4191110","","No","The financial services industry has undergone a profound transformation from traditional brick-and-mortar operations to digital-first business models, necessitating robust enterprise infrastructure frameworks. This article explores the foundational elements powering modern financial institutions through three interconnected domains: platform engineering, hybrid cloud architectures, and regulatory compliance. Platform engineering establishes standardized, self-service capabilities that abstract infrastructure complexity while maintaining the specialized transaction integrity requirements critical for financial systems. Hybrid cloud architectures balance innovation agility with security controls through strategic combinations of public and private environments, addressing data sovereignty concerns and performance requirements for latency-sensitive applications. Regulatory frameworks like MiFID II, SOX, GDPR, and PCI DSS directly influence infrastructure design decisions, requiring sophisticated approaches to translate compliance requirements into technical specifications and implement them as code-driven policies. By examining these domains through a financial services lens, the article provides IT professionals, engineers, and decision-makers with a conceptual framework for understanding how secure, compliant, and scalable infrastructure supports digital transformation in financial services while ensuring operational excellence."
"A governance framework model for cloud computing: role of AI, security, compliance, and management","https://scispace.com/papers/a-governance-framework-model-for-cloud-computing-role-of-ai-3v3vfumr6lq5","2024","Journal Article","World Journal Of Advanced Research and Reviews","Adebola Folorunso
Adeola Adewa
Daniel Olatunde Babalola
Chineme Edgar Nwatu","10.30574/wjarr.2024.24.2.3513","","No","The rapid adoption of cloud computing has transformed how organizations manage their IT resources, necessitating robust governance frameworks to address the complexities and risks inherent in cloud environments. This review proposes a comprehensive governance framework model that integrates the roles of artificial intelligence (AI), security, compliance, and management to enhance the effectiveness of cloud operations. AI plays a critical role in optimizing resource allocation and improving decision-making processes within cloud governance. By leveraging machine learning algorithms, organizations can achieve dynamic resource management, predictive analytics, and automated compliance monitoring, which enhance operational efficiency and reduce human error. Furthermore, the integration of AI in security management facilitates real-time threat detection and response, allowing organizations to proactively mitigate risks associated with data breaches and cyberattacks. Security is a paramount concern in cloud governance, given the shared responsibility model between cloud providers and clients. This framework emphasizes the implementation of comprehensive security measures, including data encryption, identity management, and incident response protocols, to safeguard sensitive information and maintain customer trust. Compliance with regulatory requirements is essential in ensuring organizational accountability and minimizing legal risks. The proposed governance model incorporates automated compliance checks and reporting mechanisms, ensuring adherence to industry-specific regulations such as GDPR and HIPAA. Moreover, effective management of cloud resources is crucial for optimizing performance and controlling costs. The governance framework outlines best practices for lifecycle management, cost optimization, and resource allocation, enabling organizations to achieve their strategic objectives. This governance framework model underscores the importance of integrating AI, security, compliance, and management for a holistic approach to cloud governance, providing organizations with the necessary tools to navigate the complexities of cloud computing while maximizing its benefits."
"Methods and systems for managing regulatory governance and compliance","https://scispace.com/papers/methods-and-systems-for-managing-regulatory-governance-and-gt3xyohe6z","2015","Patent","","Oscar Andres Jofre
Liam Lynch
Vlado Sinkovic
Jason Richard Futko
Gregory William Harper","","","No","A method and system is provided for managing regulatory governance and compliance comprising a corporate compliance platform capable of storing and managing corporate records. Compliance is governed by a rules engine which ensures that regulatory and corporate requirements are followed. The platform enables stakeholders including crowdfunding portals, shareholders, board directors, CEO, CFO, corporate secretary, lawyers, auditors, IR, members and 3rd party providers to manage corporate information from a Single Point of Entry within a secure platform that results in efficient and transparent corporate governance."
"Policy-guided software evolution","https://scispace.com/papers/policy-guided-software-evolution-20ne4sps3x","2003","Proceedings Article","International Conference on Software Maintenance","Nazim H. Madhavji
Josée Tassé","10.1109/ICSM.2003.1235408","","No","Ensuring that software systems evolve in a desired manner has thus far been an elusive goal. In a continuing effort towards this objective, in this paper we propose a new approach that monitors an evolving software system, or its evolution process, against evolutionary policies so that any feedback obtained can be used to improve the system or its process. Two key concepts that make this possible are: (1) a mechanism to detect policy violations; and (2) a contextual framework to support activities of evolving a software system beyond the next release. Together, they could provide a wide and deep scope for managing software evolution. The benefit of our approach is that it would help in: sustaining the quality of a software system as it evolves; reducing evolutionary costs; and improving evolutionary processes."
"Cloud-Native Design Patterns for Highly Regulated Environments","https://scispace.com/papers/cloud-native-design-patterns-for-highly-regulated-bas465h3pyi4","2025","Journal Article","","Anusha Joodala","10.71097/ijsat.v16.i3.7867","","No","Cloud-native technologies are transforming how businesses build and run applications, enabling them to become more agile, scalable, and faster through automation. However, regulated industries like healthcare, finance, and government have unique challenges in their adoption of this technology because of strict compliance rules, data sovereignty laws, auditability, and security requirements. In this paper, provides detailed study on the cloud-native design patterns, customized for the regulated environments. also will investigate trends like Immutable Infrastructure, Sidecar Proxy, Compliance-as-Code, Zero Trust Architecture, Service Mesh and their success in satisfying regulatory requirements without slowing down agility and innovation. And focus on bringing back real-world use cases and evaluation matrix to offer a framework that can provide insights and direction to run the cloud native architecture from a regulation “compliance” key standards as GDPR, HIPAA and PCI DSS among others. The research offers a blueprint for architects and DevSecOps teams to create secure, auditable, and compliant cloud-native systems in challenging governance environments."
"Compliance in service-oriented architectures: A model-driven and view-based approach","https://scispace.com/papers/compliance-in-service-oriented-architectures-a-model-driven-41qjhwzfzp","2012","Journal Article","Information & Software Technology","Huy Tran
Uwe Zdun
Ta'id Holmes
Ernst Oberortner
Emmanuel Mulo
Schahram Dustdar","10.1016/J.INFSOF.2012.01.001","https://scispace.com/pdf/compliance-in-service-oriented-architectures-a-model-driven-41qjhwzfzp.pdf","No","Context: Ensuring software systems conforming to multiple sources of relevant policies, laws, and regulations is significant because the consequences of infringement can be serious. Unfortunately, this goal is hardly achievable due to the divergence and frequent changes of compliance sources and the differences in perception and expertise of the involved stakeholders. In the long run, these issues lead to problems regarding complexity, understandability, maintainability, and reusability of compliance concerns. Objective: In this article, we present a model-driven and view-based approach for addressing problems related to compliance concerns. Method: Compliance concerns are represented using separate view models. This is achieved using domain-specific languages (DSLs) that enable non-technical and technical experts to formulate only the excerpts of the system according to their expertise and domain knowledge. The compliance implementations, reports, and documentation can be automatically generated from the models. The applicability of our approach has been validated using an industrial case study. Results: Our approach supports stakeholders in dealing with the divergence of multiple compliance sources. The compliance controls and relevant reports and documentation are generated from the models and hence become traceable, understandable, and reusable. Because the generated artifacts are associated with the models, the compliance information won't be lost as the system evolves. DSLs and view models convey compliance concerns to each stakeholder in a view that is most appropriate for his/her current work task. Conclusions: Our approach lays a solid foundation for ensuring conformance to relevant laws and regulations. This approach, on the one hand, aims at addressing the variety of expertise and domain knowledge of stakeholders. On the other hand, it also aims at ensuring the explicit links between compliance sources and the corresponding implementations, reports, and documents for conducting many important tasks such as root cause analysis, auditing, and governance."
"Unifying Governance, Risk and Controls Framework Using SDLC, CICD and DevOps","https://scispace.com/papers/unifying-governance-risk-and-controls-framework-using-sdlc-149wfu1wn0","2023","Journal Article","","Sai Alekhya Ganugapati
Sandeep Prabhu","10.1109/icces57224.2023.10192730","","No","This paper aims to study different software development frameworks and propose an efficient and comprehensive framework for handling Software Development Life Cycle (SDLC) in an IT Project. Risks and controls, work products and IT Audit risk parameters for each phase are also analysed. Furthermore, it covers Continuous Integration Continuous Deployment/Deliver (CICD) during support to the project along with management of code, branching strategies, storage of code, and CICD Pipelining. The paper also introduces Development-Operations (DevOps) and teaming structures to orchestrate project’s success. It also depicts the importance of cross functional teams in a DevOps environment."
"AWS Compliance Acceleration: Integrating Preventive, Detective, and Corrective Controls for Robust Cloud Governance","https://scispace.com/papers/aws-compliance-acceleration-integrating-preventive-detective-wzql0inarm1j","2025","Journal Article","European modern studies journal","Parag Gurunath Sakhalkar","10.59573/emsj.9(5).2025.77","https://scispace.com/pdf/aws-compliance-acceleration-integrating-preventive-detective-wzql0inarm1j.pdf","No","Regulatory compliance within cloud implementations constitutes a fundamental operational priority as enterprises transition critical systems to distributed computing platforms. Government agencies, sector regulators, and independent auditors systematically examine cloud infrastructure arrangements, requiring thorough documentation of security measures and administrative procedures. This expanding oversight demands structured compliance methodologies incorporating distinct control categories throughout resource lifecycles. Preventive systems establish configuration parameters before deployment, detective mechanisms continually assess environment conditions against defined standards, while corrective processes automatically address identified discrepancies. Establishing this multifaceted framework presents coordination challenges across existing technical processes, necessitating alignment between development activities, operational functions, and governance structures. Organizations must resolve potential capability gaps between native platform services, establish appropriate automation boundaries, and maintain consistent classification schemes across control types. Automation possibilities extend throughout compliance processes, from standard definition through enforcement and into evidence compilation for verification purposes. Forward-looking compliance structures provide considerable operational benefits beyond regulatory fulfillment, including faster deployment through pre-validated designs, fewer security events through uniform control implementation, efficient audit preparation through ongoing evidence gathering, and enhanced risk awareness through unified compliance visibility. These practical advantages transform compliance activities from obligatory requirements into strategic assets through improved governance maturity and operational discipline."
"Developing and Enforcing Policies for Access Control, Resource Usage, and Adaptation - A Practical Approach","https://scispace.com/papers/developing-and-enforcing-policies-for-access-control-4vms7135ie","2013","Book Chapter","Web Services and Formal Methods","Andrea Margheri
Andrea Margheri
Massimiliano Masi
Rosario Pugliese
Francesco Tiezzi","10.1007/978-3-319-08260-8_6","https://scispace.com/pdf/developing-and-enforcing-policies-for-access-control-4vms7135ie.pdf","No","Policy-based software architectures are nowadays widely exploited to regulate different aspects of systems’ behavior, such as access control, resource usage, and adaptation. Several languages and technologies have been proposed as, e.g., the standard XACML. However, developing real-world systems using such approaches is still a tricky task, being them complex and error-prone. To overcome such difficulties, we advocate the use of FACPL, a formal policy language inspired to but simpler than XACML. FACPL has an intuitive syntax, a mathematical semantics and easy-to-use software tools supporting policy development and enforcement. We illustrate potentialities and effectiveness of our approach through a case study from the Cloud computing domain."
"A Model Centric Framework and Approach for Complex Systems Policy","https://scispace.com/papers/a-model-centric-framework-and-approach-for-complex-systems-4js4y0w2oo","2021","Journal Article","IEEE Systems Journal","Shamsnaz Virani Bhada
Rahul Krishnan","10.1109/JSYST.2020.3003204","https://scispace.com/pdf/a-model-centric-framework-and-approach-for-complex-systems-4js4y0w2oo.pdf","Yes","Twenty-first century systems engineering is no longerdocument-centric; instead, it is model-centric. Model-centric systems engineering helps reduce ambiguity, increase clarity, and increase the analytics of the resulting complex systems. However, complex systems are governed by organizational policies that are still document-centric. Such policies are difficult to analyze, and gaps in policy can lead to major deficiencies in the resulting complex systems. This article introduces a framework for policy content modeling (PCM) and analysis. The framework represents the conceptual view and is supported by a step-by-step approach to achieve complete policy modeling and analysis. This approach was used with the intention of identifying and analyzing gaps in policy content and calculating policy toxicity, which negatively affects the resulting system. This framework and approach was also applied to Veterans Affairs (VA) and university policies. The VA PCM is conducted to discover toxicity in the policies and University policies modeling is done to graphically represent an undocumented policy and toxicity in the policy implementation."
"Enhancing Secure Software Development with AZTRM-D: An AI-Integrated Approach Combining DevSecOps, Risk Management, and Zero Trust","https://scispace.com/papers/enhancing-secure-software-development-with-aztrm-d-an-ai-q7i7z3p0jc1h","2025","Journal Article","Applied Sciences","Ian Coston
Karl David Hezel
Eadan Plotnizky
Mehrdad Nojoumian","10.3390/app15158163","","No","This paper introduces the Automated Zero Trust Risk Management with DevSecOps Integration (AZTRM-D) framework, a novel approach that embeds security throughout the entire Secure Software and System Development Life Cycle (S-SDLC). AZTRM-D strategically unifies three established methodologies: DevSecOps practices, the NIST Risk Management Framework (RMF), and the Zero Trust (ZT) model. It then significantly augments their capabilities through the pervasive application of Artificial Intelligence (AI). This integration shifts traditional, often fragmented, security paradigms towards a proactive, automated, and continuously adaptive security posture. AI serves as the foundational enabler, providing real-time threat intelligence, automating critical security controls, facilitating continuous vulnerability detection, and enabling dynamic policy enforcement from initial code development through operational deployment. By automating key security functions and providing continuous oversight, AZTRM-D enhances risk mitigation, reduces vulnerabilities, streamlines compliance, and significantly strengthens the overall security posture of software systems, thereby addressing the complexities of modern cyber threats and accelerating the delivery of secure software."
"Policy-driven governance in cloud service ecosystems","https://scispace.com/papers/policy-driven-governance-in-cloud-service-ecosystems-5fcs2gkvvu","2016","Dissertation","","Dimitrios Kourtesis","","","Yes","Cloud application development platforms facilitate new models of software co-development and forge environments best characterised as cloud service ecosystems. The value of those ecosystems increases exponentially with the addition of more users and third-party services. Growth however breeds complexity and puts reliability at risk, requiring all stakeholders to exercise control over changes in the ecosystem that may affect them. This is a challenge of governance. From the viewpoint of the ecosystem coordinator, governance is about preventing negative ripple effects from new software added to the platform. From the viewpoint of third-party developers and end-users, governance is about ensuring that the cloud services they consume or deliver comply with requirements on a continuous basis. To facilitate different forms of governance in a cloud service ecosystem we need governance support systems that achieve separation of concerns between the roles of policy provider, governed resource provider and policy evaluator. This calls for better modularisation of the governance support system architecture, decoupling governance policies from policy evaluation engines and governed resources. It also calls for an improved approach to policy engineering with increased automation and efficient exchange of governance policies and related data between ecosystem partners. The thesis supported by this research is that governance support systems that satisfy such requirements are both feasible and useful to develop through a framework that integrates Semantic Web technologies and Linked Data principles. The PROBE framework presented in this dissertation comprises four components: (1) a governance ontology serving as shared ecosystem vocabulary for policies and resources; (2) a method for the definition of governance policies; (3) a method for sharing descriptions of governed resources between ecosystem partners; (4) a method for evaluating governance policies against descriptions of governed ecosystem resources. The feasibility and usefulness of PROBE are demonstrated with the help of an industrial case study on cloud service ecosystem governance."
"EAGER: Deployment-Time API Governance for Modern PaaS Clouds","https://scispace.com/papers/eager-deployment-time-api-governance-for-modern-paas-clouds-3qqn1jnwxb","2015","Proceedings Article","IEEE International Conference on Cloud Engineering","Hiranya Jayathilaka
Chandra Krintz
Rich Wolski","10.1109/IC2E.2015.69","","Yes","To track, control, and compel reuse of web APIs, we investigate a new approach to API governance -- combined policy, implementation, and deployment control of web APIs. Our approach, called EAGER, provides a software architecture that integrates into PaaS platforms to support systemwide, deployment-time enforcement of governance policies. Specifically, EAGER checks for and prevents backward incompatible API changes from being deployed into production PaaS clouds, enforces service reuse, and facilitates enforcement of other best practices in software maintenance via policies. Our experiments with an EAGER prototype show that enforcing API governance at deployment-time in PaaS clouds is efficient and scalable to thousands of APIs and policies."
"Context Model Based SOA Policy Framework","https://scispace.com/papers/context-model-based-soa-policy-framework-3j5n930dyj","2010","Proceedings Article","International Conference on Web Services","Yu Chen Zhou
Xin Peng Liu
Xi Ning Wang
Liang Xue
Chen Tian
Xiao Xing Liang","10.1109/ICWS.2010.115","","No","With the popularity of SOA, SOA policy becomes one of the core technical enablers for SOA governance and management. Different in several aspects from traditional policy for distributed system management, policy applied in SOA solutions needs to take into account various policy types and enforcement points in different layers of SOA solution stack and different phases of SOA lifecycle. As well, it has the unique requirements on compliance to match existing SOA technologies and characteristics, as simplicity, standardization, high performance, etc. In this paper, a novel context model based SOA policy management framework by innovatively extending W3C Service Modeling Language (SML) and ISO Schematron is introduced. Firstly, a common context model distilled from SOA policy types typically including service policy, service governance policy, application policy and business policy, is presented. Then, the core components - context model based policy engine and definition tool are described. Finally, it is illustrated how the unified definition tools and policy engine are manipulated within the context model based SOA policy framework to manage and enforce policies in typical scenarios as service meta-data management, service match making and business process management. Based on the project, we participated in the works for defining W3C SML V1.1 working draft and proposed the works introduced in this paper to W3C SML Working Group. This paper demonstrates how these technologies and architectures significantly enhance the capability of SOA governance and management throughout whole SOA lifecycle and spanning the layers of SOA solution stack."
"Compliance policy management systems and methods","https://scispace.com/papers/compliance-policy-management-systems-and-methods-10d3id564f","2008","Patent","","David S. Tyree
James E. Tomlinson","","","No","In an exemplary system, a compliance policy processing subsystem is selectively and communicatively coupled to a rules management subsystem. The rules management subsystem is configured to maintain a rules database. The compliance policy processing subsystem is configured to facilitate selection by a user of a section of text within a compliance policy, direct the rules management subsystem to identify one or more rules within the rules database that are relevant to the section of text, and display a representation of the relevant rules."
"Policy management: an architecture and approach","https://scispace.com/papers/policy-management-an-architecture-and-approach-2oqa2dlr9w","1993","Proceedings Article","","M.J. Maullo
S.B. Calo","10.1109/IWSM.1993.315293","https://ieeexplore.ieee.org/iel2/915/7607/00315293.pdf","No","This paper deals with the role of policies in the management of large complex systems. An approach is suggested for the transformation of policy statements into executable process decision functions; and, an architecture is outlined to help organize the elements of policy in a manageable way. To illustrate the concepts, an example is given from information processing that conveys more concretely the manner in which this architecture can be applied to policy management, Tools are introduced to deploy a policy management system. >"
"Continuous Compliance: Experiences, Challenges, and Opportunities","https://scispace.com/papers/continuous-compliance-experiences-challenges-and-txho7p8d2u","2018","Proceedings Article","World Congress on Services","Robert Filepp
Constantin Adam
Milton H. Hernandez
Maja Vukovic
Nikos Anerousis
Guan Qun Zhang","10.1109/SERVICES.2018.00029","","No","IT compliance is an area of increasing attention and capital spend in enterprise IT environments. We present ""Continuous Compliance"", a framework that allows a managed IT services provider to automate the overall process of keeping IT assets conformant with enterprise policies, regulatory frameworks, and other best practices. Our framework applies to all cloud layers and service models: Infrastructure-, Platform-, and Software-as-a-Service. We describe our framework design, its operation, and the post-process analytics and reporting. We also examine remediation reports gathered from over 2,000 servers for a seven month period, graph the incidence of repeated remediations, and explore some reasons for gradually subsiding remediations."
"Guest Editors' Introduction: Software Engineering for Compliance","https://scispace.com/papers/guest-editors-introduction-software-engineering-for-1175vm06en","2012","Journal Article","IEEE Software","Uwe Zdun
Ayse Bener
Erlinda L. Olalia-Carin","10.1109/MS.2012.63","","No","This special issue of IEEE Software explores the challenges in developing compliant software systems. Typically, organizations face conflicting objectives, with compliance policies possibly hindering innovation, slowing down the product development process, or making the whole process most costly. The goal of software engineering for compliance is to bridge the gap between the software engineering community and the compliance community. The articles in this special issue explain the nature and extent of this domain from different viewpoints, the technical challenges it poses, novel software engineering methods for supporting compliance, and the current state of the art."
"Policy Verification and Validation Framework Based on Model Checking Approach","https://scispace.com/papers/policy-verification-and-validation-framework-based-on-model-4u6ntzpj9h","2007","Proceedings Article","International Conference on Autonomic Computing","Shinji Kikuchi
Satoshi Tsuchiya
Motomitsu Adachi
Tsuneo Katsuyama","10.1109/ICAC.2007.31","","No","Policy-based management is drawing attention as a solution to managing today's complex information systems. To be dependable, a policy-based system must be able to check the validity of a policy written by administrators. However, common test methods such as operations tests in a test scenario and simulations cannot check whether systems with given policies will work properly in every possible situation. To solve this problem, we propose a policy verification and validation framework based on model checking that exhaustively verifies a policy's validity by considering the relations between system characteristics and policies. We first define the validity of policies and the information needed to verify them from the viewpoint of model checking. We then construct our policy verification framework based on the definition and, finally, present a case study applying this framework to an on-demand data center scenario and show the effectiveness of our approach."
"Configuration and compliance automation in modern networks: A framework for enhanced security and operational efficiency","https://scispace.com/papers/configuration-and-compliance-automation-in-modern-networks-a-ujdjseb3ptk4","2025","Journal Article","World Journal of Advanced Engineering Technology and Sciences","Suresh Reddy Thati","10.30574/wjaets.2025.15.2.0613","","No","Configuration and compliance automation represents a transformative approach to modern network management, addressing the escalating complexity of enterprise network environments. As organizations expand their digital footprint through cloud integration, IoT adoption, and hybrid work models, the traditional manual approach to network configuration has become increasingly unsustainable. The heterogeneous nature of contemporary networks, typically encompassing multiple vendors, platforms, and technologies, creates significant challenges for maintaining configuration consistency, ensuring regulatory compliance, and safeguarding security postures. This article explores the fundamental components of effective configuration and compliance automation frameworks, including centralized policy repositories, configuration management tools, continuous monitoring systems, and automated remediation workflows. It presents implementation strategies based on organizational maturity and network complexity, outlining critical success factors and addressing common challenges such as legacy device integration and change management resistance. The substantial benefits of automation across operational efficiency, security enhancement, compliance management, and financial performance demonstrate why configuration and compliance automation has become essential for organizations seeking to maintain competitive advantage in an increasingly digital business landscape. As automation technologies continue to evolve, incorporating artificial intelligence and machine learning capabilities, the potential for self-healing, adaptive networks points toward a future where network operations can focus on innovation rather than maintenance."
"System and method for achieving compliance through a closed loop integrated compliance framework and toolkit","https://scispace.com/papers/system-and-method-for-achieving-compliance-through-a-closed-4xiacxozpb","2013","Patent","","Mohanakrishnan Shankar
Gideon Premkumar Manoharan
Amit Saha","","","No","The disclosed embodiments relate to a method, apparatus, and computer-readable medium for managing policy compliance. As exemplary method comprises receiving, by at least one of the one or more computing devices, information associated with a policy event corresponding to a system resource; determining, by at least one of the one or more computing devices, whether the policy event is in compliance with one or more policies; determining, by at least one of the one or more computing devices, a corrective action if the policy event is not in compliance with at least one of the one or more policies; and transmitting, by at least one of the one or more computing devices, information associated with the corrective action if the policy event is not in compliance with at least one of the one or more policies."
"A Survey of Policy Specification Approaches","https://scispace.com/papers/a-survey-of-policy-specification-approaches-4mypakyg77","2002","","","Nicodemos Damianou
Arosha K. Bandara
Morris Sloman
Emil Lupu","","https://scispace.com/pdf/a-survey-of-policy-specification-approaches-4mypakyg77.pdf","Yes","Policies are rules governing the choices in behaviour of a system. They are often used as a means of implementing flexible and adaptive systems for management of internet services, distributed systems, and security systems. There is also a need for a common specification of security policy for large-scale, multiorganisational systems where access control is implemented in a variety of heterogeneous components. In this paper we survey both security and management policy specification approaches. We also cover the issues relating to detecting and resolving conflicts which can arise in the policies and some ideas on how to refine high level goals and service level agreements into implementable policies. The paper briefly outlines some of the research issues that have to be solved for large-scale adoption of policy-based systems"
"AI-Driven Governance for DevOps Compliance","https://scispace.com/papers/ai-driven-governance-for-devops-compliance-6s6mucg79a3m","2022","Journal Article","International journal of scientific research in science, engineering and technology","Sandeep Belidhe","10.32628/ijsrset221654","","No","This particular form of research, specialism DevOps compliance governance, aims to explore how AI is used to complement it. It also shows how AI can fully automate compliance checks, intelligent risk assessments, round-the-clock security monitoring, policies, and policy compliance and automatically prepare the necessary documentation. In AI, human error is eliminated, compliance workflows are accelerated, and constant compliance can be sustained in diverse DevOps settings. The study shows that, with AI implementation, the compliance teams can achieve both dogma and security while allowing the development teams to preserve speed. Finally, AI harnessing in DevOps makes the ways of the respective governance smoother, more accurate, and more reliable for organizations understanding and managing challenging regulatory processes."
"Policy management of enterprise systems: a requirements study","https://scispace.com/papers/policy-management-of-enterprise-systems-a-requirements-study-2oahhv35x5","2006","Proceedings Article","IEEE International Workshop on Policies for Distributed Systems and Networks","Pranam Kolari
Tim Finin
Yelena Yesha
Kelly Lyons
Jen Hawkins
Stephen Perelgut","10.1109/POLICY.2006.23","https://scispace.com/pdf/policy-management-of-enterprise-systems-a-requirements-study-2oahhv35x5.pdf","Yes","Policy enabled applications are being increasingly employed to support responsive information technology services. In competitive business environments, such services increase adaptability of both software and the processes they implement through externalized business and security logic. Over the last decade this has driven both industry and academia to contribute to policy research and engineering, by developing specification languages, frameworks and toolkits. Since this work has typically been applied to and evaluated using new enterprise solutions, policy management for existing applications has been less well studied. In this paper we share our experiences on policy enabling an existing Web based solution, together with identifying new policy enabling requirements from a specific class of enterprise systems."
"CHOReOS Governance V&V policies and rules (D4.1)","https://scispace.com/papers/choreos-governance-v-v-policies-and-rules-d4-1-4v90fc35f4","2011","","","Antonia Bertolino
Guglielmo De Angelis
Cesare Bartolini
Amira Ben Hamida
Felipe M. Besson
Antonello Calabrò
Flavio Corradini
Francesco De Angelis
Mario Fusani
Fabio Kon
Pedro M.B. Leal
Francesca Lonetti
Daniela Mulas
Andrea Polini
Sarah Zribi","","https://hal.inria.fr/hal-00664273/document","Yes","This document presents an initial view of the framework under development for CHOReOS governance and V&V. The focus is on specifying policies and rules on which the framework will rely. After discussing the ULS-FI challenges which are more strictly related to WP 4 goals, we overview the preliminary architecture which will support governance and V&V. We classify policies supporting governance, and start discussing more relevant ones, concerning choreography roles and life-cycle. We also propose approaches for modeling and handling SLA-related requirements. We devote special attention to V&V-related governance aspects, and identify some policies to govern online testing, service ranking and scalability. The framework is still preliminary, in that governance is a transversal concern, and it certainly needs to be harmonized with the components and processes undergoing parallel investigation in the other CHOReOS WPs."
"AI-Augmented DevSecOps Toolchains for Compliance-Critical Cloud Applications in Healthcare and Finance","https://scispace.com/papers/ai-augmented-devsecops-toolchains-for-compliance-critical-xwnsqv20bkrh","2025","Journal Article","International Journal of Leading Research Publication.","Sai Nitesh Palamakula -","10.70528/ijlrp.v6.i7.1686","","No","Cloud applications in healthcare and finance must comply with stringent regulations such as HIPAA, PCI-DSS, and SOC 2. Traditional DevSecOps pipelines rely on manual policy checks and static scanners, which often fail to detect emerging vulnerabilities and compliance drift in real time. This paper introduces an AI-augmented DevSecOps toolchain that embeds autonomous agents throughout the CI/CD workflow to dynamically enforce regulatory controls. The proposed system integrates static code analysis, container scanning, and infrastructure-as-code validation with machine learning models trained to recognize non-compliant patterns in code and configuration. The architecture supports continuous compliance enforcement, reduces manual overhead, and improves audit readiness across regulated cloud environments. This paper delves into the design, implementation of this framework, highlighting its applicability to healthcare and financial workloads."
"Towards governance of rule and policy driven components in distributed systems","https://scispace.com/papers/towards-governance-of-rule-and-policy-driven-components-in-435zap367k","2011","Book Chapter","","Pierre de Leusse
Krzysztof Zieliński","10.1007/978-3-642-24755-2_33","","No","The rule and policy technological landscape is becoming ever more complex, with an extended number of specifications and products. It is therefore becoming increasingly difficult to integrate rule and policy driven components and manage interoperability in distributed environments. The described work presents an infrastructure going towards the governance of heterogeneous rule and policy driven components in distributed systems. The authors' approach leverages on a set of middleware, discovery protocol, knowledge interchange and consolidation to alleviate the environment's complexity."
"Qapla: Policy Compliance for Database-backed Systems","https://scispace.com/papers/qapla-policy-compliance-for-database-backed-systems-15hh31wzo2","2017","Proceedings Article","USENIX Security Symposium","Aastha Mehta
Eslam Elnikety
Katura Harvey
Deepak Garg
Peter Druschel","","","Yes","Many database-backed systems store confidential data that is accessed on behalf of users with different privileges. Policies governing access are often fine-grained, being specific to users, time, accessed columns and rows, values in the database (e.g., user roles), and operators used in queries (e.g., aggregators, group by, and join). Today, applications are often relied upon to issue policy compliant queries or filter the results of non-compliant queries, which is vulnerable to application errors. Qapla provides an alternate approach to policy enforcement that neither depends on application correctness, nor on specialized database support. In Qapla, policies are specific to rows and columns and may additionally refer to the querier’s identity and time, are specified in SQL, and stored in the database itself. We prototype Qapla in a database adapter, and evaluate it by enforcing applicable policies in the HotCRP conference management system and a system for managing academic job applications."
"Governify. An agreement-based service governance framework","https://scispace.com/papers/governify-an-agreement-based-service-governance-framework-57kb5rwq9h","2024","Journal Article","Software impacts","Rafael Fresno-Aranda
Juan Ojeda-Perez
Pablo Fernández
Antonio Ruiz-Corts","10.1016/j.simpa.2024.100629","","No","Governify is a service governance framework designed to enhance service operation by providing automated audit capabilities. It enables the creation of customized microservice architectures to fit various domains. This framework has been applied in real scenarios in both Industry and Academy where it has served researchers and practitioners in service governance as both a visual analytic tool and a test bed for experiments. Governify has proved its ability to gather insights into potential risks tied to noncompliance and to design and monitor best practices in forms of agreements."
"Secure SDLC Frameworks","https://scispace.com/papers/secure-sdlc-frameworks-tjzgo84emd3e","2025","Journal Article","","Mohammad Alauthman
Ahmad Al–Qerem
Amjad Aldweesh
Ammar Almomani","10.4018/979-8-3693-9851-7.ch003","","No","Software applications have become indispensable across sectors, necessitating robust security throughout their lifecycle. This chapter examines transforming the Software Development Life Cycle (SDLC) into a Secure SDLC by embedding security principles at every phase. Through DevSecOps—merging development, operations, and continuous security—organizations strengthen their cyber resilience. A well-structured Secure SDLC with DevSecOps principles mitigates risks while ensuring faster delivery cycles, regulatory compliance, and sustained user trust. The chapter provides methodologies for threat modeling, automation, collaboration, and monitoring, creating a clear pathway for businesses to incorporate security as an integral part of software engineering rather than an afterthought. Through theoretical frameworks and case studies, it demonstrates how security integration drives both protection and business value."
"Compliance Management of IaC-Based Cloud Deployments During Runtime","https://scispace.com/papers/compliance-management-of-iac-based-cloud-deployments-during-4zbye9paxo","2023","Proceedings Article","","Ghareeb Falazi
Lukas Harzenetter
Kálmán Képes
Frank Leymann
Uwe Breitenbücher
Evangelos Ntentos
Uwe Zdun
Martin Becker
Elena Heldwein","10.1145/3603166.3632135","","No","Modern cloud applications increasingly depend on Infrastructure-as-Code (IaC) practices for infrastructure automation to help manage the complexity of deploying large-scale architectures. Additionally, the deployment of cloud applications is commonly subject to compliance rules. Moreover, designing compliant IaC-based cloud deployments is not enough since runtime changes to the infrastructure or the configuration of individual components may introduce compliance violations. Often, the process of checking and fixing such violations is done manually, which is time-consuming and error-prone. Therefore, this work aims to define and implement a method for runtime IaC compliance management that reduces the complexity, effort, and uncertainty of checking and enforcing compliance rules against IaC-based cloud deployments at runtime. To this end, we follow the design-science research methodology to design and implement (i) the Runtime IaC Compliance Management (RICMa) method and (ii) the IaC Compliance Management Framework (IaCMF) that supports the execution of the RICMa method. We prototypically implement IaCMF and evaluate it using a qualitative interview study with industry experts."
"A Model-Based Framework for Legal Policy Simulation and Compliance Checking","https://scispace.com/papers/a-model-based-framework-for-legal-policy-simulation-and-321hbcnw33","2017","","","Ghanem Soltana","","https://scispace.com/pdf/a-model-based-framework-for-legal-policy-simulation-and-321hbcnw33.pdf","Yes","Information systems implementing requirements from laws and regulations, such as taxes and social benefits, need to be thoroughly verified to demonstrate their compliance. Several Verification and Validation (V&V) techniques, such as reliability testing, and modeling and simulation, can be used for assessing that such systems meet their legal. Typically, one has to model the expected (legal) behavior of the system in a form that can be executed (simulated), subject the resulting models and the system to the same input data, and then compare the observed behavior of the model simulation and system execution. Existing V&V techniques often rely on code and complex logical expressions with no intuitive appeal to legal experts for specifying the expected behavior of a given system. Subsequently, one has no practical way to validate with legal experts that the underlying legal requirements are indeed complete and constitute a faithful representation of what needs to be implemented. Further, manually defining the expected behavior of a system and its test oracles is a tedious and error-prone task. The challenge here is to find a suitable knowledge representation that can be understood by all the involved stakeholders, e.g., software engineers and legal experts, but that remains complete and precise enough to enable automated analysis such as simulation and testing. As real data is seldom accessible in highly regulated domains, V&V requires the generation of synthetic testing data that can be used to build confidence in the reliability of the system under test. In particular, such data has to be structurally and logically well-formed to raise meaningful failures that can help reasoning about the reliability of the system under test. Further, the data should exhibit as much as possible the actual or anticipated system usage to help mimic how the system would behave under realistic circumstances. Generating such data is not a trivial task as the underlying data schemas are usually large and subject to numerous complex domain-related logical constraints. In this thesis, we investigate the use of the Unified Modeling Language (UML) and model-driven technologies, e.g., model to code transformations, to facilitate V&V activities for information systems that have to conform to laws and regulations, while tackling the above challenges. All our technical solutions have been developed and empirically evaluated in close collaboration with a government administration. Concretely, the technical solutions covered by this thesis include: - A modeling notation and methodology for formalizing legal policies. We propose a modeling notation and methodology for building abstract interpretations of the law. Models built using our methodology are simple enough to be understood by the involved stakeholders and are, at the same time, detailed enough to enable automated V&V activities. - A model-based simulation framework. We develop a model-based framework and associated tool support for simulating legal policies, when formalized…"
"Holding on to Compliance While Adopting DevSecOps: An SLR","https://scispace.com/papers/holding-on-to-compliance-while-adopting-devsecops-an-slr-3emlprho","2022","Journal Article","Electronics","Xhesika Ramaj
Mary Sánchez-Gordón
Vasileios Gkioulos
Sabarathinam Chockalingam
Ricardo Colomo-Palacios","10.3390/electronics11223707","https://scispace.com/pdf/holding-on-to-compliance-while-adopting-devsecops-an-slr-3emlprho.pdf","Yes","The software industry has witnessed a growing interest in DevSecOps due to the premises of integrating security in the software development lifecycle. However, security compliance cannot be disregarded, given the importance of adherence to regulations, laws, industry standards, and frameworks. This study aims to provide an overview of compliance aspects in the context of DevSecOps and explore how compliance is ensured. Furthermore, this study reveals the trends of compliance according to the extant literature and identifies potential directions for further research in this context. Therefore, we carried out a systematic literature review on the integration of compliance aspects in DevSecOps, which rigorously followed the guidelines proposed by Kitchenham and Charters. We found 934 articles related to the topic by searching five bibliographic databases (163) and Google Scholar (771). Through a rigorous selection process, we selected 15 papers as primary studies. Then, we identified the compliance aspects of DevSecOps and grouped them into three main categories: compliance initiation, compliance management, and compliance technicalities. We observed a low number of studies; therefore, we encourage further efforts into the exploration of compliance aspects, their automated integration, and the development of metrics to evaluate such a process in the context of DevSecOps."
"Securing Infrastructure as Code (IaC) through DevSecOps:A Comprehensive Risk Management Framework","https://scispace.com/papers/securing-infrastructure-as-code-iac-through-devsecops-a-72f22yuhh2wz","2023","Proceedings Article","","Ammar Zeini
Ruth G. Lennon
Patrick Lennon","10.1109/cyber-rci59474.2023.10671452","","No","Despite the evident advantages of Infrastructure as Code (IaC) in software development, the nature of bugs and potential threats arising from its implementation remains subject to ongoing investigation. The formulation of a list, enumerating potential threats during the IaC process remains an unattained goal. However, it is not enough to recounting IaC threats only, it is imperative for Development (Dev), Security (Sec), and Operations (Ops) teams to synergistically collaborate from early developmental stages to conduct thorough risks’ analysis, estimation, and mitigation procedures concerning IaC-related risks. Moreover, adhering to security standards and risk management framework throughout the IaC lifecycle will enhance the overall security of the deployment process. A risk management framework for IaC is essential. The extant risk management and threat modeling methodologies may necessitate tailoring to effectively protect the Software Development Lifecycle (SDLC) from IaC misuse. This research aims to identify threats that threaten IaC lifecycle or arise from the utilization of IaC. In addition, it tries to integrate IaC practices with the DevSecOps culture to devise a robust risk management framework and prescribe pertinent practices conducive to fostering secure IaC implementation."
"Analysis of Adaptive Policy-Based Approach to Avoid Policy Conflicts","https://scispace.com/papers/analysis-of-adaptive-policy-based-approach-to-avoid-policy-1dg2tkj631","2012","Proceedings Article","Asia-Pacific Software Engineering Conference","Abdehamid Abdelhadi Mansor
Wan Mohd. Nasir Wan Kadir
Toni Anwar
Shamsul Sahibuddin","10.1109/APSEC.2012.155","","No","PobMC is an adaptive scalable framework which uses policies to control and adapt the system behaviour. Moreover, PobMC has the capability to decouple the adaptation concerns from the application code. Since policies are used to govern the system behavior, conflicts may arise in the set of policies and also may arise during the refinement process, between the high-level goals and the implementable policies. Moreover, policy conflict can result from propagation, action composition and other constraint policies, which cannot be detected by simply comparing authorization policies. In this paper we present a static analysis to address the inconsistencies, scalability when there are two or more policies are enforced simultaneously. Then, we classify our system policy conflicts to verify that policies are enforced correctly. Moreover, the paper provides temporal specification patterns to detect each type of conflicts."
"A Design For Comprehensive Information System Management Framework Integrating Secure Software Development, Resource Management, and Real-Time Monitoring","https://scispace.com/papers/a-design-for-comprehensive-information-system-management-13roe4sqra79","2024","Proceedings Article","","Herlambang Rafli Wicaksono
Ihsan Fadli Tampati
Nathanael Berliano Novanka Putra
Hermawan Setiawan
Dimas Rifqi Firmansyah","10.1109/icicos62600.2024.10636894","","No","This paper proposes a holistic framework for the development, management, and monitoring of secure web information systems. Emphasizing a secure software development life cycle (SDLC), resource management, and real-time monitoring, the framework aims to standardize and enhance the process of web application development while prioritizing security at every phase. The framework incorporates threat modeling during planning and design, security guidelines during implementation, and continuous vulnerability scanning. Additionally, it integrates resource management to ensure effective allocation of human, hardware, and software resources. Tools are employed for real-time monitoring, providing usage insights that inform managerial decisions. The proposed framework strives to create a comprehensive approach to web application development that is both secure and well-managed. The implementation results demonstrate the proposed framework’s effectiveness in simplifying development, optimizing resources, and enhancing security for web applications. Furthermore, compared to the secure software development lifecycle (SSDLC) framework, it offers advantages in resource management and real-time monitoring, rendering it more comprehensive."
"Software development governor: Automating governance in software development environments","https://scispace.com/papers/software-development-governor-automating-governance-in-26126sctp5","2009","Proceedings Article","International Conference on Software Engineering","Avi Yaeli
Alex Kofman
Yael Dubinsky","10.1109/ICSE-COMPANION.2009.5071038","","No","IBM Software Development Governor is a novel tool that supports specification and enactment of governance in software development environments. It enables specifying key decision points and policies throughout the lifecycle of development artifacts and automating these specifications in Rational Team Concert-a collaborative software development and delivery environment. In this paper we describe the concepts on which Software Development Governor is built and present the tool and its architecture."
"Policy Driven Development: Flexible Policy Insertion for Large Scale Systems","https://scispace.com/papers/policy-driven-development-flexible-policy-insertion-for-1te2ujfkm9","2012","Proceedings Article","IEEE International Symposium on Policies for Distributed Systems and Networks","Barry Demchak
Ingolf H. Krüger","10.1109/POLICY.2012.13","https://scispace.com/pdf/policy-driven-development-flexible-policy-insertion-for-1te2ujfkm9.pdf","Yes","The success of a software system depends critically on how well it reflects and adapts to stakeholder requirements. Traditional development methods often frustrate stakeholders by creating long latencies between requirement articulation and system deployment, especially in large scale systems. One source of latency is the maintenance of policy decisions encoded directly into system workflows at development time, including those involving access control and feature set selection. We created the Policy Driven Development (PDD) methodology to address these development latencies by enabling the flexible injection of decision points into existing workflows at runtime, thus enabling policy composition that integrates requirements furnished by multiple, oblivious stakeholder groups. Using PDD, we designed and implemented a production cyber infrastructure that demonstrates policy and workflow injection that quickly implements stakeholder requirements, including features not contemplated in the original system design. PDD provides a path to quickly and cost effectively evolve such applications over a long lifetime."
"Service-Oriented Policy Management for Web-Application Frameworks","https://scispace.com/papers/service-oriented-policy-management-for-web-application-9t7ugbyifz","2009","Journal Article","IEEE Internet Computing","Kevin Feeney
David Lewis
Declan O'Sullivan","10.1109/MIC.2009.95","","No","Policy-based management technologies represent an important tool for managing the user services that Web-application frameworks provide. However, current policy-management systems are a poor fit for the domain because they don't support decentralized management in open environments. The Community-Based Policy-Management System (CBPMS) can manage services in domains where relationships are dynamic and flexible, policy specification is distributed and uses multiple languages, and management decision-making is shared between users and service providers. This article describes the CBPMS schema and architecture, showing how it provides flexible, dynamic, and extensible policy-based management capabilities to those who provide user services on the Web."
"intelliGOV – Compliance Verification of Service-Oriented Architectures with Ontologies and Semantic Rules and Queries","https://scispace.com/papers/intelligov-compliance-verification-of-service-oriented-16r77q4cgt","2014","Book Chapter","Database and Expert Systems Applications","Haroldo Maria Teixeira Filho
Leonardo Guerreiro Azevedo
Leonardo Guerreiro Azevedo
Sean W. M. Siqueira","10.1007/978-3-319-10073-9_34","","No","Organizations are adopting Service-Oriented Architecture (SOA) to simplify system landscape, reduce costs and achieve deadlines. To accomplish these goals, it is necessary to ensure that the architecture and its evolution are compliant with business goals, best practices, legal and regulatory requirements. However, compliance verification of SOA is difficult due to the wide set of domains and the heterogeneity of the elements used to compose a service oriented solution. Although ontologies and rules could provide a solution for this problem, this approach cannot represent and verify a significant set of governance policies. Therefore, we propose intelliGOV, an architecture that gathers data from SOA environment, loads it in an ontology and uses semantic rules and queries to verify compliance. A case study conducted in a global energy company provides evidence of solution expressiveness, low coding demand and independence of methods and tools."
"Towards Adaptive Compliance","https://scispace.com/papers/towards-adaptive-compliance-2tr8afjkao","2016","Proceedings Article","arXiv: Software Engineering","Jesús García-Galán
Liliana Pasquale
George Grispos
Bashar Nuseibeh","10.1145/2897053.2897070","https://scispace.com/pdf/towards-adaptive-compliance-2tr8afjkao.pdf","Yes","Mission critical software is often required to comply with multiple regulations, standards or policies. Recent paradigms, such as cloud computing, also require software to operate in heterogeneous, highly distributed, and changing environments. In these environments, compliance requirements can vary at runtime and traditional compliance management techniques, which are normally applied at design time, may no longer be sufficient. In this paper, we motivate the need for adaptive compliance by illustrating possible compliance concerns determined by runtime variability. We further motivate our work by means of a cloud computing scenario, and present two main contributions. First, we propose and justify a process to support adaptive compliance that ex- tends the traditional compliance management lifecycle with the activities of the Monitor-Analyse-Plan-Execute (MAPE) loop, and enacts adaptation through re-configuration. Second, we explore the literature on software compliance and classify existing work in terms of the activities and concerns of adaptive compliance. In this way, we determine how the literature can support our proposal and what are the open research challenges that need to be addressed in order to fully support adaptive compliance."
"Mitigating an Oxymoron: Compliance in a DevOps Environments","https://scispace.com/papers/mitigating-an-oxymoron-compliance-in-a-devops-environments-2ph9utffig","2016","Proceedings Article","Computer Software and Applications Conference","John R. Michener
Aaron T. Clager","10.1109/COMPSAC.2016.155","","No","Compliance and regulation are fundamentally intended to establish trust between entities that create and use shared computing systems across all layers. Security compliance requirements (such as those of Payment Card Industry (PCI) Data Security Standard (DSS)1 or the US NIST 800 special publication series2) are framed around a classic &#x0022;Waterfall&#x0022; software development methodology. The software industries recent shift to a &#x0022;DevOps&#x0022; methodology has put the trust created with compliance at risk. This paper contains a proposed strategy to achieve compliance and establish trust using a DevOps environment."
"Multi-dimensional Model Driven Policy Generation","https://scispace.com/papers/multi-dimensional-model-driven-policy-generation-3qus95v301","2013","Book Chapter","International Conference on Cloud Computing and Services Science","Juan Li
Wendpanga Francis Ouedraogo
Frédérique Biennier","10.1007/978-3-319-11561-0_5","https://scispace.com/pdf/multi-dimensional-model-driven-policy-generation-3qus95v301.pdf","No","As Cloud Computing provides agile and scalable IT infrastructure, QoS-assured services and customizable computing environment, it increases the call for agile and dynamic deployment and governance environments over multi-cloud infrastructure. By now, governance and Non Functional Properties (such as security, QoS…) are managed in a static way, limiting the global benefits of deploying service-based information system over multi-cloud environments. To overcome this limit, we propose a contextualised policy generation process to allow both an agile management NFP in a multi-cloud context and a secured deployment of the service-based information system. The last step of this Model Driven Policy Engineering approach uses policies as Model@runtime to select, compose, deploy and orchestrate NFP management functions depending on the exact execution context. Moreover, a dynamic governance loop including autonomic KPI management is used to control continuously the governance results."
"Model management for regulatory compliance: a position paper","https://scispace.com/papers/model-management-for-regulatory-compliance-a-position-paper-5bpsdh8d1p","2016","Proceedings Article","","Sahar Kokaly
Rick Salay
Mehrdad Sabetzadeh
Marsha Chechik
Tom Maibaum","10.1145/2896982.2896985","","No","Software has come to mediate many of the activities in life, including financial service platforms, social networks and vehicle control As a result, governing bodies have responded to this trend by creating standards and regulations to address issues such as safety and privacy In this context, the compliance of software development to standards and regulations has emerged as a key issue For software development organizations, compliance is a complex and costly goal to achieve They may have to comply with multiple standards due to multiple jurisdictions or to address different aspects of the software and these may overlap and conflict with each other The evolution of standards must be tracked and changes assessed Evidence for claims of compliance must be collected and managed Finally, maintaining families of related software products (product lines) further multiplies the effort In this paper, we propose to exploit the connection between the field of model management and the problem of compliance management and explore how to use model management techniques to address software compliance management issues"
"Common policy language for Policy Compliance and Change Detection System in managed service in data networks","https://scispace.com/papers/common-policy-language-for-policy-compliance-and-change-49qbfbg417","2014","Proceedings Article","International Symposium on Networks, Computers and Communications","Saeed M. Agbariah","10.1109/SNCC.2014.6866525","","No","As networks continue to grow exponentially, the need to build, maintain, and troubleshoot the growing number of heterogeneous network components has also increased significantly. Often times, scheduled and ad-hoc configuration changes lead to potential configuration errors, policy violations, inefficiencies, and vulnerable states. The current network management landscape offers a variety of configuration auditing tools to reduce risks and achieve compliance. However; they mostly operate in an offline fashion and lack real time reporting capabilities. In our previous work, we proposed an Automated Policy Compliance and Change Detection System capable of audit configurations against internal policies or external best practices and provide centralized reporting for monitoring and regulatory purposes in real time. One of the core requirements for our proposed system is a common policy language for expressing device and organizational policies. This paper defines some of the building blocks of the proposed policy language. A common policy language that will ease the enforcement of policies to all components of the network. Furthermore, the proposed common policy language will bring numerous practical advantages, such as lowering implementation overhead, as well as the possibility to use the same or at least similar tools to maintain the policies."
"Automated Drift Detection and Remediation in Infrastructure-as-Code (IaC) Deployments","https://norma.ncirl.ie/7730/","","","","AM Solanki","","https://norma.ncirl.ie/7730/1/anujamahendrasinghsolanki.pdf","No","[Abstract not available]"
"Automating infrastructure with infrastructure as code (iac)","https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4986767","2019","Journal Article","International journal of science and research","Sandeep Chinamanagonda","10.21275/sr24829170834","https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=4986767","No","[Abstract not available]"
"AI-Driven Configuration Drift Detection in Cloud Environments","https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5138379","","Journal Article","Social Science Research Network","Gogulakrishnan Thiyagarajan
Vinay Bist
Prabhudarshi Nayak","10.2139/ssrn.5138379","https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=5138379","No","[Abstract not available]"
"Towards a taxonomy of infrastructure as code misconfigurations: an ansible study","https://link.springer.com/chapter/10.1007/978-3-031-72578-4_5","2024","Journal Article","Communications in computer and information science","Rohollah Nasiri
Indika Kumara
Damian A. Tamburri
Willem‐Jan van den Heuvel","10.1007/978-3-031-72578-4_5","","No","[Abstract not available]"
"Ansible Vs. Terraform: A Comparative Study on Infrastructure As Code (IaC) Efficiency in Enterprise IT","https://www.ijetcsit.org/index.php/ijetcsit/article/view/117","2023","Journal Article","","Ali Syed
Erik Anazagasty","10.63282/3050-9246.ijetcsit-v4i2p105","https://www.ijetcsit.org/index.php/ijetcsit/article/download/117/91","No","[Abstract not available]"
"Infrastructure as Code–Technology Review and Research Challenges","https://www.researchgate.net/profile/Claus-Pahl/publication/389406746_Infrastructure_as_Code_-Technology_Review_and_Research_Challenges/links/67c17529461fb56424ec2b8e/Infrastructure-as-Code-Technology-Review-and-Research-Challenges.pdf","","","","C Pahl
NG Gunduz
OC Sezen
A Ghamgosar","","https://www.researchgate.net/profile/Claus-Pahl/publication/389406746_Infrastructure_as_Code_-Technology_Review_and_Research_Challenges/links/67c17529461fb56424ec2b8e/Infrastructure-as-Code-Technology-Review-and-Research-Challenges.pdf","No","[Abstract not available]"
"AI-Driven Configuration Management: Automating Infrastructure as Code (IaC)","https://www.researchgate.net/profile/Dorcas-Esther/publication/388633079_AI-Driven_Configuration_Management_Automating_Infrastructure_as_Code_IaC/links/67a012d7207c0c20fa72eac5/AI-Driven-Configuration-Management-Automating-Infrastructure-as-Code-IaC.pdf","","","","A Diefenbach","","https://www.researchgate.net/profile/Dorcas-Esther/publication/388633079_AI-Driven_Configuration_Management_Automating_Infrastructure_as_Code_IaC/links/67a012d7207c0c20fa72eac5/AI-Driven-Configuration-Management-Automating-Infrastructure-as-Code-IaC.pdf","No","[Abstract not available]"
"Testing idempotence for infrastructure as code","https://link.springer.com/chapter/10.1007/978-3-642-45065-5_19","2013","Book Chapter","International Middleware Conference","Waldemar Hummer
Florian Rosenberg
Fábio Oliveira
Tamar Eilam","10.1007/978-3-642-45065-5_19","https://inria.hal.science/hal-01480784/file/978-3-642-45065-5_19_Chapter.pdf","Yes","Due to the competitiveness of the computing industry, software developers are pressured to quickly deliver new code releases. At the same time, operators are expected to update and keep production systems stable at all times. To overcome the development–operations barrier, organizations have started to adopt Infrastructure as Code (IaC) tools to efficiently deploy middleware and applications using automation scripts. These automations comprise a series of steps that should be idempotent to guarantee repeatability and convergence. Rigorous testing is required to ensure that the system idempotently converges to a desired state, starting from arbitrary states. We propose and evaluate a model-based testing framework for IaC. An abstracted system model is utilized to derive state transition graphs, based on which we systematically generate test cases for the automation. The test cases are executed in light-weight virtual machine environments. Our prototype targets one popular IaC tool (Chef), but the approach is general. We apply our framework to a large base of public IaC scripts written by operators, showing that it correctly detects non-idempotent automations."
"IT Infrastructure Automation Management with Infrastructure-As-Code (IAC) Modelling in Multi-Cloud Environments","http://jurnal-tmit.com/index.php/home/article/view/1421","","","","A Sulaiman","","https://jurnal-tmit.com/index.php/home/article/download/1421/393","No","[Abstract not available]"
"Learning with drift detection","https://link.springer.com/chapter/10.1007/978-3-540-28645-5_29","2004","Book Chapter","Brazilian Symposium on Artificial Intelligence","João Gama
Pedro Medas
Gladys Castillo
Gladys Castillo
Pedro Pereira Rodrigues","10.1007/978-3-540-28645-5_29","https://sweet.ua.pt/gladys/Papers/GamaMedasCastilloRodriguesSBIA04.pdf","No","Most of the work in machine learning assume that examples are generated at random according to some stationary probability distribution. In this work we study the problem of learning when the distribution that generate the examples changes over time. We present a method for detection of changes in the probability distribution of examples. The idea behind the drift detection method is to control the online error-rate of the algorithm. The training examples are presented in sequence. When a new training example is available, it is classified using the actual model. Statistical theory guarantees that while the distribution is stationary, the error will decrease. When the distribution changes, the error will increase. The method controls the trace of the online error of the algorithm. For the actual context we define a warning level, and a drift level. A new context is declared, if in a sequence of examples, the error increases reaching the warning level at example k w , and the drift level at example k d . This is an indication of a change in the distribution of the examples. The algorithm learns a new model using only the examples since k w . The method was tested with a set of eight artificial datasets and a real world dataset. We used three learning algorithms: a perceptron, a neural network and a decision tree. The experimental results show a good performance detecting drift and with learning the new concept. We also observe that the method is independent of the learning algorithm."
"An experimental evaluation of process concept drift detection","https://www.vldb.org/pvldb/vol16/p1856-adams.pdf","2023","Journal Article","Proceedings of The Vldb Endowment","Jan Niklas Adams
Cameron Pitsch
T. Brockhoff
Wil M. P. van der Aalst","10.14778/3594512.3594517","https://www.vldb.org/pvldb/vol16/p1856-adams.pdf","No","Process mining provides techniques to learn models from event data. These models can be descriptive (e.g., Petri nets) or predictive (e.g., neural networks). The learned models offer operational support to process owners by conformance checking, process enhancement, or predictive monitoring. However, processes are frequently subject to significant changes, making the learned models outdated and less valuable over time. To tackle this problem, Process Concept Drift (PCD) detection techniques are employed. By identifying when the process changes occur, one can replace learned models by relearning, updating, or discounting pre-drift knowledge. Various techniques to detect PCDs have been proposed. However, each technique's evaluation focuses on different evaluation goals out of accuracy, latency, versatility, scalability, parameter sensitivity, and robustness. Furthermore, the employed evaluation techniques and data sets differ. Since many techniques are not evaluated against more than one other technique, this lack of comparability raises one question: How do PCD detection techniques compare against each other? With this paper, we propose, implement, and apply a unified evaluation framework for PCD detection. We do this by collecting evaluation goals and evaluation techniques together with data sets. We derive a representative sample of techniques from a taxonomy for PCD detection. The implemented techniques and proposed evaluation framework are provided in a publicly available repository. We present the results of our experimental evaluation and observe that none of the implemented techniques works well across all evaluation goals. However, the results indicate future improvement points of algorithms and guide practitioners."
"An overview of unsupervised drift detection methods","https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1381","2020","Journal Article","Wiley Interdisciplinary Reviews-Data Mining and Knowledge Discovery","Rosana Noronha Gemaque
Albert Franca Josua Costa
Rafael Giusti
Eulanda Miranda dos Santos","10.1002/WIDM.1381","https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/widm.1381","Yes","Practical applications involving big data, such as weather monitoring, identification of customer preferences, Internet log analysis, and sensors warnings require challenging data analysis, since these are examples of problems whose data are generated in streams and usually demand real-time analytics. Patterns in such data stream problems may change quickly. Consequently, machine learning models that operate in this context must be updated over time. This phenomenon is called concept drift in machine learning and data mining literature. Several different directions have been pursued to learn from data stream and to deal with concept drift. However, most drift detection methods consider that an instance's class label is available right after its prediction, since these methods work by monitoring the prediction results of a base classifier or an ensemble of classifiers. Nevertheless, this constraint is unrealistic in several practical problems. To cope with this constraint, some works are focused on proposing efficient unsupervised or semi-supervised concept drift detectors. While interesting and recent overview papers dedicated to supervised drift detectors have been published, the scenario is not the same in terms of unsupervised methods. Therefore, this work presents a comprehensive overview of approaches that tackle concept drift in classification problems in an unsupervised manner. Additional contribution includes a proposed taxonomy of state-of-the-art approaches for concept drift detection based on unsupervised strategies. This article is categorized under: Technologies > Classification Technologies > Machine Learning. © 2020 The Authors. WIREs Data Mining and Knowledge Discovery published by Wiley Periodicals LLC."
"Early drift detection method","https://www.academia.edu/download/48905428/Early_Drift_Detection_Method_20160917-1085-1m513qn.pdf","2005","","","Manuel Baena-Garc
Jose del Campo ¶ Avila
Albert Bifet
Ricard Gavald
Rafael Morales-Bueno","","https://www.academia.edu/download/48905428/Early_Drift_Detection_Method_20160917-1085-1m513qn.pdf","Yes","An emerging problem in Data Streams is the detection of concept drift. This problem is aggravated when the drift is gradual over time. In this work we deflne a method for detecting concept drift, even in the case of slow gradual change. It is based on the estimated distribution of the distances between classiflcation errors. The proposed method can be used with any learning algorithm in two ways: using it as a wrapper of a batch learning algorithm or implementing it inside an incremental and online algorithm. The experimentation results compare our method (EDDM) with a similar one (DDM). Latter uses the error-rate instead of distance-error-rate."
"Adaptive concept drift detection","https://onlinelibrary.wiley.com/doi/abs/10.1002/sam.10054","2009","Journal Issue","Statistical Analysis and Data Mining","Anton Dries
Ulrich Rückert","10.1002/SAM.V2:5/6","https://epubs.siam.org/doi/pdf/10.1137/1.9781611972795.21","No","An established method to detect concept drift in data streams is to perform statistical hypothesis testing on the multivariate data in the stream. The statistical theory offers rank-based statistics for this task. However, these statistics depend on a fixed set of characteristics of the underlying distribution. Thus, they work well whenever the change in the underlying distribution affects the properties measured by the statistic, but they perform not very well, if the drift influences the characteristics caught by the test statistic only to a small degree. To address this problem, we show how uniform convergence bounds in learning theory can be adjusted for adaptive concept drift detection. In particular, we present three novel drift detection tests, whose test statistics are dynamically adapted to match the actual data at hand. The first one is based on a rank statistic on density estimates for a binary representation of the data, the second compares average margins of a linear classifier induced by the 1-norm support vector machine (SVM), and the last one is based on the average zero-one, sigmoid or stepwise linear error rate of an SVM classifier. We compare these new approaches with the maximum mean discrepancy method, the StreamKrimp system, and the multivariate Wald–Wolfowitz test. The results indicate that the new methods are able to detect concept drift reliably and that they perform favorably in a precision-recall analysis. Copyright © 2009 Wiley Periodicals, Inc. Statistical Analysis and Data Mining 2: 311-327, 2009"
"Flexible consistency checking","https://dl.acm.org/doi/abs/10.1145/839268.839271","2003","Journal Article","ACM Transactions on Software Engineering and Methodology","Christian Nentwich
Wolfgang Emmerich
Anthony Finkelsteiin
Ernst Ellmer","10.1145/839268.839271","https://dl.acm.org/doi/pdf/10.1145/839268.839271","No","The problem of managing the consistency of heterogeneous, distributed software engineering documents is central to the development of large and complex systems. We show how this problem can be addressed using xlinkit, a lightweight framework for consistency checking that leverages standard Internet technologies. xlinkit provides flexibility, strong diagnostics, and support for distribution and document heterogeneity. We use xlinkit in a comprehensive case study that demonstrates how design, implementation and deployment information of an Enterprise JavaBeans system can be checked for consistency, and rechecked incrementally when changes are made."
"Visual drift detection for event sequence data of business processes","https://ieeexplore.ieee.org/abstract/document/9316994/","2020","Journal Article","arXiv: Human-Computer Interaction","Anton Yeshchenko
Claudio Di Ciccio
Jan Mendling
Artem Polyvyanyy","10.1109/TVCG.2021.3050071","https://arxiv.org/pdf/2011.09130","Yes","Event sequence data is increasingly available in various application domains, such as business process management, software engineering, or medical pathways. Processes in these domains are typically represented as process diagrams or flow charts. So far, various techniques have been developed for automatically generating such diagrams from event sequence data. An open challenge is the visual analysis of drift phenomena when processes change over time. In this paper, we address this research gap. Our contribution is a system for fine-granular process drift detection and corresponding visualizations for event logs of executed business processes. We evaluated our system both on synthetic and real-world data. On synthetic logs, we achieved an average F-score of 0.96 and outperformed all the state-of-the-art methods. On real-world logs, we identified all types of process drifts in a comprehensive manner. Finally, we conducted a user study highlighting that our visualizations are easy to use and useful as perceived by process mining experts. In this way, our work contributes to research on process mining, event sequence analysis, and visualization of temporal data."
"Concept drift detection for streaming data","https://ieeexplore.ieee.org/abstract/document/7280398/","2015","Proceedings Article","International Joint Conference on Neural Network","Heng Wang
Zubin Abraham","10.1109/IJCNN.2015.7280398","https://arxiv.org/pdf/1504.01044","Yes","Common statistical prediction models often require and assume stationarity in the data However, in many practical applications, changes in the relationship of the response and predictor variables are regularly observed over time, resulting in the deterioration of the predictive performance of these models This paper presents Linear Four Rates (LFR), a framework for detecting these concept drifts and subsequently identifying the data points that belong to the new concept (for relearning the model) Unlike conventional concept drift detection approaches, LFR can be applied to both batch and stream data; is not limited by the distribution properties of the response variable (eg, datasets with imbalanced labels); is independent of the underlying statistical-model; and uses user-specified parameters that are intuitively comprehensible The performance of LFR is compared to benchmark approaches using both simulated and commonly used public datasets that span the gamut of concept drift types The results show LFR significantly outperforms benchmark approaches in terms of recall, accuracy and delay in detection of concept drifts across datasets"
"Automated consistency checking of requirements specifications","https://dl.acm.org/doi/abs/10.1145/234426.234431","1996","Journal Article","ACM Transactions on Software Engineering and Methodology","Constance L. Heitmeyer
Ralph D. Jeffords
B. Labaw","10.1145/234426.234431","https://dl.acm.org/doi/pdf/10.1145/234426.234431","No","This article describes a formal analysis technique, called consistency checking, for automatic detection of errors, such as type errors, nondeterminism, missing cases, and circular definitions, in requirements specifications. The technique is designed to analyze requirements specifications expressed in the SCR (Software Cost Reduction) tabular notation. As background, the SCR approach to specifying requirements is reviewed. To provide a formal semantics for the SCR notation and a foundation for consistency checking, a formal requirements model is introduced; the model represents a software system as a finite-state automation which produces externally visible outputs in response to changes in monitored environmental quantities. Results of two experiments are presented which evaluated the utility and scalability of our technique for consistency checking in real-world avionics application. The role of consistency checking during the requirements phase of software development is discussed."
"Instant consistency checking for the UML","https://dl.acm.org/doi/abs/10.1145/1134285.1134339","2006","Proceedings Article","International Conference on Software Engineering","Alexander Egyed","10.1145/1134285.1134339","https://dl.acm.org/doi/pdf/10.1145/1134285.1134339","Yes","Inconsistencies in design models should be detected immediately to save the engineer from unnecessary rework. Yet, tools are not capable of keeping up with the engineers' rate of model changes. This paper presents an approach for quickly, correctly, and automatically deciding what consistency rules to evaluate when a model changes. The approach does not require consistency rules with special annotations. Instead, it treats consistency rules as black-box entities and observes their behavior during their evaluation to identify what model elements they access. The UML/Analyzer tool, integrated with IBM Rational Rose™, fully implements this approach. It was used to evaluate 29 models with tens-of-thousands of model elements, evaluated on 24 types of consistency rules over 140,000 times. We found that the approach provided design feedback correctly and required, in average, less than 9ms evaluation time per model change with a worst case of less than 2 seconds at the expense of a linearly increasing memory need. This is a significant improvement over the state-of-the-art."
"Fast and accurate business process drift detection","https://link.springer.com/chapter/10.1007/978-3-319-23063-4_27","2015","Book Chapter","Business Process Management","Abderrahmane Maaradji
Marlon Dumas
Marcello La Rosa
Alireza Ostovar","10.1007/978-3-319-23063-4_27","https://eprints.qut.edu.au/83013/1/paper.pdf","Yes","Business processes are prone to continuous and unexpected changes Process workers may start executing a process differently in order to adjust to changes in workload, season, guidelines or regulations for example Early detection of business process changes based on their event logs --- also known as business process drift detection --- enables analysts to identify and act upon changes that may otherwise affect process performance Previous methods for business process drift detection are based on an exploration of a potentially large feature space and in some cases they require users to manually identify the specific features that characterize the drift Depending on the explored feature set, these methods may miss certain types of changes This paper proposes a fully automated and statistically grounded method for detecting process drift The core idea is to perform statistical tests over the distributions of runs observed in two consecutive time windows By adaptively sizing the window, the method strikes a trade-off between classification accuracy and drift detection delay A validation on synthetic and real-life logs shows that the method accurately detects typical change patterns and scales up to the extent that it works for online drift detection"
"xlinkit: A consistency checking and smart link generation service","https://dl.acm.org/doi/abs/10.1145/514183.514186","2002","Journal Article","ACM Transactions on Internet Technology","Christian Nentwich
Licia Capra
Wolfgang Emmerich
Anthony Finkelsteiin","10.1145/514183.514186","https://dl.acm.org/doi/pdf/10.1145/514183.514186","No","xlinkit is a lightweight application service that provides rule-based link generation and checks the consistency of distributed Web content. It leverages standard Internet technologies, notably XML, XPath, and XLink. xlinkit can be used as part of a consistency management scheme or in applications that require smart link generation, including portal construction and management of large document repositories. In this article we show how consistency constraints can be expressed and checked. We describe a novel semantics for first-order logic that produces links instead of truth values and give an account of our content management strategy. We present the architecture of our service and the results of two substantial case studies that use xlinkit for checking course syllabus information and for validating UML models supplied by industrial partners."
"Online and non-parametric drift detection methods based on Hoeffding's bounds","https://ieeexplore.ieee.org/abstract/document/6871418/","2015","Journal Article","IEEE Transactions on Knowledge and Data Engineering","Isvani Frias-Blanco
José del Campo-Ávila
Gonzalo Ramos-Jiménez
Rafael Morales-Bueno
Agustín Alejandro Ortiz-Díaz
Yailé Caballero-Mota","10.1109/TKDE.2014.2345382","","No","Incremental and online learning algorithms are more relevant in the data mining context because of the increasing necessity to process data streams. In this context, the target function may change over time, an inherent problem of online learning (known as concept drift). In order to handle concept drift regardless of the learning model, we propose new methods to monitor the performance metrics measured during the learning process, to trigger drift signals when a significant variation has been detected. To monitor this performance, we apply some probability inequalities that assume only independent, univariate and bounded random variables to obtain theoretical guarantees for the detection of such distributional changes. Some common restrictions for the online change detection as well as relevant types of change (abrupt and gradual) are considered. Two main approaches are proposed, the first one involves moving averages and is more suitable to detect abrupt changes. The second one follows a widespread intuitive idea to deal with gradual changes using weighted moving averages. The simplicity of the proposed methods, together with the computational efficiency make them very advantageous. We use a Naive Bayes classifier and a Perceptron to evaluate the performance of the methods over synthetic and real data."
"Concept drift detection via competence models","https://www.sciencedirect.com/science/article/pii/S0004370214000034","2014","Journal Article","Artificial Intelligence","Ning Lu
Guangquan Zhang
Jie Lu","10.1016/J.ARTINT.2014.01.001","","Yes","[Abstract not available]"
"Concept drift detection and localization in process mining: An integrated and efficient approach enabled by trace clustering","https://dl.acm.org/doi/abs/10.1145/3412841.3441918","2021","Proceedings Article","ACM Symposium on Applied Computing","Rafael Gaspar de Sousa
Sarajane Marques Peres
Marcelo Fantinato
Hajo A. Reijers","10.1145/3412841.3441918","https://dl.acm.org/doi/pdf/10.1145/3412841.3441918","No","Business processes are subject to changes over time due to the need for adaptation and flexibility to a complex environment. Detecting drift as soon as possible and identifying the process elements involved, lead to a much better understanding of the process behavior, which can be a competitive edge for businesses. However, most existing approaches focus on each of these two tasks separately. Isolated approaches do not always have interfaces between them that allow you to combine solutions effectively for each corresponding task. In such cases, using the two isolated solutions together is neither feasible nor even useful from the point of view of a business analyst. This paper proposes an integrated approach to detect and locate concept drifts based on an online setting for trace clustering. Experiments with synthetic event logs with different types of control-flow changes showed that concept drifts can be detected and located efficiently."
"Drift correction for gas sensors using multivariate methods","https://analyticalsciencejournals.onlinelibrary.wiley.com/doi/pdf/10.1002/1099-128X(200009/12)14:5/6%3C711::AID-CEM607%3E3.0.CO;2-4","2000","Journal Article","Journal of Chemometrics","Tom Artursson
Tomas Eklöv
Ingemar Lundström
Per Mårtensson
Michael Sjöström
Martin Holmberg","10.1002/1099-128X(200009/12)14:5/6<711::AID-CEM607>3.0.CO;2-4","","No","Drift is one of the most serious impairments afflicting gas sensors. It can be seen as a gradual change in the sensor response over a long period of time when the external conditions an constant. T ..."
"Self‐healing materials","https://advanced.onlinelibrary.wiley.com/doi/abs/10.1002/adma.201003036","2012","Reference Entry","","Michael W. Keller","10.1002/9781118097298.WEOC219","","No","This article discusses the current developments and advances for the incorporation of a damage repair mechanism in composite materials. There are several approaches for imparting this functionality, but each approach can be described as belonging to one of two broad families, an active-phase mechanism or an active-matrix mechanism. Active-phase mechanisms incorporate another phase into the composite material, besides reinforcement and matrix, to accomplish damage repair. Active-matrix self-healing materials seek to incorporate a fundamental chemical phenomenon, such as reversible bonds, that can perform damage repair. Each of these approaches is described in detail including both the manufacturing or synthesis techniques and the material characterization approaches that have been adopted to assess self-healing capability. A brief summary and outlook is also provided that describes the current challenges and maturity of the field. Keywords: self-healing composite; microencapsulation; remendable polymer; hollow fiber; damage repair"
"Self-healing materials: a review","https://pubs.rsc.org/en/content/articlehtml/2008/sm/b711716g","2008","Journal Article","Soft Matter","Richard P. Wool","10.1039/B711716G","https://www.researchgate.net/profile/R-Wool/publication/228525532_Self-healing_materials_A_review/links/0f3175303da2c8b8c3000000/Self-healing-materials-A-review.pdf","No","The ability of materials to self-heal from mechanical and thermally induced damage is explored in this paper and has significance in the field of fracture and fatigue. The history and evolution of several self-repair systems is examined including nano-beam healing elements, passive self-healing, autonomic self-healing and ballistic self-repair. Self-healing mechanisms utilized in the design of these unusual materials draw much information from the related field of polymer–polymer interfaces and crack healing. The relationship of material damage to material healing is examined in a manner to provide an understanding of the kinetics and damage reversal processes necessary to impart self-healing characteristics. In self-healing systems, there are transitions from hard-to-soft matter in ballistic impact and solvent bonding and conversely, soft-to-hard matter transitions in high rate yielding materials and shear-thickening fluids. These transitions are examined in terms of a new theory of the glass transition and yielding, viz., the twinkling fractal theory of the hard-to-soft matter transition. Success in the design of self-healing materials has important consequences for material safety, product performance and enhanced fatigue lifetime."
"A surprise from 1954: siloxane equilibration is a simple, robust, and obvious polymer self-healing mechanism","https://pubs.acs.org/doi/abs/10.1021/ja2113257","2012","Journal Article","Journal of the American Chemical Society","Peiwen Zheng
Thomas J. McCarthy","10.1021/JA2113257","","No","Tetramethylammonium silanolate-initiated ring-opening copolymerization of octamethylcyclotetrasiloxane (D4) and bis(heptamethylcyclotetrasiloxanyl)ethane (bis-D4) renders cross-linked network polymers that contain ethylene bridges and active silanolate end groups. These “living” reactive anionic species are not neutralized by ambient atmosphere exposure (are stable to water, oxygen, CO2) and promote thermally activated equilibration among different network isomers and cyclic oligomers. The cross-link density of these living networks can be controlled by the ratio of D4:bis-D4, and the density of active chain ends is determined from the initiator:monomer ratio. We report that samples prepared with particular ratios of initiator:D4:bis-D4 can be cut with a sharp knife, even into two pieces, and can heal by siloxane equilibration to restore the original strength of the silicone sample. Fracture toughness measurements were carried out and revealed complete (mechanical) healing. Broken and healed samples gener..."
"Self-healing polymeric materials","https://pubs.rsc.org/en/content/articlehtml/2009/vr/c3cs60109a","2013","Journal Article","Chemical Society Reviews","Ying Yang
Marek W. Urban","10.1039/C3CS60109A","","No","Inspired by nature, self-healing materials represent the forefront of recent developments in materials chemistry and engineering. This review outlines the recent advances in the field of self-healing polymers. The first part discusses thermodynamic requirements for self-healing networks in the context of conformation changes that contribute to the Gibbs free energy. The chain flexibility significantly contributes to the entropy changes, whereas the heat of reaction and the external energy input are the main contributors to enthalpy changes. The second part focuses on chemical reactions that lead to self-healing, and the primary classes are the covalent bonding, supramolecular assemblies, ionic interactions, chemo-mechanical self-healing, and shape memory polymers. The third part outlines recent advances using encapsulation, remote self-healing and the role of shape memory polymers. Recent developments in the field of self-healing polymers undeniably indicate that the main challenge will be the designing of high glass transition (Tg) functional materials, which also exhibit stimuli-responsive attributes. Build-in controllable hierarchical heterogeneousness at various length scales capable of remote self-healing by physical and chemical responses will be essential in designing future materials of the 21st century."
"Frequency and phase drift correction of magnetic resonance spectroscopy data by spectral registration in the time domain","https://onlinelibrary.wiley.com/doi/abs/10.1002/mrm.25094","2015","Journal Article","Magnetic Resonance in Medicine","Jamie Near
Richard A.E. Edden
Christopher John Evans
R Paquin
Ashley D. Harris
Peter Jezzard","10.1002/MRM.25094","https://pmc.ncbi.nlm.nih.gov/articles/PMC5851009/pdf/nihms942582.pdf","Yes","Purpose Frequency and phase drifts are a common problem in the acquisition of in vivo magnetic resonance spectroscopy (MRS) data If not accounted for, frequency and phase drifts will result in artifactual broadening of spectral peaks, distortion of spectral lineshapes, and a reduction in signal-to-noise ratio (SNR) We present herein a new method for estimating and correcting frequency and phase drifts in in vivo MRS data Methods We used a simple method of fitting each spectral average to a reference scan (often the first average in the series) in the time domain through adjustment of frequency and phase terms Due to the similarity with image registration, this method is referred to as “spectral registration” Using simulated data with known frequency and phase drifts, the performance of spectral registration was compared with two existing methods at various SNR levels Results Spectral registration performed well in comparison with the other methods tested in terms of both frequency and phase drift estimation Conclusions Spectral registration provides an effective method for frequency and phase drift correction It does not involve the collection of navigator echoes, and does not rely on any specific resonances, such as residual water or creatine, making it highly versatile Magn Reson Med 73:44–50, 2015 © 2014 Wiley Periodicals, Inc"
"Chemical and physical aspects of self-healing materials","https://www.sciencedirect.com/science/article/pii/S0079670015000696","2015","Journal Article","Progress in Polymer Science","Ying Yang
Xiaochu Ding
Marek W. Urban","10.1016/J.PROGPOLYMSCI.2015.06.001","https://www.academia.edu/download/43269050/2015-Self-healing_materials_review.pdf","Yes","[Abstract not available]"
"Self-healing structural composite materials","https://www.sciencedirect.com/science/article/pii/S1359835X03001386","2003","Journal Article","Composites Part A-applied Science and Manufacturing","Michael R. Kessler
Nancy R. Sottos
Scott R. White","10.1016/S1359-835X(03)00138-6","https://scispace.com/pdf/self-healing-structural-composite-materials-4wonigopl1.pdf","No","A self-healing fiber-reinforced structural polymer matrix composite material is demonstrated. In the composite, a microencapsulated healing agent and a solid chemical catalyst are dispersed within the polymer matrix phase. Healing is triggered by crack propagation through the microcapsules, which then release the healing agent into the crack plane. Subsequent exposure of the healing agent to the chemical catalyst initiates polymerization and bonding of the crack faces. Self-healing (autonomic healing) is demonstrated on width-tapered double cantilever beam fracture specimens in which a mid-plane delamination is introduced and then allowed to heal. Autonomic healing at room temperature yields as much as 45% recovery of virgin interlaminar fracture toughness, while healing at 80 °C increases the recovery to over 80%. The in situ kinetics of healing in structural composites is investigated in comparison to that of neat epoxy resin."
"Self-healing polymers","https://www.nature.com/articles/s41578-020-0202-4","2015","Book Chapter","","Timothy C. Mauldin
Dylan J. Boday","10.1002/9783527674107.CH36","https://par.nsf.gov/servlets/purl/10233054","No","[Abstract not available]"
"Self healing concrete: a biological approach","https://link.springer.com/chapter/10.1007/978-1-4020-6250-6_9","2007","Book Chapter","","Henk M. Jonkers","10.1007/978-1-4020-6250-6_9","https://www.academia.edu/download/54319894/Livro_-_Self_Healing_Materials_-_An_Alternative_Approach_to_20_Centuries_of_Materials_Science.pdf#page=205","No","Concrete can be considered as a kind of artificial rock with properties more or less similar to certain natural rocks. As it is strong, durable, and relatively cheap, concrete is, since almost two centuries, the most used construction material worldwide, which can easily be recognized as it has changed the physiognomy of rural areas. However, due to the heterogeneity of the composition of its principle components, cement, water, and a variety of aggregates, the properties of the final product can widely vary. The structural designer therefore must previously establish which properties are important for a specific application and must choose the correct composition of the concrete ingredients in order to ensure that the final product applies to the previously set standards. Concrete is typically characterized by a high-compressive strength, but unfortunately also by a rather low-tensile strength. However, through the application of steel or other material reinforcements, the latter can be compensated for as such reinforcements can take over tensile forces. Modern concrete is based on Portland cement, a hydraulic cement patented by Joseph Aspdin in the early 19th century. Already in Roman times hydraulic cements, made from burned limestone and volcanic earth, slowly replaced the widely used non-hydraulic cements, which were based on burned limestone as main ingredient. When limestone is burned (or “calcined”) at a temperature between 800 and 900◦C, a process that drives off bound carbon dioxide (CO2), lime (calcium oxide; CaO) is produced. Lime, when brought into contact with water, reacts to form portlandite (Ca(OH)2) which can further react with CO2, which in turn forms back into calcite (CaCO3), or limestone, the pre-burning starting material. However, a major drawback of this non-hydraulic cement is that it will not set under water and, moreover, its reaction products portlandite and limestone are relatively soluble, and thus will deteriorate rapidly in wet and/or acidic environments. In contrast, portland cement produces, upon reaction with water, a much harder and insoluble material that will also set under water. For portland cement production a source of calcium, silicon, aluminum, and iron is needed and therefore usually limestone, clay, some bauxite, and iron ore are burned in a kiln at temperatures up to 1, 500◦C. The cement clinker produced is mainly composed of the minerals alite (3CaO.SiO2), belite (2CaO.SiO2), aluminate (3CaO.Al2O3), and ferrite (4CaO.Al2O3.Fe2O3), which all yield specific hydration products with different characteristics upon reaction with water."
"Self-healing superamphiphobicity","https://pubs.rsc.org/en/content/articlehtml/2011/cc/c0cc04066e","2011","Journal Article","Chemical Communications","Xiaolong Wang
Xinjie Liu
Feng Zhou
Weimin Liu","10.1039/C0CC04066E","","No","[Abstract not available]"
"Self healing materials: an alternative approach to 20 centuries of materials science","https://www.degruyterbrill.com/document/doi/10.1515/ci.2008.30.6.20/html","2007","Book","","Sylbrand van der Zwaag","","","Yes","Foreword M.F. Ashby Preface 1. Introduction to material design principles S. van der Zwaag 2. Self healing polymers and composites H.M. Andersson, M.W. Keller, J.S. Moore, N.R. Sottos and S.R. White 3. Remendable polymers S.D. Bergman and F. Wudl 4. Thermally induced self healing of thermosetting resins and matrices in smart composites F.R. Jones, W. Zhang and S.A. Hayes 5. Ionomers as self healing polymers R. Varley 6. Self healing fibre reinforced polymer composites: an overview I.P. Bond, R.S. Trask, H.R. Williams and G.R. Williams 7. Self healing polymer coatings R.A.T.M. van Benthem, W. Ming and G. de With 8. Self healing in concrete materials V.C. Li and E. Yang 9. Self healing concrete: a biological approach H.M. Jonkers 10. Exploring mechanisms of healing in asphalt mixtures and quantifying its impact D. N. Little and A. Bhasin 11. Self healing in aluminium alloys R. Lumley 12. Crack and void healing in metals H. Wang, P. Huang and Z. Li 13. Advances in transmission electron microscopy: self healing, or is prevention better than cure J.Th.M. de Hosson and H.Y. Yasuda 14. Self healing in coatings at high temperatures W.G. Sloof 15. Hierarchical structure and repair of bone: deformation, remodeling, healing P. Fratzl and R. Weinkamer 16. Modelling of self healing of skin tissue F.J. Vermolen, W.G. van Rossum, E. Javierre and J.A. Adam 17. Numerical models for self healing mechanisms J.J.C. Remmers and R. de Borst About the authors"
"Self-healing polymers and composites","https://www.annualreviews.org/content/journals/10.1146/annurev-matsci-070909-104532","2010","Journal Article","International Materials Reviews","Timothy C. Mauldin
Michael R. Kessler","10.1179/095066010X12646898728408","http://autonomic.beckman.illinois.edu/nrs097.pdf","Yes","Inspired by the unique and efficient wound healing processes in biological systems, several approaches to develop synthetic polymers that can repair themselves with complete, or nearly complete, autonomy have recently been developed. This review aims to survey the rapidly expanding field of self-healing polymers by reviewing the major successful autonomic repairing mechanisms developed over the last decade. Additionally, we discuss several issues related to transferring these self-healing technologies from the laboratory to real applications, such as virgin polymer property changes as a result of the added healing functionality, healing in thin films v. bulk polymers, and healing in the presence of structural reinforcements."
"Self-healing soft electronics","https://www.nature.com/articles/s41928-019-0235-0","2019","Journal Article","","Jiheong Kang
Jeffrey B.-H. Tok
Zhenan Bao","10.1038/S41928-019-0235-0","","No","Biological systems have the powerful ability to self-heal. Human skin can, for example, autonomously heal from wounds of various degrees, allowing it to restore its mechanical and electrical properties. In contrast, human-made electronic devices degrade over time due to fatigue, corrosion or damage incurred during operation, leading to device failure. Self-healing chemistry has emerged in recent years as a promising method for constructing soft electronic materials that are mechanically robust and can self-repair. Here we review the development of self-healing electronic materials and examine how such materials can be used to fabricate self-healing electronic devices. We explore the potential new functionalities of self-healing electronic systems that would not typically be possible with conventional electronic systems and discuss the current challenges in delivering self-healing soft electronics for practical applications. This Review Article examines the development of self-healing electronic materials and devices, explores their potential applications and discusses the challenges that exist in delivering practical systems."
"Self‐healing hydrogels","https://advanced.onlinelibrary.wiley.com/doi/abs/10.1002/adma.201601613","2016","Journal Article","Advanced Materials","Danielle L. Taylor
Marc in het Panhuis","10.1002/ADMA.201601613","https://advanced.onlinelibrary.wiley.com/doi/am-pdf/10.1002/adma.201601613","Yes","Over the past few years, there has been a great deal of interest in the development of hydrogel materials with tunable structural, mechanical, and rheological properties, which exhibit rapid and autonomous self-healing and self-recovery for utilization in a broad range of applications, from soft robotics to tissue engineering. However, self-healing hydrogels generally either possess mechanically robust or rapid self-healing properties but not both. Hence, the development of a mechanically robust hydrogel material with autonomous self-healing on the time scale of seconds is yet to be fully realized. Here, the current advances in the development of autonomous self-healing hydrogels are reviewed. Specifically, methods to test self-healing efficiencies and recoveries, mechanisms of autonomous self-healing, and mechanically robust hydrogels are presented. The trends indicate that hydrogels that self-heal better also achieve self-healing faster, as compared to gels that only partially self-heal. Recommendations to guide future development of self-healing hydrogels are offered and the potential relevance of self-healing hydrogels to the exciting research areas of 3D/4D printing, soft robotics, and assisted health technologies is highlighted."
"Sample drift correction in 3D fluorescence photoactivation localization microscopy","https://opg.optica.org/abstract.cfm?uri=oe-19-16-15009","2011","Journal Article","Optics Express","Michael J. Mlodzianoski
John M. Schreiner
Steven P. Callahan
Katarína Smolková
Andrea Dlasková
Jitka Šantorová
Petr Ježek
Joerg Bewersdorf","10.1364/OE.19.015009","https://opg.optica.org/viewmedia.cfm?seq=0&uri=oe-19-16-15009","Yes","The recent development of diffraction-unlimited far-field fluorescence microscopy has overcome the classical resolution limit of ~250 nm of conventional light microscopy by about a factor of ten. The improved resolution, however, reveals not only biological structures at an unprecedented resolution, but is also susceptible to sample drift on a much finer scale than previously relevant. Without correction, sample drift leads to smeared images with decreased resolution, and in the worst case to misinterpretation of the imaged structures. This poses a problem especially for techniques such as Fluorescence Photoactivation Localization Microscopy (FPALM/PALM) or Stochastic Optical Reconstruction Microscopy (STORM), which often require minutes recording time. Here we discuss an approach that corrects for three-dimensional (3D) drift in images of fixed samples without the requirement for fiduciary markers or instrument modifications. Drift is determined by calculating the spatial cross-correlation function between subsets of localized particles imaged at different times. Correction down to ~5 nm precision is achieved despite the fact that different molecules are imaged in each frame. We demonstrate the performance of our drift correction algorithm with different simulated structures and analyze its dependence on particle density and localization precision. By imaging mitochondria with Biplane FPALM we show our algorithm's feasibility in a practical application."
"Self-healing polymeric materials: A review of recent developments","https://www.sciencedirect.com/science/article/pii/S0079670008000208","2008","Journal Article","Progress in Polymer Science","Dong Yang Wu
Sam Meure
David H. Solomon","10.1016/J.PROGPOLYMSCI.2008.02.001","","No","[Abstract not available]"
"Towards architecture-based self-healing systems","https://dl.acm.org/doi/abs/10.1145/582128.582133","2002","Proceedings Article","Workshop on Self-healing systems","Eric M. Dashofy
André van der Hoek
Richard N. Taylor","10.1145/582128.582133","https://dl.acm.org/doi/pdf/10.1145/582128.582133","No","Our approach to creating self-healing systems is based on software architecture, where repairs are done at the level of a software system's components and connectors. In our approach, event-based software architectures are targeted because they offer significant benefits for run-time adaptation. Before an automated planning agent can decide how to repair a self-healing system, a significant infrastructure must be in place to support making the planned repair. Specifically, the self-healing system must be built using a framework that allows for run-time adaptation, there must be a language in which to express the repair plan, and there must be a reconfiguration agent that can execute the repair plan once it is created. In this paper, we present tools and methods that implement these infrastructure elements in the context of an overall architecture-based vision for building self-healing systems. The paper concludes with a gap analysis of our current infrastructure vs. the overall vision, and our plans for fulfilling that vision."
"A review of self‐healing concrete for damage management of structures","https://advanced.onlinelibrary.wiley.com/doi/abs/10.1002/admi.201800074","2018","Journal Article","Advanced Materials Interfaces","Nele De Belie
Elke Gruyaert
Abir Al-Tabbaa
Paola Antonaci
Cornelia Baera
Diana Bajare
Aveline Darquennes
Robert Davies
Liberato Ferrara
Tony Jefferson
Chrysoula Litina
Bojan Miljević
Anna Otlewska
Jonjaua Ranogajec
Marta Roig-Flores
Kevin Paine
Pawel Lukowski
Pedro Serna
Jean Marc Christian Tulliani
Snezana Vucetic
Jianyun Wang
Henk M. Jonkers","10.1002/ADMI.201800074","https://re.public.polimi.it/bitstream/11311/1054570/1/admi.201800074_R1.pdf","Yes","The increasing concern for safety and sustainability of structures is calling for the development of smart self-healing materials and preventive repair methods. The appearance of small cracks (<300 µm in width) in concrete is almost unavoidable, not necessarily causing a risk of collapse for the structure, but surely impairing its functionality, accelerating its degradation, and diminishing its service life and sustainability. This review provides the state-of-the-art of recent developments of self-healing concrete, covering autogenous or intrinsic healing of traditional concrete followed by stimulated autogenous healing via use of mineral additives, crystalline admixtures or (superabsorbent) polymers, and subsequently autonomous self-healing mechanisms, i.e. via, application of micro-, macro-, or vascular encapsulated polymers, minerals,or bacteria. The (stimulated) autogenous mechanisms are generally limited to healing crack widths of about 100–150 µm. In contrast, most autonomous self-healing mechanisms can heal cracks of 300 µm, even sometimes up to more than 1 mm, and usually act faster. After explaining the basic concept for each self-healing technique, the most recent advances are collected, explaining the progress and current limitations, to provide insights toward the future developments. This review addresses the research needs required to removehindrances that limit market penetration of self-healing concrete technologies."
"Kubernetes","https://dzone.com/storage/attachments/14131598-dzone-kubernetesbundle.pdf","2022","Book Chapter","","William J. Severud","10.1007/978-1-4842-7996-0_14","https://dzone.com/storage/attachments/14131598-dzone-kubernetesbundle.pdf","No","Kubernetes is a popular container orchestration framework. It runs containers on Linux machines (virtual or physical) based on various parameters."
"Kubernetes in action","https://books.google.com/books?hl=en&lr=&id=WTgzEAAAQBAJ&oi=fnd&pg=PT29&dq=%22Terraform%22+OR+%22CloudFormation%22+OR+%22Ansible%22+OR+%22Pulumi%22+OR+%22Kubernetes%22+OR+%22GitOps%22+OR+%22ArgoCD%22+OR+%22Flux%22&ots=FugCB1osdt&sig=IwrgE97tF7d6IDUMCNe377UgD3w","2018","Book","","Marko Lukša","","","Yes","[Abstract not available]"
"The control of flux","https://m.productshows.com/quantitative-medicine/wp-content/uploads/sites/117/2016/08/KacserBurns1973_21yearsOn_Pedro.pdf","1973","Journal Article","Symposia of the Society for Experimental Biology","Henrik Kacser
J A Burns","","https://m.productshows.com/quantitative-medicine/wp-content/uploads/sites/117/2016/08/KacserBurns1973_21yearsOn_Pedro.pdf","Yes","Molecular Enzymology Group Colloquium Organized by D. Fell (School of Biological and Molecular Sciences, Oxford Brooke University) and D. Kell (Department of Biological Sciences, University College, Wales, Aberystwyth), Edited by D. Fell and Sponsored by Xenova Ltd, Zeneca Bioproducts, Glaxo Research and Development Ltd and SmithKline Beecham Pharmaceuticals. 653rd Meeting held at the University of Sussex on I 3I 6 December 1994."
"A review of flux-profile relationships","https://link.springer.com/article/10.1007/BF00240838","1974","Journal Article","Boundary-Layer Meteorology","A. J. Dyer","10.1007/BF00240838","http://www.climatexchange.nl/projects/alteddy/papers/Dyer-1974.pdf","No","Flux-profile relationships in the constant flux layer are reviewed The preferred relationships are found to be those of Dyer and Hicks (1970), namely, φ H =φ W =(1−16(z/L))−1/2, φ M =(1−16(z/L))−1/4 for the unstable region, and φ H =φ W =φ M = 1+5(z/L) for the stable region The carefully determined results of Businger et al (1971) remain a difficulty which calls for considerable clarification"
"Measuring autophagosome flux","https://www.tandfonline.com/doi/abs/10.1080/15548627.2018.1469590","2018","Journal Article","Autophagy","André du Toit
Jan-Hendrik S. Hofmeyr
Thomas J. Gniadek
Ben Loos","10.1080/15548627.2018.1469590","https://www.tandfonline.com/doi/pdf/10.1080/15548627.2018.1469590","Yes","Macroautophagy/autophagy is a proteolytic pathway that is involved in both bulk degradation of cytoplasmic proteins as well as in selective degradation of cytoplasmic organelles. Autophagic flux is..."
"Why should autophagic flux be assessed?","https://www.nature.com/articles/aps2012184","2013","Journal Article","Acta Pharmacologica Sinica","Xiao Jie Zhang
Sheng Chen
Kai Xing Huang
Weidong Le","10.1038/APS.2012.184","https://www.nature.com/articles/aps2012184.pdf","Yes","As autophagy is involved in cell growth, survival, development and death, impaired autophagic flux has been linked to a variety of human pathophysiological processes, including neurodegeneration, cancer, myopathy, cardiovascular and immune-mediated disorders. There is a growing need to identify and quantify the status of autophagic flux in different pathological conditions. Given that autophagy is a highly dynamic and complex process that is regulated at multiple steps, it is often assessed accurately. This perspective review article will focus on the autophagic flux defects in different human disorders and update the current methods of monitoring autophagic flux. This knowledge is essential for developing autophagy-related therapeutics for treating the diseases."
"Science in flux","https://books.google.com/books?hl=en&lr=&id=MRaoBgAAQBAJ&oi=fnd&pg=PR9&dq=%22Terraform%22+OR+%22CloudFormation%22+OR+%22Ansible%22+OR+%22Pulumi%22+OR+%22Kubernetes%22+OR+%22GitOps%22+OR+%22ArgoCD%22+OR+%22Flux%22&ots=YJJF_sjT0q&sig=5WktuQ3US9vsxY0HGs-omfwhuEg","1975","Journal Article","Physics Today","Joseph Agassi","10.1063/1.3024668","","No","To what extent and in what respect is science intellectually valuable? This is a controversial matter. What is hardly disputed is that what is alterable in science is of mere ephemeral value; and what is valuable in it is that which is more universal and permanent, that which is more solid and lasting. One of the very few philosophers who oppose this accepted view is Sir Karl Popper. In his view, science is so valuable because of its open- mindedness, because any of its achievements may at any time be given up and newer achievements may be hoped for to replace the relinquished ones. Science, says Popper, is at constant war with itself, and it progresses by revolutions and internal conflicts."
"Mastering Kubernetes: Master the art of container management by using the power of Kubernetes","https://books.google.com/books?hl=en&lr=&id=nPBZDwAAQBAJ&oi=fnd&pg=PP1&dq=%22Terraform%22+OR+%22CloudFormation%22+OR+%22Ansible%22+OR+%22Pulumi%22+OR+%22Kubernetes%22+OR+%22GitOps%22+OR+%22ArgoCD%22+OR+%22Flux%22&ots=53lEma6rfN&sig=NNtKWJtBWV08TNxB6Z2l0QIHTxE","","","","G Sayfan","","http://ndl.ethernet.edu.et/bitstream/123456789/40210/2/115.Gigi%20Sayfan.pdf","No","[Abstract not available]"
"Gas flux","https://acsess.onlinelibrary.wiley.com/doi/abs/10.2136/sssabookser5.1.2ed.c47","","","","D. E. Rolston","10.2136/sssabookser5.1.2ed.c47","","No","[Abstract not available]"
"Rearchitecting kubernetes for the edge","https://dl.acm.org/doi/abs/10.1145/3434770.3459730","2021","Proceedings Article","arXiv: Distributed, Parallel, and Cluster Computing","Andrew Jeffery
Heidi Howard
Richard Mortier","10.1145/3434770.3459730","https://dl.acm.org/doi/pdf/10.1145/3434770.3459730","Yes","Recent years have seen Kubernetes emerge as a primary choice for container orchestration. Kubernetes largely targets the cloud environment but new use cases require performant, available and scalable orchestration at the edge. Kubernetes stores all cluster state in etcd, a strongly consistent key-value store. We find that at larger etcd cluster sizes, offering higher availability, write request latency significantly increases and throughput decreases similarly. Coupled with approximately 30% of Kubernetes requests being writes, this directly impacts the request latency and availability of Kubernetes, reducing its suitability for the edge. We revisit the requirement of strong consistency and propose an eventually consistent approach instead. This enables higher performance, availability and scalability whilst still supporting the broad needs of Kubernetes. This aims to make Kubernetes much more suitable for performance-critical, dynamically-scaled edge solutions."
"Xi commandments of kubernetes security: A systematization of knowledge related to kubernetes security practices","https://ieeexplore.ieee.org/abstract/document/9230176/","2020","Posted Content","arXiv: Cryptography and Security","Md. Shazibul Islam Shamim
Farzana Ahamed Bhuiyan
Akond Rahman","","https://arxiv.org/pdf/2006.15275","Yes","Kubernetes is an open-source software for automating management of computerized services Organizations, such as IBM, Capital One and Adidas use Kubernetes to deploy and manage their containers, and have reported benefits related to deployment frequency Despite reported benefits, Kubernetes deployments are susceptible to security vulnerabilities, such as those that occurred at Tesla in 2018 A systematization of Kubernetes security practices can help practitioners mitigate vulnerabilities in their Kubernetes deployments The goal of this paper is to help practitioners in securing their Kubernetes installations through a systematization of knowledge related to Kubernetes security practices We systematize knowledge by applying qualitative analysis on 104 Internet artifacts We identify 11 security practices that include (i) implementation of role-based access control (RBAC) authorization to provide least privilege, (ii) applying security patches to keep Kubernetes updated, and (iii) implementing pod and network specific security policies"
"Modelling performance & resource management in kubernetes","https://dl.acm.org/doi/abs/10.1145/2996890.3007869","2016","Proceedings Article","IEEE/ACM International Conference Utility and Cloud Computing","Víctor Medel
Omer Rana
José Ángel Bañares
Unai Arronategui","10.1145/2996890.3007869","https://dl.acm.org/doi/pdf/10.1145/2996890.3007869","No","Containers are rapidly replacing Virtual Machines (VMs) as the compute instance of choice in cloud-based deployments. The significantly lower overhead of deploying containers (compared to VMs) has often been cited as one reason for this. We analyse performance of the Kubernetes system and develop a Reference net-based model of resource management within this system. Our model is characterised using real data from a Kubernetes deployment, and can be used as a basis to design scalable applications that make use of Kubernetes."
"The kubernetes book","https://it-systems.su/wp-content/uploads/2022/03/nigel-poulton-the-kubernetes-book-2020.pdf","","","","N Poulton
P Joglekar","","https://it-systems.su/wp-content/uploads/2022/03/nigel-poulton-the-kubernetes-book-2020.pdf","No","[Abstract not available]"
"The open flux problem","https://iopscience.iop.org/article/10.3847/1538-4357/aa8a70/meta","2017","Journal Article","arXiv: Solar and Stellar Astrophysics","Jon A. Linker
Ronald M. Caplan
Cooper Downs
Pete Riley
Zoran Mikic
Roberto Lionello
Carl J. Henney
Charles N. Arge
Y. Liu
Marc L. DeRosa
Anthony R. Yeates
Mathew J. Owens","10.3847/1538-4357/AA8A70","https://iopscience.iop.org/article/10.3847/1538-4357/aa8a70/pdf","Yes","The heliospheric magnetic field is of pivotal importance in solar and space physics. The field is rooted in the Sun's photosphere, where it has been observed for many years. Global maps of the solar magnetic field based on full disk magnetograms are commonly used as boundary conditions for coronal and solar wind models. Two primary observational constraints on the models are (1) the open field regions in the model should approximately correspond to coronal holes observed in emission, and (2) the magnitude of the open magnetic flux in the model should match that inferred from in situ spacecraft measurements. In this study, we calculate both MHD and PFSS solutions using fourteen different magnetic maps produced from five different types of observatory magnetograms, for the time period surrounding July, 2010. We have found that for all of the model/map combinations, models that have coronal hole areas close to observations underestimate the interplanetary magnetic flux, or, conversely, for models to match the interplanetary flux, the modeled open field regions are larger than coronal holes observed in EUV emission. In an alternative approach, we estimate the open magnetic flux entirely from solar observations by combining automatically detected coronal holes for Carrington rotation 2098 with observatory synoptic magnetic maps. This approach also underestimates the interplanetary magnetic flux. Our results imply that either typical observatory maps underestimate the Sun's magnetic flux, or a significant portion of the open magnetic flux is not rooted in regions that are obviously dark in EUV and X-ray emission."
"Generations in flux","https://rickesassociates.com/wp-content/uploads/2019/09/Generations-in-Flux-FINAL.pdf","","","","PC Rickes","","https://rickesassociates.com/wp-content/uploads/2019/09/Generations-in-Flux-FINAL.pdf","No","[Abstract not available]"
"Kubernetes scheduling: Taxonomy, ongoing issues and challenges","https://dl.acm.org/doi/abs/10.1145/3539606","2022","Journal Article","ACM Computing Surveys","Carmen Carrión","10.1145/3539606","https://dl.acm.org/doi/pdf/10.1145/3539606","No","Continuous integration enables the development of microservices-based applications using container virtualization technology. Container orchestration systems such as Kubernetes, which has become the de facto standard, simplify the deployment of container-based applications. However, developing efficient and well-defined orchestration systems is a challenge. This article focuses specifically on the scheduler, a key orchestrator task that assigns physical resources to containers. Scheduling approaches are designed based on different Quality of Service (QoS) parameters to provide limited response time, efficient energy consumption, better resource utilization, and other things. This article aims to establish insight knowledge into Kubernetes scheduling, find the main gaps, and thus guide future research in the area. Therefore, we conduct a study of empirical research on Kubernetes scheduling techniques and present a new taxonomy for Kubernetes scheduling. The challenges, future direction, and research opportunities are also discussed."
"A survey of Kubernetes scheduling algorithms","https://link.springer.com/article/10.1186/s13677-023-00471-1","2023","Journal Article","Journal of cloud computing","Khaldoun Senjab
Sohail Abbas
Naveed Ahmad
Atta ur Rehman Khan","10.1186/s13677-023-00471-1","https://link.springer.com/content/pdf/10.1186/s13677-023-00471-1.pdf","Yes","Abstract As cloud services expand, the need to improve the performance of data center infrastructure becomes more important. High-performance computing, advanced networking solutions, and resource optimization strategies can help data centers maintain the speed and efficiency necessary to provide high-quality cloud services. Running containerized applications is one such optimization strategy, offering benefits such as improved portability, enhanced security, better resource utilization, faster deployment and scaling, and improved integration and interoperability. These benefits can help organizations improve their application deployment and management, enabling them to respond more quickly and effectively to dynamic business needs. Kubernetes is a container orchestration system designed to automate the deployment, scaling, and management of containerized applications. One of its key features is the ability to schedule the deployment and execution of containers across a cluster of nodes using a scheduling algorithm. This algorithm determines the best placement of containers on the available nodes in the cluster. In this paper, we provide a comprehensive review of various scheduling algorithms in the context of Kubernetes. We characterize and group them into four sub-categories: generic scheduling, multi-objective optimization-based scheduling, AI-focused scheduling, and autoscaling enabled scheduling, and identify gaps and issues that require further research."
"Borg, omega, and kubernetes","https://dl.acm.org/doi/fullHtml/10.1145/2890784","2016","Journal Article","Communications of The ACM","Brendan Burns
Brian Grant
David Oppenheimer
Eric Brewer
John Wilkes","10.1145/2890784","https://dl.acm.org/doi/pdf/10.1145/2890784","Yes","Though widespread interest in software containers is a relatively recent phenomenon, at Google we have been managing Linux containers at scale for more than ten years and built three different container-management systems in that time. Each system was heavily influenced by its predecessors, even though they were developed for different reasons. This article describes the lessons we’ve learned from developing and operating them."
"What are flux transfer events?","https://www.sciencedirect.com/science/article/pii/0032063388901092","1988","Journal Article","Planetary and Space Science","David J. Southwood
Charlie J. Farrugia
M. A. Saunders","10.1016/0032-0633(88)90109-2","","No","[Abstract not available]"
"A Survey on Hybrid and Multi-Cloud Environments: Integration Strategies, Challenges, and Future Directions","https://ijctece.com/index.php/IJCTEC/article/view/275","","","","V Bitkuri
R Kendyala
J Kurma
JV Mamidala","","https://ijctece.com/index.php/IJCTEC/article/download/275/235","No","[Abstract not available]"
"Kubernetes for Multi-Cloud and Hybrid Cloud: Orchestration, Scaling, and Security Challenges","https://www.researchgate.net/profile/Bhanuprakash-Madupati/publication/388427390_Kubernetes_for_Multi-Cloud_and_Hybrid_Cloud_Orchestration_Scaling_and_Security_Challenges/links/67a0f26a96e7fb48b9b10db7/Kubernetes-for-Multi-Cloud-and-Hybrid-Cloud-Orchestration-Scaling-and-Security-Challenges.pdf","2025","Repository","Social Science Research Network","Bhanuprakash Madupati","10.2139/ssrn.5076649","https://www.researchgate.net/profile/Bhanuprakash-Madupati/publication/388427390_Kubernetes_for_Multi-Cloud_and_Hybrid_Cloud_Orchestration_Scaling_and_Security_Challenges/links/67a0f26a96e7fb48b9b10db7/Kubernetes-for-Multi-Cloud-and-Hybrid-Cloud-Orchestration-Scaling-and-Security-Challenges.pdf","No","[Abstract not available]"
"Containerization in multi-cloud environment: roles, strategies, challenges, and solutions for effective implementation","https://arxiv.org/abs/2403.12980","2024","Journal Article","arXiv.org","Muhammad Waseem
Aakash Ahmad
Peng Liang
Muhammad Azeem Akbar
Arif Ali Khan
Iftikhar Ahmad
Manu Setälä
Tommi Mikkonen","10.48550/arxiv.2403.12980","https://arxiv.org/pdf/2403.12980","No","Containerization in a multi-cloud environment facilitates workload portability and optimized resource utilization. Containerization in multi-cloud environments has received significant attention in recent years both from academic research and industrial development perspectives. However, there exists no effort to systematically investigate the state of research on this topic. The aim of this research is to systematically identify and categorize the multiple aspects of container utilization in multi-cloud environment. We conduct the Systematic Mapping Study (SMS) on the literature published between January 2013 and March 2023. Eighty-six studies were finally selected and the key results are: (1) Four leading themes on cloud computing and network systems research were identified: 'Scalability and High Availability', 'Performance and Optimization', 'Security and Privacy', and 'Multi-Cloud Container Monitoring and Adaptation'. (2) Seventy-four patterns and strategies for containerization in multi-cloud environment were classified across 10 subcategories and 4 categories. (3) Ten quality attributes considered were identified with 47 associated tactics. (4) Four distinct frameworks were introduced based on the analysis of identified challenges and solutions: a security challenge-solution framework, an automation challenge-solution framework, a deployment challenge-solution framework, and a monitoring challenge-solution framework. The results of this SMS will assist researchers and practitioners in pursuing further studies on containerization in multi-cloud environment and developing specialized solutions for challenges related to containerization applications in multi-cloud environment."
"Towards multi-cloud configurations using feature models and ontologies","https://dl.acm.org/doi/abs/10.1145/2462326.2462332","2013","Proceedings Article","","Clément Quinton
Nicolas Haderer
Romain Rouvoy
Laurence Duchien","10.1145/2462326.2462332","https://dl.acm.org/doi/pdf/10.1145/2462326.2462332","Yes","Configuration and customization choices arise due to the heterogeneous and scalable aspect of the cloud computing paradigm. To avoid being restricted to a given cloud and ensure application requirements, using several clouds to deploy a multi-cloud configuration is recommended but introduces several challenges due to the amount of providers and their intrinsic variability. In this paper, we present a model-driven approach based on Feature Models (FMs) originating from Software Product Lines (SPL) to handle cloud variability and then manage and create cloud configurations. We combine it with ontologies, used to model the various semantics of cloud systems. The approach takes into consideration application technical requirements as well as non-functional ones to provide a set of valid cloud or multi-cloud configurations and is implemented in a framework named SALOON."
"Multi-cloud: a comprehensive review","https://ieeexplore.ieee.org/abstract/document/9318176/","2020","Proceedings Article","IEEE International Multitopic Conference","Hamza Ali Imran
Usama Latif
Ataul Aziz Ikram
Maryam Ehsan
Ahmed Jamal Ikram
Waleed Ahmad Khan
Saad Wazir","10.1109/INMIC50486.2020.9318176","https://ieeexplore.ieee.org/iel7/9318042/9318043/09318176.pdf","Yes","In the span of a decade, innovations in cloud computing have led to a new understanding of computing to be used as a utility. Majority of cloud service providers are making the service better and competitive for end-user. Aside from the number of services introduced by these providers, users are feeling uneasy and are unaware of consequences while switching from one service to another. Internal architecture of the cloud makes it difficult for end-users to understand. To overcome this issue a new concept of multi-cloud has been introduced. In multi-cloud technology, we can use multiple clouds from different vendors without platform complexity. Hence summarized, Multi-cloud is the usage of autonomous cloud platforms with one interface which may clue to different administrative and implementation domains. This paper reviews the literature of recently presented solutions and architectures for multi-cloud platforms."
"Multi-cloud platform-as-a-service model, functionalities and approaches","https://www.sciencedirect.com/science/article/pii/S187705091632097X","2016","Journal Article","Procedia Computer Science","Ana Juan Ferrer
David Garcia Perez
Román Sosa González","10.1016/J.PROCS.2016.08.281","https://www.sciencedirect.com/science/article/pii/S187705091632097X/pdf?md5=3ac2afeb73de67caee43f617f101b614&pid=1-s2.0-S187705091632097X-main.pdf&_valck=1","Yes","[Abstract not available]"
"Multi-cloud management: Technologies, tools, and techniques","https://link.springer.com/chapter/10.1007/978-3-319-78637-7_10","2018","Book Chapter","","Pethuru Raj
Anupama Raman","10.1007/978-3-319-78637-7_10","","No","The future clearly beckons and reckons for hybrid Clouds. The Cloud journey thus far is simply a roller coaster ride. Clouds are typically online, on-demand, and off-premise/on-premise. There are public, private, and community Clouds in plenty to comfortably cater to different regions and requirements. There is a number of purpose-specific Cloud environments catering to different communities. Precisely speaking, there are environment-specific, organization-wide, business-centric, private, and localized Clouds comprising bare metal servers, virtual machines, and containers. In the recent past, there are edge or fog device Clouds emerging an evolving fast with the maturity and stability of edge or fog computing. That is, multi-faceted devices are being meticulously clubbed together to form powerful and pioneering device Clouds to attend environment-specific and time-sensitive tasks. On the other hand, there are massive public Clouds by various providers to meet their clients’ computing, networking, and storage needs. Thus, the Cloud evolution and revolution are definitely and decisively amazing. The next innovation, disruption, and transformation in this mesmerizing journey is to form and leverage hybrid Clouds. Many kinds of distributed Cloud environments are to be connected with one another to achieve bigger and better things for the IT, which is invariably mandated to do more with less. This chapter is dedicated to conveying what and why hybrid Clouds and how the hybrid Cloud management tasks are being meticulously accomplished through integrated management tools."
"Navigating the multi-cloud maze: benefits, challenges, and future trends","https://ijgis.pubpub.org/pub/plmsrs5y","2024","Journal Article","","Dhruv Seth
Harshavardhan Nerella
Madhavi Najana
Ayisha Tabbassum","10.21428/e90189c8.8c704fe4","","No","[Abstract not available]"
"Hybrid IT and multi cloud an emerging trend and improved performance in cloud computing","https://link.springer.com/article/10.1007/s42979-020-00277-x","2020","Journal Article","","Srinivasa Rao Gundu
Charanarur Panem
Anuradha Thimmapuram","10.1007/S42979-020-00277-X","https://www.academia.edu/download/96203521/s42979-020-00277-x.pdf","Yes","In the present day scenario cloud computing is an attractive subject for IT and non IT personnel. It is a service-oriented pay per use computational model. Cloud has working models with service-oriented delivery mechanism as well as deployment-oriented infrastructure mechanism. Data centers are the backbone of cloud computing. The massive participation of public has also increased the load on the cloud servers. Proper scheduling of resources is always needed. Quality of service is to be provided as per the service level agreement. Virtualization technique is the main reason behind the huge success of cloud. Multi-cloud exchanges to optimize connectivity today, multi-cloud exchanges offer the next level in direct connectivity, allowing organizations to safely and easily expand multi-cloud capabilities. Exchanges eliminate the added worries that an open Internet can bring as well as the tedious provisioning and configuring that comes with connecting to the public Internet. Importantly, multi-cloud exchanges allow organizations to establish a single connection to multiple cloud providers at the same time through an Ethernet switching platform, rather than wrestling with multiple individual connections to cloud providers."
"Optimizing hybrid and multi-cloud architectures for real-time data streaming and analytics: Strategies for scalability and integration","https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4963389","2022","Journal Article","World Journal of Advanced Engineering Technology and Sciences","Jobin George","10.30574/wjaets.2022.7.1.0087","https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=4963389","No","The adoption of artificial intelligence with multi-cloud is one useful area that businesses and organizations should explore mainly due to its scalability, flexibility, and efficiency. As a result, this integration must come with several pulls that have to be dealt with to realize proper implementation. This paper seeks to identify the major issues of implementing AI and coming up with the best solutions in multi-cloud infrastructures. Firstly, compatibility problems appear as a fundamental issue in the process of implementing AI across more than one cloud. Every cloud provider uses different APIs, formats for data, and possibilities to configure the infrastructure that hinders data and services integration. To counter this, there is a need to have the compliance that comes in terms of standard development through the use of data formats, APIs, and interoperability frameworks. Furthermore, features such as Docker and Kubernetes make the work with ports lighter and let the AI components smoothly interconnect regardless of the used cloud environment. Secondly, data management as well as the governance of big data serve up significant challenges for multi-cloud AI implementation. Legal requirements concerning data privacy, global compliance standards, as well as data sovereignty concerns call for strong governance of cloud data to ensure they are accurate, secure, as well as compliant in the required cloud settings. These risks must be addressed, nonetheless, to build trust in the multi-cloud AI utilization; in this regard, robust data management, encompassing data encryption, access privileges, as well as data auditing, can be implemented in organizational settings. In addition, the optimization of performance is another significant issue to consider as AI computational tasks may be executed across different cloud environments resulting in increased throughput time and network congestion and contention. Through auto-scaling and workload scheduling algorithms used in orchestration, resources can be effectively allocated and loaded in the heterogeneous cloud infrastructures in the most efficient and optimum way thus reducing operational costs. The other is achieving robustness and dependability of multi-cloud AI applications. It is an immutable fact that one can always imagine a situation when clouds, networks, or hardware will fail; therefore, specific measures should be taken to ensure the availability and reliability of the system. The TCP/IP model also classes the means used for implementing redundant mechanisms, data replication strategies and disaster recovery protocols in different geographically situated cloud regions that improve the dependable computing system’s resources."
"Compliance","https://karger.com/pps/article-abstract/58/3-4/161/281532","1960","Journal Article","","B Blackwell","10.1097/00000542-196001000-00089","","No","[Abstract not available]"
"Governance","https://books.google.com/books?hl=en&lr=&id=Ht-tEAAAQBAJ&oi=fnd&pg=PA1989&dq=%22policy+as+code%22+OR+%22compliance%22+OR+%22governance%22&ots=DdQnCbE-L_&sig=l_Jt01hHWSao8M0DtjXwb2oSRA4","","","","AM Kjaer","","","No","[Abstract not available]"
"Understanding governance: Ten years on","https://journals.sagepub.com/doi/abs/10.1177/0170840607076586","2007","Journal Article","Organization Studies","Roderick Rhodes","10.1177/0170840607076586","https://www.researchgate.net/profile/R-A-W-Rhodes/publication/233870082_Understanding_Governance_Policy_Networks_Governance_Reflexivity_and_Accountability/links/56e2725e08ae03f0278eeffe/Understanding-Governance-Policy-Networks-Governance-Reflexivity-and-Accountability.pdf","No","The paper reassesses the argument in Understanding Governance (1997). The first section summarizes where we are now in the study of governance, reviewing briefly the key concepts of policy networks, governance, core executive, hollowing out the state and the differentiated polity. The second section engages with my critics with the aim of opening new directions of research. I concentrate on the key issues of: the context of policy networks, explaining change and the role of ideas, the decline of the state, rescuing the core executive, and steering networks. Under each heading, I sketch a decentred answer to the question of where we go from here. I argue the analysis of governance should focus on beliefs, practices, traditions and dilemmas."
"How do you improve compliance?","https://publications.aap.org/pediatrics/article-abstract/115/6/e718/67454","2005","Journal Article","Pediatrics","Sheldon Winnick
David O. Lucas
Adam L. Hartman
Adam L. Hartman
David Toll","10.1542/PEDS.2004-1133","","Yes","Compliance, or adherence, as it relates to health care is the extent to which a person's behavior coincides with medical or health advice. Medication compliance is critical for all aspects of pediatrics, specifically in successful treatment, disease prevention, and health promotion. Compliance depends on the patient's and physician's committing to the same objectives. It is unfortunate that numerous studies and physician accounts reveal difficulties in achieving compliance with pediatric medication therapy. Medication compliance in pediatric patients ranges from 11% to 93%. At least one third of all patients fail to complete relatively short-term treatment regimens. Poor compliance places children at risk for problems such as continued disease, complicates the physician-patient relationship, and prevents accurate assessment of the quality of care provided. This article presents the issue in the context of its incidence of and barriers to compliance and provides general principles to improve compliance in pediatrics by improving communication and characteristics of the practice setting. A one-on-one relationship between physician and patient is needed for communication and improved compliance."
"Governance matters","https://papers.ssrn.com/sol3/papers.cfm?abstract_id=188568","2020","Journal Article","Report of the United Nations Joint Staff Pension Board","D Kaufmann
A Kraay
P Zoido","10.18356/9789211068993c013","https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=188568","No","[Abstract not available]"
"Democratic governance","https://www.degruyterbrill.com/document/doi/10.1515/9781400836857","2022","Journal Article","Demokratične vrâduvannâ","M Bevir","10.23939/dg","","No","[Abstract not available]"
"The governance perspective","https://library.oapen.org/bitstream/handle/20.500.12657/35130/340216.pdf?sequence=1#page=12","2005","Other","","Jan Kooiman
Maarten Bavinck","10.1017/9789048505326.002","https://library.oapen.org/bitstream/handle/20.500.12657/35130/340216.pdf?sequence=1#page=12","No","[Abstract not available]"
"Governance: From theory to practice","https://link.springer.com/content/pdf/10.1057/9780230583344_10?pdf=chapter%20toc","2009","Book Chapter","","Vasudha Chhotray
Gerry Stoker","10.1057/9780230583344_10","","No","Governance is concerned with the practice of making collective decisions. Governance theory, as such, has both an explanatory dimension and an advisory character. This twin theory-practice focus justifies the core intellectual pursuit of the book, which is to delineate not only the development but also the application of governance theory. The book explores governance theory from a cross-disciplinary perspective and offers those interested in governance access to some of the valuable analytical tools that each discipline has to offer in its distinctive treatment of the idea of governance."
"Multi-IaC-Eval: Benchmarking Cloud Infrastructure as Code Across Multiple Formats","https://arxiv.org/abs/2509.05303v1","2025","Preprint","","Sam Davidson
Li Sun
Bhavana Bhasker
Laurent Callot
Anoop Deoras","","https://arxiv.org/pdf/2509.05303v1","Yes","Infrastructure as Code (IaC) is fundamental to modern cloud computing, enabling teams to define and manage infrastructure through machine-readable configuration files. However, different cloud service providers utilize diverse IaC formats. The lack of a standardized format requires cloud architects to be proficient in multiple IaC languages, adding complexity to cloud deployment. While Large Language Models (LLMs) show promise in automating IaC creation and maintenance, progress has been limited by the lack of comprehensive benchmarks across multiple IaC formats. We present Multi-IaC-Bench, a novel benchmark dataset for evaluating LLM-based IaC generation and mutation across AWS CloudFormation, Terraform, and Cloud Development Kit (CDK) formats. The dataset consists of triplets containing initial IaC templates, natural language modification requests, and corresponding updated templates, created through a synthetic data generation pipeline with rigorous validation. We evaluate several state-of-the-art LLMs on Multi-IaC-Bench, demonstrating that while modern LLMs can achieve high success rates (>95%) in generating syntactically valid IaC across formats, significant challenges remain in semantic alignment and handling complex infrastructure patterns. Our ablation studies highlight the importance of prompt engineering and retry mechanisms in successful IaC generation. We release Multi-IaC-Bench to facilitate further research in AI-assisted infrastructure management and establish standardized evaluation metrics for this crucial domain."
"DevOps Automation Pipeline Deployment with IaC (Infrastructure as Code)","https://arxiv.org/abs/2503.16038v1","2025","Preprint","","Adarsh Saxena
Sudhakar Singh
Shiv Prakash
Tiansheng Yang
Rajkumar Singh Rathore","10.1109/SILCON63976.2024.10910699","https://arxiv.org/pdf/2503.16038v1","Yes","DevOps pipeline is a set of automated tasks or processes or jobs that has tasks assigned to execute automatically that allow the Development team and Operations team to collaborate for building and deployment of the software or services. DevOps as a culture includes better collaboration between different teams within an organization and the removal of silos between them. This paper aims to streamline the current software development and deployment process that is being followed in most of today's generation DevOps deployment as Continuous Integration and Continuous Delivery (CI/CD) pipelines. Centered to the level of software development life cycle (SDLC), it also describes the current ambiguous definition to clarify the implementation of DevOps in practice along a sample CI/CD pipeline deployment. The further objective of the paper is to demonstrate the implementation strategy of DevOps Infrastructure as Code (IaC) and Pipeline as a code and the removal of ambiguity in the definition of DevOps Infrastructure as a Code methodology."
"Source Code Properties of Defective Infrastructure as Code Scripts","https://arxiv.org/abs/1810.09605v1","2018","Preprint","","Akond Rahman
Laurie Williams","10.1016/j.infsof.2019.04.013","https://arxiv.org/pdf/1810.09605v1","Yes","Context: In continuous deployment, software and services are rapidly deployed to end-users using an automated deployment pipeline. Defects in infrastructure as code (IaC) scripts can hinder the reliability of the automated deployment pipeline. We hypothesize that certain properties of IaC source code such as lines of code and hard-coded strings used as configuration values, show correlation with defective IaC scripts. Objective: The objective of this paper is to help practitioners in increasing the quality of infrastructure as code (IaC) scripts through an empirical study that identifies source code properties of defective IaC scripts. Methodology: We apply qualitative analysis on defect-related commits mined from open source software repositories to identify source code properties that correlate with defective IaC scripts. Next, we survey practitioners to assess the practitioner's agreement level with the identified properties. We also construct defect prediction models using the identified properties for 2,439 scripts collected from four datasets. Results: We identify 10 source code properties that correlate with defective IaC scripts. Of the identified 10 properties we observe lines of code and hard-coded string to show the strongest correlation with defective IaC scripts. Hard-coded string is the property of specifying configuration value as hard-coded string. According to our survey analysis, majority of the practitioners show agreement for two properties: include, the property of executing external modules or scripts, and hard-coded string. Using the identified properties, our constructed defect prediction models show a precision of 0.70~0.78, and a recall of 0.54~0.67."
"InfraFix: Technology-Agnostic Repair of Infrastructure as Code","https://arxiv.org/abs/2503.17220v2","2025","Preprint","","Nuno Saavedra
João F. Ferreira
Alexandra Mendes","","https://arxiv.org/pdf/2503.17220v2","Yes","Infrastructure as Code (IaC) enables scalable and automated IT infrastructure management but is prone to errors that can lead to security vulnerabilities, outages, and data loss. While prior research has focused on detecting IaC issues, Automated Program Repair (APR) remains underexplored, largely due to the lack of suitable specifications. In this work, we propose InfraFix, the first technology-agnostic framework for repairing IaC scripts. Unlike prior approaches, InfraFix allows APR techniques to be guided by diverse information sources. Additionally, we introduce a novel approach for generating repair scenarios, enabling large-scale evaluation of APR techniques for IaC. We implement and evaluate InfraFix using an SMT-based repair module and a state inference module that uses system calls, demonstrating its effectiveness across 254,288 repair scenarios with a success rate of 95.7%. Our work provides a foundation for advancing APR in IaC by enabling researchers to experiment with new state inference and repair techniques using InfraFix and to evaluate their approaches at scale with our repair scenario generation method."
"IaC Generation with LLMs: An Error Taxonomy and A Study on Configuration Knowledge Injection","https://arxiv.org/abs/2512.14792v1","2025","Preprint","","Roman Nekrasov
Stefano Fossati
Indika Kumara
Damian Andrew Tamburri
Willem-Jan van den Heuvel","","https://arxiv.org/pdf/2512.14792v1","Yes","Large Language Models (LLMs) currently exhibit low success rates in generating correct and intent-aligned Infrastructure as Code (IaC). This research investigated methods to improve LLM-based IaC generation, specifically for Terraform, by systematically injecting structured configuration knowledge. To facilitate this, an existing IaC-Eval benchmark was significantly enhanced with cloud emulation and automated error analysis. Additionally, a novel error taxonomy for LLM-assisted IaC code generation was developed. A series of knowledge injection techniques was implemented and evaluated, progressing from Naive Retrieval-Augmented Generation (RAG) to more sophisticated Graph RAG approaches. These included semantic enrichment of graph components and modeling inter-resource dependencies. Experimental results demonstrated that while baseline LLM performance was poor (27.1% overall success), injecting structured configuration knowledge increased technical validation success to 75.3% and overall success to 62.6%. Despite these gains in technical correctness, intent alignment plateaued, revealing a ""Correctness-Congruence Gap"" where LLMs can become proficient ""coders"" but remain limited ""architects"" in fulfilling nuanced user intent."
"Statically Inferring Usage Bounds for Infrastructure as Code","https://arxiv.org/abs/2402.15632v1","2024","Preprint","","Feitong Qiao
Aryana Mohammadi
Jürgen Cito
Mark Santolucito","","https://arxiv.org/pdf/2402.15632v1","Yes","Infrastructure as Code (IaC) has enabled cloud customers to have more agility in creating and modifying complex deployments of cloud-provisioned resources. By writing a configuration in IaC languages such as CloudFormation, users can declaratively specify their infrastructure and CloudFormation will handle the creation of the resources. However, understanding the complexity of IaC deployments has emerged as an unsolved issue. In particular, estimating the cost of an IaC deployment requires estimating the future usage and pricing models of every cloud resource in the deployment. Gaining transparency into predicted usage/costs is a leading challenge in cloud management. Existing work either relies on historical usage metrics to predict cost or on coarse-grain static analysis that ignores interactions between resources. Our key insight is that the topology of an IaC deployment imposes constraints on the usage of each resource, and we can formalize and automate the reasoning on constraints by using an SMT solver. This allows customers to have formal guarantees on the bounds of their cloud usage. We propose a tool for fine-grained static usage analysis that works by modeling the inter-resource interactions in an IaC deployment as a set of SMT constraints, and evaluate our tool on a benchmark of over 1000 real world IaC configurations."
"DeepIaC: Deep Learning-Based Linguistic Anti-pattern Detection in IaC","https://arxiv.org/abs/2009.10801v1","2020","Preprint","","Nemania Borovits
Indika Kumara
Parvathy Krishnan
Stefano Dalla Palma
Dario Di Nucci
Fabio Palomba
Damian A. Tamburri
Willem-Jan van den Heuvel","","https://arxiv.org/pdf/2009.10801v1","Yes","Linguistic anti-patterns are recurring poor practices concerning inconsistencies among the naming, documentation, and implementation of an entity. They impede readability, understandability, and maintainability of source code. This paper attempts to detect linguistic anti-patterns in infrastructure as code (IaC) scripts used to provision and manage computing environments. In particular, we consider inconsistencies between the logic/body of IaC code units and their names. To this end, we propose a novel automated approach that employs word embeddings and deep learning techniques. We build and use the abstract syntax tree of IaC code units to create their code embedments. Our experiments with a dataset systematically extracted from open source repositories show that our approach yields an accuracy between0.785and0.915in detecting inconsistencies"
"GenSIaC: Toward Security-Aware Infrastructure-as-Code Generation with Large Language Models","https://arxiv.org/abs/2511.12385v1","2025","Preprint","","Yikun Li
Matteo Grella
Daniel Nahmias
Gal Engelberg
Dan Klein
Giancarlo Guizzardi
Thijs van Ede
Andrea Continella","","https://arxiv.org/pdf/2511.12385v1","Yes","In recent years, Infrastructure as Code (IaC) has emerged as a critical approach for managing and provisioning IT infrastructure through code and automation. IaC enables organizations to create scalable and consistent environments, effectively managing servers and development settings. However, the growing complexity of cloud infrastructures has led to an increased risk of misconfigurations and security vulnerabilities in IaC scripts. To address this problem, this paper investigates the potential of Large Language Models (LLMs) in generating security-aware IaC code, avoiding misconfigurations introduced by developers and administrators. While LLMs have made significant progress in natural language processing and code generation, their ability to generate secure IaC scripts remains unclear. This paper addresses two major problems: 1) the lack of understanding of security weaknesses in IaC scripts generated by LLMs, and 2) the absence of techniques for enhancing security in generating IaC code with LLMs. To assess the extent to which LLMs contain security knowledge, we first conduct a comprehensive evaluation of base LLMs in recognizing major IaC security weaknesses during the generation and inspection of IaC code. Then, we propose GenSIaC, an instruction fine-tuning dataset designed to improve LLMs' ability to recognize potential security weaknesses. Leveraging GenSIaC, we fine-tune LLMs and instruct models to generate security-aware IaC code. Our evaluation demonstrates that our models achieve substantially improved performance in recognizing and preventing IaC security misconfigurations, e.g., boosting the F1-score from 0.303 to 0.858. Additionally, we perform ablation studies and explore GenSIaC's generalizability to other LLMs and its cross-language capabilities."
"Smells-sus: Sustainability Smells in IaC","https://arxiv.org/abs/2501.07676v2","2025","Preprint","","Seif Kosbar
Mohammad Hamdaqa","","https://arxiv.org/pdf/2501.07676v2","Yes","Practitioners use Infrastructure as Code (IaC) scripts to efficiently configure IT infrastructures through machine-readable definition files. However, during the development of these scripts, some code patterns or deployment choices may lead to sustainability issues like inefficient resource utilization or redundant provisioning for example. We call this type of patterns sustainability smells. These inefficiencies pose significant environmental and financial challenges, given the growing scale of cloud computing. This research focuses on Terraform, a widely adopted IaC tool. Our study involves defining seven sustainability smells and validating them through a survey with 19 IaC practitioners. We utilized a dataset of 28,327 Terraform scripts from 395 open-source repositories. We performed a detailed qualitative analysis of a randomly sampled 1,860 Terraform scripts from the original dataset to identify code patterns that correspond to the sustainability smells and used the other 26,467 Terraform scripts to study the prevalence of the defined sustainability smells. Our results indicate varying prevalence rates of these smells across the dataset. The most prevalent smell is Monolithic Infrastructure, which appears in 9.67\% of the scripts. Additionally, our findings highlight the complexity of conducting root cause analysis for sustainability issues, as these smells often arise from a confluence of script structures, configuration choices, and deployment contexts."
"A Framework for Measuring the Quality of Infrastructure-as-Code Scripts","https://arxiv.org/abs/2502.03127v1","2025","Preprint","","Pandu Ranga Reddy Konala
Vimal Kumar
David Bainbridge
Junaid Haseeb","","https://arxiv.org/pdf/2502.03127v1","Yes","Infrastructure as Code (IaC) has become integral to modern software development, enabling automated and consistent configuration of computing environments. The rapid proliferation of IaC scripts has highlighted the need for better code quality assessment methods. This paper proposes a new IaC code quality framework specifically showcased for Ansible repositories as a foundation. By analyzing a comprehensive dataset of repositories from Ansible Galaxy, we applied our framework to evaluate code quality across multiple attributes. The analysis of our code quality metrics applied to Ansible Galaxy repositories reveal trends over time indicating improvements in areas such as metadata and error handling, while highlighting declines in others such as sophistication and automation. The framework offers practitioners a systematic tool for assessing and enhancing IaC scripts, fostering standardization and facilitating continuous improvement. It also provides a standardized foundation for further work into IaC code quality."
"Using a Feedback Loop for LLM-based Infrastructure as Code Generation","https://arxiv.org/abs/2411.19043v1","2024","Preprint","","Mayur Amarnath Palavalli
Mark Santolucito","","https://arxiv.org/pdf/2411.19043v1","Yes","Code generation with Large Language Models (LLMs) has helped to increase software developer productivity in coding tasks, but has yet to have significant impact on the tasks of software developers that surround this code. In particular, the challenge of infrastructure management remains an open question. We investigate the ability of an LLM agent to construct infrastructure using the Infrastructure as Code (IaC) paradigm. We particularly investigate the use of a feedback loop that returns errors and warnings on the generated IaC to allow the LLM agent to improve the code. We find that, for each iteration of the loop, its effectiveness decreases exponentially until it plateaus at a certain point and becomes ineffective."
"Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents","https://arxiv.org/abs/2510.20211v1","2025","Preprint","","Zhenning Yang
Hui Guan
Victor Nicolet
Brandon Paulsen
Joey Dodds
Daniel Kroening
Ang Chen","","https://arxiv.org/pdf/2510.20211v1","Yes","Cloud infrastructure is managed through a mix of interfaces -- traditionally, cloud consoles, command-line interfaces (CLI), and SDKs are the tools of choice. Recently, Infrastructure-as-Code/IaC frameworks (e.g., Terraform) have quickly gained popularity. Unlike conventional tools, IaC~frameworks encode the infrastructure in a ""source-of-truth"" configuration. They are capable of automatically carrying out modifications to the cloud -- deploying, updating, or destroying resources -- to bring the actual infrastructure into alignment with the IaC configuration. However, when IaC is used alongside consoles, CLIs, or SDKs, it loses visibility into external changes, causing infrastructure drift, where the configuration becomes outdated, and later IaC operations may undo valid updates or trigger errors. We present NSync, an automated system for IaC reconciliation that propagates out-of-band changes back into the IaC program. Our key insight is that infrastructure changes eventually all occur via cloud API invocations -- the lowest layer for cloud management operations. NSync gleans insights from API traces to detect drift (i.e., non-IaC changes) and reconcile it (i.e., update the IaC configuration to capture the changes). It employs an agentic architecture that leverages LLMs to infer high-level intents from noisy API sequences, synthesize targeted IaC updates using specialized tools, and continually improve through a self-evolving knowledge base of past reconciliations. We further introduce a novel evaluation pipeline for injecting realistic drifts into cloud infrastructure and assessing reconciliation performance. Experiments across five real-world Terraform projects and 372 drift scenarios show that NSync outperforms the baseline both in terms of accuracy (from 0.71 to 0.97 pass@3) and token efficiency (1.47$\times$ improvement)."
"Detection of security smells in IaC scripts through semantics-aware code and language processing","https://arxiv.org/abs/2509.18790v1","2025","Preprint","","Aicha War
Adnan A. Rawass
Abdoul K. Kabore
Jordan Samhi
Jacques Klein
Tegawende F. Bissyande","","https://arxiv.org/pdf/2509.18790v1","Yes","Infrastructure as Code (IaC) automates the provisioning and management of IT infrastructure through scripts and tools, streamlining software deployment. Prior studies have shown that IaC scripts often contain recurring security misconfigurations, and several detection and mitigation approaches have been proposed. Most of these rely on static analysis, using statistical code representations or Machine Learning (ML) classifiers to distinguish insecure configurations from safe code. In this work, we introduce a novel approach that enhances static analysis with semantic understanding by jointly leveraging natural language and code representations. Our method builds on two complementary ML models: CodeBERT, to capture semantics across code and text, and LongFormer, to represent long IaC scripts without losing contextual information. We evaluate our approach on misconfiguration datasets from two widely used IaC tools, Ansible and Puppet. To validate its effectiveness, we conduct two ablation studies (removing code text from the natural language input and truncating scripts to reduce context) and compare against four large language models (LLMs) and prior work. Results show that semantic enrichment substantially improves detection, raising precision and recall from 0.46 and 0.79 to 0.92 and 0.88 on Ansible, and from 0.55 and 0.97 to 0.87 and 0.75 on Puppet, respectively."
"IntelliSA: An Intelligent Static Analyzer for IaC Security Smell Detection Using Symbolic Rules and Neural Inference","https://arxiv.org/abs/2601.14595v1","2026","Preprint","","Qiyue Mei
Michael Fu","","https://arxiv.org/pdf/2601.14595v1","Yes","Infrastructure as Code (IaC) enables automated provisioning of large-scale cloud and on-premise environments, reducing the need for repetitive manual setup. However, this automation is a double-edged sword: a single misconfiguration in IaC scripts can propagate widely, leading to severe system downtime and security risks. Prior studies have shown that IaC scripts often contain security smells--bad coding patterns that may introduce vulnerabilities--and have proposed static analyzers based on symbolic rules to detect them. Yet, our preliminary analysis reveals that rule-based detection alone tends to over-approximate, producing excessive false positives and increasing the burden of manual inspection. In this paper, we present IntelliSA, an intelligent static analyzer for IaC security smell detection that integrates symbolic rules with neural inference. IntelliSA applies symbolic rules to over-approximate potential smells for broad coverage, then employs neural inference to filter false positives. While an LLM can effectively perform this filtering, reliance on LLM APIs introduces high cost and latency, raises data governance concerns, and limits reproducibility and offline deployment. To address the challenges, we adopt a knowledge distillation approach: an LLM teacher generates pseudo-labels to train a compact student model--over 500x smaller--that learns from the teacher's knowledge and efficiently classifies false positives. We evaluate IntelliSA against two static analyzers and three LLM baselines (Claude-4, Grok-4, and GPT-5) using a human-labeled dataset including 241 security smells across 11,814 lines of real-world IaC code. Experimental results show that IntelliSA achieves the highest F1 score (83%), outperforming baselines by 7-42%. Moreover, IntelliSA demonstrates the best cost-effectiveness, detecting 60% of security smells while inspecting less than 2% of the codebase."
"Consistency Checking and Querying in Probabilistic Databases under Integrity Constraints","https://arxiv.org/abs/1303.3233v1","2013","Preprint","","Sergio Flesca
Filippo Furfaro
Francesco Parisi","","https://arxiv.org/pdf/1303.3233v1","Yes","We address the issue of incorporating a particular yet expressive form of integrity constraints (namely, denial constraints) into probabilistic databases. To this aim, we move away from the common way of giving semantics to probabilistic databases, which relies on considering a unique interpretation of the data, and address two fundamental problems: consistency checking and query evaluation. The former consists in verifying whether there is an interpretation which conforms to both the marginal probabilities of the tuples and the integrity constraints. The latter is the problem of answering queries under a ""cautious"" paradigm, taking into account all interpretations of the data in accordance with the constraints. In this setting, we investigate the complexity of the above-mentioned problems, and identify several tractable cases of practical relevance."
"Team-oriented Consistency Checking of Heterogeneous Engineering Artifacts","https://arxiv.org/abs/2103.14860v1","2021","Preprint","","Michael Alexander Tröls
Atif Mashkoor
Alexander Egyed","","https://arxiv.org/pdf/2103.14860v1","Yes","Consistency checking of interdependent heterogeneous engineering artifacts, such as requirements, specifications, and code, is a challenging task in large-scale engineering projects. The lack of team-oriented solutions allowing a multitude of project stakeholders to collaborate in a consistent manner is thus becoming a critical problem. In this context, this work proposes an approach for team-oriented consistency checking of collaboratively developed heterogeneous engineering artifacts."
"Consistency-Checking Problems: A Gateway to Parameterized Sample Complexity","https://arxiv.org/abs/2308.11416v1","2023","Preprint","","Robert Ganian
Liana Khazaliya
Kirill Simonov","","https://arxiv.org/pdf/2308.11416v1","Yes","Recently, Brand, Ganian and Simonov introduced a parameterized refinement of the classical PAC-learning sample complexity framework. A crucial outcome of their investigation is that for a very wide range of learning problems, there is a direct and provable correspondence between fixed-parameter PAC-learnability (in the sample complexity setting) and the fixed-parameter tractability of a corresponding ""consistency checking"" search problem (in the setting of computational complexity). The latter can be seen as generalizations of classical search problems where instead of receiving a single instance, one receives multiple yes- and no-examples and is tasked with finding a solution which is consistent with the provided examples. Apart from a few initial results, consistency checking problems are almost entirely unexplored from a parameterized complexity perspective. In this article, we provide an overview of these problems and their connection to parameterized sample complexity, with the primary aim of facilitating further research in this direction. Afterwards, we establish the fixed-parameter (in)-tractability for some of the arguably most natural consistency checking problems on graphs, and show that their complexity-theoretic behavior is surprisingly very different from that of classical decision problems. Our new results cover consistency checking variants of problems as diverse as (k-)Path, Matching, 2-Coloring, Independent Set and Dominating Set, among others."
"Optimal Reads-From Consistency Checking for C11-Style Memory Models","https://arxiv.org/abs/2304.03714v2","2023","Preprint","","Hünkar Can Tunç
Parosh Aziz Abdulla
Soham Chakraborty
Shankaranarayanan Krishna
Umang Mathur
Andreas Pavlogiannis","","https://arxiv.org/pdf/2304.03714v2","Yes","Over the years, several memory models have been proposed to capture the subtle concurrency semantics of C/C++.One of the most fundamental problems associated with a memory model M is consistency checking: given an execution X, is X consistent with M? This problem lies at the heart of numerous applications, including specification testing and litmus tests, stateless model checking, and dynamic analyses. As such, it has been explored extensively and its complexity is well-understood for traditional models like SC and TSO. However, less is known for the numerous model variants of C/C++, for which the problem becomes challenging due to the intricacies of their concurrency primitives. In this work we study the problem of consistency checking for popular variants of the C11 memory model, in particular, the RC20 model, its release-acquire (RA) fragment, the strong and weak variants of RA (SRA and WRA), as well as the Relaxed fragment of RC20. Motivated by applications in testing and model checking, we focus on reads-from consistency checking. The input is an execution X specifying a set of events, their program order and their reads-from relation, and the task is to decide the existence of a modification order on the writes of X that makes X consistent in a memory model. We draw a rich complexity landscape for this problem; our results include (i)~nearly-linear-time algorithms for certain variants, which improve over prior results, (ii)~fine-grained optimality results, as well as (iii)~matching upper and lower bounds (NP-hardness) for other variants. To our knowledge, this is the first work to characterize the complexity of consistency checking for C11 memory models. We have implemented our algorithms inside the TruSt model checker and the C11Tester testing tool. Experiments on standard benchmarks show that our new algorithms improve consistency checking, often by a significant margin."
"Incremental Consistency Checking in Delta-oriented UML-Models for Automation Systems","https://arxiv.org/abs/1604.00348v1","2016","Preprint","","Matthias Kowal
Ina Schaefer","10.4204/EPTCS.206.4","https://arxiv.org/pdf/1604.00348v1","Yes","Automation systems exist in many variants and may evolve over time in order to deal with different environment contexts or to fulfill changing customer requirements. This induces an increased complexity during design-time as well as tedious maintenance efforts. We already proposed a multi-perspective modeling approach to improve the development of such systems. It operates on different levels of abstraction by using well-known UML-models with activity, composite structure and state chart models. Each perspective was enriched with delta modeling to manage variability and evolution. As an extension, we now focus on the development of an efficient consistency checking method at several levels to ensure valid variants of the automation system. Consistency checking must be provided for each perspective in isolation, in-between the perspectives as well as after the application of a delta."
"Agent-Based Output Drift Detection for Breast Cancer Response Prediction in a Multisite Clinical Decision Support System","https://arxiv.org/abs/2512.18450v1","2025","Preprint","","Xavier Rafael-Palou
Jose Munuera
Ana Jimenez-Pastor
Richard Osuala
Karim Lekadir
Oliver Diaz","","https://arxiv.org/pdf/2512.18450v1","Yes","Modern clinical decision support systems can concurrently serve multiple, independent medical imaging institutions, but their predictive performance may degrade across sites due to variations in patient populations, imaging hardware, and acquisition protocols. Continuous surveillance of predictive model outputs offers a safe and reliable approach for identifying such distributional shifts without ground truth labels. However, most existing methods rely on centralized monitoring of aggregated predictions, overlooking site-specific drift dynamics. We propose an agent-based framework for detecting drift and assessing its severity in multisite clinical AI systems. To evaluate its effectiveness, we simulate a multi-center environment for output-based drift detection, assigning each site a drift monitoring agent that performs batch-wise comparisons of model outputs against a reference distribution. We analyse several multi-center monitoring schemes, that differ in how the reference is obtained (site-specific, global, production-only and adaptive), alongside a centralized baseline. Results on real-world breast cancer imaging data using a pathological complete response prediction model shows that all multi-center schemes outperform centralized monitoring, with F1-score improvements up to 10.3% in drift detection. In the absence of site-specific references, the adaptive scheme performs best, with F1-scores of 74.3% for drift detection and 83.7% for drift severity classification. These findings suggest that adaptive, site-aware agent-based drift monitoring can enhance reliability of multisite clinical decision support systems."
"GLaMoR: Consistency Checking of OWL Ontologies using Graph Language Models","https://arxiv.org/abs/2504.19023v1","2025","Preprint","","Justin Mücke
Ansgar Scherp","","https://arxiv.org/pdf/2504.19023v1","Yes","Semantic reasoning aims to infer new knowledge from existing knowledge, with OWL ontologies serving as a standardized framework for organizing information. A key challenge in semantic reasoning is verifying ontology consistency. However, state-of-the-art reasoners are computationally expensive, and their efficiency decreases as ontology sizes grow. While classical machine learning models have been explored for consistency checking, they struggle to capture complex relationships within ontologies. Large language models (LLMs) have shown promising results for simple reasoning tasks but perform poorly on structured reasoning. The recently introduced Graph Language Model (GLM) offers a way to simultaneously process graph-structured data and text. This paper proposes GLaMoR (Graph Language Model for Reasoning), a reasoning pipeline that transforms OWL ontologies into graph-structured data and adapts the GLM architecture for consistency checking. We evaluate GLaMoR on ontologies from the NCBO BioPortal repository, converting them into triples suitable for model input. Our results show that the GLM outperforms all baseline models, achieving $95\%$ accuracy while being 20 times faster than classical reasoners. The Code is accessible under: https://github.com/JustinMuecke/GLaMoR"
"Towards Dynamic Consistency Checking in Goal-directed Predicate Answer Set Programming","https://arxiv.org/abs/2110.12053v1","2021","Preprint","","Joaquín Arias
Manuel Carro
Gopal Gupta","","https://arxiv.org/pdf/2110.12053v1","Yes","Goal-directed evaluation of Answer Set Programs is gaining traction thanks to its amenability to create AI systems that can, due to the evaluation mechanism used, generate explanations and justifications. s(CASP) is one of these systems and has been already used to write reasoning systems in several fields. It provides enhanced expressiveness w.r.t. other ASP systems due to its ability to use constraints, data structures, and unbound variables natively. However, the performance of existing s(CASP) implementations is not on par with other ASP systems: model consistency is checked once models have been generated, in keeping with the generate-and-test paradigm. In this work, we present a variation of the top-down evaluation strategy, termed Dynamic Consistency Checking, which interleaves model generation and consistency checking. This makes it possible to determine when a literal is not compatible with the denials associated to the global constraints in the program, prune the current execution branch, and choose a different alternative. This strategy is specially (but not exclusively) relevant in problems with a high combinatorial component. We have experimentally observed speedups of up to 90x w.r.t. the standard versions of s(CASP)."
"L2C2: Logic-based LSC Consistency Checking","https://arxiv.org/abs/1002.3083v1","2010","Preprint","","Hai-Feng Guo
Wen Zheng
Mahadevan Subramaniam","","https://arxiv.org/pdf/1002.3083v1","Yes","Live sequence charts (LSCs) have been proposed as an inter-object scenario-based specification and visual programming language for reactive systems. In this paper, we introduce a logic-based framework to check the consistency of an LSC specification. An LSC simulator has been implemented in logic programming, utilizing a memoized depth-first search strategy, to show how a reactive system in LSCs would response to a set of external event sequences. A formal notation is defined to specify external event sequences, extending the regular expression with a parallel operator and a testing control. The parallel operator allows interleaved parallel external events to be tested in LSCs simultaneously; while the testing control provides users to a new approach to specify and test certain temporal properties (e.g., CTL formula) in a form of LSC. Our framework further provides either a state transition graph or a failure trace to justify the consistency checking results."
"Scalable Drift Monitoring in Medical Imaging AI","https://arxiv.org/abs/2410.13174v2","2024","Preprint","","Jameson Merkow
Felix J. Dorfner
Xiyu Yang
Alexander Ersoy
Giridhar Dasegowda
Mannudeep Kalra
Matthew P. Lungren
Christopher P. Bridge
Ivan Tarapov","","https://arxiv.org/pdf/2410.13174v2","Yes","The integration of artificial intelligence (AI) into medical imaging has advanced clinical diagnostics but poses challenges in managing model drift and ensuring long-term reliability. To address these challenges, we develop MMC+, an enhanced framework for scalable drift monitoring, building upon the CheXstray framework that introduced real-time drift detection for medical imaging AI models using multi-modal data concordance. This work extends the original framework's methodologies, providing a more scalable and adaptable solution for real-world healthcare settings and offers a reliable and cost-effective alternative to continuous performance monitoring addressing limitations of both continuous and periodic monitoring methods. MMC+ introduces critical improvements to the original framework, including more robust handling of diverse data streams, improved scalability with the integration of foundation models like MedImageInsight for high-dimensional image embeddings without site-specific training, and the introduction of uncertainty bounds to better capture drift in dynamic clinical environments. Validated with real-world data from Massachusetts General Hospital during the COVID-19 pandemic, MMC+ effectively detects significant data shifts and correlates them with model performance changes. While not directly predicting performance degradation, MMC+ serves as an early warning system, indicating when AI systems may deviate from acceptable performance bounds and enabling timely interventions. By emphasizing the importance of monitoring diverse data streams and evaluating data shifts alongside model performance, this work contributes to the broader adoption and integration of AI solutions in clinical settings."
"Interpretable Model Drift Detection","https://arxiv.org/abs/2503.06606v1","2025","Preprint","","Pranoy Panda
Kancheti Sai Srinivas
Vineeth N Balasubramanian
Gaurav Sinha","10.1145/3632410.3632434","https://arxiv.org/pdf/2503.06606v1","Yes","Data in the real world often has an evolving distribution. Thus, machine learning models trained on such data get outdated over time. This phenomenon is called model drift. Knowledge of this drift serves two purposes: (i) Retain an accurate model and (ii) Discovery of knowledge or insights about change in the relationship between input features and output variable w.r.t. the model. Most existing works focus only on detecting model drift but offer no interpretability. In this work, we take a principled approach to study the problem of interpretable model drift detection from a risk perspective using a feature-interaction aware hypothesis testing framework, which enjoys guarantees on test power. The proposed framework is generic, i.e., it can be adapted to both classification and regression tasks. Experiments on several standard drift detection datasets show that our method is superior to existing interpretable methods (especially on real-world datasets) and on par with state-of-the-art black-box drift detection methods. We also quantitatively and qualitatively study the interpretability aspect including a case study on USENET2 dataset. We find our method focuses on model and drift sensitive features compared to baseline interpretable drift detectors."
"Autoregressive based Drift Detection Method","https://arxiv.org/abs/2203.04769v2","2022","Preprint","","Mansour Zoubeirou A Mayaki
Michel Riveill","10.1109/IJCNN55064.2022.9892066","https://arxiv.org/pdf/2203.04769v2","Yes","In the classic machine learning framework, models are trained on historical data and used to predict future values. It is assumed that the data distribution does not change over time (stationarity). However, in real-world scenarios, the data generation process changes over time and the model has to adapt to the new incoming data. This phenomenon is known as concept drift and leads to a decrease in the predictive model's performance. In this study, we propose a new concept drift detection method based on autoregressive models called ADDM. This method can be integrated into any machine learning algorithm from deep neural networks to simple linear regression model. Our results show that this new concept drift detection method outperforms the state-of-the-art drift detection methods, both on synthetic data sets and real-world data sets. Our approach is theoretically guaranteed as well as empirical and effective for the detection of various concept drifts. In addition to the drift detector, we proposed a new method of concept drift adaptation based on the severity of the drift."
"Dense Hybrid Recurrent Multi-view Stereo Net with Dynamic Consistency Checking","https://arxiv.org/abs/2007.10872v1","2020","Preprint","","Jianfeng Yan
Zizhuang Wei
Hongwei Yi
Mingyu Ding
Runze Zhang
Yisong Chen
Guoping Wang
Yu-Wing Tai","","https://arxiv.org/pdf/2007.10872v1","Yes","In this paper, we propose an efficient and effective dense hybrid recurrent multi-view stereo net with dynamic consistency checking, namely $D^{2}$HC-RMVSNet, for accurate dense point cloud reconstruction. Our novel hybrid recurrent multi-view stereo net consists of two core modules: 1) a light DRENet (Dense Reception Expanded) module to extract dense feature maps of original size with multi-scale context information, 2) a HU-LSTM (Hybrid U-LSTM) to regularize 3D matching volume into predicted depth map, which efficiently aggregates different scale information by coupling LSTM and U-Net architecture. To further improve the accuracy and completeness of reconstructed point clouds, we leverage a dynamic consistency checking strategy instead of prefixed parameters and strategies widely adopted in existing methods for dense point cloud reconstruction. In doing so, we dynamically aggregate geometric consistency matching error among all the views. Our method ranks \textbf{$1^{st}$} on the complex outdoor \textsl{Tanks and Temples} benchmark over all the methods. Extensive experiments on the in-door DTU dataset show our method exhibits competitive performance to the state-of-the-art method while dramatically reduces memory consumption, which costs only $19.4\%$ of R-MVSNet memory consumption. The codebase is available at \hyperlink{https://github.com/yhw-yhw/D2HC-RMVSNet}{https://github.com/yhw-yhw/D2HC-RMVSNet}."
"Consistency Checking of Functional Requirements","https://arxiv.org/abs/1804.10486v1","2018","Preprint","","Simone Vuotto","","https://arxiv.org/pdf/1804.10486v1","Yes","Requirements are informal and semi-formal descriptions of the expected behavior of a system. They are usually expressed in the form of natural language sentences and checked for errors manually, e.g., by peer reviews. Manual checks are error-prone, time-consuming and not scalable. With the increasing complexity of cyber-physical systems and the need of operating in safety- and security-critical environments, it became essential to automatize the consistency check of requirements and build artifacts to help system engineers in the design process."
"Demo: LE3D: A Privacy-preserving Lightweight Data Drift Detection Framework","https://arxiv.org/abs/2211.01827v2","2022","Preprint","","Ioannis Mavromatis
Aftab Khan","","https://arxiv.org/pdf/2211.01827v2","Yes","This paper presents LE3D; a novel data drift detection framework for preserving data integrity and confidentiality. LE3D is a generalisable platform for evaluating novel drift detection mechanisms within the Internet of Things (IoT) sensor deployments. Our framework operates in a distributed manner, preserving data privacy while still being adaptable to new sensors with minimal online reconfiguration. Our framework currently supports multiple drift estimators for time-series IoT data and can easily be extended to accommodate new data types and drift detection mechanisms. This demo will illustrate the functionality of LE3D under a real-world-like scenario."
"STUDD: A Student-Teacher Method for Unsupervised Concept Drift Detection","https://arxiv.org/abs/2103.00903v1","2021","Preprint","","Vitor Cerqueira
Heitor Murilo Gomes
Albert Bifet
Luis Torgo","","https://arxiv.org/pdf/2103.00903v1","Yes","Concept drift detection is a crucial task in data stream evolving environments. Most of state of the art approaches designed to tackle this problem monitor the loss of predictive models. However, this approach falls short in many real-world scenarios, where the true labels are not readily available to compute the loss. In this context, there is increasing attention to approaches that perform concept drift detection in an unsupervised manner, i.e., without access to the true labels. We propose a novel approach to unsupervised concept drift detection based on a student-teacher learning paradigm. Essentially, we create an auxiliary model (student) to mimic the behaviour of the primary model (teacher). At run-time, our approach is to use the teacher for predicting new instances and monitoring the mimicking loss of the student for concept drift detection. In a set of experiments using 19 data streams, we show that the proposed approach can detect concept drift and present a competitive behaviour relative to the state of the art approaches."
"TraceWalk: Semantic-based Process Graph Embedding for Consistency Checking","https://arxiv.org/abs/1905.06883v1","2019","Preprint","","Chen Qian
Lijie Wen
Akhil Kumar","","https://arxiv.org/pdf/1905.06883v1","Yes","Process consistency checking (PCC), an interdiscipline of natural language processing (NLP) and business process management (BPM), aims to quantify the degree of (in)consistencies between graphical and textual descriptions of a process. However, previous studies heavily depend on a great deal of complex expert-defined knowledge such as alignment rules and assessment metrics, thus suffer from the problems of low accuracy and poor adaptability when applied in open-domain scenarios. To address the above issues, this paper makes the first attempt that uses deep learning to perform PCC. Specifically, we proposed TraceWalk, using semantic information of process graphs to learn latent node representations, and integrates it into a convolutional neural network (CNN) based model called TraceNet to predict consistencies. The theoretical proof formally provides the PCC's lower limit and experimental results demonstrate that our approach performs more accurately than state-of-the-art baselines."
"Flexible and Efficient Drift Detection without Labels","https://arxiv.org/abs/2506.08734v2","2025","Preprint","","Nelvin Tan
Yu-Ching Shih
Dong Yang
Amol Salunkhe","","https://arxiv.org/pdf/2506.08734v2","Yes","Machine learning models are being increasingly used to automate decisions in almost every domain, and ensuring the performance of these models is crucial for ensuring high quality machine learning enabled services. Ensuring concept drift is detected early is thus of the highest importance. A lot of research on concept drift has focused on the supervised case that assumes the true labels of supervised tasks are available immediately after making predictions. Controlling for false positives while monitoring the performance of predictive models used to make inference from extremely large datasets periodically, where the true labels are not instantly available, becomes extremely challenging. We propose a flexible and efficient concept drift detection algorithm that uses classical statistical process control in a label-less setting to accurately detect concept drifts. We show empirically that under computational constraints, our approach has better statistical power than previous known methods. Furthermore, we introduce a new semi-supervised drift detection framework to model the scenario of detecting drift (without labels) given prior detections, and show how our drift detection algorithm can be incorporated effectively into this framework. We demonstrate promising performance via numerical simulations."
"Message Passing for Analysis and Resilient Design of Self-Healing Interdependent Cyber-Physical Networks","https://arxiv.org/abs/1606.00955v2","2016","Preprint","","Ali Behfarnia
Ali Eslami","","https://arxiv.org/pdf/1606.00955v2","Yes","Coupling cyber and physical systems gives rise to numerous engineering challenges and opportunities. An important challenge is the contagion of failure from one system to another, that can lead to large scale cascading failures. On the other hand, self-healing ability emerges as a valuable opportunity where the overlay cyber network can cure failures in the underlying physical network. To capture both self-healing and contagion, we introduce a factor graph representation of inter-dependent cyber-physical systems in which factor nodes represent various node functionalities and the edges capture the interactions between the nodes. We develop a message passing algorithm to study the dynamics of failure propagation and healing in this representation. Through applying a fixed-point analysis to this algorithm, we investigate the network reaction to initial disruptions. Our analysis provides simple yet critical guidelines for choosing network parameters to achieve resiliency against cascading failures."
"A Self Healing Model Based on Polymer-Mediated Chromophore Correlations","https://arxiv.org/abs/1205.0481v2","2012","Preprint","","Shiva Kumar Ramini
Mark G. Kuzyk","10.1063/1.4739295","https://arxiv.org/pdf/1205.0481v2","Yes","Here we present a model of self healing in which correlations between chromophores, as mediated by the polymer, are key to the recovery process. Our model determines the size distribution of the correlation volume using a grand canonical ensemble through a free energy advantage parameter. Choosing a healing rate that is proportional to the number of undamaged molecules in a correlated region, and a decay rate proportional to the intensity normalized to the correlation volume, the ensemble average is shown to correctly predict decay and recovery of the population of disperse orange 11-DO11 (1-amino-2-methylanthraquinone) molecules doped in PMMA polymer as a function of time and concentration as measured with amplified spontaneous emission and linear absorption spectroscopy using only three parameters that apply to the full set of data. Our model also predicts the temperature dependence of the process. One set of parameters should be characteristic of a particular polymer and dopant chromophore combination. Thus, use of the model in determining these parameters for various materials systems should provide the data needed to test fundamental models of the underlying mechanism responsible for self healing."
"Self-healing of structured light: a review","https://arxiv.org/abs/2207.04767v1","2022","Preprint","","Yijie Shen
Shankar Pidishety
Isaac Nape
Angela Dudley","10.1088/2040-8986/ac8888","https://arxiv.org/pdf/2207.04767v1","Yes","Self-healing of light refers to the ability of a light field to recover its structure after being damaged by a partial obstruction placed in its propagation path. Here, we will give a comprehensive review of the history and development of self-healing effects, especially highlighting its importance in vector vortex beams carrying spin and orbital angular momenta. Moreover, an unified zoology of self-healing, structured light is proposed to unveil a deeper understanding of its physical mechanism and provide a bird's eye view on diverse forms of self-healing effects of different kinds of complex structured light. Finally, we outline the open challenges we are facing, potential opportunities and future trends for both fundamental physics and applications."
"OAM-Assisted Self-Healing Is Directional, Proportional and Persistent","https://arxiv.org/abs/2504.02103v1","2025","Preprint","","Marek Klemes
Lan Hu
Greg Bowles
Alireza Ghayekhloo
Mohammad Akbari
Soulideth Thirakoune
Michael Schwartzman
Kevin Zhang
Tan Huy Ho
David Wessel
Wen Tong","","https://arxiv.org/pdf/2504.02103v1","Yes","In this paper we demonstrate the postulated mechanism of self-healing specifically due to orbital-angular-momentum (OAM) in radio vortex beams having equal beam-widths. In previous work we experimentally demonstrated self-healing effects in OAM beams at 28 GHz and postulated a theoretical mechanism to account for them. In this work we further characterize the OAM self-healing mechanism theoretically and confirm those characteristics with systematic and controlled experimental measurements on a 28 GHz outdoor link. Specifically, we find that the OAM self-healing mechanism is an additional self-healing mechanism in structured electromagnetic beams which is directional with respect to the displacement of an obstruction relative to the beam axis. We also confirm our previous findings that the amount of OAM self-healing is proportional to the OAM order, and additionally find that it persists beyond the focusing region into the far field. As such, OAM-assisted self-healing brings an advantage over other so-called non-diffracting beams both in terms of the minimum distance for onset of self-healing and the amount of self-healing obtainable. We relate our findings by extending theoretical models in the literature and develop a unifying electromagnetic analysis to account for self-healing of OAM-bearing non-diffracting beams more rigorously."
"Self-Healing Behavior of Ice","https://arxiv.org/abs/2111.08367v1","2021","Preprint","","Menno Demmenie
Paul Kolpakov
Yuki Nagata
Sander Woutersen
Daniel Bonn","","https://arxiv.org/pdf/2111.08367v1","Yes","We show that the surface of ice is self-healing: micrometer deep scratches in the ice surface spontaneously disappear by relaxation on a time scale of roughly an hour. Following the dynamics and comparing it to different mass transfer mechanisms, we find that sublimation from and condensation onto the ice surface is the dominant self-healing mechanism. The self-healing kinetics shows a strong temperature dependence, following an Arrhenius behavior with an activation energy of $ΔE = 58.6 \pm 4.6$ kJ/mole, agreeing with the proposed sublimation mechanism, and at odds with surface diffusion or fluid flow or evaporation-condensation from a quasi-liquid layer."
"A Survey on Self-healing Software System","https://arxiv.org/abs/2403.00455v1","2024","Preprint","","Zahra Yazdanparast","","https://arxiv.org/pdf/2403.00455v1","Yes","With the increasing complexity of software systems, it becomes very difficult to install, configure, adjust, and maintain them. As systems become more interconnected and diverse, system architects are less able to predict and design the interaction between components, deferring the handling of these issues to runtime. One of the important problems that occur during execution is system failures, which increase the need for self-healing systems. The main purpose of self-healing is to have an automatic system that can heal itself without human intervention. This system has predefined actions and procedures that are suitable for recovering the system from different failure modes. In this study, different self-healing methods are categorized and a summary of them is presented."
"Compact Routing Messages in Self-Healing Trees","https://arxiv.org/abs/1508.04234v1","2015","Preprint","","Armando Castaneda
Danny Dolev
Amitabh Trehan","","https://arxiv.org/pdf/1508.04234v1","Yes","Existing compact routing schemes, e.g., Thorup and Zwick [SPAA 2001] and Chechik [PODC 2013], often have no means to tolerate failures, once the system has been setup and started. This paper presents, to our knowledge, the first self-healing compact routing scheme. Besides, our schemes are developed for low memory nodes, i.e., nodes need only $O(\log^2 n)$ memory, and are thus, compact schemes. We introduce two algorithms of independent interest: The first is CompactFT, a novel compact version (using only $O(\log n)$ local memory) of the self-healing algorithm Forgiving Tree of Hayes et al. [PODC 2008]. The second algorithm (CompactFTZ) combines CompactFT with Thorup-Zwick's tree-based compact routing scheme [SPAA 2001] to produce a fully compact self-healing routing scheme. In the self-healing model, the adversary deletes nodes one at a time with the affected nodes self-healing locally by adding few edges. CompactFT recovers from each attack in only $O(1)$ time and $Δ$ messages, with only +3 degree increase and $O(log Δ)$ graph diameter increase, over any sequence of deletions ($Δ$ is the initial maximum degree). Additionally, CompactFTZ guarantees delivery of a packet sent from sender s as long as the receiver t has not been deleted, with only an additional $O(y \log Δ)$ latency, where $y$ is the number of nodes that have been deleted on the path between $s$ and $t$. If $t$ has been deleted, $s$ gets informed and the packet removed from the network."
"Modeling Adaptive Self-healing Systems","https://arxiv.org/abs/2304.12773v1","2023","Preprint","","Habtom Kahsay Gidey
Diego Marmsoler
Dominik Ascher","","https://arxiv.org/pdf/2304.12773v1","Yes","Motivation: Smart grids design requires energy distribution operations to be adaptable to abnormality. This requirement entails distribution system operators (DSOs) to optimize restoration to normal operational states dynamically. However, these design challenges demand collaborative research efforts on sophisticated modeling and simulation approaches. Approach: In the ESOSEG research project, analyzing the smart grid domain as a software-intensive system, we employed a dynamic architecture approach, particularly the FOCUS theory, to model and assure the domains' self-healing requirements. Although some works specify various self-healing systems, to the best of our knowledge, the use of the approach in smart grids is the first work to enable a formal specification and verification of self-healing properties in smart grids. Results: As a result, to support the modeling and verification process, we developed tool support with Eclipse Modeling Framework (EMF), Xtext, and other languages in the EMF ecosystem. The tool includes a grammar or a meta-model of the DSL, an interface to enable textual and graphical modeling of architectural patterns and code transformer engine for verification. Furthermore, we evaluated the modeling and verification features of the tool support with an e-Car charging scenario for modeling adaptive self-healing properties. Futureworks: As an outlook, future works could include investigation of comprehensive case studies. These, for instance, could be further particular adaptability scenarios addressing challenges in DSOs. Another interesting aspect could be the evaluation of the modeling approach by investigating its use with engineers involved in a smart grid design. Next, the evaluation could be followed with abstractions of the verification process to make it useable by system architects with no knowledge of the proof language, Isabelle/HOL."
"Self-Healing Robust Neural Networks via Closed-Loop Control","https://arxiv.org/abs/2206.12963v1","2022","Preprint","","Zhuotong Chen
Qianxiao Li
Zheng Zhang","","https://arxiv.org/pdf/2206.12963v1","Yes","Despite the wide applications of neural networks, there have been increasing concerns about their vulnerability issue. While numerous attack and defense techniques have been developed, this work investigates the robustness issue from a new angle: can we design a self-healing neural network that can automatically detect and fix the vulnerability issue by itself? A typical self-healing mechanism is the immune system of a human body. This biology-inspired idea has been used in many engineering designs but is rarely investigated in deep learning. This paper considers the post-training self-healing of a neural network, and proposes a closed-loop control formulation to automatically detect and fix the errors caused by various attacks or perturbations. We provide a margin-based analysis to explain how this formulation can improve the robustness of a classifier. To speed up the inference of the proposed self-healing network, we solve the control problem via improving the Pontryagin Maximum Principle-based solver. Lastly, we present an error estimation of the proposed framework for neural networks with nonlinear activation functions. We validate the performance on several network architectures against various perturbations. Since the self-healing method does not need a-priori information about data perturbations/attacks, it can handle a broad class of unforeseen perturbations."
"Self-healing mechanism of lithium in lithium metal batteries","https://arxiv.org/abs/2106.10979v2","2021","Preprint","","Junyu Jiao
Genming Lai
Liang Zhao
Jiaze Lu
Qidong Li
Xianqi Xu
Yao Jiang
Yan-Bing He
Chuying Ouyang
Feng Pan
Hong Li
Jiaxin Zheng","","https://arxiv.org/pdf/2106.10979v2","Yes","Li metal is an ideal anode material for use in state-of-the-art secondary batteries. However, Li-dendrite growth is a safety concern and results in low coulombic efficiency, which significantly restricts the commercial application of Li secondary batteries. Unfortunately, the Li deposition (growth) mechanism is poorly understood on the atomic scale. Here, we used machine learning to construct a Li potential model with quantum-mechanical computational accuracy. Molecular dynamics simulations in this study with this model revealed two self-healing mechanisms in a large Li-metal system, viz. surface self-healing and bulk self-healing, and identified three Li-dendrite morphologies under different conditions, viz. ""needle"", ""mushroom"", and ""hemisphere"". Finally, we introduce the concepts of local current density and variance in local current density to supplement the critical current density when evaluating the probability of self-healing."
"Screening of Fungi for the Application of Self-Healing Concrete","https://arxiv.org/abs/1711.10386v6","2017","Preprint","","Rakenth R. Menon
Jing Luo
Xiaobo Chen
Hui Zhou
Zhiyong Liu
Guangwen Zhou
Ning Zhang
Congrui Jin","","https://arxiv.org/pdf/1711.10386v6","Yes","Concrete is susceptible to cracking owing to drying shrinkage, freeze-thaw cycles, delayed ettringite formation, reinforcement corrosion, creep and fatigue, etc. Since maintenance and inspection of concrete infrastructure require onerous labor and high costs, self-healing of harmful cracks without human interference or intervention could be of great attraction. The goal of this study is to explore a new self-healing approach in which fungi are used as a self-healing agent to promote calcium carbonate precipitation to fill the cracks in concrete structures. Recent research results in the field of geomycology have shown that many species of fungi could play an important role in promoting calcium carbonate mineralization, but their application in self-healing concrete has not been reported. Therefore, a screening of different species of fungi has been conducted in this study. Our results showed that, despite the drastic pH increase owing to the leaching of calcium hydroxide from concrete, Aspergillus nidulans (MAD1445), a pH regulatory mutant, could grow on concrete plates and promote calcium carbonate precipitation."
"Self-healing unitarity is an optical illusion","https://arxiv.org/abs/2307.04127v2","2023","Preprint","","Archit Vidyarthi","10.1103/PhysRevD.109.016020","https://arxiv.org/pdf/2307.04127v2","Yes","Among the vast variety of proposals put forward by the community to resolve tree-level unitarity violations in Higgs inflation models, there exists the concept of self-healing. It heals the theory from supposed tree-level violations for elastic scattering processes by summing over successive vacuum polarization loop corrections. In this work, we examine this technique to check whether unitarity is indeed restored and find that there exist underlying constraints in self-healing unitarity that pose the same perturbative unitarity bounds that it was expected to heal."
"Collusion resistant self-healing key distribution in mobile wireless networks","https://arxiv.org/abs/1206.6285v1","2012","Preprint","","Ratna Dutta
Sugata Sanyal","","https://arxiv.org/pdf/1206.6285v1","Yes","A fundamental concern of any secure group communication system is key management and wireless environments create new challenges. One core requirement in these emerging networks is self-healing. In systems where users can be offline and miss updates, self-healing allows a user to recover lost session keys and get back into the secure communication without putting extra burden on the group manager. Clearly, self-healing must only be available to authorized users. This paper fixes the problem of collusion attack in an existing self-healing key distribution scheme and provides a highly efficient scheme as compared to the existing works. It is computationally secure, resists collusion attacks made between newly joined users and revoked users and achieves forward and backward secrecy. Our security analysis is in an appropriate security model. Unlike the existing constructions, our scheme does not forbid revoked users from rejoining in later sessions."
"Self-Healing First-Order Distributed Optimization","https://arxiv.org/abs/2104.01959v2","2021","Preprint","","Israel L. Donato Ridgley
Randy A. Freeman
Kevin M. Lynch","10.1109/CDC45484.2021.9683487","https://arxiv.org/pdf/2104.01959v2","Yes","In this paper we describe a parameterized family of first-order distributed optimization algorithms that enable a network of agents to collaboratively calculate a decision variable that minimizes the sum of cost functions at each agent. These algorithms are self-healing in that their correctness is guaranteed even if they are initialized randomly, agents drop in or out of the network, local cost functions change, or communication packets are dropped. Our algorithms are the first single-Laplacian methods to exhibit all of these characteristics. We achieve self-healing by sacrificing internal stability, a fundamental trade-off for single-Laplacian methods."
"Percolation Modeling of Conductance of Self-Healing Composites","https://arxiv.org/abs/0704.0935v2","2007","Preprint","","Alexander Dementsov
Vladimir Privman","10.1016/j.physa.2007.07.025","https://arxiv.org/pdf/0704.0935v2","Yes","We explore the conductance of self-healing materials as a measure of the material integrity in the regime of the onset of the initial fatigue. Continuum effective-field modeling and lattice numerical simulations are reported. Our results illustrate the general features of the self-healing process: The onset of the material fatigue is delayed, by developing a plateau-like time-dependence of the material quality. We demonstrate that in this low-damage regime, the changes in the conductance and similar transport/response properties of the material can be used as measures of the material quality degradation."
"A self-healing tactile sensor using an optical waveguide","https://arxiv.org/abs/2411.05159v1","2024","Preprint","","Seiichi Yamamoto
Hiroki Ishizuka
Sei Ikeda
Osamu Oshiro","","https://arxiv.org/pdf/2411.05159v1","Yes","We propose an optical tactile sensor using self-healing materials. The proposed tactile sensor consists of a structure that includes a diode, a phototransistor, and an optical waveguide made from self-healing materials. This design offers the advantage of being less susceptible to electromagnetic noise compared to traditional tactile sensors based on electrical detection principles. The sensor estimates the applied force by detecting changes in the total internal reflection caused by deformation due to contact force. In this study, we first established a fabrication method for the optical waveguide-based tactile sensor using self-healing materials. Subsequently, we measured the sensor output when a static load was applied to the fabricated tactile sensor and evaluated its characteristics. The results confirmed that the sensor output decreases in response to the applied load."
"Angular-spectrum-based analysis on the self-healing effect of Laguerre-Gaussian beams after an obstacle","https://arxiv.org/abs/1906.08474v1","2019","Preprint","","Jian-Dong Zhang
Zi-Jing Zhang
Jun-Yan Hu
Long-Zhu Cen
Yi-Fei Sun
Chen-Fei Jin
Yuan Zhao","","https://arxiv.org/pdf/1906.08474v1","Yes","Self-healing, as an exotic effect, has showed many potential applications. In this paper, we focus on the self-healing effect of Laguerre-Gaussian beams after an obstacle. By taking advantage of angular spectrum theory, we study self-healing limit of the beam against on-axis obstacle. The dependence of self-healing capability on the radius of obstacle is analyzed. Additionally, we briefly discuss the self-healing limit of the beam in an off-axis scenario. Our results indicate that field amplitude of the beam will be healed well when the obstacle is approximately on-axis without oversized radius, perhaps providing advantages for optical communication, imaging, and remote sensing systems."
"Nonadiabatic Self-Healing of Trotter Errors in Digitized Counterdiabatic Dynamics","https://arxiv.org/abs/2512.22636v1","2025","Preprint","","Mara Vizzuso
Gianluca Passarelli
Giovanni Cantele
Procolo Lucignano
Xi Chen
Koushik Paul","","https://arxiv.org/pdf/2512.22636v1","Yes","Trotter errors in digitized quantum dynamics arise from approximating time-ordered evolution under noncommuting Hamiltonian terms with a product formula. In the adiabatic regime, such errors are known to exhibit long-time self-healing [Phys. Rev. Lett. \textbf{131}, 060602 (2023)], where discretization effects are effectively suppressed. Here we show that self-healing persists at finite evolution times once nonadiabatic errors induced by finite-speed ramps are compensated. Using counterdiabatic driving to cancel diabatic transitions and isolate discretization effects, we study both noninteracting and interacting spin models and characterize the finite-time scaling with the Trotter steps and the total evolution time. In the instantaneous eigenbasis of the driven Hamiltonian, the leading digital error maps to an effective harmonic perturbation whose dominant Fourier component yields an analytic upper bound on the finite-time Trotter error and reveals the phase-cancellation mechanism underlying self-healing. Our results establish finite-time self-healing as a generic feature of digitized counterdiabatic protocols, clarify its mechanism beyond the long-time adiabatic limit, and provide practical guidance for high-fidelity state preparation on gate-based quantum processors."
"Self-Healing by Means of Runtime Execution Profiling","https://arxiv.org/abs/1203.5748v1","2012","Preprint","","Mohammad Muztaba Fuad
Debzani Deb
Jinsuk Baek","10.1109/ICCITechn.2011.6164784","https://arxiv.org/pdf/1203.5748v1","Yes","A self-healing application brings itself into a stable state after a failure put the software into an unstable state. For such self-healing software application, finding fix for a previously unseen fault is a grand challenge. Asking the user to provide fixes for every fault is bad for productivity, especially when the users are non-savvy in technical aspect of computing. If failure scenarios come into existence, the user wants the runtime environment to handle those situations autonomically. This paper presents a new technique of finding self-healing actions by matching a fault scenario to already established fault models. By profiling and capturing runtime parameters and execution pathWays, stable execution models are established and later are used to match with an unstable execution scenario. Experimentation and results are presented that showed that even with additional overheads; this technique can prove beneficial for autonomically healing faults and reliving system administrators from mundane troubleshooting situations."
"Inducing mechanical self-healing in glassy polymer melts","https://arxiv.org/abs/2404.11787v1","2024","Preprint","","José Ruiz-Franco
Andrea Giuntoli","","https://arxiv.org/pdf/2404.11787v1","Yes","Glassy polymer melts such as the plastics used in pipes, structural materials, and medical devices are ubiquitous in daily life. They accumulate damage over time due to their use, which limits their functionalities and demands periodic replacement. The resulting economic and social burden could be mitigated by the design of self-healing mechanisms that expand the lifespan of materials. However, the characteristic low molecular mobility in glassy polymer melts intrinsically limits the design of self-healing behavior. We demonstrate through numerical simulations that controlled oscillatory deformations enhance the local molecular mobility of glassy polymers without compromising their structural or mechanical stability. We apply this principle to increase the molecular mobility around the surface of a crack, inducing fracture repair and recovering the mechanical properties of the pristine material. Our findings establish a general physical mechanism of self-healing in glasses that may inspire the design and processing of new glassy materials."
"KubeAdaptor: A Docking Framework for Workflow Containerization on Kubernetes","https://arxiv.org/abs/2207.01222v1","2022","Preprint","","Chenggang Shan
Guan Wang
Yuanqing Xia
Yufeng Zhan
Jinhui Zhang","","https://arxiv.org/pdf/2207.01222v1","Yes","As Kubernetes becomes the infrastructure of the cloud-native era, the integration of workflow systems with Kubernetes is gaining more and more popularity. To our knowledge, workflow systems employ scheduling algorithms that optimize task execution order of workflow to improve performance and execution efficiency. However, due to its inherent scheduling mechanism, Kubernetes does not execute containerized scheduling following the optimized task execution order of workflow amid migrating workflow systems to the Kubernetes platform. This inconsistency in task scheduling order seriously degrades the efficiency of workflow execution and brings numerous challenges to the containerized process of workflow systems on Kubernetes. In this paper, we propose a cloud-native workflow engine, also known as KubeAdaptor, a docking framework able to implement workflow containerization on Kubernetes, integrate workflow systems with Kubernetes, ensuring the consistency of task scheduling order. We introduce the design and architecture of the KubeAdaptor, elaborate on the functionality implementation and the event-trigger mechanism within the KubeAdaptor. Experimental results about four real-world workflows show that the KubeAdaptor ensures the consistency of the workflow systems and Kubernetes in the task scheduling order. Compared with the baseline Argo workflow engine, the KubeAdaptor achieves better performance in terms of the average execution time of task pod, average workflow lifecycle, and resource usage rate."
"Insights from the Usage of the Ansible Lightspeed Code Completion Service","https://arxiv.org/abs/2402.17442v4","2024","Preprint","","Priyam Sahoo
Saurabh Pujar
Ganesh Nalawade
Richard Gebhardt
Louis Mandel
Luca Buratti","","https://arxiv.org/pdf/2402.17442v4","Yes","The availability of Large Language Models (LLMs) which can generate code, has made it possible to create tools that improve developer productivity. Integrated development environments or IDEs which developers use to write software are often used as an interface to interact with LLMs. Although many such tools have been released, almost all of them focus on general-purpose programming languages. Domain-specific languages, such as those crucial for Information Technology (IT) automation, have not received much attention. Ansible is one such YAML-based IT automation-specific language. Ansible Lightspeed is an LLM-based service designed explicitly to generate Ansible YAML, given natural language prompt. In this paper, we present the design and implementation of the Ansible Lightspeed service. We then evaluate its utility to developers using diverse indicators, including extended utilization, analysis of user edited suggestions, as well as user sentiments analysis. The evaluation is based on data collected for 10,696 real users including 3,910 returning users. The code for Ansible Lightspeed service and the analysis framework is made available for others to use. To our knowledge, our study is the first to involve thousands of users of code assistants for domain-specific languages. We are also the first code completion tool to present N-Day user retention figures, which is 13.66% on Day 30. We propose an improved version of user acceptance rate, called Strong Acceptance rate, where a suggestion is considered accepted only if less than 50% of it is edited and these edits do not change critical parts of the suggestion. By focusing on Ansible, Lightspeed is able to achieve a strong acceptance rate of 49.08% for multi-line Ansible task suggestions. With our findings we provide insights into the effectiveness of small, dedicated models in a domain-specific context."
"Three-dimensional evolution of erupted flux ropes from the Sun (2-20 Rs) to 1 AU","https://arxiv.org/abs/1211.2108v2","2012","Preprint","","A. Isavnin
A. Vourlidas
E. K. J. Kilpua","10.1007/s11207-012-0214-3","https://arxiv.org/pdf/1211.2108v2","Yes","Studying the evolution of magnetic clouds entrained in coronal mass ejections using in-situ data is a difficult task since only a limited number of observational points is available at large heliocentric distances. Remote sensing observations can, however, provide important information for events close to the Sun. In this work we estimate the flux rope orientation first in the close vicinity of the Sun (2-20 Rs) using forward modeling of STEREO/SECCHI and SOHO/LASCO coronagraph images of coronal mass ejections and then in-situ using Grad-Shafranov reconstruction of the magnetic cloud. Thus, we are able to measure changes in the orientation of the erupted flux ropes as they propagate from the Sun to 1 AU. We present both techniques and use them to study 15 magnetic clouds observed during the minimum following Solar Cycle 23 and the rise of Solar Cycle 24. This is the first multievent study to compare the three-dimensional parameters of CMEs from imaging and in-situ reconstructions. The results of our analysis confirm earlier studies showing that the flux ropes tend to deflect towards the solar equatorial plane. We also find evidence of rotation on their travel from the Sun to 1 AU. In contrast to past studies, our method allows one to deduce the evolution of the three-dimensional orientation of individual flux ropes rather than on a statistical basis."
"Security Smells in Ansible and Chef Scripts: A Replication Study","https://arxiv.org/abs/1907.07159v2","2019","Preprint","","Akond Rahman
Md. Rayhanur Rahman
Chris Parnin
Laurie Williams","","https://arxiv.org/pdf/1907.07159v2","Yes","Context: Security smells are recurring coding patterns that are indicative of security weakness, and require further inspection. As infrastructure as code (IaC) scripts, such as Ansible and Chef scripts, are used to provision cloud-based servers and systems at scale, security smells in IaC scripts could be used to enable malicious users to exploit vulnerabilities in the provisioned systems. Goal: The goal of this paper is to help practitioners avoid insecure coding practices while developing infrastructure as code scripts through an empirical study of security smells in Ansible and Chef scripts. Methodology: We conduct a replication study where we apply qualitative analysis with 1,956 IaC scripts to identify security smells for IaC scripts written in two languages: Ansible and Chef. We construct a static analysis tool called Security Linter for Ansible and Chef scripts (SLAC) to automatically identify security smells in 50,323 scripts collected from 813 open source software repositories. We also submit bug reports for 1,000 randomly-selected smell occurrences. Results: We identify two security smells not reported in prior work: missing default in case statement and no integrity check. By applying SLAC we identify 46,600 occurrences of security smells that include 7,849 hard-coded passwords. We observe agreement for 65 of the responded 94 bug reports, which suggests the relevance of security smells for Ansible and Chef scripts amongst practitioners. Conclusion: We observe security smells to be prevalent in Ansible and Chef scripts, similar to that of the Puppet scripts. We recommend practitioners to rigorously inspect the presence of the identified security smells in Ansible and Chef scripts using (i) code review, and (ii) static analysis tools."
"Performance Evaluation of Intent-Based Networking Scenarios: A GitOps and Nephio Approach","https://arxiv.org/abs/2509.13901v1","2025","Preprint","","Saptarshi Ghosh
Ioannis Mavromatis
Konstantinos Antonakoglou
Konstantinos Katsaros","","https://arxiv.org/pdf/2509.13901v1","Yes","GitOps has emerged as a foundational paradigm for managing cloud-native infrastructures by enabling declarative configuration, version-controlled state, and automated reconciliation between intents and runtime deployments. Despite its widespread adoption, the performance and scalability of GitOps tools in Intent-Based Networking (IBN) scenarios are insufficiently evaluated. This paper presents a reproducible, metric-driven benchmarking, assessing the latency and resource overheads of three widely used GitOps operators: Argo CD, Flux CD, and ConfigSync. We conduct controlled experiments under both single- and multi-intent scenarios, capturing key performance indicators such as latency and resource consumption. Our results highlight trade-offs between the tools in terms of determinism, resource efficiency, and responsiveness. We further investigate a realistic orchestration scenario, using Nephio as our orchestrator, to quantify the processing latency and overhead in declarative end-to-end deployment pipelines. Our findings can offer valuable insights for tool selection and optimisation in future autonomous network orchestration systems."
"Accelerating Control Systems with GitOps: A Path to Automation and Reliability","https://arxiv.org/abs/2511.05663v1","2025","Preprint","","M. Gonzalez
M. Acosta","","https://arxiv.org/pdf/2511.05663v1","Yes","GitOps is a foundational approach for modernizing infrastructure by leveraging Git as the single source of truth for declarative configurations. The poster explores how GitOps transforms traditional control system infrastructure, services and applications by enabling fully automated, auditable, and version-controlled infrastructure management. Cloud-native and containerized environments are shifting the ecosystem not only in the IT industry but also within the computational science field, as is the case of CERN [1] and Diamond Light Source [2] among other Accelerator/Science facilities which are slowly shifting towards modern software and infrastructure paradigms. The ACORN project, which aims to modernize Fermilab's control system infrastructure and software is implementing proven best-practices and cutting-edge technology standards including GitOps, containerization, infrastructure as code and modern data pipelines for control system data acquisition and the inclusion of AI/ML in our accelerator complex."
"Dozer: Migrating Shell Commands to Ansible Modules via Execution Profiling and Synthesis","https://arxiv.org/abs/2203.12065v1","2022","Preprint","","Eric Horton
Chris Parnin","","https://arxiv.org/pdf/2203.12065v1","Yes","Software developers frequently use the system shell to perform configuration management tasks. Unfortunately, the shell does not scale well to large systems, and configuration management tools like Ansible are more difficult to learn. We address this problem with Dozer, a technique to help developers push their shell commands into Ansible task definitions. It operates by tracing and comparing system calls to find Ansible modules with similar behaviors to shell commands, then generating and validating migrations to find the task which produces the most similar changes to the system. Dozer is syntax agnostic, which should allow it to generalize to other configuration management platforms. We evaluate Dozer using datasets from open source configuration scripts."
"The Ultimate Configuration Management Tool? Lessons from a Mixed Methods Study of Ansible's Challenges","https://arxiv.org/abs/2504.08678v3","2025","Preprint","","Carolina Carreira
Nuno Saavedra
Alexandra Mendes
João F. Ferreira","","https://arxiv.org/pdf/2504.08678v3","Yes","Infrastructure as Code (IaC) tools have transformed the way IT infrastructure is automated and managed, but their growing adoption has also exposed numerous challenges for practitioners. In this paper, we investigate these challenges through the lens of Ansible, a popular IaC tool. Using a mixed methods approach, we investigate challenges faced by practitioners. We analyze 59,157 posts from Stack Overflow, Reddit, and the Ansible Forum to identify common pain points, complemented by 20 semi-structured interviews with practitioners of varying expertise levels. Based on our findings, we highlight key directions for improving Ansible, with implications for other IaC technologies, including stronger failure locality to support debugging, clearer separation of language and templating boundaries, targeted documentation, and improved execution backends to address performance issues. By grounding these insights in the real-world struggles of Ansible users, this study provides actionable guidance for tool designers and for the broader IaC community, and contributes to a deeper understanding of the trade-offs inherent in IaC tools."
"Noise-Resistant Quantum Teleportation, Ansibles, and the No-Projector Theorem","https://arxiv.org/abs/1605.09233v1","2016","Preprint","","Samuel R. Hedemann","","https://arxiv.org/pdf/1605.09233v1","Yes","A method is presented for achieving entanglement-free teleportation of a quantum state subject to any quantum noise. We apply this as a light-speed noise-resistant communicator, but also treat the possibility of a quantum ansible, a device for effectively superluminal communication and quantum broadcasting. The results suggest a ""no-projector theorem"" analogous to the no-cloning theorem. We then show how to build a pseudo-ansible for connection-free light-speed communication."
"Kubernetes in Action: Exploring the Performance of Kubernetes Distributions in the Cloud","https://arxiv.org/abs/2403.01429v1","2024","Preprint","","Hossein Aqasizade
Ehsan Ataie
Mostafa Bastam","","https://arxiv.org/pdf/2403.01429v1","Yes","Kubernetes has emerged as a leading open-source platform for container orchestration, allowing organizations to efficiently manage and deploy containerized applications at scale. This paper investigates the performance of four Kubernetes distributions, namely Kubeadm, K3s, MicroK8s, and K0s when running OpenFaaS as a containerized service on a cluster of computing nodes on CloudLab. For this purpose, experiments are conducted to examine the performance of two virtualization modes, namely HVM and PV, supported by Xen as the underlying hypervisor. Moreover, two container runtimes that are integrated with Kubernetes, namely Docker, and Containerd, are examined to assess their performance on both disk-intensive and CPU-intensive workloads. After determining the appropriate underlying Xen mode and container runtime, the Kubernetes distributions are set up and their performance is measured using various metrics, such as request rate, CPU utilization, and scaling behavior."
"Configuration Defects in Kubernetes","https://arxiv.org/abs/2512.05062v2","2025","Preprint","","Yue Zhang
Uchswas Paul
Marcelo d'Amorim
Akond Rahman","","https://arxiv.org/pdf/2512.05062v2","Yes","Kubernetes is a tool that facilitates rapid deployment of software. Unfortunately, configuring Kubernetes is prone to errors. Configuration defects are not uncommon and can result in serious consequences. This paper reports an empirical study about configuration defects in Kubernetes with the goal of helping practitioners detect and prevent these defects. We study 719 defects that we extract from 2,260 Kubernetes configuration scripts using open source repositories. Using qualitative analysis, we identify 15 categories of defects. We find 8 publicly available static analysis tools to be capable of detecting 8 of the 15 defect categories. We find that the highest precision and recall of those tools are for defects related to data fields. We develop a linter to detect two categories of defects that cause serious consequences, which none of the studied tools are able to detect. Our linter revealed 26 previously-unknown defects that have been confirmed by practitioners, 19 of which have already been fixed. We conclude our paper by providing recommendations on how defect detection and repair techniques can be used for Kubernetes configuration scripts. The datasets and source code used for the paper are publicly available online."
"Kubernetes Deployment Options for On-Prem Clusters","https://arxiv.org/abs/2407.01620v1","2024","Preprint","","Lincoln Bryant
Robert W. Gardner
Fengping Hu
David Jordan
Ryan P. Taylor","","https://arxiv.org/pdf/2407.01620v1","Yes","Over the last decade, the Kubernetes container orchestration platform has become essential to many scientific workflows. Despite its popularity, deploying a production-ready Kubernetes cluster on-premises can be challenging for system administrators. Many of the proprietary integrations that application developers take for granted in commercial cloud environments must be replaced with alternatives when deployed locally. This article will compare three popular deployment strategies for sites deploying Kubernetes on-premise: Kubeadm with Kubespray, OpenShift / OKD and Rancher via K3S/RKE2."
"Kubernetes as an Availability Manager for Microservice Applications","https://arxiv.org/abs/1901.04946v1","2019","Preprint","","Leila Abdollahi Vayghan
Mohamed Aymen Saied
Maria Toeroe
Ferhat Khendek","","https://arxiv.org/pdf/1901.04946v1","Yes","The move towards the microservice based architecture is well underway. In this architectural style, small and loosely coupled modules are developed, deployed, and scaled independently to compose cloud-native applications. However, for carrier-grade service providers to migrate to the microservices architectural style, availability remains a concern. Kubernetes is an open source platform that defines a set of building blocks which collectively provide mechanisms for deploying, maintaining, scaling, and healing containerized microservices. Thus, Kubernetes hides the complexity of microservice orchestration while managing their availability. In a preliminary work we evaluated Kubernetes, using its default configuration, from the availability perspective in a private cloud settings. In this paper, we investigate more architectures and conduct more experiments to evaluate the availability that Kubernetes delivers for its managed microservices. We present different architectures for public and private clouds. We evaluate the availability achievable through the healing capability of Kubernetes. We investigate the impact of adding redundancy on the availability of microservice based applications. We conduct experiments under the default configuration of Kubernetes as well as under its most responsive one. We also perform a comparative evaluation with the Availability Management Framework (AMF), which is a proven solution as a middleware service for managing high-availability. The results of our investigations show that in certain cases, the service outage for applications managed with Kubernetes is significantly high."
"P4Kube: In-Network Load Balancer for Kubernetes","https://arxiv.org/abs/2505.05996v1","2025","Preprint","","Garegin Grigoryan
Kevin Penkowski
Minseok Kwon","10.1109/CCNC54725.2025.10976037","https://arxiv.org/pdf/2505.05996v1","Yes","Kubernetes Services such as LoadBalancer and NodePort expose applications running on pods within a Kubernetes cluster to external users. While the LoadBalancer Service requires an external load-balancing middleware, its alternative, NodePort Service, adds additional hops on the path between clients and the worker nodes. In this paper, we propose P4Kube, a framework consisting of a P4 data plane program and a Kubernetes plugin. Our solution effectively performs load balancing of requests to the worker nodes of a cluster based on the number of running replicas. In P4Kube, the data packets completely bypass the system's control plane. Unlike the previous work, to update its state, the P4Kube data plane works directly with the Kubernetes control plane without any involvement of the network control plane. Our experiments show up to 50% improvement in the average request time to the cluster compared to conventional approaches."
"Characterising resource management performance in Kubernetes","https://arxiv.org/abs/2401.17125v1","2024","Preprint","","Víctor Medel
Rafael Tolosana-Calasanz
José Ángel Bañares
Unai Arronategui
Omer F. Rana","10.1016/j.compeleceng.2018.03.041","https://arxiv.org/pdf/2401.17125v1","Yes","A key challenge for supporting elastic behaviour in cloud systems is to achieve a good performance in automated (de-)provisioning and scheduling of computing resources. One of the key aspects that can be significant is the overheads associated with deploying, terminating and maintaining resources. Therefore, due to their lower start up and termination overhead, containers are rapidly replacing Virtual Machines (VMs) in many cloud deployments, as the computation instance of choice. In this paper, we analyse the performance of Kubernetes achieved through a Petri net-based performance model. Kubernetes is a container management system for a distributed cluster environment. Our model can be characterised using data from a Kubernetes deployment, and can be exploited for supporting capacity planning and designing Kubernetes-based elastic applications."
"Comparison of high-energy galactic and atmospheric tau neutrino flux","https://arxiv.org/abs/hep-ph/0112222v2","2001","Preprint","","H. Athar
Kingman Cheung
Guey-Lin Lin
Jie-Jun Tseng","10.1016/S0927-6505(02)00183-4","https://arxiv.org/pdf/hep-ph/0112222v2","Yes","We compare the tau neutrino flux arising from the galaxy and the earth atmosphere for 10^3 < E/GeV < 10^11. The intrinsic and oscillated tau neutrino fluxes from both sources are calculated. The intrinsic galactic ν_τ flux (E > 10^3 GeV) is calculated by considering the interactions of high-energy cosmic-rays with the matter present in our galaxy, whereas the oscillated galactic ν_τ flux is coming from the oscillation of the galactic ν_μ flux. For the intrinsic atmospheric ν_τ flux, we extend the validity of a previous calculation from E < 10^6 GeV up to E < 10^11 GeV. The oscillated atmospheric ν_τ flux is, on the other hand, rather suppressed. We find that, for 10^3 < E/GeV < 5\cdot 10^7, the oscillated ν_τ flux along the galactic plane dominates over the maximal intrinsic atmospheric ν_τ flux, i.e., the flux along the horizontal direction. We also briefly mention the presently envisaged prospects for observing these high-energy tau neutrinos."
"Benefits, Challenges, and Research Topics: A Multi-vocal Literature Review of Kubernetes","https://arxiv.org/abs/2211.07032v1","2022","Preprint","","Shazibul Islam Shamim
Jonathan Alexander Gibson
Patrick Morrison
Akond Rahman","","https://arxiv.org/pdf/2211.07032v1","Yes","Context: Kubernetes is an open source software that helps in automated deployment of software and orchestration of containers. With Kubernetes, IT organizations, such as IBM, Pinterest, and Spotify have experienced an increase in release frequency. Objective: The goal of this paper is to inform practitioners and researchers on benefits and challenges of Kubernetes usage by conducting a multi-vocal literature review of Kubernetes. Methodology: We conduct a multi-vocal literature review (MLR) where we use 321 Kubernetes-related Internet artifacts to identify benefits and challenges perceived by practitioners. In our MLR, we also analyze 105 peer-reviewed publications to identify the research topics addressed by the research community. Findings: We find 8 benefits that include service level objective (SLO)-based scalability and self-healing containers. Our identified 15 challenges related to Kubernetes include unavailability of diagnostics and security tools and attack surface reduction. We observe researchers to address 14 research topics related to Kubernetes, which includes efficient resource utilization. We also identify 9 challenges that are under-explored in research publications, which include cultural change, hardware compatibility, learning curve, maintenance, and testing."
"Migration of CMSWEB Cluster at CERN to Kubernetes","https://arxiv.org/abs/2102.12751v1","2021","Preprint","","Muhammad Imran
Valentin Kuznetsov
Lina Marcella
Katarzyna Maria Dziedziniewicz-Wojcik
Andreas Pfeiffer
Panos Paparrigopoulos","10.22323/1.390.0911","https://arxiv.org/pdf/2102.12751v1","Yes","The CMS experiment heavily relies on the CMSWEB cluster to host critical services for its operational needs. The cluster is deployed on virtual machines (VMs) from the CERN OpenStack cloud and is manually maintained by operators and developers. The release cycle is composed of several steps, from building RPMs, their deployment to perform validation, and integration tests. To enhance the sustainability of the CMSWEB cluster, CMS decided to migrate its cluster to a containerized solution such as Docker, orchestrated with Kubernetes (k8s). This allows us to significantly reduce the release upgrade cycle, follow the end-to-end deployment procedure, and reduce operational cost. This paper gives an overview of the current CMSWEB cluster and its issues. We describe the new architecture of the CMSWEB cluster in Kubernetes. We also provide a comparison of VM and Kubernetes deployment approaches and report on lessons learned during the migration process."
"A study of the link between cosmic rays and clouds with a cloud chamber at the CERN PS","https://arxiv.org/abs/physics/0104048v1","2001","Preprint","","The Cloud Collaboration","","https://arxiv.org/pdf/physics/0104048v1","Yes","Recent satellite data have revealed a surprising correlation between galactic cosmic ray (GCR) intensity and the fraction of the Earth covered by clouds. If this correlation were to be established by a causal mechanism, it could provide a crucial step in understanding the long-sought mechanism connecting solar and climate variability. The Earth's climate seems to be remarkably sensitive to solar activity, but variations of the Sun's electromagnetic radiation appear to be too small to account for the observed climate variability. However, since the GCR intensity is strongly modulated by the solar wind, a GCR-cloud link may provide a sufficient amplifying mechanism. Moreover if this connection were to be confirmed, it could have profound consequences for our understanding of the solar contributions to the current global warming. The CLOUD (Cosmics Leaving OUtdoor Droplets) project proposes to test experimentally the existence a link between cosmic rays and cloud formation, and to understand the microphysical mechanism. CLOUD plans to perform detailed laboratory measurements in a particle beam at CERN, where all the parameters can be precisely controlled and measured. The beam will pass through an expansion cloud chamber and a reactor chamber where the atmosphere is to be duplicated by moist air charged with selected aerosols and trace condensable vapours. An array of external detectors and mass spectrometers is used to analyse the physical and chemical characteristics of the aerosols and trace gases during beam exposure. Where beam effects are found, the experiment will seek to evaluate their significance in the atmosphere by incorporating them into aerosol and cloud models."
"CLOUD: an atmospheric research facility at CERN","https://arxiv.org/abs/physics/0104076v1","2001","Preprint","","The Cloud Collaboration","","https://arxiv.org/pdf/physics/0104076v1","Yes","This report is the second of two addenda to the CLOUD proposal at CERN (physics/0104048), which aims to test experimentally the existence a link between cosmic rays and cloud formation, and to understand the microphysical mechanism. The document places CLOUD in the framework of a CERN facility for atmospheric research, and provides further details on the particle beam requirements."
"Addendum to the CLOUD proposal","https://arxiv.org/abs/physics/0104068v1","2001","Preprint","","The Cloud Collaboration","","https://arxiv.org/pdf/physics/0104068v1","Yes","This report is the first of two addenda to the CLOUD proposal at CERN (physics/0104048), which aims to test experimentally the existence a link between cosmic rays and cloud formation, and to understand the microphysical mechanism. The document provides further details on the detector design, scientific motivation and experimental programme."
"Supporting Multi-Cloud in Serverless Computing","https://arxiv.org/abs/2209.09367v4","2022","Preprint","","Haidong Zhao
Zakaria Benomar
Tobias Pfandzelter
Nikolaos Georgantas","10.1109/UCC56403.2022.00051","https://arxiv.org/pdf/2209.09367v4","Yes","Serverless computing is a widely adopted cloud execution model composed of Function-as-a-Service (FaaS) and Backend-as-a-Service (BaaS) offerings. The increased level of abstraction makes vendor lock-in inherent to serverless computing, raising more concerns than previous cloud paradigms. Multi-cloud serverless is a promising emerging approach against vendor lock-in, yet multiple challenges must be overcome to tap its potential. First, we need to be aware of both the performance and cost of each FaaS provider. Second, a multi-cloud architecture must be proposed before deploying a multi-cloud workflow. Domain-specific serverless offerings must then be integrated into the multi-cloud architecture to improve performance or save costs. Moreover, dealing with serverless offerings from multiple providers is challenging. Finally, we require workload portability support for serverless multi-cloud. In this paper, we present a multi-cloud library for cross-serverless offerings. We develop the End Analysis System (EAS) to support comparison among public FaaS providers in terms of performance and cost. Moreover, we design proof-of-concept multi-cloud architectures with domain-specific serverless offerings to alleviate problems such as data gravity. Finally, we deploy workloads on these architectures to evaluate several public FaaS offerings."
"Multi-agent Reinforcement Learning-based In-place Scaling Engine for Edge-cloud Systems","https://arxiv.org/abs/2507.07671v1","2025","Preprint","","Jovan Prodanov
Blaž Bertalanič
Carolina Fortuna
Shih-Kai Chou
Matjaž Branko Jurič
Ramon Sanchez-Iborra
Jernej Hribar","10.1109/CLOUD67622.2025.00014","https://arxiv.org/pdf/2507.07671v1","Yes","Modern edge-cloud systems face challenges in efficiently scaling resources to handle dynamic and unpredictable workloads. Traditional scaling approaches typically rely on static thresholds and predefined rules, which are often inadequate for optimizing resource utilization and maintaining performance in distributed and dynamic environments. This inefficiency hinders the adaptability and performance required in edge-cloud infrastructures, which can only be achieved through the newly proposed in-place scaling. To address this problem, we propose the Multi-Agent Reinforcement Learning-based In-place Scaling Engine (MARLISE) that enables seamless, dynamic, reactive control with in-place resource scaling. We develop our solution using two Deep Reinforcement Learning algorithms: Deep Q-Network (DQN), and Proximal Policy Optimization (PPO). We analyze each version of the proposed MARLISE solution using dynamic workloads, demonstrating their ability to ensure low response times of microservices and scalability. Our results show that MARLISE-based approaches outperform heuristic method in managing resource elasticity while maintaining microservice response times and achieving higher resource efficiency."
"Modeling Operational Fairness of Hybrid Cloud Brokerage","https://arxiv.org/abs/2205.05078v1","2022","Preprint","","Sreekrishnan Venkateswaran
Santonu Sarkar","10.1109/CCGRID.2018.00083","https://arxiv.org/pdf/2205.05078v1","Yes","Cloud service brokerage is an emerging technology that attempts to simplify the consumption and operation of hybrid clouds. Today's cloud brokers attempt to insulate consumers from the vagaries of multiple clouds. To achieve the insulation, the modern cloud broker needs to disguise itself as the end-provider to consumers by creating and operating a virtual data center construct that we call a meta-cloud, which is assembled on top of a set of participating supplier clouds. It is crucial for such a cloud broker to be considered a trusted partner both by cloud consumers and by the underpinning cloud suppliers. A fundamental tenet of brokerage trust is vendor neutrality. On the one hand, cloud consumers will be comfortable if a cloud broker guarantees that they will not be led through a preferred path. And on the other hand, cloud suppliers would be more interested in partnering with a cloud broker who promises a fair apportioning of client provisioning requests. Because consumer and supplier trust on a meta-cloud broker stems from the assumption of being agnostic to supplier clouds, there is a need for a test strategy that verifies the fairness of cloud brokerage. In this paper, we propose a calculus of fairness that defines the rules to determine the operational behavior of a cloud broker. The calculus uses temporal logic to model the fact that fairness is a trait that has to be ascertained over time; it is not a characteristic that can be judged at a per-request fulfillment level. Using our temporal calculus of fairness as the basis, we propose an algorithm to determine the fairness of a broker probabilistically, based on its observed request apportioning policies. Our model for the fairness of cloud broker behavior also factors in inter-provider variables such as cost divergence and capacity variance."
"An Open API Architecture to Discover the Trustworthy Explanation of Cloud AI Services","https://arxiv.org/abs/2411.03376v1","2024","Preprint","","Zerui Wang
Yan Liu
Jun Huang","10.1109/TCC.2024.3398609","https://arxiv.org/pdf/2411.03376v1","Yes","This article presents the design of an open-API-based explainable AI (XAI) service to provide feature contribution explanations for cloud AI services. Cloud AI services are widely used to develop domain-specific applications with precise learning metrics. However, the underlying cloud AI services remain opaque on how the model produces the prediction. We argue that XAI operations are accessible as open APIs to enable the consolidation of the XAI operations into the cloud AI services assessment. We propose a design using a microservice architecture that offers feature contribution explanations for cloud AI services without unfolding the network structure of the cloud models. We can also utilize this architecture to evaluate the model performance and XAI consistency metrics showing cloud AI services trustworthiness. We collect provenance data from operational pipelines to enable reproducibility within the XAI service. Furthermore, we present the discovery scenarios for the experimental tests regarding model performance and XAI consistency metrics for the leading cloud vision AI services. The results confirm that the architecture, based on open APIs, is cloud-agnostic. Additionally, data augmentations result in measurable improvements in XAI consistency metrics for cloud AI services."
"A U-band survey of brown dwarfs in the Taurus Molecular Cloud with the XMM-Newton Optical/UV Monitor","https://arxiv.org/abs/astro-ph/0609027v1","2006","Preprint","","Nicolas Grosso
Marc Audard
Jérôme Bouvier
Kevin R. Briggs
Manuel Güdel
the The XMM-Newton Extended Surveyof the Taurus Molecular Cloud
Collaboration","10.1051/0004-6361:20065425","https://arxiv.org/pdf/astro-ph/0609027v1","Yes","We aim to characterize the U-band variability of young brown dwarfs in the Taurus Molecular Cloud and discuss its origin. We used the XMM-Newton Extended Survey of the Taurus Molecular Cloud, where a sample of 11 young bona fide brown dwarfs (spectral type later than M6) were observed simultaneously in X-rays with XMM-Newton and in the U-band with the XMM-Newton Optical/UV Monitor (OM). We obtained upper limits to the U-band emission of 10 brown dwarfs (U>19.6-20.6 mag), whereas 2MASSJ04141188+2811535 was detected in the U-band. Remarkably, the magnitude of this brown dwarf increased regularly from U~19.5 mag at the beginning of the observation, peaked 6h later at U~18.4 mag, and then decreased to U~18.65 mag in the next 2h. The first OM U-band measurement is consistent with the quiescent level observed about one year later thanks to ground follow-up observations. This brown dwarf was not detected in X-rays by XMM-Newton during the OM observation. We discuss the possible sources of U-band variability for this young brown dwarf, namely a magnetic flare, non-steady accretion onto the substellar surface, and rotational modulation of a hot spot. We conclude that this event is related to accretion from a circumsubstellar disk, where the mass accretion rate was about a factor of 3 higher than during the quiescent level."
"Search-based Methods for Multi-Cloud Configuration","https://arxiv.org/abs/2204.09437v1","2022","Preprint","","Małgorzata Łazuka
Thomas Parnell
Andreea Anghel
Haralampos Pozidis","","https://arxiv.org/pdf/2204.09437v1","Yes","Multi-cloud computing has become increasingly popular with enterprises looking to avoid vendor lock-in. While most cloud providers offer similar functionality, they may differ significantly in terms of performance and/or cost. A customer looking to benefit from such differences will naturally want to solve the multi-cloud configuration problem: given a workload, which cloud provider should be chosen and how should its nodes be configured in order to minimize runtime or cost? In this work, we consider solutions to this optimization problem. We develop and evaluate possible adaptations of state-of-the-art cloud configuration solutions to the multi-cloud domain. Furthermore, we identify an analogy between multi-cloud configuration and the selection-configuration problems commonly studied in the automated machine learning (AutoML) field. Inspired by this connection, we utilize popular optimizers from AutoML to solve multi-cloud configuration. Finally, we propose a new algorithm for solving multi-cloud configuration, CloudBandit (CB). It treats the outer problem of cloud provider selection as a best-arm identification problem, in which each arm pull corresponds to running an arbitrary black-box optimizer on the inner problem of node configuration. Our experiments indicate that (a) many state-of-the-art cloud configuration solutions can be adapted to multi-cloud, with best results obtained for adaptations which utilize the hierarchical structure of the multi-cloud configuration domain, (b) hierarchical methods from AutoML can be used for the multi-cloud configuration task and can outperform state-of-the-art cloud configuration solutions and (c) CB achieves competitive or lower regret relative to other tested algorithms, whilst also identifying configurations that have 65% lower median cost and 20% lower median time in production, compared to choosing a random provider and configuration."
"Identity and Access Management Framework for Multi-tenant Resources in Hybrid Cloud Computing","https://arxiv.org/abs/2203.11463v1","2022","Preprint","","Saurabh Deochake
Vrushali Channapattan","","https://arxiv.org/pdf/2203.11463v1","Yes","While more organizations have been trying to move their infrastructure to the cloud in recent years, there have been significant challenges in how identities and access are managed in a hybrid cloud setting. This paper showcases a novel identity and access management framework for shared resources in a multi-tenant hybrid cloud environment. The paper demonstrates a method to implement the ""mirror"" identities of on-premise identities in the cloud. Following the best security practices, the framework ensures that only rightful users can use their mirror identities in the cloud. Furthermore, the paper also proposes a technique in scaling the framework to accommodate large-scale enterprises. The framework exhibited in the paper provides a comprehensive and scalable solution for enterprises to implement identity and access control in their hybrid cloud infrastructure. Although the paper focuses on implementing the framework in Google Cloud Platform, it can be easily applied to any major public cloud platform."
"Joint Orchestration of Cloud-Based Microservices and Virtual Network Functions","https://arxiv.org/abs/1801.09984v1","2018","Preprint","","Hadi Razzaghi Kouchaksaraei
Holger Karl","","https://arxiv.org/pdf/1801.09984v1","Yes","Recent studies show the increasing popularity of distributed cloud applications, which are composed of multiple microservices. Besides their known benefits, microservice architecture also enables to mix and match cloud applications and Network Function Virtualization (NFV) services (service chains), which are composed of Virtual Network Functions (VNFs). Provisioning complex services containing VNFs and microservices in a combined NFV/cloud platform can enhance service quality and optimise cost. Such a platform can be based on the multi-cloud concept. However, current multi-cloud solutions do not support NFV requirements, making them inadequate to support complex services. In this paper, we investigate these challenges and propose a solution for jointly managing and orchestrating microservices and virtual network functions."
"Orchestration in the Cloud-to-Things Compute Continuum: Taxonomy, Survey and Future Directions","https://arxiv.org/abs/2309.02172v1","2023","Preprint","","Amjad Ullah
Tamas Kiss
József Kovács
Francesco Tusa
James Deslauriers
Huseyin Dagdeviren
Resmi Arjun
Hamed Hamzeh","","https://arxiv.org/pdf/2309.02172v1","Yes","IoT systems are becoming an essential part of our environment. Smart cities, smart manufacturing, augmented reality, and self-driving cars are just some examples of the wide range of domains, where the applicability of such systems has been increasing rapidly. These IoT use cases often require simultaneous access to geographically distributed arrays of sensors, and heterogeneous remote, local as well as multi-cloud computational resources. This gives birth to the extended Cloud-to-Things computing paradigm. The emergence of this new paradigm raised the quintessential need to extend the orchestration requirements i.e., the automated deployment and run-time management) of applications from the centralised cloud-only environment to the entire spectrum of resources in the Cloud-to-Things continuum. In order to cope with this requirement, in the last few years, there has been a lot of attention to the development of orchestration systems in both industry and academic environments. This paper is an attempt to gather the research conducted in the orchestration for the Cloud-to-Things continuum landscape and to propose a detailed taxonomy, which is then used to critically review the landscape of existing research work. We finally discuss the key challenges that require further attention and also present a conceptual framework based on the conducted analysis."
"The Effects of Relative Importance of User Constraints in Cloud of Things Resource Discovery: A Case Study","https://arxiv.org/abs/1611.05170v1","2016","Preprint","","Luiz H. Nunes
Julio C. Estrella
Alexandre C. B. Delbem
Charith Perera
Stephan Reiff-Marganiec","","https://arxiv.org/pdf/1611.05170v1","Yes","Over the last few years, the number of smart objects connected to the Internet has grown exponentially in comparison to the number of services and applications. The integration between Cloud Computing and Internet of Things, named as Cloud of Things, plays a key role in managing the connected things, their data and services. One of the main challenges in Cloud of Things is the resource discovery of the smart objects and their reuse in different contexts. Most of the existent work uses some kind of multi-criteria decision analysis algorithm to perform the resource discovery, but do not evaluate the impact that the user constraints has in the final solution. In this paper, we analyse the behaviour of the SAW, TOPSIS and VIKOR multi-objective decision analyses algorithms and the impact of user constraints on them. We evaluated the quality of the proposed solutions using the Pareto-optimality concept."
"Performance Analysis of Zero-Trust multi-cloud","https://arxiv.org/abs/2105.02334v1","2021","Preprint","","Simone Rodigari
Donna O'Shea
Pat McCarthy
Martin McCarry
Sean McSweeney","","https://arxiv.org/pdf/2105.02334v1","Yes","Zero Trust security model permits to secure cloud native applications while encrypting all network communication, authenticating, and authorizing every request. The service mesh can enable Zero Trust using a side-car proxy without changes to the application code. To the best of our knowledge, no previous work has provided a performance analysis of Zero Trust in a multi-cloud environment. This paper proposes a multi-cloud framework and a testing workflow to analyze performance of the data plane under load and the impact on the control plane, when Zero Trust is enabled. The results of preliminary tests show that Istio has reduced latency variability in responding to sequential HTTP requests. Results also reveal that the overall CPU and memory usage can increase based on service mesh configuration and the cloud environment."
"Data Privacy in Multi-Cloud: An Enhanced Data Fragmentation Framework","https://arxiv.org/abs/2211.11577v1","2022","Preprint","","Randolph Loh
Vrizlynn L. L. Thing","10.1109/PST52912.2021.9647746","https://arxiv.org/pdf/2211.11577v1","Yes","Data splitting preserves privacy by partitioning data into various fragments to be stored remotely and shared. It supports most data operations because data can be stored in clear as opposed to methods that rely on cryptography. However, majority of existing data splitting techniques do not consider data already in the multi-cloud. This leads to unnecessary use of resources to re-split data into fragments. This work proposes a data splitting framework that leverages on existing data in the multi-cloud. It improves data splitting mechanisms by reducing the number of splitting operations and resulting fragments. Therefore, decreasing the number of storage locations a data owner manages. Broadcasts queries locate third-party data fragments to avoid costly operations when splitting data. This work examines considerations for the use of third-party fragments and application to existing data splitting techniques. The proposed framework was also applied to an existing data splitting mechanism to complement its capabilities."
"Framework for cloud computing adoption: A road map for Smes to cloud migration","https://arxiv.org/abs/1601.01608v1","2016","Preprint","","Nabeel Khan
Adil Al-Yasiri","10.5121/ijccsa.2015.5601","https://arxiv.org/pdf/1601.01608v1","Yes","Small and Medium size Enterprises (SME) are considered as a backbone of many developing and developed economies of the world; they are the driving force to any major economy across the globe. Through Cloud Computing firms outsource their entire information technology (IT) process while concentrating more on their core business. It allows businesses to cut down heavy cost incurred over IT infrastructure without losing focus on customer needs. However, Cloud industry to an extent has struggled to grow among SMEs due to the reluctance and concerns expressed by them. Throughout the course of this study several interviews were conducted and the literature was reviewed to understand how cloud providers offer services and what challenges SMEs are facing. The study identified issues like cloud knowledge, interoperability, security and contractual concerns to be hindering SMEs adoption of cloud services. From the interviews common practices followed by cloud vendors and what concerns SMEs have were identified as a basis for a cloud framework which will bridge gaps between cloud vendors and SMEs. A stepwise framework for cloud adoption is formulated which identifies and provides recommendation to four most predominant challenges which are hurting cloud industry and taking SMEs away from cloud computing, as well as guide SMEs aiding in successful cloud adoption. Moreover, this framework streamlines the cloud adoption process for SMEs by removing ambiguity in regards to fundamentals associated with their organisation and cloud adoption process."
"Handling Confidential Data on the Untrusted Cloud: An Agent-based Approach","https://arxiv.org/abs/1012.0759v1","2010","Preprint","","Ernesto Damiani
Francesco Pagano","","https://arxiv.org/pdf/1012.0759v1","Yes","Cloud computing allows shared computer and storage facilities to be used by a multitude of clients. While cloud management is centralized, the information resides in the cloud and information sharing can be implemented via off-the-shelf techniques for multiuser databases. Users, however, are very diffident for not having full control over their sensitive data. Untrusted database-as-a-server techniques are neither readily extendable to the cloud environment nor easily understandable by non-technical users. To solve this problem, we present an approach where agents share reserved data in a secure manner by the use of simple grant-and-revoke permissions on shared data."
"Cross-Layer Multi-Cloud Real-Time Application QoS Monitoring and Benchmarking As-a-Service Framework","https://arxiv.org/abs/1502.00206v2","2015","Preprint","","Khalid Alhamazani
Rajiv Ranjan
Prem Prakash Jayaraman
Karan Mitra
Chang Liu
Fethi Rabhi
Dimitrios Georgakopoulos
Lizhe Wang","10.1109/TCC.2015.2441715","https://arxiv.org/pdf/1502.00206v2","Yes","Cloud computing provides on-demand access to affordable hardware (multi-core CPUs, GPUs, disks, and networking equipment) and software (databases, application servers and data processing frameworks) platforms with features such as elasticity, pay-per-use, low upfront investment and low time to market. This has led to the proliferation of business critical applications that leverage various cloud platforms. Such applications hosted on single or multiple cloud provider platforms have diverse characteristics requiring extensive monitoring and benchmarking mechanisms to ensure run-time Quality of Service (QoS) (e.g., latency and throughput). This paper proposes, develops and validates CLAMBS:Cross-Layer Multi-Cloud Application Monitoring and Benchmarking as-a-Service for efficient QoS monitoring and benchmarking of cloud applications hosted on multi-clouds environments. The major highlight of CLAMBS is its capability of monitoring and benchmarking individual application components such as databases and web servers, distributed across cloud layers, spread among multiple cloud providers. We validate CLAMBS using prototype implementation and extensive experimentation and show that CLAMBS efficiently monitors and benchmarks application components on multi-cloud platforms including Amazon EC2 and Microsoft Azure."
"Online QoS Modeling in the Cloud: A Hybrid and Adaptive Multi-Learners Approach","https://arxiv.org/abs/1504.03961v1","2015","Preprint","","Tao Chen
Rami Bahsoon
Xin Yao","10.1109/UCC.2014.42","https://arxiv.org/pdf/1504.03961v1","Yes","Given the on-demand nature of cloud computing, managing cloud-based services requires accurate modeling for the correlation between their Quality of Service (QoS) and cloud configurations/resources. The resulted models need to cope with the dynamic fluctuation of QoS sensitivity and interference. However, existing QoS modeling in the cloud are limited in terms of both accuracy and applicability due to their static and semi- dynamic nature. In this paper, we present a fully dynamic multi- learners approach for automated and online QoS modeling in the cloud. We contribute to a hybrid learners solution, which improves accuracy while keeping model complexity adequate. To determine the inputs of QoS model at runtime, we partition the inputs space into two sub-spaces, each of which applies different symmetric uncertainty based selection techniques, and we then combine the sub-spaces results. The learners are also adaptive; they simultaneously allow several machine learning algorithms to model QoS function and dynamically select the best model for prediction on the fly. We experimentally evaluate our models using RUBiS benchmark and realistic FIFA 98 workload. The results show that our multi-learners approach is more accurate and effective in contrast to the other state-of-the-art approaches."
"A Comparative Study of Load Balancing Algorithms in Cloud Computing Environment","https://arxiv.org/abs/1403.6918v1","2014","Preprint","","Mayanka Katyal
Atul Mishra","","https://arxiv.org/pdf/1403.6918v1","Yes","Cloud Computing is a new trend emerging in IT environment with huge requirements of infrastructure and resources. Load Balancing is an important aspect of cloud computing environment. Efficient load balancing scheme ensures efficient resource utilization by provisioning of resources to cloud users on demand basis in pay as you say manner. Load Balancing may even support prioritizing users by applying appropriate scheduling criteria. This paper presents various load balancing schemes in different cloud environment based on requirements specified in Service Level Agreement (SLA)."
"Artificial Intelligence in Governance, Risk and Compliance: Results of a study on potentials for the application of artificial intelligence (AI) in governance, risk and compliance (GRC)","https://arxiv.org/abs/2212.03601v2","2022","Preprint","","Eva Ponick
Gabriele Wieczorek","","https://arxiv.org/pdf/2212.03601v2","Yes","The digital transformation leads to fundamental change in organizational structures. To be able to apply new technologies not only selectively, processes in companies must be revised and functional units must be viewed holistically, especially with regard to interfaces. Target-oriented management decisions are made, among other things, on the basis of risk management and compliance in combination with the internal control system as governance functions. The effectiveness and efficiency of these functions is decisive to follow guidelines and regulatory requirements as well as for the evaluation of alternative options for acting with regard to activities of companies. GRC (Governance, Risk and Compliance) means an integrated governance-approach, in which the mentioned governance functions are interlinked and not separated from each other. Methods of artificial intelligence represents an important technology of digital transformation. This technology, which offers a broad range of methods such as machine learning, artificial neural networks, natural language processing or deep learning, offers a lot of possible applications in many business areas from purchasing to production or customer service. Artificial intelligence is also being used in GRC, for example for processing and analysis of unstructured data sets. This study contains the results of a survey conducted in 2021 to identify and analyze the potential applications of artificial intelligence in GRC."
"Advanced Drone Swarm Security by Using Blockchain Governance Game","https://arxiv.org/abs/2112.15454v4","2021","Preprint","","Song-Kyoo Kim","10.3390/math10183338","https://arxiv.org/pdf/2112.15454v4","Yes","This research contributes to the security design of an advanced smart drone swarm network based on a variant of the Blockchain Governance Game (BGG), which is the theoretical game model to predict the moments of security actions before attacks, and the Strategic Alliance for Blockchain Governance Game (SABGG), which is one of the BGG variants which has been adapted to construct the best strategies to take preliminary actions based on strategic alliance for protecting smart drones in a blockchain-based swarm network. Smart drones are artificial intelligence (AI)-enabled drones which are capable of being operated autonomously without having any command center. Analytically tractable solutions from the SABGG allow us to estimate the moments of taking preliminary actions by delivering the optimal accountability of drones for preventing attacks. This advanced secured swarm network within AI-enabled drones is designed by adapting the SABGG model. This research helps users to develop a new network-architecture-level security of a smart drone swarm which is based on a decentralized network."
"DLT Compliance Reporting","https://arxiv.org/abs/2206.03270v1","2022","Preprint","","Henrik Axelsen
Johannes Rude Jensen
Omri Ross","","https://arxiv.org/pdf/2206.03270v1","Yes","The IS discourse on the potential of distributed ledger technology (DLT) in the financial services has grown at a tremendous pace in recent years. Yet, little has been said about the related implications for the costly and highly regulated process of compliance reporting. Working with a group of representatives from industry and regulatory authorities, we employ the design science research methodology (DSR) in the design, development, and evaluation of an artefact, enabling the automated collection and enrichment of transactional data. Our findings indicate that DLT may facilitate the automation of key compliance processes through the implementation of a ""pull-model"", in which regulators can access compliance data in near real-time to stage aggregate exposures at the supranational level. Generalizing our preliminary results, we present four propositions on the implications of DLT in compliance. The findings contribute new practical insights on the topic of compliance to the growing IS discourse on DLT."
"Tactics for Internal Compliance: A Literature Review","https://arxiv.org/abs/2008.03775v1","2020","Preprint","","Ralph Foorthuis","","https://arxiv.org/pdf/2008.03775v1","Yes","Compliance of organizations with internal and external norms is a highly relevant topic for both practitioners and academics nowadays. However, the substantive, elementary compliance tactics that organizations can use for achieving internal compliance have been described in a fragmented manner and in the literatures of distinct academic disciplines. Using a multidisciplinary structured literature review of 134 publications, this study offers three contributions. First, we present a typology of 45 compliance tactics, which constitutes a comprehensive and rich overview of elementary ways for bringing the organization into compliance. Secondly, we provide an overview of fundamental concepts in the theory of compliance, which forms the basis for the framework we developed for positioning compliance tactics and for analyzing or developing compliance strategies. Thirdly, we present insights for moving from compliance tactics to compliance strategies. In the process, and using the multidisciplinary literature review to take a bird's-eye view, we demonstrate that compliance strategies need to be regarded as a richer concept than perceived hitherto. We also show that opportunities for innovation exist."
"How Decentralized is the Governance of Blockchain-based Finance: Empirical Evidence from four Governance Token Distributions","https://arxiv.org/abs/2102.10096v2","2021","Preprint","","Johannes Rude Jensen
Victor von Wachter
Omri Ross","","https://arxiv.org/pdf/2102.10096v2","Yes","Novel blockchain technology provides the infrastructure layer for the creation of decentralized appli-cations. A rapidly growing ecosystem of applications is built around financial services, commonly referred to as decentralized finance. Whereas the intangible concept of decentralization is presented as a key driver for the applications, defining and measuring decentralization is multifaceted. This pa-per provides a framework to quantify decentralization of governance power among blockchain appli-cations. Governance of the applications is increasingly important and requires striking a balance be-tween broad distribution, fostering user activity, and financial incentives. Therefore, we aggregate, parse, and analyze empirical data of four finance applications calculating coefficients for the statistical dispersion of the governance token distribution. The gauges potentially support IS scholars for an objective evaluation of the capabilities and limitations of token governance and for fast iteration in design-driven governance mechanisms."
"A multilevel framework for AI governance","https://arxiv.org/abs/2307.03198v2","2023","Preprint","","Hyesun Choung
Prabu David
John S. Seberger","","https://arxiv.org/pdf/2307.03198v2","Yes","To realize the potential benefits and mitigate potential risks of AI, it is necessary to develop a framework of governance that conforms to ethics and fundamental human values. Although several organizations have issued guidelines and ethical frameworks for trustworthy AI, without a mediating governance structure, these ethical principles will not translate into practice. In this paper, we propose a multilevel governance approach that involves three groups of interdependent stakeholders: governments, corporations, and citizens. We examine their interrelationships through dimensions of trust, such as competence, integrity, and benevolence. The levels of governance combined with the dimensions of trust in AI provide practical insights that can be used to further enhance user experiences and inform public policy related to AI."
"Reproducibility: The New Frontier in AI Governance","https://arxiv.org/abs/2510.11595v1","2025","Preprint","","Israel Mason-Williams
Gabryel Mason-Williams","","https://arxiv.org/pdf/2510.11595v1","Yes","AI policymakers are responsible for delivering effective governance mechanisms that can provide safe, aligned and trustworthy AI development. However, the information environment offered to policymakers is characterised by an unnecessarily low Signal-To-Noise Ratio, favouring regulatory capture and creating deep uncertainty and divides on which risks should be prioritised from a governance perspective. We posit that the current publication speeds in AI combined with the lack of strong scientific standards, via weak reproducibility protocols, effectively erodes the power of policymakers to enact meaningful policy and governance protocols. Our paper outlines how AI research could adopt stricter reproducibility guidelines to assist governance endeavours and improve consensus on the AI risk landscape. We evaluate the forthcoming reproducibility crisis within AI research through the lens of crises in other scientific domains; providing a commentary on how adopting preregistration, increased statistical power and negative result publication reproducibility protocols can enable effective AI governance. While we maintain that AI governance must be reactive due to AI's significant societal implications we argue that policymakers and governments must consider reproducibility protocols as a core tool in the governance arsenal and demand higher standards for AI research. Code to replicate data and figures: https://github.com/IFMW01/reproducibility-the-new-frontier-in-ai-governance"
"The Nuclear Analogy in AI Governance Research","https://arxiv.org/abs/2510.21203v1","2025","Preprint","","Sophia Hatz","","https://arxiv.org/pdf/2510.21203v1","Yes","The analogy between Artificial Intelligence (AI) and nuclear weapons is prominent in academic and policy discourse on AI governance. This chapter reviews 43 scholarly works which explicitly draw on the nuclear domain to derive lessons for AI governance. We identify four problem areas where researchers apply nuclear precedents: (1) early development and governance of transformative technologies; (2) international security risks and strategy; (3) international institutions and agreements; and (4) domestic safety regulation. While nuclear-inspired AI proposals are often criticised due to differences across domains, this review clarifies how historical analogies can inform policy development even when technological domains differ substantially. Valuable functions include providing conceptual frameworks for analyzing strategic dynamics, offering cautionary lessons about unsuccessful governance approaches, and expanding policy imagination by legitimizing radical proposals. Given that policymakers already invoke the nuclear analogy, continued critical engagement with these historical precedents remains essential for shaping effective global AI governance."
"Towards an AI Observatory for the Nuclear Sector: A tool for anticipatory governance","https://arxiv.org/abs/2504.12358v1","2025","Preprint","","Aditi Verma
Elizabeth Williams","","https://arxiv.org/pdf/2504.12358v1","Yes","AI models are rapidly becoming embedded in all aspects of nuclear energy research and work but the safety, security, and safeguards consequences of this embedding are not well understood. In this paper, we call for the creation of an anticipatory system of governance for AI in the nuclear sector as well as the creation of a global AI observatory as a means for operationalizing anticipatory governance. The paper explores the contours of the nuclear AI observatory and an anticipatory system of governance by drawing on work in science and technology studies, public policy, and foresight studies."
"Compliance Generation for Privacy Documents under GDPR: A Roadmap for Implementing Automation and Machine Learning","https://arxiv.org/abs/2012.12718v1","2020","Preprint","","David Restrepo Amariles
Aurore Clément Troussel
Rajaa El Hamdani","","https://arxiv.org/pdf/2012.12718v1","Yes","Most prominent research today addresses compliance with data protection laws through consumer-centric and public-regulatory approaches. We shift this perspective with the Privatech project to focus on corporations and law firms as agents of compliance. To comply with data protection laws, data processors must implement accountability measures to assess and document compliance in relation to both privacy documents and privacy practices. In this paper, we survey, on the one hand, current research on GDPR automation, and on the other hand, the operational challenges corporations face to comply with GDPR, and that may benefit from new forms of automation. We attempt to bridge the gap. We provide a roadmap for compliance assessment and generation by identifying compliance issues, breaking them down into tasks that can be addressed through machine learning and automation, and providing notes about related developments in the Privatech project."
"Computable Gap Assessment of Artificial Intelligence Governance in Children's Centres: Evidence-Mechanism-Governance-Indicator Modelling of UNICEF's Guidance on AI and Children 3.0 Based on the Graph-GAP Framework","https://arxiv.org/abs/2601.04216v1","2025","Preprint","","Wei Meng","","https://arxiv.org/pdf/2601.04216v1","Yes","This paper tackles practical challenges in governing child centered artificial intelligence: policy texts state principles and requirements but often lack reproducible evidence anchors, explicit causal pathways, executable governance toolchains, and computable audit metrics. We propose Graph-GAP, a methodology that decomposes requirements from authoritative policy texts into a four layer graph of evidence, mechanism, governance, and indicator, and that computes two metrics, GAP score and mitigation readiness, to identify governance gaps and prioritise actions. Using the UNICEF Innocenti Guidance on AI and Children 3.0 as primary material, we define reproducible extraction units, coding manuals, graph patterns, scoring scales, and consistency checks, and we demonstrate exemplar gap profiles and governance priority matrices for ten requirements. Results suggest that compared with privacy and data protection, requirements related to child well being and development, explainability and accountability, and cross agency implementation and resource allocation are more prone to indicator gaps and mechanism gaps. We recommend translating requirements into auditable closed loop governance that integrates child rights impact assessments, continuous monitoring metrics, and grievance redress procedures. At the coding level, we introduce a multi algorithm review aggregation revision workflow that runs rule based encoders, statistical or machine learning evaluators, and large model evaluators with diverse prompt configurations as parallel coders. Each extraction unit outputs evidence, mechanism, governance, and indicator labels plus readiness scores with evidence anchors. Reliability, stability, and uncertainty are assessed using Krippendorff alpha, weighted kappa, intraclass correlation, and bootstrap confidence intervals."
"The Gender Code: Gendering the Global Governance of Artificial Intelligence","https://arxiv.org/abs/2512.09570v1","2025","Preprint","","Jelena Cupac","","https://arxiv.org/pdf/2512.09570v1","Yes","This paper examines how international AI governance frameworks address gender issues and gender-based harms. The analysis covers binding regulations, such as the EU AI Act; soft law instruments, like the UNESCO Recommendations on AI Ethics; and global initiatives, such as the Global Partnership on AI (GPAI). These instruments reveal emerging trends, including the integration of gender concerns into broader human rights frameworks, a shift toward explicit gender-related provisions, and a growing emphasis on inclusivity and diversity. Yet, some critical gaps persist, including inconsistent treatment of gender across governance documents, limited engagement with intersectionality, and a lack of robust enforcement mechanisms. However, this paper argues that effective AI governance must be intersectional, enforceable, and inclusive. This is key to moving beyond tokenism toward meaningful equity and preventing reinforcement of existing inequalities. The study contributes to ethical AI debates by highlighting the importance of gender-sensitive governance in building a just technological future."
"The Global Majority in International AI Governance","https://arxiv.org/abs/2601.17191v1","2026","Preprint","","Chinasa T. Okolo
Mubarak Raji","","https://arxiv.org/pdf/2601.17191v1","Yes","This chapter examines the global governance of artificial intelligence (AI) through the lens of the Global AI Divide, focusing on disparities in AI development, innovation, and regulation. It highlights systemic inequities in education, digital infrastructure, and access to decision-making processes, perpetuating a dependency and exclusion cycle for Global Majority countries. The analysis also explores the dominance of Western nations and corporations in shaping AI governance frameworks, which often sideline the unique priorities and contexts of the Global Majority. Additionally, this chapter identifies emerging countertrends, such as national and regional AI strategies, as potential avenues for fostering equity and inclusivity in global AI governance. The chapter concludes with actionable recommendations to democratize AI governance for Majority World countries, emphasizing the importance of systemic reforms, resource redistribution, and meaningful participation. It calls for collaborative action to ensure AI governance becomes a catalyst for shared prosperity, addressing global disparities rather than deepening them."
"VAT Compliance Incentives","https://arxiv.org/abs/2002.07862v3","2020","Preprint","","Maria-Augusta Miceli","","https://arxiv.org/pdf/2002.07862v3","Yes","In this work I clarify VAT evasion incentives through a game theoretical approach. Traditionally, evasion has been linked to the decreasing risk aversion in higher revenues (Allingham and Sandmo (1972), Cowell (1985) (1990)). I claim tax evasion to be a rational choice when compliance is stochastically more expensive than evading, even in absence of controls and sanctions. I create a framework able to measure the incentives for taxpayers to comply. The incentives here are deductions of specific VAT documented expenses from the income tax. The issue is very well known and deduction policies at work in many countries. The aim is to compute the right parameters for each precise class of taxpayers. VAT evasion is a collusive conduct between the two counterparts of the transaction. I therefore first explore the convenience for the two private counterparts to agree on the joint evasion and to form a coalition. Crucial is that compliance incentives break the agreement among the transaction participants' coalition about evading. The game solution leads to boundaries for marginal tax rates or deduction percentages, depending on parameters, able to create incentives to comply The stylized example presented here for VAT policies, already in use in many countries, is an attempt to establish a more general method for tax design, able to make compliance the ""dominant strategy"", satisfying the ""outside option"" constraint represented by evasion, even in absence of audit and sanctions. The theoretical results derived here can be easily applied to real data for precise tax design engineering."
"M-PACE: Mother Child Framework for Multimodal Compliance","https://arxiv.org/abs/2509.15241v1","2025","Preprint","","Shreyash Verma
Amit Kesari
Vinayak Trivedi
Anupam Purwar
Ratnesh Jamidar","","https://arxiv.org/pdf/2509.15241v1","Yes","Ensuring that multi-modal content adheres to brand, legal, or platform-specific compliance standards is an increasingly complex challenge across domains. Traditional compliance frameworks typically rely on disjointed, multi-stage pipelines that integrate separate modules for image classification, text extraction, audio transcription, hand-crafted checks, and rule-based merges. This architectural fragmentation increases operational overhead, hampers scalability, and hinders the ability to adapt to dynamic guidelines efficiently. With the emergence of Multimodal Large Language Models (MLLMs), there is growing potential to unify these workflows under a single, general-purpose framework capable of jointly processing visual and textual content. In light of this, we propose Multimodal Parameter Agnostic Compliance Engine (M-PACE), a framework designed for assessing attributes across vision-language inputs in a single pass. As a representative use case, we apply M-PACE to advertisement compliance, demonstrating its ability to evaluate over 15 compliance-related attributes. To support structured evaluation, we introduce a human-annotated benchmark enriched with augmented samples that simulate challenging real-world conditions, including visual obstructions and profanity injection. M-PACE employs a mother-child MLLM setup, demonstrating that a stronger parent MLLM evaluating the outputs of smaller child models can significantly reduce dependence on human reviewers, thereby automating quality control. Our analysis reveals that inference costs reduce by over 31 times, with the most efficient models (Gemini 2.0 Flash as child MLLM selected by mother MLLM) operating at 0.0005 per image, compared to 0.0159 for Gemini 2.5 Pro with comparable accuracy, highlighting the trade-off between cost and output quality achieved in real time by M-PACE in real life deployment over advertising data."
"A five-layer framework for AI governance: integrating regulation, standards, and certification","https://arxiv.org/abs/2509.11332v1","2025","Preprint","","Avinash Agarwal
Manisha J. Nene","10.1108/TG-03-2025-0065","https://arxiv.org/pdf/2509.11332v1","Yes","Purpose: The governance of artificial iintelligence (AI) systems requires a structured approach that connects high-level regulatory principles with practical implementation. Existing frameworks lack clarity on how regulations translate into conformity mechanisms, leading to gaps in compliance and enforcement. This paper addresses this critical gap in AI governance. Methodology/Approach: A five-layer AI governance framework is proposed, spanning from broad regulatory mandates to specific standards, assessment methodologies, and certification processes. By narrowing its scope through progressively focused layers, the framework provides a structured pathway to meet technical, regulatory, and ethical requirements. Its applicability is validated through two case studies on AI fairness and AI incident reporting. Findings: The case studies demonstrate the framework's ability to identify gaps in legal mandates, standardization, and implementation. It adapts to both global and region-specific AI governance needs, mapping regulatory mandates with practical applications to improve compliance and risk management. Practical Implications - By offering a clear and actionable roadmap, this work contributes to global AI governance by equipping policymakers, regulators, and industry stakeholders with a model to enhance compliance and risk management. Social Implications: The framework supports the development of policies that build public trust and promote the ethical use of AI for the benefit of society. Originality/Value: This study proposes a five-layer AI governance framework that bridges high-level regulatory mandates and implementation guidelines. Validated through case studies on AI fairness and incident reporting, it identifies gaps such as missing standardized assessment procedures and reporting mechanisms, providing a structured foundation for targeted governance measures."
"Defining a new perspective: Enterprise Information Governance","https://arxiv.org/abs/2409.14388v1","2024","Preprint","","Alastair McCullough","","https://arxiv.org/pdf/2409.14388v1","Yes","This paper adduces a novel definition of regulatory enterprise information governance as a strategic framework that acts through control mechanisms designed to assure accountability in managing decision rights over information and data assets in organizations. This new pragmatic definition takes the perspectives of both the practitioner and of the scholar. It builds upon earlier definitions to take a novel and more clearly regulatory approach and to synthesize a new definition for such governance; to build out a view of it as a scalable regulatory framework for large or complex organizations that sees governance from this new perspective as a business architecture or target operating model in this increasingly critical domain. The paper supports and enables scholarly consideration and further research. It looks at definitions of information and data; of strategy in relation to information and data; of data management; of enterprise architecture; of governance, and governance as a type of strategic endeavor, and of the nature of strategic and tactical policies and standards that form the basis for such governance."
"Automated Environmental Compliance Monitoring with IoT and Open Government Data","https://arxiv.org/abs/2010.11945v1","2020","Preprint","","Lizaveta Miasayedava
Keegan McBride
Jeffrey Andrew Tuhtan","","https://arxiv.org/pdf/2010.11945v1","Yes","Negative environmental impacts on societies and ecosystems are frequently driven by human activity and amplified by increasing climatic variability. Properly managing these impacts relies on a government's ability to ensure environmental regulatory compliance in the face of increasing uncertainty. Water flow rates are the most widely used evaluation metric for river regulatory compliance. Specifically, compliance thresholds are set by calculating the minimum flow rates required by aquatic species such as fish. These are then designated as the minimum ""environmental flows"" (eflows) for each river. In this paper, we explore how IoT-generated open government data can be used to enhance the development of an automated IoT-based eflows compliance system. To reduce development and operational costs, the proposed solution relies on routinely collected river monitoring data. Our approach allows for any authority with similar data to rapidly develop, test and verify a scalable solution for eflow regulatory compliance monitoring and evaluation. Furthermore, we demonstrate a real-world application of our system using open government data from Estonia's national river monitoring network. The main novelty of this work is that the proposed IoT-based system provides a simple evaluation tool that re-purposes IoT-generated open government data to evaluate compliance and improve monitoring at a national scale. This work showcases a new paradigm of IoT-based solutions using open government data and provides a real-world example of how the solution can automatically evaluate environmental compliance in increasingly uncertain environments."
"Distributed and Decentralised Training: Technical Governance Challenges in a Shifting AI Landscape","https://arxiv.org/abs/2507.07765v1","2025","Preprint","","Jakub Kryś
Yashvardhan Sharma
Janet Egan","","https://arxiv.org/pdf/2507.07765v1","Yes","Advances in low-communication training algorithms are enabling a shift from centralised model training to compute setups that are either distributed across multiple clusters or decentralised via community-driven contributions. This paper distinguishes these two scenarios - distributed and decentralised training - which are little understood and often conflated in policy discourse. We discuss how they could impact technical AI governance through an increased risk of compute structuring, capability proliferation, and the erosion of detectability and shutdownability. While these trends foreshadow a possible new paradigm that could challenge key assumptions of compute governance, we emphasise that certain policy levers, like export controls, remain relevant. We also acknowledge potential benefits of decentralised AI, including privacy-preserving training runs that could unlock access to more data, and mitigating harmful power concentration. Our goal is to support more precise policymaking around compute, capability proliferation, and decentralised AI development."