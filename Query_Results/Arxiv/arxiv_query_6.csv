"Paper Title","Paper Link","Publication Year","Publication Type","Publication Title","Author Names","DOI","PDF Link","Abstract"
"Artificial Intelligence in Governance, Risk and Compliance: Results of a study on potentials for the application of artificial intelligence (AI) in governance, risk and compliance (GRC)","https://scispace.com/paper/http://arxiv.org/abs/2212.03601v2","2022","Preprint","","Eva Ponick
Gabriele Wieczorek","","https://arxiv.org/pdf/2212.03601v2","The digital transformation leads to fundamental change in organizational structures. To be able to apply new technologies not only selectively, processes in companies must be revised and functional units must be viewed holistically, especially with regard to interfaces. Target-oriented management decisions are made, among other things, on the basis of risk management and compliance in combination with the internal control system as governance functions. The effectiveness and efficiency of these functions is decisive to follow guidelines and regulatory requirements as well as for the evaluation of alternative options for acting with regard to activities of companies. GRC (Governance, Risk and Compliance) means an integrated governance-approach, in which the mentioned governance functions are interlinked and not separated from each other. Methods of artificial intelligence represents an important technology of digital transformation. This technology, which offers a broad range of methods such as machine learning, artificial neural networks, natural language processing or deep learning, offers a lot of possible applications in many business areas from purchasing to production or customer service. Artificial intelligence is also being used in GRC, for example for processing and analysis of unstructured data sets. This study contains the results of a survey conducted in 2021 to identify and analyze the potential applications of artificial intelligence in GRC."
"Advanced Drone Swarm Security by Using Blockchain Governance Game","https://scispace.com/paper/http://arxiv.org/abs/2112.15454v4","2021","Preprint","","Song-Kyoo Kim","10.3390/math10183338","https://arxiv.org/pdf/2112.15454v4","This research contributes to the security design of an advanced smart drone swarm network based on a variant of the Blockchain Governance Game (BGG), which is the theoretical game model to predict the moments of security actions before attacks, and the Strategic Alliance for Blockchain Governance Game (SABGG), which is one of the BGG variants which has been adapted to construct the best strategies to take preliminary actions based on strategic alliance for protecting smart drones in a blockchain-based swarm network. Smart drones are artificial intelligence (AI)-enabled drones which are capable of being operated autonomously without having any command center. Analytically tractable solutions from the SABGG allow us to estimate the moments of taking preliminary actions by delivering the optimal accountability of drones for preventing attacks. This advanced secured swarm network within AI-enabled drones is designed by adapting the SABGG model. This research helps users to develop a new network-architecture-level security of a smart drone swarm which is based on a decentralized network."
"DLT Compliance Reporting","https://scispace.com/paper/http://arxiv.org/abs/2206.03270v1","2022","Preprint","","Henrik Axelsen
Johannes Rude Jensen
Omri Ross","","https://arxiv.org/pdf/2206.03270v1","The IS discourse on the potential of distributed ledger technology (DLT) in the financial services has grown at a tremendous pace in recent years. Yet, little has been said about the related implications for the costly and highly regulated process of compliance reporting. Working with a group of representatives from industry and regulatory authorities, we employ the design science research methodology (DSR) in the design, development, and evaluation of an artefact, enabling the automated collection and enrichment of transactional data. Our findings indicate that DLT may facilitate the automation of key compliance processes through the implementation of a ""pull-model"", in which regulators can access compliance data in near real-time to stage aggregate exposures at the supranational level. Generalizing our preliminary results, we present four propositions on the implications of DLT in compliance. The findings contribute new practical insights on the topic of compliance to the growing IS discourse on DLT."
"Tactics for Internal Compliance: A Literature Review","https://scispace.com/paper/http://arxiv.org/abs/2008.03775v1","2020","Preprint","","Ralph Foorthuis","","https://arxiv.org/pdf/2008.03775v1","Compliance of organizations with internal and external norms is a highly relevant topic for both practitioners and academics nowadays. However, the substantive, elementary compliance tactics that organizations can use for achieving internal compliance have been described in a fragmented manner and in the literatures of distinct academic disciplines. Using a multidisciplinary structured literature review of 134 publications, this study offers three contributions. First, we present a typology of 45 compliance tactics, which constitutes a comprehensive and rich overview of elementary ways for bringing the organization into compliance. Secondly, we provide an overview of fundamental concepts in the theory of compliance, which forms the basis for the framework we developed for positioning compliance tactics and for analyzing or developing compliance strategies. Thirdly, we present insights for moving from compliance tactics to compliance strategies. In the process, and using the multidisciplinary literature review to take a bird's-eye view, we demonstrate that compliance strategies need to be regarded as a richer concept than perceived hitherto. We also show that opportunities for innovation exist."
"How Decentralized is the Governance of Blockchain-based Finance: Empirical Evidence from four Governance Token Distributions","https://scispace.com/paper/http://arxiv.org/abs/2102.10096v2","2021","Preprint","","Johannes Rude Jensen
Victor von Wachter
Omri Ross","","https://arxiv.org/pdf/2102.10096v2","Novel blockchain technology provides the infrastructure layer for the creation of decentralized appli-cations. A rapidly growing ecosystem of applications is built around financial services, commonly referred to as decentralized finance. Whereas the intangible concept of decentralization is presented as a key driver for the applications, defining and measuring decentralization is multifaceted. This pa-per provides a framework to quantify decentralization of governance power among blockchain appli-cations. Governance of the applications is increasingly important and requires striking a balance be-tween broad distribution, fostering user activity, and financial incentives. Therefore, we aggregate, parse, and analyze empirical data of four finance applications calculating coefficients for the statistical dispersion of the governance token distribution. The gauges potentially support IS scholars for an objective evaluation of the capabilities and limitations of token governance and for fast iteration in design-driven governance mechanisms."
"A multilevel framework for AI governance","https://scispace.com/paper/http://arxiv.org/abs/2307.03198v2","2023","Preprint","","Hyesun Choung
Prabu David
John S. Seberger","","https://arxiv.org/pdf/2307.03198v2","To realize the potential benefits and mitigate potential risks of AI, it is necessary to develop a framework of governance that conforms to ethics and fundamental human values. Although several organizations have issued guidelines and ethical frameworks for trustworthy AI, without a mediating governance structure, these ethical principles will not translate into practice. In this paper, we propose a multilevel governance approach that involves three groups of interdependent stakeholders: governments, corporations, and citizens. We examine their interrelationships through dimensions of trust, such as competence, integrity, and benevolence. The levels of governance combined with the dimensions of trust in AI provide practical insights that can be used to further enhance user experiences and inform public policy related to AI."
"Reproducibility: The New Frontier in AI Governance","https://scispace.com/paper/http://arxiv.org/abs/2510.11595v1","2025","Preprint","","Israel Mason-Williams
Gabryel Mason-Williams","","https://arxiv.org/pdf/2510.11595v1","AI policymakers are responsible for delivering effective governance mechanisms that can provide safe, aligned and trustworthy AI development. However, the information environment offered to policymakers is characterised by an unnecessarily low Signal-To-Noise Ratio, favouring regulatory capture and creating deep uncertainty and divides on which risks should be prioritised from a governance perspective. We posit that the current publication speeds in AI combined with the lack of strong scientific standards, via weak reproducibility protocols, effectively erodes the power of policymakers to enact meaningful policy and governance protocols. Our paper outlines how AI research could adopt stricter reproducibility guidelines to assist governance endeavours and improve consensus on the AI risk landscape. We evaluate the forthcoming reproducibility crisis within AI research through the lens of crises in other scientific domains; providing a commentary on how adopting preregistration, increased statistical power and negative result publication reproducibility protocols can enable effective AI governance. While we maintain that AI governance must be reactive due to AI's significant societal implications we argue that policymakers and governments must consider reproducibility protocols as a core tool in the governance arsenal and demand higher standards for AI research. Code to replicate data and figures: https://github.com/IFMW01/reproducibility-the-new-frontier-in-ai-governance"
"ARPaCCino: An Agentic-RAG for Policy as Code Compliance","https://scispace.com/paper/http://arxiv.org/abs/2507.10584v2","2025","Preprint","","Francesco Romeo
Luigi Arena
Francesco Blefari
Francesco Aurelio Pironti
Matteo Lupinacci
Angelo Furfaro","10.1007/978-3-032-05727-3_39","https://arxiv.org/pdf/2507.10584v2","Policy as Code (PaC) is a paradigm that encodes security and compliance policies into machine-readable formats, enabling automated enforcement in Infrastructure as Code (IaC) environments. However, its adoption is hindered by the complexity of policy languages and the risk of misconfigurations. In this work, we present ARPaCCino, an agentic system that combines Large Language Models (LLMs), Retrieval-Augmented-Generation (RAG), and tool-based validation to automate the generation and verification of PaC rules. Given natural language descriptions of the desired policies, ARPaCCino generates formal Rego rules, assesses IaC compliance, and iteratively refines the IaC configurations to ensure conformance. Thanks to its modular agentic architecture and integration with external tools and knowledge bases, ARPaCCino supports policy validation across a wide range of technologies, including niche or emerging IaC frameworks. Experimental evaluation involving a Terraform-based case study demonstrates ARPaCCino's effectiveness in generating syntactically and semantically correct policies, identifying non-compliant infrastructures, and applying corrective modifications, even when using smaller, open-weight LLMs. Our results highlight the potential of agentic RAG architectures to enhance the automation, reliability, and accessibility of PaC workflows."
"The Nuclear Analogy in AI Governance Research","https://scispace.com/paper/http://arxiv.org/abs/2510.21203v1","2025","Preprint","","Sophia Hatz","","https://arxiv.org/pdf/2510.21203v1","The analogy between Artificial Intelligence (AI) and nuclear weapons is prominent in academic and policy discourse on AI governance. This chapter reviews 43 scholarly works which explicitly draw on the nuclear domain to derive lessons for AI governance. We identify four problem areas where researchers apply nuclear precedents: (1) early development and governance of transformative technologies; (2) international security risks and strategy; (3) international institutions and agreements; and (4) domestic safety regulation. While nuclear-inspired AI proposals are often criticised due to differences across domains, this review clarifies how historical analogies can inform policy development even when technological domains differ substantially. Valuable functions include providing conceptual frameworks for analyzing strategic dynamics, offering cautionary lessons about unsuccessful governance approaches, and expanding policy imagination by legitimizing radical proposals. Given that policymakers already invoke the nuclear analogy, continued critical engagement with these historical precedents remains essential for shaping effective global AI governance."
"Towards an AI Observatory for the Nuclear Sector: A tool for anticipatory governance","https://scispace.com/paper/http://arxiv.org/abs/2504.12358v1","2025","Preprint","","Aditi Verma
Elizabeth Williams","","https://arxiv.org/pdf/2504.12358v1","AI models are rapidly becoming embedded in all aspects of nuclear energy research and work but the safety, security, and safeguards consequences of this embedding are not well understood. In this paper, we call for the creation of an anticipatory system of governance for AI in the nuclear sector as well as the creation of a global AI observatory as a means for operationalizing anticipatory governance. The paper explores the contours of the nuclear AI observatory and an anticipatory system of governance by drawing on work in science and technology studies, public policy, and foresight studies."
"Compliance Generation for Privacy Documents under GDPR: A Roadmap for Implementing Automation and Machine Learning","https://scispace.com/paper/http://arxiv.org/abs/2012.12718v1","2020","Preprint","","David Restrepo Amariles
Aurore Clément Troussel
Rajaa El Hamdani","","https://arxiv.org/pdf/2012.12718v1","Most prominent research today addresses compliance with data protection laws through consumer-centric and public-regulatory approaches. We shift this perspective with the Privatech project to focus on corporations and law firms as agents of compliance. To comply with data protection laws, data processors must implement accountability measures to assess and document compliance in relation to both privacy documents and privacy practices. In this paper, we survey, on the one hand, current research on GDPR automation, and on the other hand, the operational challenges corporations face to comply with GDPR, and that may benefit from new forms of automation. We attempt to bridge the gap. We provide a roadmap for compliance assessment and generation by identifying compliance issues, breaking them down into tasks that can be addressed through machine learning and automation, and providing notes about related developments in the Privatech project."
"Computable Gap Assessment of Artificial Intelligence Governance in Children's Centres: Evidence-Mechanism-Governance-Indicator Modelling of UNICEF's Guidance on AI and Children 3.0 Based on the Graph-GAP Framework","https://scispace.com/paper/http://arxiv.org/abs/2601.04216v1","2025","Preprint","","Wei Meng","","https://arxiv.org/pdf/2601.04216v1","This paper tackles practical challenges in governing child centered artificial intelligence: policy texts state principles and requirements but often lack reproducible evidence anchors, explicit causal pathways, executable governance toolchains, and computable audit metrics. We propose Graph-GAP, a methodology that decomposes requirements from authoritative policy texts into a four layer graph of evidence, mechanism, governance, and indicator, and that computes two metrics, GAP score and mitigation readiness, to identify governance gaps and prioritise actions. Using the UNICEF Innocenti Guidance on AI and Children 3.0 as primary material, we define reproducible extraction units, coding manuals, graph patterns, scoring scales, and consistency checks, and we demonstrate exemplar gap profiles and governance priority matrices for ten requirements. Results suggest that compared with privacy and data protection, requirements related to child well being and development, explainability and accountability, and cross agency implementation and resource allocation are more prone to indicator gaps and mechanism gaps. We recommend translating requirements into auditable closed loop governance that integrates child rights impact assessments, continuous monitoring metrics, and grievance redress procedures. At the coding level, we introduce a multi algorithm review aggregation revision workflow that runs rule based encoders, statistical or machine learning evaluators, and large model evaluators with diverse prompt configurations as parallel coders. Each extraction unit outputs evidence, mechanism, governance, and indicator labels plus readiness scores with evidence anchors. Reliability, stability, and uncertainty are assessed using Krippendorff alpha, weighted kappa, intraclass correlation, and bootstrap confidence intervals."
"The Gender Code: Gendering the Global Governance of Artificial Intelligence","https://scispace.com/paper/http://arxiv.org/abs/2512.09570v1","2025","Preprint","","Jelena Cupac","","https://arxiv.org/pdf/2512.09570v1","This paper examines how international AI governance frameworks address gender issues and gender-based harms. The analysis covers binding regulations, such as the EU AI Act; soft law instruments, like the UNESCO Recommendations on AI Ethics; and global initiatives, such as the Global Partnership on AI (GPAI). These instruments reveal emerging trends, including the integration of gender concerns into broader human rights frameworks, a shift toward explicit gender-related provisions, and a growing emphasis on inclusivity and diversity. Yet, some critical gaps persist, including inconsistent treatment of gender across governance documents, limited engagement with intersectionality, and a lack of robust enforcement mechanisms. However, this paper argues that effective AI governance must be intersectional, enforceable, and inclusive. This is key to moving beyond tokenism toward meaningful equity and preventing reinforcement of existing inequalities. The study contributes to ethical AI debates by highlighting the importance of gender-sensitive governance in building a just technological future."
"The Global Majority in International AI Governance","https://scispace.com/paper/http://arxiv.org/abs/2601.17191v1","2026","Preprint","","Chinasa T. Okolo
Mubarak Raji","","https://arxiv.org/pdf/2601.17191v1","This chapter examines the global governance of artificial intelligence (AI) through the lens of the Global AI Divide, focusing on disparities in AI development, innovation, and regulation. It highlights systemic inequities in education, digital infrastructure, and access to decision-making processes, perpetuating a dependency and exclusion cycle for Global Majority countries. The analysis also explores the dominance of Western nations and corporations in shaping AI governance frameworks, which often sideline the unique priorities and contexts of the Global Majority. Additionally, this chapter identifies emerging countertrends, such as national and regional AI strategies, as potential avenues for fostering equity and inclusivity in global AI governance. The chapter concludes with actionable recommendations to democratize AI governance for Majority World countries, emphasizing the importance of systemic reforms, resource redistribution, and meaningful participation. It calls for collaborative action to ensure AI governance becomes a catalyst for shared prosperity, addressing global disparities rather than deepening them."
"VAT Compliance Incentives","https://scispace.com/paper/http://arxiv.org/abs/2002.07862v3","2020","Preprint","","Maria-Augusta Miceli","","https://arxiv.org/pdf/2002.07862v3","In this work I clarify VAT evasion incentives through a game theoretical approach. Traditionally, evasion has been linked to the decreasing risk aversion in higher revenues (Allingham and Sandmo (1972), Cowell (1985) (1990)). I claim tax evasion to be a rational choice when compliance is stochastically more expensive than evading, even in absence of controls and sanctions. I create a framework able to measure the incentives for taxpayers to comply. The incentives here are deductions of specific VAT documented expenses from the income tax. The issue is very well known and deduction policies at work in many countries. The aim is to compute the right parameters for each precise class of taxpayers. VAT evasion is a collusive conduct between the two counterparts of the transaction. I therefore first explore the convenience for the two private counterparts to agree on the joint evasion and to form a coalition. Crucial is that compliance incentives break the agreement among the transaction participants' coalition about evading. The game solution leads to boundaries for marginal tax rates or deduction percentages, depending on parameters, able to create incentives to comply The stylized example presented here for VAT policies, already in use in many countries, is an attempt to establish a more general method for tax design, able to make compliance the ""dominant strategy"", satisfying the ""outside option"" constraint represented by evasion, even in absence of audit and sanctions. The theoretical results derived here can be easily applied to real data for precise tax design engineering."
"M-PACE: Mother Child Framework for Multimodal Compliance","https://scispace.com/paper/http://arxiv.org/abs/2509.15241v1","2025","Preprint","","Shreyash Verma
Amit Kesari
Vinayak Trivedi
Anupam Purwar
Ratnesh Jamidar","","https://arxiv.org/pdf/2509.15241v1","Ensuring that multi-modal content adheres to brand, legal, or platform-specific compliance standards is an increasingly complex challenge across domains. Traditional compliance frameworks typically rely on disjointed, multi-stage pipelines that integrate separate modules for image classification, text extraction, audio transcription, hand-crafted checks, and rule-based merges. This architectural fragmentation increases operational overhead, hampers scalability, and hinders the ability to adapt to dynamic guidelines efficiently. With the emergence of Multimodal Large Language Models (MLLMs), there is growing potential to unify these workflows under a single, general-purpose framework capable of jointly processing visual and textual content. In light of this, we propose Multimodal Parameter Agnostic Compliance Engine (M-PACE), a framework designed for assessing attributes across vision-language inputs in a single pass. As a representative use case, we apply M-PACE to advertisement compliance, demonstrating its ability to evaluate over 15 compliance-related attributes. To support structured evaluation, we introduce a human-annotated benchmark enriched with augmented samples that simulate challenging real-world conditions, including visual obstructions and profanity injection. M-PACE employs a mother-child MLLM setup, demonstrating that a stronger parent MLLM evaluating the outputs of smaller child models can significantly reduce dependence on human reviewers, thereby automating quality control. Our analysis reveals that inference costs reduce by over 31 times, with the most efficient models (Gemini 2.0 Flash as child MLLM selected by mother MLLM) operating at 0.0005 per image, compared to 0.0159 for Gemini 2.5 Pro with comparable accuracy, highlighting the trade-off between cost and output quality achieved in real time by M-PACE in real life deployment over advertising data."
"A five-layer framework for AI governance: integrating regulation, standards, and certification","https://scispace.com/paper/http://arxiv.org/abs/2509.11332v1","2025","Preprint","","Avinash Agarwal
Manisha J. Nene","10.1108/TG-03-2025-0065","https://arxiv.org/pdf/2509.11332v1","Purpose: The governance of artificial iintelligence (AI) systems requires a structured approach that connects high-level regulatory principles with practical implementation. Existing frameworks lack clarity on how regulations translate into conformity mechanisms, leading to gaps in compliance and enforcement. This paper addresses this critical gap in AI governance.
  Methodology/Approach: A five-layer AI governance framework is proposed, spanning from broad regulatory mandates to specific standards, assessment methodologies, and certification processes. By narrowing its scope through progressively focused layers, the framework provides a structured pathway to meet technical, regulatory, and ethical requirements. Its applicability is validated through two case studies on AI fairness and AI incident reporting.
  Findings: The case studies demonstrate the framework's ability to identify gaps in legal mandates, standardization, and implementation. It adapts to both global and region-specific AI governance needs, mapping regulatory mandates with practical applications to improve compliance and risk management.
  Practical Implications - By offering a clear and actionable roadmap, this work contributes to global AI governance by equipping policymakers, regulators, and industry stakeholders with a model to enhance compliance and risk management.
  Social Implications: The framework supports the development of policies that build public trust and promote the ethical use of AI for the benefit of society.
  Originality/Value: This study proposes a five-layer AI governance framework that bridges high-level regulatory mandates and implementation guidelines. Validated through case studies on AI fairness and incident reporting, it identifies gaps such as missing standardized assessment procedures and reporting mechanisms, providing a structured foundation for targeted governance measures."
"Defining a new perspective: Enterprise Information Governance","https://scispace.com/paper/http://arxiv.org/abs/2409.14388v1","2024","Preprint","","Alastair McCullough","","https://arxiv.org/pdf/2409.14388v1","This paper adduces a novel definition of regulatory enterprise information governance as a strategic framework that acts through control mechanisms designed to assure accountability in managing decision rights over information and data assets in organizations. This new pragmatic definition takes the perspectives of both the practitioner and of the scholar. It builds upon earlier definitions to take a novel and more clearly regulatory approach and to synthesize a new definition for such governance; to build out a view of it as a scalable regulatory framework for large or complex organizations that sees governance from this new perspective as a business architecture or target operating model in this increasingly critical domain. The paper supports and enables scholarly consideration and further research. It looks at definitions of information and data; of strategy in relation to information and data; of data management; of enterprise architecture; of governance, and governance as a type of strategic endeavor, and of the nature of strategic and tactical policies and standards that form the basis for such governance."
"Automated Environmental Compliance Monitoring with IoT and Open Government Data","https://scispace.com/paper/http://arxiv.org/abs/2010.11945v1","2020","Preprint","","Lizaveta Miasayedava
Keegan McBride
Jeffrey Andrew Tuhtan","","https://arxiv.org/pdf/2010.11945v1","Negative environmental impacts on societies and ecosystems are frequently driven by human activity and amplified by increasing climatic variability. Properly managing these impacts relies on a government's ability to ensure environmental regulatory compliance in the face of increasing uncertainty. Water flow rates are the most widely used evaluation metric for river regulatory compliance. Specifically, compliance thresholds are set by calculating the minimum flow rates required by aquatic species such as fish. These are then designated as the minimum ""environmental flows"" (eflows) for each river. In this paper, we explore how IoT-generated open government data can be used to enhance the development of an automated IoT-based eflows compliance system. To reduce development and operational costs, the proposed solution relies on routinely collected river monitoring data. Our approach allows for any authority with similar data to rapidly develop, test and verify a scalable solution for eflow regulatory compliance monitoring and evaluation. Furthermore, we demonstrate a real-world application of our system using open government data from Estonia's national river monitoring network. The main novelty of this work is that the proposed IoT-based system provides a simple evaluation tool that re-purposes IoT-generated open government data to evaluate compliance and improve monitoring at a national scale. This work showcases a new paradigm of IoT-based solutions using open government data and provides a real-world example of how the solution can automatically evaluate environmental compliance in increasingly uncertain environments."
"Distributed and Decentralised Training: Technical Governance Challenges in a Shifting AI Landscape","https://scispace.com/paper/http://arxiv.org/abs/2507.07765v1","2025","Preprint","","Jakub Kryś
Yashvardhan Sharma
Janet Egan","","https://arxiv.org/pdf/2507.07765v1","Advances in low-communication training algorithms are enabling a shift from centralised model training to compute setups that are either distributed across multiple clusters or decentralised via community-driven contributions. This paper distinguishes these two scenarios - distributed and decentralised training - which are little understood and often conflated in policy discourse. We discuss how they could impact technical AI governance through an increased risk of compute structuring, capability proliferation, and the erosion of detectability and shutdownability. While these trends foreshadow a possible new paradigm that could challenge key assumptions of compute governance, we emphasise that certain policy levers, like export controls, remain relevant. We also acknowledge potential benefits of decentralised AI, including privacy-preserving training runs that could unlock access to more data, and mitigating harmful power concentration. Our goal is to support more precise policymaking around compute, capability proliferation, and decentralised AI development."